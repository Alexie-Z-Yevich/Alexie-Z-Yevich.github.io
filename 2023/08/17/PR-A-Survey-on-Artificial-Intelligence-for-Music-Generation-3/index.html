<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0"><title>音乐生成的人工智能综述：智能体、领域和前景(part.3) | New Try &amp;&amp; New Life</title><meta name="author" content="Alexie-Z-Yevich"><meta name="copyright" content="Alexie-Z-Yevich"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="7、人机交互正如我们在引言中所提到的，人机交互技术的重要性是整个人工智能音乐创作的关键概念之一。随着世界各地的活动和竞赛，如人工智能歌曲大赛，将与人工智能共同创作音乐的团队聚集在一起，共同创作变得越来越重要。在本节中，我们将深入研究在音乐生成领域和用户中提出的用户界面。在本节中，我们总结了图中所示的合成工作流的代理。让位于下一节中的评估。 HC 交互中最重要的元素之一是用户界面。随着深度生成模型的">
<meta property="og:type" content="article">
<meta property="og:title" content="音乐生成的人工智能综述：智能体、领域和前景(part.3)">
<meta property="og:url" content="https://www.fenrisx.icu/2023/08/17/PR-A-Survey-on-Artificial-Intelligence-for-Music-Generation-3/index.html">
<meta property="og:site_name" content="New Try &amp;&amp; New Life">
<meta property="og:description" content="7、人机交互正如我们在引言中所提到的，人机交互技术的重要性是整个人工智能音乐创作的关键概念之一。随着世界各地的活动和竞赛，如人工智能歌曲大赛，将与人工智能共同创作音乐的团队聚集在一起，共同创作变得越来越重要。在本节中，我们将深入研究在音乐生成领域和用户中提出的用户界面。在本节中，我们总结了图中所示的合成工作流的代理。让位于下一节中的评估。 HC 交互中最重要的元素之一是用户界面。随着深度生成模型的">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://www.fenrisx.icu/images/head.jpg">
<meta property="article:published_time" content="2023-08-17T03:30:19.000Z">
<meta property="article:modified_time" content="2023-08-27T04:00:01.111Z">
<meta property="article:author" content="Alexie-Z-Yevich">
<meta property="article:tag" content="人工智能">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="音乐生成">
<meta property="article:tag" content="音乐信息检索">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="人机交互">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://www.fenrisx.icu/images/head.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://www.fenrisx.icu/2023/08/17/PR-A-Survey-on-Artificial-Intelligence-for-Music-Generation-3/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: Alexie-Z-Yevich","link":"链接: ","source":"来源: New Try && New Life","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '音乐生成的人工智能综述：智能体、领域和前景(part.3)',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-08-27 12:00:01'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.2"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/images/head.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">35</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">52</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">13</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/attacks/"><i class="fa-fw fas fa-images"></i><span> 哒咩</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="New Try &amp;&amp; New Life"><span class="site-name">New Try &amp;&amp; New Life</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/attacks/"><i class="fa-fw fas fa-images"></i><span> 哒咩</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">音乐生成的人工智能综述：智能体、领域和前景(part.3)</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-08-17T03:30:19.000Z" title="发表于 2023-08-17 11:30:19">2023-08-17</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-08-27T04:00:01.111Z" title="更新于 2023-08-27 12:00:01">2023-08-27</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Paper-Reading/">Paper Reading</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Paper-Reading/A-Survey-on-Artificial-Intelligence-for-Music-Generation/">A Survey on Artificial Intelligence for Music Generation</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="音乐生成的人工智能综述：智能体、领域和前景(part.3)"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h4 id="7、人机交互"><a href="#7、人机交互" class="headerlink" title="7、人机交互"></a>7、人机交互</h4><p>正如我们在引言中所提到的，人机交互技术的重要性是整个人工智能音乐创作的关键概念之一。随着世界各地的活动和竞赛，如人工智能歌曲大赛，将与人工智能共同创作音乐的团队聚集在一起，共同创作变得越来越重要。在本节中，我们将深入研究在音乐生成领域和用户中提出的用户界面。在本节中，我们总结了图中所示的合成工作流的代理。让位于下一节中的评估。</p>
<p>HC 交互中最重要的元素之一是用户界面。随着深度生成模型的最新进展及其在计算机视觉领域的新功能，对现代用户界面的研究正在增加，这推动了人工智能音乐生成新界面的诞生。设计良好的界面不仅给用户带来更好的体验，还允许用户与模型进行不同级别的交互，尤其是在基于 AI 的艺术模型中。在这一部分中，模型通常是一个黑框，用于响应界面中的用户提示。因此，在合成工作流的这一部分中有两个重要的代理：用户和界面。</p>
<h6 id="A-界面"><a href="#A-界面" class="headerlink" title="A.界面"></a>A.界面</h6><p>界面是用户通常体验到的第一个也是唯一一个部分。具有复杂或基本的界面是取决于要构建的工具或产品的设计决策。完美的界面并不存在，但之前对目标用户的分析以及构建某个产品所用技术的知识可以帮助设计一个好的界面。</p>
<p>Bougueng 和 Ens（2019）的 Apollo 旨在通过创建、编辑和操纵音乐语料库来组织音乐数据。用户可以修改他们上传的音乐文件，并使用控制音符密度、小节数或音高类别的参数生成音乐。</p>
<p>COSMIC（2021）提出了一种用于人类人工智能音乐与聊天的交互界面，该界面使用 NLP 核心将人类输入处理为文本，并与人类交互以定义或细化输出音乐。该过程从创建元数据的开始状态开始，与人的文本输入相匹配的旋律生成，与允许在给定条件下细化旋律的 HCI 的旋律修订，也通过与人交互的歌词生成和修订，以及会话关闭时的结束状态。需要传递到自然语言理解第一模块的音乐属性是：音符密度、音高变化、节奏变化、歌词类型和歌词关键词。这些参数被转换为关键字，并传递给下一个模块对话状态跟踪器（DST）。这是一个类似聊天的界面示例，其中用户的输入是文本。</p>
<p>Louie 等人（2022）提出了两个接口，旨在测量用户与两种音乐生成模型的交互：收音机和转向接口。尽管无线电界面依赖于用户用来生成音乐的简单按钮，但操纵界面提供了不同级别的控制，如音高、键等，它还允许用户通过选择由先前序列制作的序列来创作作品。Louie 等人通过以下指标来衡量用户体验：表达、沟通、音乐连贯性、所有权、控制和功效。在所有这些指标中，指导界面获得了更好的结果，但用户在音乐创作方面的经验或知识水平没有得到深入研究，这就留下了一个悬而未决的问题，即专业作曲家是否更喜欢更完整的界面，而更简单的界面是否适合业余音乐家，如果接口与目标用户具有直接关系。</p>
<p>郭等人的 MusIAC（2022）定义了一个具有基于音乐结构的音轨级或小节级控件的控制界面。这些级别允许定义与和声或节奏相关的控制，例如张力。这些基于音乐原理的控件适用于具有一定音乐基础的用户。</p>
<p>SonyCSL 的其他项目，如用 Javascript 开发的 NONOTO 和 PI-ANOTO，提出了修复符号音乐的接口。而 PIANOTO 是基于一个类似钢琴的界面，用户可以通过在界面中选择区域进行修复并创建符号音乐，NONOTO 面向声音创作和符号生成，并使用 DeepBach 进行修复。</p>
<p>Magenta 团队还为 Ableton 开发了插件，这些插件在后端使用了该团队开发的模型。</p>
<p>我们看到了不同的用户界面，可以与基于人工智能的音乐生成模型交互，在某些情况下可以控制音乐主体，在其他情况下可以进行其他“探索性”控制。我们还看到了接口所具有的控件数量的差异。近年来，将会有更多的界面被提出，考虑到文本提示和语音在图像生成应用程序中的成功，可以合理地假设，其中一些类似提示的界面也将用于音乐生成，特别是对于那些可能只喜欢通过键入句子来生成音乐的初学者用户。这方面的一个例子是给出提示的音乐生成：“生成基于肖邦 C 大调夜曲的一分钟音乐，悲伤的音乐”。在音频生成领域，有一种最新的模型，AudioGen，能够在给定文本的情况下生成音频。尽管该模型不生成音乐，但它可以在音乐样本上进行训练，以实现文本引导的音乐生成。</p>
<p>现在，我们将深入探讨在没有提供接口的情况下，用户对模型的看法和评估。未来的研究主题将依赖于测量界面和用户水平，以根据用户在使用这些技术时的音乐知识或目标来构建更个性化的界面。</p>
<h6 id="B-用户"><a href="#B-用户" class="headerlink" title="B.用户"></a>B.用户</h6><p>最终用户是合成工作流程中的最后一个智能体，但在我们看来，它是最重要的一个。计算机视觉领域多年来一直在将知识从学术界转移到工业界。最终用户的反馈不仅是行业层面的关键部分，也是学术界的关键部分。有一些研究用户如何与音乐生成系统交互的工作，因为该领域的工作一直致力于模型，并且由于音乐生成领域与计算机视觉相比是新的，因此缺乏来自用户的反馈，无法帮助该领域朝着特定方向发展。</p>
<p>MuseGAN 使用主观测量来评估模型，主观测量取决于用户的音乐知识。这一点很重要，因为音乐是主观的，用户在与音乐生成的生成模型交互时的体验可能会有偏差。一个好的方法是将用户分为初级、中级和专业级别。这些级别是指没有音乐知识的用户（初学者）、学习过音乐的用户（中级）以及能够深入识别和分析音乐的专业音乐家或作曲家（专业）。我们认为，考虑到最终用户，该领域可以提出不同的模型，在界面上或多或少具有可控性，以更好地接近他们。</p>
<h4 id="8、评估"><a href="#8、评估" class="headerlink" title="8、评估"></a>8、评估</h4><p>在 MIR 中，评估音乐生成是一个悬而未决的问题，因为这些系统中有一个难以衡量的创造性组成部分。此外，由于音乐是主观的，因此很难评估或量化音乐作品的质量。研究人员已经提出了评估和比较模型性能的指标，但仍然缺乏一种用于符号音乐和音频音乐生成的通用评估方法。这些指标中的一些在不同的领域是常见的，如计算机视觉或自然语言处理领域，如混淆（perplexity）或 F-score，其他指标是特定于研究领域的。在音乐生成领域，在我们进行评估之前，我们需要从生成的音乐中提取一些特征，这并不总是一个容易的问题。近年来，人们提出了各种各样的措施，分为客观措施和主观措施。同样重要的是要强调，在符号领域，我们可以更好地测量作品的音乐方面，而在音频领域，我们可能希望测量生成信号的质量。</p>
<h6 id="A-主观评价"><a href="#A-主观评价" class="headerlink" title="A.主观评价"></a>A.主观评价</h6><p>主观评价与用户对模型的体验有关。这种评估是由用户完成的。它的弱点在于，每个模型都由不同的人进行评估，因此结果不可重复。此外，用户的知识、文化和疲惫（个人认为这里是不感兴趣）可能会改变评估结果。Ji 等人揭露了音乐质量的定量评估与人类判断之间缺乏相关性，这使得这种评估是必要的，因为最终用户是互动和生成音乐的人，他们的意见非常有价值。</p>
<p>有两种常用的方法来客观评价音乐：听力测试和图灵测试。人工智能领域提出的每个模型在进行听力测试时都使用自己的调查和方法，但最近有一些工作提出了调查模板。按照用户级别划分的听力测试的一个例子是 MuseGAN 评估中使用的测试，该评估由 144 名用户完成。更多的用户参与了 DeepBach 的评估，其中 1.272 进行了听力测试，也根据他们的音乐知识进行了分组。通常情况下，听力测试包括评分从 1 到 5 的问题，这些问题符合音乐原则。在 MuseGAN 评价的案例中，提出了衡量和声柔顺性、节奏、结构、连贯性和整体评分的问题。我们可以让用户收听生成的样本，也可以为更深入的分析提供分数。</p>
<p>主观评估也可以被视为基于人工智能的模型的调试工具。一个例子是 MusicVAE 的监听测试，该测试使用 Kruskal-Wallis H-test 来验证模型的质量，得出的结论是，该模型在使用分层解码器时表现更好。这使研究人员能够验证哪种提出的体系结构产生了更好的音乐，尽管我们应该始终关注到客观的衡量标准。</p>
<p>我们不仅可以要求用户对作品进行评分，或要求他们区分人类或人工智能作品，还可以提出与模型的创造性或生成作品的自然度有关的非定量问题，而这在客观评估中是不可能的。关于音乐生成评估的新研究通过要求参与者在 7-point Likert 量表中测量以下标准来比较音乐生成的 DL 模型：<strong>生成作品的整体性、旋律性、丰富性、韵律性、正确性、结构性和连贯性</strong>。Chu 等人证明了人类希望在基于人工智能的音乐生成系统中有更多的可控性，并声称旋律性是主观衡量这些系统的最有效标准。他们将这些标准定义为：</p>
<ul>
<li>整体。对音乐的整体满意度。</li>
<li>创造力。要求音乐是新颖的、有价值的和原创的。</li>
<li>自然。音乐听起来像是富有表现力的人类表演。</li>
<li>优美。和谐的乐曲。</li>
<li>丰富性。音乐是多样化和有趣的。</li>
<li>节奏性。节奏是否统一。</li>
<li>正确性。音乐是否存在突然停顿等技术故障。</li>
<li>相关性。条件音乐是否与参考音乐相似。</li>
</ul>
<p>在进行主观研究时，考虑我们所处的领域是很重要的，因为符号音乐需要合成，合成过程可能会影响用户对音乐的感知。</p>
<h6 id="B-客观评价"><a href="#B-客观评价" class="headerlink" title="B.客观评价"></a>B.客观评价</h6><p>与音频或符号音乐生成的主观评价相似相比，由于这两个领域的性质，客观评价呈现出更多的差异。在深入研究评估音乐生成系统的具体方法之前，我们将介绍我们可以从符号音乐中提取的特征向量，以及文献中提出的一些一般措施。</p>
<p>a） 符号音乐：我们可以从符号音乐中提取的特征向量可以分为音乐原理：音高相关、节奏相关和和声相关。</p>
<ul>
<li>音高矢量是允许测量特定乐器或乐曲组成的八度音阶的音高范围，以及测量连续音高之间音高距离（通常为半音）的音程（我们应该同时考虑单声道和多声道音乐）。我们还可以计算基音类直方图（PCH）和基音类转移矩阵（PCTM）。音高等级（PC）是指转换为某个八度音阶的音高。这意味着，如果我们有 C4 和 C5，两者的 PC 将是相同的，因为它们都对应于音符 C。因此，我们将有 12 个音高类，对应于从 C 到 B 的半音音阶中的 12 个音符。</li>
<li>节奏向量是起始间隔（IOI），它是连续音高的起始之间的差异，音符密度是音乐序列、与音符持续时间相对应的持续时间范围以及测量音乐序列中有多少步静音的占用率。我们还可以计算音符长度直方图（NLH）和音符长度转移矩阵（NLTM）。</li>
<li>和声向量是复调率，复调率是我们找到复调的细分数量，或者是音乐序列中复调音符的最大数量。</li>
</ul>
<p>这些矢量或描述符不仅可以测量音乐，还可以理解音乐，因为大多数乐器只能以特定的八度音阶演奏，并且具有人工智能模型应该建模的特定节奏特征。</p>
<p>我们必须考虑到这样一个事实，即这些特征适用于我们可以在乐曲级别（整个文件或带有所有乐器的乐曲）、音轨级别（只有一种乐器）和小节级别（包含所有乐器的小节或某一乐器的小节）进行解释的音乐序列。我们在评估中选择的水平将取决于我们的目标。</p>
<p>一旦我们计算了这些向量，我们就可以建立评估度量，并将其与训练数据进行比较。这些度量也在音乐原理中进行了划分，如表 V 所示。特征向量，这些度量可以为每个级别计算：乐曲、曲目或小节级别。</p>
<p>【表 V ：象征性音乐评价的常用方法】</p>
<p><img src="/2023/08/17/PR-A-Survey-on-Artificial-Intelligence-for-Music-Generation-3/PR-A-Survey-on-Artificial-Intelligence-for-Music-Generation-1/t5.png"></p>
<p>随着符号音乐谐波提取的更多进展，如 Cheng 和 Su 提出的 HT 模型，我们可以测量生成音乐的和弦和键以及训练集中的样本，并提出新的度量标准对现有的进行补充和扩展。这显然是通过查看度量来了解提取的可信度，从而了解我们可以从中获得的度量。</p>
<p>Yang 和 Lerch（2020）提出了一种评价符号音乐的一般客观方法。首先，提取一些音高和节奏特征。然后，我们根据这些特征构建直方图，我们可以将其近似为概率密度函数（PDF）。根据这些函数，我们可以测量 Kullback-Leibler 散度（KLD）和重叠平面积，以确定 PDF 的相似程度。PDF 是从片段和条级别构建的，通过交叉验证同一数据集的样本（集内）或将训练数据集与生成的数据集（集间）进行比较。</p>
<h4 id="9、-进一步的观点和研究"><a href="#9、-进一步的观点和研究" class="headerlink" title="9、 进一步的观点和研究"></a>9、 进一步的观点和研究</h4><h6 id="A-量子音乐时代"><a href="#A-量子音乐时代" class="headerlink" title="A.量子音乐时代"></a>A.量子音乐时代</h6><p>Eduardo Miranda 在 2021 年和 2022 年介绍了艺术与人文领域的量子计算。尽管量子机器学习是一个用于一般应用的新研究领域，但有一些研究正在定义量子音乐技术的第一步。这一新的 MIR 研究领域旨在开发创建、表演、聆听和分发音乐量子计算工具的工具。</p>
<h6 id="B-情感与主体性"><a href="#B-情感与主体性" class="headerlink" title="B.情感与主体性"></a>B.情感与主体性</h6><p>音乐中的情感已被广泛研究。从旨在检测音频信号中情绪的模型到最近旨在生成具有特定情绪的音乐的作品。音乐情感识别有专门的数据集，可以用来训练模型来自动标记或条件生成模型。尽管如此，情绪是主观的，它们取决于用户的文化、背景或音乐知识。Bao 和 Sun 提出了一个带有情感的音乐生成模型。该模型使用基于 BERT 的模型来识别情绪（在 GoEmotions 数据集上预先训练的模型），并有三个模块：用于生成歌词和旋律的编码器-解码器架构、音乐情绪分类器和使作品适应情绪调节的波束搜索算法。</p>
<h6 id="C-生成音乐的版权"><a href="#C-生成音乐的版权" class="headerlink" title="C.生成音乐的版权"></a>C.生成音乐的版权</h6><p>关于使用基于人工智能的模型获得的音乐版权的法律声明仍在进行中，这是一个令人担忧的案例。近年来，随着对使用基于人工智能工具的公司的注资，以及区块链等新技术的出现，不仅需要定义法律声明，还需要定义道德声明来控制基于人工智能的音乐产品。有几个问题需要解决，但最相关的问题之一是：版权属于谁？在使用人工智能创建音乐的过程中，有不同的智能体参与，例如创建用于训练模型的数据库的人、构建和训练模型的团队或创建音乐的用户等。尽管有人同意在版权法中应考虑该工具或程序员，但也有人声称，使用该工具的人应有权获得作者身份，因为艺术品的实例化是归属作者身份的充分条件。然而，如果音乐创作过程中没有人参与，根据 1988 年《设计和专利法》（英国）（CDPA），作者应该是为作品创作做出必要安排的人。Deltorn 和 Macrez 认为，从司法角度来看，有两种方法：现行法和拟议法。第一种是否定对计算机生成的作品的保护，并逐案分析以确定人类的贡献。第二个问题依赖于修改现有版权制度的必要性，因为软件和数据库（创作过程中的非人类智能体）已经可以受到专利保护。</p>
<h6 id="D-应用"><a href="#D-应用" class="headerlink" title="D.应用"></a>D.应用</h6><p>尽管当今音乐生成领域的趋势是在音频应用中，但音乐生成在 MIR 社区内外都越来越受到关注。不仅正在开发音乐生成界面来探索和增强 HCI，而且还出现了允许用户生成和拥有自己作品的商业应用程序。音乐生成技术还有更多的应用，我们在本文中没有涉及，尽管我们在下面展示了其中的一些：</p>
<ul>
<li>音乐教育。随着即将到来的技术和钢琴指法等任务的最新研究，学术界或工业界可以开发工具来生成带有注释的音乐，供钢琴家演奏音乐短语或片段。如果基于人工智能的模型能够很好地控制和声、节奏、风格或时期等，这些技术也可以用作人类的作文学习系统。</li>
<li>内容生成。内容创作者将受益于这些为他们的项目生成新音乐的工具。然而，这需要对此类创作的版权进行强有力的法律分析。尽管这更多的是一个行业应用，但它与研究人员如何开发模型密切相关，人类可以根据自己的兴趣、目标或音乐知识与之互动。</li>
<li>音乐制作。新的基于深度学习的音乐制作技术可以受益于音乐生成模型，用于创建给定循环的新层或延续。</li>
<li>原声音乐。为视频或电影生成音乐。这将比内容生成更进一步，因为模型需要复杂而长期的关系和分析。模型应该学习（或接受）的一些东西是对人物、场景、情绪等的分析，我们希望通过创造主旋律来唤起音乐。这并不容易，因为除了主观的情感分析之外，网络还应该识别角色并记住与每个角色相关的主题。</li>
</ul>
<h4 id="10、讨论"><a href="#10、讨论" class="headerlink" title="10、讨论"></a>10、讨论</h4><p>我们在第二节中看到了音乐如何从技术角度被解释为一种语言，我们涵盖了人类和人工智能创作过程之间的关系。尽管人类和人工智能的音乐创作方式是相似的，因为它们都是逐音符或逐和弦创作的，但人类大脑和人工智能方法对音乐的理解和感知远没有可比性。人工智能系统是为了模拟人类过程而设计的，我们可以将大脑中理解语言的部分与 LLM 联系起来，正如我们在第二节中看到的那样，但它们既不能像人脑那样工作，也不能像人脑一样理解世界。除此之外，人类在之前的知识基础上增加了一个创造性的组成部分，这一点仍有待于基于人工智能的模型来证明。人工智能的这种创造力将伴随着可以外推而不是插值的模型而来。对我们来说，基于人工智能的模型应该被建模，以理解我们在第三章中引入的音乐原理。这将允许对音乐生成系统进行调节，并更好地对长期时间-频率依赖性进行建模。从我们在第四节中描述的领域知识边缘的角度来看，我们看到了在符号领域是如何做了很多工作的。然而，由于对语音技术的研究，新的研究似乎更多地集中在音频领域。关注我们在第五节中描述的用于训练模型的数据，还需要创建更多具有高质量注释的数据集，例如情绪、高级结构、和声或任何其他音乐原理，这些注释可以用于改进当前数据集。测量数据集的偏差也很重要，因为大多数研究都集中在模型上。第六节中描述的模型架构一直是该领域研究的重点，尽管我们需要新的模型，但未来的研究可以集中在开发可以以音乐原理为条件的模型上。目前正在使用的大型 DL 模型的替代方案是将符号 AI 与这些模型相结合，因为音乐理论包含可以预定义的定义，因此模型不需要学习，而是将它们结合起来。如果不是因为我们在第七节中暴露的用户和机器之间的交互，调节就不会是音乐创作过程的关键部分。如果我们将其与专门用于模型设计的努力进行比较，则该领域缺乏对 HCI 的研究，因为到目前为止，人工智能在音乐生成方面还没有很有希望的结果。未来对接口的长期研究可能是使用脑机接口来创造艺术。在音乐生成的生成模型的评估方面也很少有研究，音乐生成是作曲工作流程中非常重要的一部分。当涉及到“调试”生成的音乐序列时，音乐的质量是一个错误的术语。我们在本文中描述的每个智能体中都可能存在偏差，这对我们在训练模型之前和之后进行分析很重要。我们在第八节中介绍了主观和客观分析生成音乐的常见指标和方法，在这方面取得了重要进展，但仍然没有一种可推广的方法来在每个代理级别和更普遍的角度评估这些系统。</p>
<p>总之，音乐生成领域正在发展，正如我们在第九节中介绍的那样，仍有一些应用和未来的研究领域可以从中受益。然而，新的模型、更好的评估系统和更多的用户界面可以扩展，让工业界和学术界了解该领域将探索的新途径和兴趣。</p>
<h4 id="11、结论和今后的工作"><a href="#11、结论和今后的工作" class="headerlink" title="11、结论和今后的工作"></a>11、结论和今后的工作</h4><p>音乐生成或作曲是一个随着艺术生成新模式的出现而不断发展的研究领域。我们已经涵盖了参与音乐创作过程的代理，我们比较了人类和人工智能创作音乐的过程，并讨论了可以从这一研究领域受益的应用。我们提出了音乐生成领域需要更多研究和关注的几个领域：为实际数据集中没有代表的音乐流派创建新的数据集，不仅分析算法的偏差，还分析数据集的偏差，开发更多的用户界面，在不同层面上根据音乐原理调节模型的新研究，音乐的长期建模研究，开发更有效的编码和模型，并创建能够使研究结果具有可复制性的评估框架。在音乐的长期建模方面仍有改进的空间，这需要在模型和音乐编码设计方面付出努力。值得注意的是，尽管该领域正朝着长期建模的方向发展，但基序等短序列的生成仍然没有解决，需要更多的关注。据我们所知，目前的模型无法生成高质量的主题，至关重要的是从它们开始，然后发展和延续它们，以创建完整的短语、主题和结构化作品。</p>
<p>为此，尚未深入探索音乐生成的神经网络架构（如 GNN）可能是一个有趣的起点。以更有效的形式对音乐进行编码还将允许用更少的数据、更少的训练和推理时间来训练深度学习模型，更好地对音乐生成中至关重要的长期依赖性进行建模，降低成本和对环境的影响。通过条件生成也是必要的，以使工具对用户更加灵活。这取决于在音频和符号领域对音乐进行更好的分析，以便在创作音乐之前能够理解音乐，这是人类在创作音乐前所做的事情。从这方面来看，有算法或模型其他 MIR 领域可以已经与组成模型分开训练，并且可以用于调节生成模型。整合所有这些模型或创建一个既可用于分析又可用于作曲的多任务或多面手模型可能是该领域的目标，开发新的用户界面将允许用户以不同的方式和领域共同创作音乐，并扩展当前技术的能力。除此之外，从神经科学的角度理解人类大脑对于开发 NeuroAI 中的新人工智能技术至关重要，人工智能还可以反馈神经科学来帮助理解认知过程。在我们采取的任何解决方案、领域或方法中，由于每种特定音乐流派的复杂性和形式，我们都应该始终牢记我们所使用的流派或音乐风格。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://www.fenrisx.icu">Alexie-Z-Yevich</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://www.fenrisx.icu/2023/08/17/PR-A-Survey-on-Artificial-Intelligence-for-Music-Generation-3/">https://www.fenrisx.icu/2023/08/17/PR-A-Survey-on-Artificial-Intelligence-for-Music-Generation-3/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://www.fenrisx.icu" target="_blank">New Try && New Life</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><a class="post-meta__tags" href="/tags/%E9%9F%B3%E4%B9%90%E7%94%9F%E6%88%90/">音乐生成</a><a class="post-meta__tags" href="/tags/%E9%9F%B3%E4%B9%90%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2/">音乐信息检索</a><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><a class="post-meta__tags" href="/tags/%E4%BA%BA%E6%9C%BA%E4%BA%A4%E4%BA%92/">人机交互</a></div><div class="post_share"><div class="social-share" data-image="/images/head.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2023/07/08/PR-A-Survey-on-Artificial-Intelligence-for-Music-Generation-1/" title="音乐生成的人工智能综述：智能体、领域和前景(part.1)"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-07-08</div><div class="title">音乐生成的人工智能综述：智能体、领域和前景(part.1)</div></div></a></div><div><a href="/2023/08/01/PR-A-Survey-on-Artificial-Intelligence-for-Music-Generation-2/" title="音乐生成的人工智能综述：智能体、领域和前景(part.2)"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-08-01</div><div class="title">音乐生成的人工智能综述：智能体、领域和前景(part.2)</div></div></a></div><div><a href="/2023/08/20/PR-MUSIC-COMPOSITION-WITH-DEEP-LEARNING-A-REVIEW-1/" title="深度学习的音乐创作综述(part.1)"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-08-20</div><div class="title">深度学习的音乐创作综述(part.1)</div></div></a></div><div><a href="/2023/08/27/PR-MUSIC-COMPOSITION-WITH-DEEP-LEARNING-A-REVIEW-2/" title="深度学习的音乐创作综述(part.2)"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-08-27</div><div class="title">深度学习的音乐创作综述(part.2)</div></div></a></div><div><a href="/2022/07/01/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA/" title="人工智能导论"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-07-01</div><div class="title">人工智能导论</div></div></a></div><div><a href="/2023/05/07/%E4%BB%8EResNet%E5%85%A5%E9%97%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="从ResNet入门卷积神经网络"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-05-07</div><div class="title">从ResNet入门卷积神经网络</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/images/head.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Alexie-Z-Yevich</div><div class="author-info__description">hello</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">35</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">52</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">13</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Alexie-Z-Yevich"><i></i><span>前往我的Github...</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Alexie-Z-Yevich" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:1213791406@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content"><center>主域名：<br><a href="https://www.fenrisx.icu"><b><font color="#5ea6e5">fenrisx.icu</font></b></a><br>其他项目：<br><a target="_blank" rel="noopener" href="http://www.fenrisx.top"><b><font color="#5ea6e5">fenrisx.top</font></b></a><br>📬：<b><font color="#a591e0">1213791406@qq.com</font></b></a></center></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#7%E3%80%81%E4%BA%BA%E6%9C%BA%E4%BA%A4%E4%BA%92"><span class="toc-text">7、人机交互</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#A-%E7%95%8C%E9%9D%A2"><span class="toc-text">A.界面</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#B-%E7%94%A8%E6%88%B7"><span class="toc-text">B.用户</span></a></li></ol></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8%E3%80%81%E8%AF%84%E4%BC%B0"><span class="toc-text">8、评估</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#A-%E4%B8%BB%E8%A7%82%E8%AF%84%E4%BB%B7"><span class="toc-text">A.主观评价</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#B-%E5%AE%A2%E8%A7%82%E8%AF%84%E4%BB%B7"><span class="toc-text">B.客观评价</span></a></li></ol></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9%E3%80%81-%E8%BF%9B%E4%B8%80%E6%AD%A5%E7%9A%84%E8%A7%82%E7%82%B9%E5%92%8C%E7%A0%94%E7%A9%B6"><span class="toc-text">9、 进一步的观点和研究</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#A-%E9%87%8F%E5%AD%90%E9%9F%B3%E4%B9%90%E6%97%B6%E4%BB%A3"><span class="toc-text">A.量子音乐时代</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#B-%E6%83%85%E6%84%9F%E4%B8%8E%E4%B8%BB%E4%BD%93%E6%80%A7"><span class="toc-text">B.情感与主体性</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#C-%E7%94%9F%E6%88%90%E9%9F%B3%E4%B9%90%E7%9A%84%E7%89%88%E6%9D%83"><span class="toc-text">C.生成音乐的版权</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#D-%E5%BA%94%E7%94%A8"><span class="toc-text">D.应用</span></a></li></ol></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#10%E3%80%81%E8%AE%A8%E8%AE%BA"><span class="toc-text">10、讨论</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11%E3%80%81%E7%BB%93%E8%AE%BA%E5%92%8C%E4%BB%8A%E5%90%8E%E7%9A%84%E5%B7%A5%E4%BD%9C"><span class="toc-text">11、结论和今后的工作</span></a></li></ol></div></div></div></div></main><footer id="footer" style="background: rgba(255,255,255,0.7)"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2023 By Alexie-Z-Yevich</div><div class="footer_custom_text">I wish you to become your own sun, no need to rely on who's light.<p><a target="_blank" href="https://hexo.io/"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo" title="博客框架为Hexo"></a>&nbsp;<a target="_blank" href="https://butterfly.js.org/"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender" title="主题采用butterfly"></a>&nbsp;<a target="_blank" href="https://www.jsdelivr.com/"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr" title="本站使用JsDelivr为静态资源提供CDN加速"></a> &nbsp;<a target="_blank" href="https://vercel.com/ "><img src="https://img.shields.io/badge/Hosted-Vervel-brightgreen?style=flat&logo=Vercel" title="本站采用双线部署，默认线路托管于Vercel"></a>&nbsp;<a target="_blank" href="https://vercel.com/ "><img src="https://img.shields.io/badge/Hosted-Coding-0cedbe?style=flat&logo=Codio" title="本站采用双线部署，联通线路托管于Coding"></a>&nbsp;<a target="_blank" href="https://github.com/"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub" title="本站项目由Gtihub托管"></a>&nbsp;<a target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris" title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><div class="js-pjax"><script>(()=>{
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://twikoo.aiznoyer.work/',
      region: '',
      onCommentLoaded: function () {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))
  }

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://twikoo.aiznoyer.work/',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      countELement.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const runFn = () => {
    init()
    
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') {
      setTimeout(runFn,0)
      return
    } 
    getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(runFn)
  }

  if ('Twikoo' === 'Twikoo' || !true) {
    if (true) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script async src="/js/title.js"></script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div><script src="/js/markmap.js"></script></body></html>