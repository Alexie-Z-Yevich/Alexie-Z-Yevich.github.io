<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>机器学习</title>
      <link href="/2023/06/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
      <url>/2023/06/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>前言：</strong></p><p>这不是一篇正儿八经的机器学习文档，完全是应付考试用的。当时6.17考完英语六级之后、6.18过生日；6.19上午8点就是机器学习考试了，所以没有时间做什么很详细的文档。我就是用着这一点PPT提取物做了个不到三千的小文档，不过顺利帮助我在5个小时左右拿下了机器学习（虽然最后只有80分），所以传上来供大家参考。</p><p>温馨提示：虽然确实内容不多，但是希望大家对数仓与数挖的文档掌握后再来看机器学习，因为聚类、分类之类的算法掌握一两个之后会比较容易理解机器学习底层的思想。</p></blockquote><h2 id="第一章-绪论"><a href="#第一章-绪论" class="headerlink" title="第一章 绪论"></a>第一章 绪论</h2><h4 id="1、基本术语"><a href="#1、基本术语" class="headerlink" title="1、基本术语"></a>1、基本术语</h4><ul><li><strong>样本(sample)&#x2F;实例(instance)：</strong>我们获得的数据集中的一条数据，被称为一个样本&#x2F;实例，在不存在数据缺失的情况下，所有样本应该具有相同的结构。样本是一个统计学概念，很多时候，一个样本对应一个个体，或者对某个对象的一次观测(observation)；</li><li><strong>特征(feature)&#x2F;属性(attribute)：</strong>记录样本的某种性质或者在某方面的表现的指标或变量，有时候我们直接用原始数据的变量作为特征，而有的时候我们对原始变量施加一个映射，转变为一组新的变量作为特征，这个过程也被称为**特征提取(feature extraction)**，可以用来提取信息或者对数据进行降维；例如，原始变量是身高和体重，我们利用公式计算出BMI作为我们关心的特征，就把两个变量减少为了一个，降低了变量的维数；</li><li><strong>特征向量(feature vector)：</strong>一个样本的全部特征构成的向量，称为特征向量。即使经过了特征提取，我们往往也会用提取得到的特征构成新的目标数据集，得到新的样本变量（毕竟特征才是我们关注的变量）。还是以身高体重为例，我们获得了小明的身高、体重，构成了一个样本；但我们关注的是BMI指数，于是我们计算出小明的BMI，这时小明的BMI就成了新的样本。我们关注的永远是特征构成的样本，因此，我们可以说，<strong>一个特征向量就是一个样本</strong>；</li><li><strong>特征空间(feature space)&#x2F;属性空间(attribute space)&#x2F;样本空间(sample space)：</strong> 由所有特征&#x2F;属性张成的空间，也即特征向量所在的空间，每一维对应一个特征（其实就是概率论中样本空间的一种具体形式，只不过后者强调随机事件）；</li><li><strong>学习(learning)&#x2F;训练(training)：</strong>模型凭借数据提供的信息改进自身性能的过程；</li><li><strong>测试(testing)：</strong>训练结束之后检验模型训练效果的过程；</li><li><strong>训练数据(training data)&#x2F;训练集(training set)：</strong>训练模型使用的数据集，其中的每一个样本称为一个训练样本(training sample)；</li><li><strong>测试数据(testing data)&#x2F;测试集(testing set)：</strong>测试模型使用的数据集，其中的每一个样本称为一个测试样本(testing sample)；</li><li><strong>泛化能力(generalization ability)：</strong>在测试集上训练得到的模型，适用于训练集之外的样本的能力，或者说训练好的模型在整个样本空间上的表现。测试的目的之一也是检验模型的泛化能力；</li><li><strong>过拟合(overfitting)：</strong>模型过度学习，导致学习了过多只属于训练数据的特点，反而使得泛化能力下降；</li><li><strong>欠拟合(underfitting)：</strong>模型学习不足，导致没有学习到训练数据中足够的一般化规律，泛化能力不足；</li></ul><h4 id="2、机器学习的目标"><a href="#2、机器学习的目标" class="headerlink" title="2、机器学习的目标"></a>2、机器学习的目标</h4><p>机器学习致力于研究如何通过计算的手段，利用经验来改善系统自身的性能，从而在计算机上从数据中产生“模型”，用于对新的情况给出判断。</p><h4 id="3、归纳偏好"><a href="#3、归纳偏好" class="headerlink" title="3、归纳偏好"></a>3、归纳偏好</h4><p>学习过程中对某种类型假设的偏好称作归纳偏好。归纳偏好可看作学习算法自身在一个可能很庞大的假设空间中对假设进行选择的启发式或“价值观”.</p><p>“奥卡姆剃刀”是一种常用的、自然科学研究中最基本的原则，即“若有多个假设与观察一致，选最简单的那个”.</p><hr><h2 id="第二章-模型评估与选择"><a href="#第二章-模型评估与选择" class="headerlink" title="第二章 模型评估与选择"></a>第二章 模型评估与选择</h2><h4 id="1、过拟合与欠拟合"><a href="#1、过拟合与欠拟合" class="headerlink" title="1、过拟合与欠拟合"></a>1、过拟合与欠拟合</h4><ul><li>过拟合:学习器把训练样本学习的“太好”，将训练样本本身的特点当做所有样本的一般性质，导致泛化性能下降<ul><li>优化目标加正则项</li><li>early stop</li></ul></li><li>欠拟合：对训练样本的一般性质尚未学好<ul><li>决策树:拓展分支</li><li>神经网络:增加训练轮数</li></ul></li></ul><h4 id="2、评估方法"><a href="#2、评估方法" class="headerlink" title="2、评估方法"></a>2、评估方法</h4><ul><li><p>留出法：</p><ul><li>直接将数据集划分为两个互斥集合</li><li>训练&#x2F;测试集划分要尽可能保持数据分布的一致性</li><li>一般若干次随机划分、重复实验取平均值</li><li>训练&#x2F;测试样本比例通常为2:1~4:1</li></ul></li><li><p>交叉验证法：</p><ul><li>将数据集分层采样划分为k个大小相似的互斥子集，每次用k-1个子集的并集作为训练集，余下的子集作为测试集，最终返回k个测试结果的均值，k最常用的取值是10.</li></ul></li><li><p>自助法：以自助采样法为基础，对数据集D有放回采样m次得到训练集D’ ,  用D\D’做测试集。</p><ul><li>实际模型与预期模型都使用m个训练样本</li><li>约有1&#x2F;3的样本没在训练集中出现</li><li>从初始数据集中产生多个不同的训练集，对集成学习有很大的好处</li><li>自助法在数据集较小、难以有效划分训练&#x2F;测试集时很有用；由于改变了数据集分布可能引入估计偏差，在数据量足够时，留出法和交叉验证法更常用。</li></ul></li></ul><h4 id="3、性能度量"><a href="#3、性能度量" class="headerlink" title="3、性能度量"></a>3、性能度量</h4><p>性能度量是衡量模型泛化能力的评价标准，反映了任务需求；使用不同的性能度量往往会导致不同的评判结果.</p><ul><li>回归任务最常用的性能度量是“均方误差”：</li></ul><p><img src="/2023/06/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2.1.png" alt="image-20230617212241399"></p><ul><li><p>对于分类任务,错误率和精度是最常用的两种性能度量：</p><ul><li>错误率：分错样本占样本总数的比例</li><li>精度：分对样本占样本总数的比率</li></ul></li><li><p>根据学习器的预测结果按正例可能性大小对样例进行排序，并逐个把样本作为正例进行预测，则可以得到查准率-查全率曲线，简称“P-R曲线”</p></li></ul><hr><h2 id="第三章-线性模型"><a href="#第三章-线性模型" class="headerlink" title="第三章 线性模型"></a>第三章 线性模型</h2><ul><li>线性模型一般形式</li></ul><p><img src="/2023/06/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/3.1.png" alt="image-20230617212541740"></p><p>x &#x3D; (x_1; x_2; ……; x_d) 是由属性描述的示例，其中 x_i 是 x 在第 i 个属性上的取值。</p><ul><li>向量形式</li></ul><p><img src="/2023/06/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/3.2.png" alt="image-20230617212739864"></p><p>其中<img src="/2023/06/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/3.3.png" alt="image-20230617212749796"></p><h4 id="1、线性模型优点"><a href="#1、线性模型优点" class="headerlink" title="1、线性模型优点"></a>1、线性模型优点</h4><ul><li>形式简单、易于建模</li><li>可解释性</li><li>非线性模型的基础<ul><li>引入层级结构或高维映射</li></ul></li></ul><h4 id="2、优化"><a href="#2、优化" class="headerlink" title="2、优化"></a>2、优化</h4><ul><li>各任务下（回归、分类）各个模型优化的目标<ul><li>最小二乘法：最小化均方误差</li><li>对数几率回归：最大化样本分布似然</li><li>线性判别分析：投影空间内最小（大）化类内（间）散度</li></ul></li><li>参数的优化方法<ul><li>最小二乘法：线性代数</li><li>对数几率回归：凸优化梯度下降、牛顿法</li><li>线性判别分析：矩阵论、广义瑞利商</li></ul></li></ul><h4 id="3、总结"><a href="#3、总结" class="headerlink" title="3、总结"></a>3、总结</h4><ul><li>线性回归<ul><li>最小二乘法（最小化均方误差）</li></ul></li><li>二分类任务<ul><li>对数几率回归<ul><li>单位阶跃函数、对数几率函数、极大似然法</li></ul></li><li>线性判别分析<ul><li>最大化广义瑞利商</li></ul></li></ul></li><li>多分类学习<ul><li>一对一</li><li>一对其余</li><li>多对多<ul><li>纠错输出码</li></ul></li></ul></li><li>类别不平衡问题<ul><li>基本策略：再缩放</li></ul></li></ul><hr><h2 id="第四章-决策树"><a href="#第四章-决策树" class="headerlink" title="第四章 决策树"></a>第四章 决策树</h2><h4 id="1、基本流程"><a href="#1、基本流程" class="headerlink" title="1、基本流程"></a>1、基本流程</h4><ul><li>决策过程中提出的每个判定问题都是对某个属性的“测试”</li><li>决策过程的最终结论对应了我们所希望的判定结果</li><li>每个测试的结果或是导出最终结论，或者导出进一步的判定问题，其考虑范围是在上次决策结果的限定范围之内</li><li>从根结点到每个叶结点的路径对应了一个判定测试序列</li></ul><blockquote><p>决策树学习的目的是为了产生一棵泛化能力强，即处理未见示例能力强的决策树</p></blockquote><h4 id="2、划分选择"><a href="#2、划分选择" class="headerlink" title="2、划分选择"></a>2、划分选择</h4><p>决策树学习的关键在于如何选择最优划分属性。一般而言，随着划分过程不断进行，我们希望决策树的分支结点所包含的样本尽可能属于同一类别，即结点的“纯度”(purity)越来越高</p><ul><li>经典的属性划分方法：<ul><li>信息增益</li><li>增益率</li><li>基尼指数</li></ul></li></ul><h4 id="3、剪枝处理"><a href="#3、剪枝处理" class="headerlink" title="3、剪枝处理"></a>3、剪枝处理</h4><ul><li><p>为什么剪枝</p><ul><li>“剪枝”是决策树学习算法对付“过拟合”的主要手段</li><li>可通过“剪枝”来一定程度避免因决策分支过多，以致于把训练集自身的一些特点当做所有数据都具有的一般性质而导致的过拟合</li></ul></li><li><p>剪枝的基本策略</p><ul><li><p>预剪枝</p><p>优点</p><ul><li>降低过拟合风险</li><li>显著减少训练时间和测试时间开销</li></ul><p>缺点</p><ul><li>欠拟合风险：有些分支的当前划分虽然不能提升泛化性能，但在其基础上进行的后续划分却有可能导致性能显著提高。预剪枝基于“贪心”本质禁止这些分支展开，带来了欠拟合风险</li></ul></li><li><p>后剪枝</p><p>优点</p><ul><li>后剪枝比预剪枝保留了更多的分支，欠拟合风险小，泛化性能往往优于预剪枝决策树</li></ul><p>缺点</p><ul><li>训练时间开销大：后剪枝过程是在生成完全决策树之后进行的，需要自底向上对所有非叶结点逐一考察</li></ul></li></ul></li><li><p>判断决策树泛化性能是否提升的方法</p><ul><li>留出法：预留一部分数据用作“验证集”以进行性能评估</li></ul></li></ul><h4 id="4、连续值处理"><a href="#4、连续值处理" class="headerlink" title="4、连续值处理"></a>4、连续值处理</h4><h6 id="连续属性离散化-二分法"><a href="#连续属性离散化-二分法" class="headerlink" title="连续属性离散化(二分法)"></a>连续属性离散化(二分法)</h6><p><img src="/2023/06/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.1.png" alt="image-20230617214027160"></p><p><img src="/2023/06/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/4.2.png" alt="image-20230617214043390"></p><blockquote><p>与离散属性不同，若当前结点划分属性为连续属性，该属性还可作为其后代结点的划分属性</p></blockquote><hr><h2 id="第五章-神经网络"><a href="#第五章-神经网络" class="headerlink" title="第五章 神经网络"></a>第五章 神经网络</h2><h2 id="第六章-支持向量机"><a href="#第六章-支持向量机" class="headerlink" title="第六章 支持向量机"></a>第六章 支持向量机</h2><h4 id="1、基本型最大间隔公式转换"><a href="#1、基本型最大间隔公式转换" class="headerlink" title="1、基本型最大间隔公式转换"></a>1、基本型最大间隔公式转换</h4><p><img src="/2023/06/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/6.1.png" alt="image-20230617214255990"></p><h4 id="2、对偶问题"><a href="#2、对偶问题" class="headerlink" title="2、对偶问题"></a>2、对偶问题</h4><p><img src="/2023/06/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/6.2.png" alt="image-20230617214400290"></p><p><img src="/2023/06/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/6.3.png" alt="image-20230617214431255"></p><h4 id="3、0-x2F-1损失函数"><a href="#3、0-x2F-1损失函数" class="headerlink" title="3、0&#x2F;1损失函数"></a>3、0&#x2F;1损失函数</h4><p><img src="/2023/06/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/6.4.png" alt="image-20230617214528105"></p><p><img src="/2023/06/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/6.5.png" alt="image-20230617214555840"></p><hr><h2 id="第七章-贝叶斯分类器"><a href="#第七章-贝叶斯分类器" class="headerlink" title="第七章 贝叶斯分类器"></a>第七章 贝叶斯分类器</h2><h4 id="1、贝叶斯决策论"><a href="#1、贝叶斯决策论" class="headerlink" title="1、贝叶斯决策论"></a>1、贝叶斯决策论</h4><p>贝叶斯决策论（Bayesian decision theory）是在概率框架下实施决策的基本方法。</p><ul><li>在分类问题情况下，在所有相关概率都已知的理想情形下，贝叶斯决策考虑如何基于这些概率和误判损失来选择最优的类别标记。</li></ul><p><img src="/2023/06/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/7.1.png" alt="image-20230617214734480"></p><p><img src="/2023/06/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/7.2.png" alt="image-20230617214753275"></p><p><img src="/2023/06/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/7.3.png" alt="image-20230617214817023"></p><h4 id="2、极大似然估计"><a href="#2、极大似然估计" class="headerlink" title="2、极大似然估计"></a>2、极大似然估计</h4><p><img src="/2023/06/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/7.4.png" alt="image-20230617214901348"></p><p><img src="/2023/06/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/7.5.png" alt="image-20230617214917354"></p><h4 id="3、朴素贝叶斯分类器"><a href="#3、朴素贝叶斯分类器" class="headerlink" title="3、朴素贝叶斯分类器"></a>3、朴素贝叶斯分类器</h4><p><img src="/2023/06/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/7.6.png" alt="image-20230617214948750"></p><p><img src="/2023/06/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/7.7.png" alt="image-20230617215014515"></p><hr><h2 id="第八章-集成学习"><a href="#第八章-集成学习" class="headerlink" title="第八章 集成学习"></a>第八章 集成学习</h2><h4 id="1、Boosting"><a href="#1、Boosting" class="headerlink" title="1、Boosting"></a>1、Boosting</h4><ul><li>个体学习器存在强依赖关系，</li><li>串行生成</li><li>每次调整训练数据的样本分布</li></ul><p><img src="/2023/06/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/8.1.png" alt="image-20230617215130686"></p><h4 id="2、Bagging"><a href="#2、Bagging" class="headerlink" title="2、Bagging"></a>2、Bagging</h4><ul><li><p>个体学习器不存在强依赖关系</p></li><li><p>并行化生成</p></li><li><p>自助采样法</p></li><li><p>优点</p><ul><li>时间复杂度低<ul><li>假定基学习器的计算复杂度为O(m)，采样与投票&#x2F;平均过程的复杂度为O(s)，则bagging的复杂度大致为T(O(m)+O(s))</li><li>由于O(s)很小且T是一个不大的常数</li><li>因此训练一个bagging集成与直接使用基学习器的复杂度同阶</li></ul></li><li>可使用包外估计</li></ul></li></ul><hr>]]></content>
      
      
      <categories>
          
          <category> 我的大学 </category>
          
          <category> 大三下学期 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 聚类 </tag>
            
            <tag> 分类 </tag>
            
            <tag> 支持向量机 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据仓库与数据挖掘（下）</title>
      <link href="/2023/06/23/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%B8%8B%EF%BC%89/"/>
      <url>/2023/06/23/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%B8%8B%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h2 id="第五章-数据挖掘基础"><a href="#第五章-数据挖掘基础" class="headerlink" title="第五章 数据挖掘基础"></a>第五章 数据挖掘基础</h2><p>数据挖掘又称为数据库中的知识发现(knowledge discovery in database，KDD)，它是一个<strong>利用人工智能，机器学习和统计学等多学科理论分析大量的数据，进行归纳性推理，从事务数据库、文本数据库、空间数据库、多媒体数据库、数据仓库以及其他数据文件中提取正确的、新颖的、有效的以及人们感兴趣的知识的高级处理过程</strong>。数据挖掘的任务是从大量的数据中发现对决策有用的知识，发现数据特性以及数据之间的关系,这些知识表现为概念、规则、模式和规律等多种形式。</p><h4 id="1、数据挖掘基础"><a href="#1、数据挖掘基础" class="headerlink" title="1、数据挖掘基础"></a>1、数据挖掘基础</h4><h6 id="（1）概念"><a href="#（1）概念" class="headerlink" title="（1）概念"></a>（1）概念</h6><p>数据挖掘不是验证某个假设的正确性，而是在数据中寻找未知模式，本质上是一个归纳学习的过程。数据挖掘是一门涉及面很广的交叉学科，融合了模式识别、数据库、统计学、机器学习、粗糙集、模糊数学和神经网络等多个领域的理论。数据挖掘有一些替代词，如数据库中的知识发现、知识提炼、模式识别、数据考古、数据捕捞和信息获取等。由于“数据挖掘”能表现“挖掘”的本质，因此在学术界和企业界被广泛应用。</p><p>概括而言，<strong>数据挖掘是从大量的、不完全的、有噪声的、模糊的、随机的数据中提取正确的、有用的、未知的、综合的以及用户感兴趣的知识并用于决策支持的过程。</strong></p><p>该课程中的定义：<strong>数据挖掘就是从大量的、不完全的、有噪声的、模糊的随机的过程中，提取隐含在其中的、人们事先不知道的但又是潜在有用的信息和知识的过程。这些信息的表现形式为：规则、概念、规律及模式。</strong></p><ul><li>数据源必须是真实的、海量的、含燥声的。</li><li>发现的是用户感兴趣、新颖的知识。</li><li>发现的知识应该可接受、可理解、可运用、有价值。</li><li>知识的形式可以是概念、规则、模式、规律等形式。</li></ul><h6 id="（2）演变过程"><a href="#（2）演变过程" class="headerlink" title="（2）演变过程"></a>（2）演变过程</h6><p><img src="/2023/06/23/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%B8%8B%EF%BC%89/5.1.png"></p><h6 id="（3）数据挖掘的过程"><a href="#（3）数据挖掘的过程" class="headerlink" title="（3）数据挖掘的过程"></a>（3）数据挖掘的过程</h6><p>数据挖掘的过程由以下步骤组成：定义业务问题，提取与预处理数据，选择挖掘方法分析，解释挖掘结果，探查新模式以及运用发现的知识。</p><p><img src="/2023/06/23/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%B8%8B%EF%BC%89/5.2.png"></p><h6 id="（4）数据可视化"><a href="#（4）数据可视化" class="headerlink" title="（4）数据可视化"></a>（4）数据可视化</h6><p>数据可视化是指通过图表的形式,对处理后的数据进行分析，揭示其中蕴含的业务问题、规律，把数据转化为有用的信息，辅助决策。</p><blockquote><p>下面是几个我觉得比较常用的可视化图表</p></blockquote><p><img src="/2023/06/23/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%B8%8B%EF%BC%89/5.3.png"></p><p><img src="/2023/06/23/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%B8%8B%EF%BC%89/5.4.png"></p><p><img src="/2023/06/23/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%B8%8B%EF%BC%89/5.5.png"></p><p><img src="/2023/06/23/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%B8%8B%EF%BC%89/5.6.png"></p><p><img src="/2023/06/23/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%B8%8B%EF%BC%89/5.7.png"></p><p><img src="/2023/06/23/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%B8%8B%EF%BC%89/5.8.png"></p><h4 id="2、数据预处理"><a href="#2、数据预处理" class="headerlink" title="2、数据预处理"></a>2、数据预处理</h4><p>数据提取包括理解业务问题、搜集并分析数据源、确定数据的相关性以及使用工具提取数据等。</p><p>数据预处理是数据挖掘过程的基础工作，一般占整个数据挖掘过程70%的工作量。数据预处理技术用于<strong>数据清洗、数据集成、数据变换和数据归约等</strong>。数据清洗是指删除噪声和不一致的数据。数据集成是把多个数据源的数据合并存储，如数据仓库。数据变换通过规范化的方法改善数据挖掘算法的精度和有效性。数据归约通过删除冗余属性，使用聚集或聚类方法压缩数据。</p><h6 id="（1）数据清洗"><a href="#（1）数据清洗" class="headerlink" title="（1）数据清洗"></a>（1）数据清洗</h6><ul><li>常用的数据清洗方法<ul><li>聚类</li><li>空值处理<ul><li>忽略包含空值的记录或属性</li><li>使用一个常数填充遗漏值，把一楼的属性值用一个常数替换</li><li>使用数值型属性的平均值或给定记录属同一类（近邻）的所有样本的平均值填充空值【在特殊规则时不适用】</li><li>把空值属性看作决策属性，使用已知属性的值预测未知属性</li><li>使用最可能的值填充空值（采用机器学习等方法）</li></ul></li></ul></li></ul><h6 id="（2）数据集成"><a href="#（2）数据集成" class="headerlink" title="（2）数据集成"></a>（2）数据集成</h6><p>数据集成把来自多个数据库或者平面文件等不同数据源的数据整合成一致的数据存储。数据集成时，需要考虑实体识别问题。例如，在一个数据库中用学号(student_No)作为学生的标识，而在另一个数据库中学号可能被命名为(S_ID)。通常使用元数据来避免数据集成中出现的错误。</p><h6 id="（3）数据变换"><a href="#（3）数据变换" class="headerlink" title="（3）数据变换"></a>（3）数据变换</h6><p>数据变换把数据转化成适于挖掘的形式。通过对某些属性按比例进行缩放，使属性取值落在较小的区间。</p><ul><li><p>平滑：平滑可以有效的去掉噪声，常用的方法有分箱（binning）、聚类和回归分析。</p><ul><li>分箱是通过分析邻近的值平滑存储数据的值，可处理连续型和分类型变量，得到更少的变量取值种类，以便于分析。数据被分布到箱中，分箱的方法是进行局部的平滑，也可以作为一种离散化技术使用。</li></ul></li><li><p>聚集：对数据进行汇总。</p><ul><li>聚集产生较小的数据集,使得分析的数据更稳定,但也应注意可能会丢失有趣的细节。</li></ul></li><li><p>数据泛化：把任务相关的数据集从较低的概念层抽象到较高的概念层。</p></li><li><p>标准化(standardization)或规范化( normalization)：如果描述样本或记录的变量单位不统一，数值差别比较大，那么就需要通过把数据归一化，指数化或标准化，把不同的属性进行比例缩放，使它们的值落在大致相同的范围内。这在聚类分析,神经网络等数据挖掘算法的数据预处理中经常用到。</p></li></ul><h6 id="（4）数据归约"><a href="#（4）数据归约" class="headerlink" title="（4）数据归约"></a>（4）数据归约</h6><p>数据挖掘时一般需要对数据集进行归约处理。对归约的数据集进行数据挖掘与原数据应该有相同或差不多的效果,但效率更高。</p><ul><li>数据立方体聚集：数据立方体聚集的基础是概念的分层，用于处理数据立方体中的数据。<ul><li>数据立方体聚集为在线分析处理的上钻等操作提供了可以快速访问的汇总数据。</li></ul></li><li>维归约：维归约可以剔除相关性较弱或者冗余的属性。<ul><li>维归约就是从决策分析相关的属性集中选择重要的属性(特征)子集，这需要启发式的算法解决，常用的方法有决策树，粗糙集(rough set)和遗传算法(genetic algorithm)等。</li></ul></li></ul><h4 id="3、数据仓库和数据挖掘的关系"><a href="#3、数据仓库和数据挖掘的关系" class="headerlink" title="3、数据仓库和数据挖掘的关系"></a>3、数据仓库和数据挖掘的关系</h4><p>从数据仓库中挖掘出对决策有用的信息和知识，是建立数据仓库最大的目的。而如何从数据仓库中挖掘出有用的数据，则是数据挖掘的研究重点，二者的本质和过程是有区别的。</p><p>数据仓库是数据挖掘的一种数据源，数据挖掘是数据仓库的一个应用。</p><blockquote><p>内容来自New Bing</p></blockquote><p>数据仓库是为了数据挖掘做预准备，数据挖掘可建立在数据仓库之上，而且两者最终目的都为了提升企业的信息化竞争能力。数据仓库为数据挖掘提供了更好的、更广泛的数据源，为数据挖掘提供了新的支持平台，为更好地使用数据挖掘这个工具提供了方便。</p><hr><h2 id="第六章-关联挖掘"><a href="#第六章-关联挖掘" class="headerlink" title="第六章 关联挖掘"></a>第六章 关联挖掘</h2><h4 id="1、关联规则的概念"><a href="#1、关联规则的概念" class="headerlink" title="1、关联规则的概念"></a>1、关联规则的概念</h4><p>人们通过发现关联规则，可以从一件事情的发生，来推测另外一件事情的发生，从而更好地了解和掌握事物的发展规律等等，这就是寻找关联规则的基本意义。</p><p>关联规则就是有关联的规则，形式是这样定义的：<strong>两个不相交的非空集合X、Y，如果有X–&gt;Y，就说X–&gt;Y是一条关联规则</strong>。</p><h4 id="2、关联规则的定义"><a href="#2、关联规则的定义" class="headerlink" title="2、关联规则的定义"></a>2、关联规则的定义</h4><p><img src="/2023/06/23/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%B8%8B%EF%BC%89/6.1.png"></p><p>项目的集合I被称为项目集合(Itemset)，简称项集。</p><p>项集中元素的个数称为项集的长度。长度为k的项集被称为**k-项集(k-Itemset)**。</p><p><img src="/2023/06/23/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%B8%8B%EF%BC%89/6.2.png"></p><p>每一个交易有一个唯一的标识—交易号，记作TID。</p><p>交易的全体被称为交易数据集或事务数据集，记作D，简称<strong>交易集</strong>。</p><p><strong>规则的支持度</strong>：支持度描述了A和B这两个物品集在所有的事务中同时出现的次数或者出现的概率有多大。</p><p><img src="/2023/06/23/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%B8%8B%EF%BC%89/6.3.png"></p><p><strong>规则的可信度</strong>：可信度就是指在出现了物品集A的事务T中，物品集B也同时出现的概率。</p><h6 id="关联规则的最小支持度和最小可信度"><a href="#关联规则的最小支持度和最小可信度" class="headerlink" title="关联规则的最小支持度和最小可信度"></a>关联规则的最小支持度和最小可信度</h6><p><img src="/2023/06/23/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%B8%8B%EF%BC%89/6.4.png"></p><p><img src="/2023/06/23/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%B8%8B%EF%BC%89/6.5.png"></p><p><strong>频繁项集</strong>：在数据集中出现频率相当高的那些项集。如果项集满足最小支持度，则它称之为频繁项集(Frequent Itemset)。</p><p><strong>强关联规则：</strong></p><p><img src="/2023/06/23/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%B8%8B%EF%BC%89/6.6.png"></p><p><img src="/2023/06/23/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%B8%8B%EF%BC%89/6.7.png"></p><h4 id="3、Apriori算法"><a href="#3、Apriori算法" class="headerlink" title="3、Apriori算法"></a>3、Apriori算法</h4><p>Apriori算法是最常用的<strong>关联规则挖掘算法</strong>。 Apriori算法的扩展性较好，可用于并行计算等领域。Apriori算法的思想是：</p><ul><li>使用频繁项集性质的先验知识。</li><li>使用逐层搜索的迭代方法产生频繁项集。</li></ul><h6 id="（1）Aprior定律"><a href="#（1）Aprior定律" class="headerlink" title="（1）Aprior定律"></a>（1）Aprior定律</h6><ol><li>如果一个集合是频繁项集，则它的所有子集都是频繁项集。<br>举例：假设一个集合{A,B}是频繁项集，即A、B同时出现在一条记录的次数大于等于最小支持度min_support，则它的子集{A},{B}出现次数必定大于等于min_support，即它的子集都是频繁项集。</li><li>如果一个集合不是频繁项集，则它的所有超集都不是频繁项。<br>举例：假设集合{A}不是频繁项集，即A出现的次数小于min_support，则它的任何超集如{A,B}出现的次数必定小于min_support，因此其超集必定也不是频繁项集。</li></ol><p><strong>利用这两条定律，我们抛掉很多的候选项集，Apriori算法就是利用这两个定理来实现快速挖掘频繁项集的。</strong></p><h6 id="（2）算法步骤"><a href="#（2）算法步骤" class="headerlink" title="（2）算法步骤"></a>（2）算法步骤</h6><ol><li>扫描整个数据集，得到所有出现过的数据，作为候选频繁1项集。k&#x3D;1，频繁0项集为空集。</li><li>挖掘频繁k项集<ul><li>扫描数据计算候选频繁k项集的支持度;</li><li><strong>去除候选频繁k项集中支持度低于阈值的数据集,得到频繁k项集。</strong>如果得到的频繁k项集为空，则直接返回频繁k-1项集的集合作为算法结果，算法结束。如果得到的频繁k项集只有一项，则直接返回频繁k项集的集合作为算法结果，算法结束;</li><li>基于频繁k项集，连接生成候选频繁k+1项集。</li></ul></li><li>令<strong>k&#x3D;k+1</strong>，转入步骤2。</li></ol><h6 id="（3）局限性"><a href="#（3）局限性" class="headerlink" title="（3）局限性"></a>（3）局限性</h6><p>在每一次产生候选集时都要扫描一次数据库，生成<strong>大量备选项集</strong>，导致计数工作量太大，影响了算法的效率。</p><h4 id="4、FP-Growth算法"><a href="#4、FP-Growth算法" class="headerlink" title="4、FP-Growth算法"></a>4、FP-Growth算法</h4><p>FP-Growth算法是针对Apriori算法的缺点提出来的全新的一种算法模式。</p><h6 id="（1）算法步骤"><a href="#（1）算法步骤" class="headerlink" title="（1）算法步骤"></a>（1）算法步骤</h6><ol><li>扫描整个数据集，得到所有出现过的数据，并得到它们的支持度计数作为候选频繁1项集，记为L。</li><li>构造FP-Tree树<ul><li>创建树的根节点，用“null”标记。</li><li>第二次扫描数据库。每个事务中的项都按L的次序处理（即按递减支持度计数排序），并<strong>对每个事务创建一个分支</strong>。</li><li>当为一个事务考虑增加分枝时，<strong>沿共同的前缀的每个结点的计数增加1，为前缀之后的项创建节点和连接</strong>。</li></ul></li><li>对FP-Tree树进行挖掘频繁项集。</li></ol><p>Apriori算法在每一次产生候选集时都要扫描一次数据库，而FP-growth则利用树形结构，无需产生候选项集而是直接得到频繁项集，大大减少了扫描交易数据库的次数。</p><h6 id="（2）FP-tree结构优点"><a href="#（2）FP-tree结构优点" class="headerlink" title="（2）FP-tree结构优点"></a>（2）FP-tree结构优点</h6><p><strong>完备性：</strong>不会打破交易中的任何模式，而且包含了挖掘序列模式所需的全部信息。</p><p><strong>紧密性：</strong>它剔除不相关信息，不包含非频繁项，按支持度降序排列，支持度高的项在FP-tree中共享的机会也高。</p><hr><h2 id="第七章-聚类分析"><a href="#第七章-聚类分析" class="headerlink" title="第七章 聚类分析"></a>第七章 聚类分析</h2><h4 id="1、聚类分析概述"><a href="#1、聚类分析概述" class="headerlink" title="1、聚类分析概述"></a>1、聚类分析概述</h4><h6 id="（1）定义"><a href="#（1）定义" class="headerlink" title="（1）定义"></a>（1）定义</h6><p><strong>聚类分析</strong>是指将物理或抽象对象的集合分组为由类似的对象组成的多个类的分析过程。</p><p>由聚类所生成的簇是一组数据对象的集合，被称为<strong>聚类集合</strong>。簇内的对象之间相似度较高，簇与簇之间对象差别较大。散落在聚类集合之外的点被称为<strong>孤立点</strong>。</p><p><strong>聚类</strong>是将物理或抽象对象分组成多个类或簇，簇内对象间有较高相似度，簇间对象差别较大。</p><p>聚类所组成的簇是<strong>一组对象的集合，这些对象与同一簇中的对象彼此类似，与其他簇中的对象相异</strong>。在许多应用中，可以将一些簇中的对象作为一个整体来对待。</p><p>聚类分析源于许多研究领域，比如数据挖掘，统计学，生物学，以及机器学习。聚类分析能作为一个独立的工具，来获得数据分布的情况，观察每个簇的特点，集中对特定的或感兴趣的某些簇做进一步分析。</p><h6 id="（2）目的"><a href="#（2）目的" class="headerlink" title="（2）目的"></a>（2）目的</h6><p>寻找数据中：</p><ul><li><p>潜在的自然分组结构</p></li><li><p>感兴趣的关系</p></li></ul><p>聚类可以自动发现分组，有时又称作自动分类，这是聚类分析的突出优点。</p><h4 id="2、差异度计算"><a href="#2、差异度计算" class="headerlink" title="2、差异度计算"></a>2、差异度计算</h4><p><img src="/2023/06/23/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%B8%8B%EF%BC%89/7.1.png"></p><h6 id="混合类型变量的差异度计算"><a href="#混合类型变量的差异度计算" class="headerlink" title="混合类型变量的差异度计算"></a>混合类型变量的差异度计算</h6><p>一个数据库可能包含区间标度量、对称二元变量、不对称二元变量、标称变量、序数型变量或者比例标度变量。</p><ol><li>计算用混合类型变量描述的对象之间的差异度方法是将变量按类型分组，对每种类型的变量进行单独的聚类分析。如果在这些分析得到兼容的结果，这种做法是可行的。</li><li>将所有变量一起处理，只进行一次聚类分析。将不同意义的变量转换到共同的值域区间[0.0,1.0]上。</li></ol><h4 id="3、分割聚类"><a href="#3、分割聚类" class="headerlink" title="3、分割聚类"></a>3、分割聚类</h4><h6 id="（1）描述"><a href="#（1）描述" class="headerlink" title="（1）描述"></a>（1）描述</h6><p>分割聚类方法作为一种基于原型的聚类方法，其本质是先从数据集中随机地选择几个对象来作为聚类的原型，然后再将其他的对象分别分配给与原型所代表的最相似，也就是<strong>距离最近</strong>的类中。<br>分割聚类方法给定一个n个对象的集合，构建数据的K个分区。大部分分割方法是<strong>基于距离</strong>的，所以只能发现<strong>球类簇</strong>。</p><h6 id="（2）基本特点"><a href="#（2）基本特点" class="headerlink" title="（2）基本特点"></a>（2）基本特点</h6><ul><li>发现球状互斥的簇</li><li>基于距离</li><li>可以用均值或者中心点代表簇的中心</li><li>对中小规模数据有效</li></ul><h6 id="（3）方法步骤"><a href="#（3）方法步骤" class="headerlink" title="（3）方法步骤"></a>（3）方法步骤</h6><p>分割聚类方法首先给定要构建的分区数k，创建一个初始划分。然后，采用一种<strong>迭代</strong>的重定位技术，通过把对象从一个组移动到另一个组来改进分割效果。一个好的分割的一般准则是：<strong>同一个簇中的对象尽可能相互接近或相关，而不同簇中的对象尽可能远离或不同。</strong> <br>分割聚类方法给定一个含有n个对象的集合，具体划分方法为构建数据的K个分区，每个分区表示一个聚簇，并且k≤n。它将数据划分为k个组，同时满足如下要求：</p><ul><li><strong>每个组至少包含一个对象；</strong></li><li><strong>每个对象必须属于一个组。</strong></li></ul><p>在某些模糊划分的技术中，第二个要求可以适当放宽。</p><h4 id="4、K-means算法"><a href="#4、K-means算法" class="headerlink" title="4、K-means算法"></a>4、K-means算法</h4><p>k-means算法是将<strong>平均值作为类的“中心”</strong>的一种分割聚类的方法。该算法以k为参数，把n个对象分成k个簇，使簇内具有较高的相似度，而簇间的相似度较低。</p><h6 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h6><p>输入：包含n个对象的数据库和簇的数目k；</p><p>输出：k个簇。</p><p>(1) 任意选择k个对象作为初始的簇中心；</p><p>(2) 对剩余的数据对象，根据其与各个簇中心之间的距离，赋给最近的簇；</p><p>(3)更新簇的平均值，即计算每个簇中对象的平均值；</p><p>(4)根据簇中对象的平均值，将每个对象(重新)赋予最类似的簇；</p><p>(5) 直到不再发生变化。</p><h4 id="5、PAM算法"><a href="#5、PAM算法" class="headerlink" title="5、PAM算法"></a>5、PAM算法</h4><p>PAM算法实际为<strong>k中心点算法</strong>。中心选用的是具体的某一个点，而不是k均值的几何中心。是对k均值算法的改进，<strong>削弱了离群值的敏感度。但是其运算量较大，适合少量数据的分析。</strong></p><h6 id="算法流程-1"><a href="#算法流程-1" class="headerlink" title="算法流程"></a>算法流程</h6><p>（1）选取若干点作为初始簇心，并将剩余的点分配到最近的簇</p><p>（2）依次循环将非簇心的点假设为簇心，替换现有的一个，计算更改前后的耗费差距</p><p>（3）选择耗费差距最小的为新的簇心</p><p>（4）簇心的位置没有改变，停止</p><h4 id="6、基于密度的聚类方法"><a href="#6、基于密度的聚类方法" class="headerlink" title="6、基于密度的聚类方法"></a>6、基于密度的聚类方法</h4><p>分割式聚类算往往只能发现凸形的聚类簇，为了发现<strong>任意形状</strong>的聚类结果，提出了基于密度的聚类方法。这类方法将簇看作是数据空间中被低密度区域分割开的高密度对象区域。<br>基于密度聚类方法的主要思想是：<strong>只要“邻域”中的密度（对象或数据点的数目）超过某个阈值，就继续增长给定的簇。</strong>也就是说，对给定簇中的每个数据点，在给定半径的邻域中必须至少包括最少数目的点。这样的方法可以用来过滤噪声或离群点，从而发现任意形状的簇。</p><h4 id="7、DBSCAN算法"><a href="#7、DBSCAN算法" class="headerlink" title="7、DBSCAN算法"></a>7、DBSCAN算法</h4><p>DBSCAN算法是一种基于高密度联通区域的聚类算法，它将类簇定义为高密度相连点的最大集合。它本身<strong>对噪声不敏感，并且能发现任意形状的类簇</strong>。</p><h6 id="基本思想"><a href="#基本思想" class="headerlink" title="基本思想"></a>基本思想</h6><p><strong>如果一个对象在它半径为ε的邻域中至少包含有MinPts个对象，那么该区域被认为是密集的。</strong>为了明确这样的密集区域，该算法涉及到有关密度的一系列定义，进而根据这些定义来确定密集区域，即确定各个类并隔离出异常值。</p><h6 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h6><p><strong>ε邻域：</strong>对于一个给定的具体对象，其半径为 ε的邻域称为该对象的 ε-邻域。</p><p><strong>核心对象：</strong>对于一个对象，如果在其 ε-邻域内至少包含有MinPts个对象,那么该对象称为核心对象。</p><p><strong>直接密度可达：</strong>在所给定的对象集D中，对于参数 ε和MinPts，如果其中q是一个核心对象，对象p在q的 ε-邻域内，那么称对象p为从对象q是直接密度可达的。</p><p><strong>密度可达：</strong>在给定的对象集D中,对于参数 ε和MinPts,如果存在对象p1,p2,…,pn,p1&#x3D;q,pn&#x3D;p,对于每一个i∈{1,2,…,n-1},对象pi+1从对象pi是直接密度可达的,那么称对象p从对象q是密度可达的。</p><p><strong>密度相连：</strong>在给定的对象集D中，对于参数 ε和MinPts，如果对象p和对象q都是从对象o密度可达的，那么称对象p和对象q是密度相连的。</p><h6 id="算法流程-2"><a href="#算法流程-2" class="headerlink" title="算法流程"></a>算法流程</h6><p>（1）扫描整个数据集，找到任意一个核心点，对该核心点进行扩充。扩充的方法是寻找从该核心点出发的所有密度相连的数据点（注意是密度相连）。遍历该核心点的 邻域内的所有核心点（因为边界点是无法扩充的），寻找与这些数据点密度相连的点，直到没有可以扩充的数据点为止。最后聚类成的簇的边界节点都是非核心数据点。</p><p>（2）重新扫描数据集（不包括之前寻找到的簇中的任何数据点），寻找没有被聚类的核心点，再重复上面的步骤，对该核心点进行扩充。</p><p>（3）直到数据集中没有新的核心点为止。数据集中没有包含在任何簇中的数据点就构成异常点。</p><hr><h2 id="第八章-分类"><a href="#第八章-分类" class="headerlink" title="第八章 分类"></a>第八章 分类</h2><h4 id="1、基本知识"><a href="#1、基本知识" class="headerlink" title="1、基本知识"></a>1、基本知识</h4><h6 id="（1）概念-1"><a href="#（1）概念-1" class="headerlink" title="（1）概念"></a>（1）概念</h6><p><strong>分类是找出数据库中具有共同特点的一组数据对象，并按照分类模型将其划分成预先定义的不同类型。</strong></p><h6 id="（2）过程"><a href="#（2）过程" class="headerlink" title="（2）过程"></a>（2）过程</h6><ol><li><p>建立模型</p><p>第一步，也称为学习步，目标是建立描述预先定义的数据类或概念集的分类器。</p><ul><li>分类算法通过从训练集“学习”来构造分类器；</li><li>训练集由数据库元组（用n维属性向量表示）和他们相对应的类编号（标签）组成；假定每个元组属于一个预定义的类；</li><li>学习模型可以用分类规则、决策树或数学公式的形式提供。</li></ul></li><li><p>使用模型</p><p>第二步，使用模型，对将来的或未知的对象进行分类。</p><ul><li>对每个测试样本，将已知的类标号和该样本的学习模型类预测比较；</li><li>模型在给定测试集上的准确率是正确被模型分类的测试样本的百分比；</li><li>测试集要独立于训练样本集，否则会出现“过分拟合”的情况。</li></ul></li></ol><h6 id="（3）评价标准"><a href="#（3）评价标准" class="headerlink" title="（3）评价标准"></a>（3）评价标准</h6><p>先假设分类目标只有正例（P）和负例（N）两种，下面介绍几个常用的分类评价术语：</p><ol><li>TP：本身为正例，并且被分类器正确划分为正例的样本数；</li><li>FP：本身为负例，但被分类器错误地划分为正例的样本数；</li><li>FN：本身为正例，但被分类器错误地划分为负例的样本数；</li><li>TN：本身为负例，并且被分类器正确划分为负例的样本数。</li></ol><ul><li>正确率（accuracy）</li></ul><p>正确率是我们最常见的评价指标，accuracy &#x3D; （TP+TN）&#x2F;(P+N)，这个很容易理解，就是被<strong>分对的样本数除以所有的样本数</strong>，通常来说，正确率越高，分类器越好；</p><ul><li>错误率（error rate)</li></ul><p>错误率则与正确率相反，描述被<strong>分类器错分的比例</strong>，error rate &#x3D; (FP+FN)&#x2F;(P+N)，对某一个实例来说，分对与分错是互斥事件，所以 accuracy &#x3D;1 - error rate；</p><ul><li>灵敏度（sensitive）</li></ul><p>sensitive &#x3D; TP&#x2F;P，表示的是<strong>所有正例中被分对的比例</strong>，衡量了分类器对正例的识别能力；</p><ul><li>特效度（specificity)</li></ul><p>specificity &#x3D; TN&#x2F;N，表示的是<strong>所有负例中被分对的比例</strong>，衡量了分类器对负例的识别能力；</p><ul><li>精度（precision）：查准率</li></ul><p>精度是精确性的度量，表示被分为<strong>正例的实例中实际为正例的比例</strong>，precision&#x3D;TP&#x2F;（TP+FP）；</p><ul><li>召回率（recall）：查全率</li></ul><p>召回率是覆盖面的度量，度量有<strong>多少个正例被分为正例</strong>，recall&#x3D;TP&#x2F;(TP+FN)&#x3D;TP&#x2F;P&#x3D;sensitive，可以看到召回率与灵敏度是一样的。</p><h4 id="2、决策树"><a href="#2、决策树" class="headerlink" title="2、决策树"></a>2、决策树</h4><h6 id="（1）什么是决策树？"><a href="#（1）什么是决策树？" class="headerlink" title="（1）什么是决策树？"></a>（1）什么是决策树？</h6><ul><li>类似于流程图的树结构</li><li>每个内部节点表示数据对象的一个特征属性</li><li>每个分枝代表属性的一个取值</li><li>每个树叶节点代表一个类编号（决策结果）</li></ul><p><img src="/2023/06/23/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%B8%8B%EF%BC%89/8.1.png"></p><p>使用决策树进行分类的过程就是从根节点开始，测试待分类项中相应的特征属性，并按照其值选择输出分支，直到到达叶子节点，将叶子节点存放的类别作为分类结果。</p><h6 id="（2）决策树的生成"><a href="#（2）决策树的生成" class="headerlink" title="（2）决策树的生成"></a>（2）决策树的生成</h6><ul><li><p>决策树构建</p><ul><li>使用属性选择度量来选择将元组最好的划分为不同的类的属性</li><li>递归的通过选定的属性，来划分样本 （必须是离散值）</li></ul></li><li><p>树剪枝</p><ul><li>决策树建立时，许多分枝反映的是训练数据中的噪声和离群点，树剪枝试图识别并剪去这种分枝，以提高对未知数据分类的准确性</li></ul></li></ul><h6 id="（3）构建流程"><a href="#（3）构建流程" class="headerlink" title="（3）构建流程"></a>（3）构建流程</h6><ol><li>得到原始数据集；</li><li>根据属性选择度量对数据集进行最优划分，由于特征值可能有多个，因此存在数据集的划分大于两个分支的情况；</li><li>采用递归的原则对数据集进行处理，首次划分后，数据将会向下传递，到达树的分支的下一个节点，在该节点上，可对数据进行再次划分，不断重复该操作，直到达到递归结束条件，才结束递归；</li><li>递归结束的条件是，算法遍历完所有划分好的数据集的属性，或每个分支下的所有实例都具有相同的分类。</li></ol><h4 id="3、ID3算法"><a href="#3、ID3算法" class="headerlink" title="3、ID3算法"></a>3、ID3算法</h4><p>ID3算法依据“<strong>最大信息熵增益</strong>”原则，这里的熵描述的是数据集的<strong>混乱程度</strong>，数据越混乱，相应的熵就越大，算法每次都选择熵减少程度最大的特征，并用该特征对数据集进行划分，根据该原则，自顶向下遍历决策树空间。ID3算法的基本思想是，<strong>随着决策树深度的增加，节点的熵迅速地降低，熵降低的速度越快越好。</strong></p><p>该方法使用<strong>信息增益</strong>来选择测试属性。</p><ol><li><strong>信息熵是随机变量的期望</strong>。度量信息的不确定程度。信息的熵越大，信息就越不容易搞清楚（杂乱）。</li><li><strong>一个系统越是有序，信息熵就越低；反之，一个系统越是混乱，信息熵就越高。</strong>信息熵也可以说是系统有序化程度的一个度量。</li><li><strong>信息熵用以表示一个事物的非确定性，</strong>如果该事物的非确定性越高，你的好奇心越重，该事物的信息熵就越高。</li><li><strong>熵是整个系统的平均消息量。 信息熵是信息论中用于度量信息量的一个概念。</strong>一个系统越是有序，信息熵就越低；反之，一个系统越是混乱，信息熵就越高。</li><li>处理信息就是为了把信息搞清楚，实质上就是要想办法让信息熵变小。</li></ol><h6 id="信息量大小的度量"><a href="#信息量大小的度量" class="headerlink" title="信息量大小的度量"></a>信息量大小的度量</h6><p><img src="/2023/06/23/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%B8%8B%EF%BC%89/8.2.png"></p><h6 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h6><p>信息增益</p><ul><li>用来衡量给定的属性区分训练样例的能力；</li><li>ID3算法在生成树的每一步使用信息增益从候选属性中选择属性；</li></ul><p>用熵度量样例的均一性</p><h6 id="不足"><a href="#不足" class="headerlink" title="不足"></a>不足</h6><ol><li>ID3没有考虑连续特征，比如长度，密度都是连续值，无法在ID3运用。这大大限制了ID3的用途。</li><li>在相同条件下，取值比较多的特征比取值少的特征信息增益大。比如一个变量有2个值，各为1&#x2F;2，另一个变量为3个值，各为1&#x2F;3，其实他们都是完全不确定的变量，但是取3个值的比取2个值的信息增益大。（信息增益反映的给定一个条件以后不确定性减少的程度，必然是分得越细的数据集确定性更高，也就是条件熵越小，信息增益越大）</li></ol><h4 id="4、SVM预测"><a href="#4、SVM预测" class="headerlink" title="4、SVM预测"></a>4、SVM预测</h4><h6 id="（1）什么是SVM？"><a href="#（1）什么是SVM？" class="headerlink" title="（1）什么是SVM？"></a>（1）什么是SVM？</h6><p>支持向量机（简称SVM）是由Cotes和Vannik首先提出来的，是多年来关注度很高的分类技术，<strong>它可以很好的解决小样本，非线性及高维度数据识别分类问题</strong>， 这种技术具有坚实的统计理论基础，在许多实际应用（如文本分类）达到了很好的效果，并能推广应用到函数拟合等其他机器学习过程中。</p><p>支持向量机的基本思想是：在线性可分情况下，在原空间寻找两类样本的最优分类超平面。<strong>在线性不可分的情况下，加入了松弛变量进行分析，通过使用非线性映射将低维输入空间的样本映射到高维属性空间使其变为线性情况，从而使得在高维属性空间采用线性算法对样本的非线性进行分析成为可能</strong>，并在该特征空间中寻找最优分类超平面。</p><h6 id="（2）最大边缘的基本原理"><a href="#（2）最大边缘的基本原理" class="headerlink" title="（2）最大边缘的基本原理"></a>（2）最大边缘的基本原理</h6><p>具有较大边缘的决策比较小边缘的决策具有更好的泛化能力。从的直觉上来说，如果边缘较小，未知数据在决策边界附近分布会对分类效果产生明显影响。因此那些决策边缘较小的分类器对模型过拟合更加敏感，从而泛化能力变差。因此，需要最大化决策边界的边缘，以确保在最坏的情况下泛化误差最小。线性SVM就是解决这个问题的分类器。</p><h6 id="（3）核函数"><a href="#（3）核函数" class="headerlink" title="（3）核函数"></a>（3）核函数</h6><p><img src="/2023/06/23/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%B8%8B%EF%BC%89/8.3.png"></p><h4 id="5、KNN算法"><a href="#5、KNN算法" class="headerlink" title="5、KNN算法"></a>5、KNN算法</h4><h6 id="（1）KNN分类"><a href="#（1）KNN分类" class="headerlink" title="（1）KNN分类"></a>（1）KNN分类</h6><p>K-最近邻算法是最近邻算法的一个延伸。基本思路是：选择未知样本一定范围内确定个数的K个样本，该K个样本大多数属于某一类型，则未知样本判定为该类型。</p><p><img src="/2023/06/23/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%B8%8B%EF%BC%89/8.4.png"></p><h6 id="（2）算法步骤-1"><a href="#（2）算法步骤-1" class="headerlink" title="（2）算法步骤"></a>（2）算法步骤</h6><ol><li>计算测试数据与各个训练数据之间的距离；</li><li>按照距离的递增关系进行排序；</li><li>选取距离最小的K个点；</li><li>确定前K个点所在类别的出现频率；</li><li>返回前K个点中出现频率最高的类别作为测试数据的预测分类。</li></ol><h6 id="（3）优点"><a href="#（3）优点" class="headerlink" title="（3）优点"></a>（3）优点</h6><ol><li>简单，易于理解，易于实现，无需估计参数，无需训练；</li><li>适合对稀有事件进行分类；</li><li>特别适合于多分类问题(对象具有多个类别标签)，KNN比SVM的表现要好。</li></ol><h6 id="（4）缺点"><a href="#（4）缺点" class="headerlink" title="（4）缺点"></a>（4）缺点</h6><ol><li>当样本不平衡时，如一个类的样本容量很大，而其他类样本容量很小时，可能导致当输入一个新样本时，该样本的K个邻居中大容量类的样本占多数。</li><li>计算量较大，因为对每一个待分类的文本都要计算它到全体已知样本的距离，才能求得它的K个最近邻点。</li><li>可理解性差，无法给出像决策树那样的规则。</li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>数据仓库的部分其实比较详细了，在写文档的过程中又补充了一些以前没有细细了解过的，比如说元数据、OLAP等。其实有时候会发现其实大部分用过的软件中或多或少会带点理论的影子，比如说Hive、Maxwell都在MySQL中创建了MetaStore，其实这个时候就是创建了元数据数据库；再比如工作流的建立其实和OLAP联机分析处理有着异曲同工之处，都能在线提供分析处理功能。</p><p>数据挖掘部分就没有那么详细了，一个是没有这么多前置的文档记录，本身我自己也算是半路出家，对数据科学这方面也有不少问题；二个是多合一，商务智能、机器学习、数仓与数挖三门课相当于用这一个文档做了一个简单的小总结（其中机器学习还可能用不到，只不过是在理解的基础上学习机器学习比较轻松）；最后是时间问题，写这个文档的时候已经考完了，对这方面也没太伤心，难免有些敷衍。数挖其实还有不少我比较想介绍的内容，比如一些算法的技巧和通俗图解，但是因为时间和精力关系短时间不太能做了。以后有机会或者有时间会补上的。——Alexie·Z·Yevich 2023.6.23</p>]]></content>
      
      
      <categories>
          
          <category> 我的大学 </category>
          
          <category> 大三下学期 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> 数据挖掘 </tag>
            
            <tag> 聚类 </tag>
            
            <tag> 分类 </tag>
            
            <tag> 关联分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据仓库与数据挖掘（上）</title>
      <link href="/2023/06/21/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%B8%8A%EF%BC%89/"/>
      <url>/2023/06/21/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%B8%8A%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本来不是很想做这个文档，因为一开始以为这个课的主体是数据仓库，而之前我在Little Tips专题中做过关于离线数仓的完整流程，所以本来不准备进行补充了，但是上到一半发现这个课的主体居然是数据挖掘。。。emmmm所以这个学期所有的课程都需要学习数据挖掘的样子。（商务智能、Spark MLlib、机器学习和这个）刚巧备考商务智能的时候发现数据挖掘的内容挺多的，所以做来做去拆拆合合，还是捣鼓成两个文档了，数据仓库的部分就在文档就在下面；数据挖掘的部分就在另外一个文档。</p></blockquote><h2 id="第一章-数据仓库的概念和体系结构"><a href="#第一章-数据仓库的概念和体系结构" class="headerlink" title="第一章 数据仓库的概念和体系结构"></a>第一章 数据仓库的概念和体系结构</h2><blockquote><p>很多基本概念在各种小文章中都有提及，所以如果有没有涉及的点，大概率是我在其他的文章中有过介绍，或者我觉得可能这已经是常识了。供大家自行补充。</p></blockquote><h4 id="1、数据仓库的基本概念"><a href="#1、数据仓库的基本概念" class="headerlink" title="1、数据仓库的基本概念"></a>1、数据仓库的基本概念</h4><h6 id="（1）元数据（metadata）"><a href="#（1）元数据（metadata）" class="headerlink" title="（1）元数据（metadata）"></a>（1）元数据（metadata）</h6><p>元数据是数据仓库不可或缺的重要部分，它是描述数据仓库中数据的数据。它可以帮助用户方便快速地找到所需的数据；元数据是描述数据仓库中数据结构和构建方法的数据。</p><p>对元数据的分类按照应用场合可以分为<strong>数据元数据和过程元数据</strong>。数据元数据又可以称为信息系统元数据，信息系统使用元数据对数据源进行描述，以按照用户的需求检索、存取和理解元数据，数据元数据保证了数据的正常使用，它支撑着系统信息结构的演进。过程元数据又可以称为软件结构元数据，它是关于应用系统的描述信息，可以帮助用户查找、评估、存取和管理数据，系统软件结构中关于各个组件接口、功能和依赖关系的元数据保证了软件组建的灵活动态配置。</p><p>按照用途的不同，元数据可以分为<strong>技术元数据和业务元数据</strong>两类。技术元数据是关于数据仓库系统各项技术实现细节、被用于开发和管理数据仓库的数据，保证了数据仓库的正常运行。业务元数据从业务角度出发，提供了介于用户和实际系统之间的语义层描述，以辅助数据仓库用户能够“读懂”数据仓库中的数据。</p><h6 id="（2）数据粒度"><a href="#（2）数据粒度" class="headerlink" title="（2）数据粒度"></a>（2）数据粒度</h6><p>数据仓库所存在的不同数据综合级别，一般就称之为“粒度”。不同的粒度级别代表着不同的数据细节程度和综合程度，一般粒度越大，数据的细节程度越低，综合程度越高。</p><h6 id="（3）数据模型"><a href="#（3）数据模型" class="headerlink" title="（3）数据模型"></a>（3）数据模型</h6><p>数据模型是对现实世界的抽象表达，根据抽象程度的不同，衍生了不同层次的数据模型。</p><ul><li>和数据库数据模型的主要区别<ul><li>数据仓库数据模型增加了时间属性以区分不同时期的历史数据</li><li>数据仓库的数据模型不含有纯操作型数据</li><li>数据仓库的数据模型中增加了一些额外的综合数据</li></ul></li><li>概念数据模型<ul><li>概念数据模型是连接主观世界与客观世界的桥梁，常用的概念数据模型有星型模型、雪花模型以及星系模型三种。</li></ul></li><li>逻辑数据模型<ul><li>逻辑数据模型是对数据仓库中主题的逻辑实现，定义了每一个主题所有关系表之间的关系模式。</li></ul></li><li>物理数据模型<ul><li>物理数据模型是逻辑数据模型在数据仓库中的具体实现。</li></ul></li></ul><h6 id="（4）ETL（extract，transform-and-load）"><a href="#（4）ETL（extract，transform-and-load）" class="headerlink" title="（4）ETL（extract，transform and load）"></a>（4）ETL（extract，transform and load）</h6><p>原始数据源的数据经过抽取、转换并加载到数据仓库中的数据库的过程称为ETL。</p><p>数据抽取主要包括数据提取、数据清洁、数据转换以及生成衍生数据四个主要功能。</p><ul><li>数据提取要完成的主要工作就是确定要导入到数据仓库的数据有哪些。</li><li>数据清洁负责检查数据源中是否存在脏数据，并按照实现给定的规则对数据进行修改。</li><li>数据转换负责将数据源中的数据转换为数据仓库统一的格式，其中包括数据格式的转换，数据模式的转换时由于数据仓库和信息系统所面向的数据操作不同，所以在数据模式上也存在不同。</li></ul><h6 id="（5）数据集市"><a href="#（5）数据集市" class="headerlink" title="（5）数据集市"></a>（5）数据集市</h6><p>数据集市在某种程度上来讲就是一个小型的数据仓库。数据集市中的数据往往是关于少数几个主题的，它的数据量远远不如数据仓库，但数据集市所使用到的技术和数据仓库是同样的，它们都是面向分析决策型应用的。</p><h4 id="2、数据仓库的特点与组成"><a href="#2、数据仓库的特点与组成" class="headerlink" title="2、数据仓库的特点与组成"></a>2、数据仓库的特点与组成</h4><h6 id="（1）数据仓库的特点"><a href="#（1）数据仓库的特点" class="headerlink" title="（1）数据仓库的特点"></a>（1）数据仓库的特点</h6><p>数据仓库的定义是<strong>面向主题的、数据集成的、数据非易失的、数据随时间变化的</strong>一个支持管理决策的数据集合。</p><ul><li>面向主题<ul><li>数据库技术是面向应用，它为每个单独的应用程序组织数据。数据仓库中数据是面向主题来进行组织的；面向主题是建立数据仓库所必须遵守的基本原则，数据仓库中的所有数据都是围绕某一主题组织、展开的。</li></ul></li></ul><blockquote><p><strong>何为主题？</strong></p><p>主题是一个比较抽象的概念，它是在较高层次上对各信息系统的数据综合、归类并进行数据分析利用的抽象，在逻辑关系上，它对应着我们进行宏观分析时所涉及的数据的一个完整、一致的描述，它能够完整、统一的描述各个分析对象所涉及的各项数据，以及数据之间的关系。</p><p>从数据组织的角度来看，主题就是一些数据集合，这些数据集合对分析对象进行了比较完整的、一致的数据描述，这种描述不仅涉及数据自身，还涉及数据与数据自身的关系。</p><p>从信息系统角度来看，注意就是在一个较高的管理层次上对各信息系统中的数据按照某一具体的管理对象进行综合、归类所形成的分析对象。</p><p>数据仓库的创建、使用都是围绕主题实现的，因此，必须了解如何按照决策分析来抽取主题，所抽取的主题应该包含哪些数据内容，以及这些数据该如何组织。每一个主题要具有明确的界限，独立的内涵。在划分主题时，需要保证在对主题进行分析时所需要的数据都可以在此主题中找到，保证主题数据的完整性。</p></blockquote><ul><li>数据集成<ul><li>需要注意一致性问题</li></ul></li><li>非易失的</li><li>随时间不断变化的<ul><li>随着时间的推移数据仓库不断增加新的数据内容</li><li>随着时间的推移数据仓库中的旧数据被不断删除</li><li>数据仓库中包含大量的综合数据，这些综合数据往往和时间有某种必然的联系，数据会随着时间的推移不断进行重新综合。</li></ul></li></ul><h6 id="（2）数据仓库的组成"><a href="#（2）数据仓库的组成" class="headerlink" title="（2）数据仓库的组成"></a>（2）数据仓库的组成</h6><ul><li><p>满足日常的数据分析操作，必须满足以下几点要求</p><ul><li>数据仓库中的数据能够动态添加</li><li>提供对数据仓库的管理和维护功能</li><li>允许用户增加需求</li></ul></li><li><p>数据仓库系统应该具备以下功能</p><ul><li>数据抽取与加载</li><li>数据清洗</li><li>数据备份与备存</li><li>查询导向，即将所有的查询导向适合的数据源</li></ul></li><li><p>数据仓库主要由三大管理器组成</p><ul><li>加载管理器：负责从原始信息系统中抽取数据并对抽取的数据进行简单的转换，然后将转换后的数据加载到数据暂存区<ul><li>自源系统数据抽取</li><li>将抽取到的数据快速加载到数据暂存区</li><li>对数据进行简单的转换</li><li>将转换后的数据加载到与数据仓库类似的数据结构中</li></ul></li></ul><blockquote><p><strong>简单数据转换操作：</strong></p><ol><li>删除一些不必要的字段</li><li>对数据类型进行转换</li><li>对数据格式进行转换（例如首字母大写、删除前置空格符等）</li><li>根据需求校验字段值得有效性</li><li>检验所需字段是否有空值</li></ol></blockquote><ul><li>仓库管理器：负责数据的转换和管理，备存与备份数据<ul><li>对数据暂存区得数据进行转换与合并，加载到数据仓库数据库</li><li>为数据仓库中的数据创建索引、视图以及分区</li><li>对数据仓库进行备份（完整备份或者添加式备份）</li><li>对超过数据存储期限的数据进行备份（转移到其他存储介质）</li><li>验证各字段之间的关系与一致性</li><li>创建新的集合信息或者更新已有集合的信息</li></ul></li><li>查询管理器：管理所有的数据仓库查询请求并进行数据源引导</li></ul></li></ul><p>数据仓库中的数据由事实数据和维度数据组成；事实数据是从原始数据中经过数据清洗后得数据，它能反映过去事实的数据；维度数据是为了加速数据查询速度而创建的索引数据。</p><h4 id="3、数据仓库的体系结构"><a href="#3、数据仓库的体系结构" class="headerlink" title="3、数据仓库的体系结构"></a>3、数据仓库的体系结构</h4><h6 id="（1）传统得数据仓库体系结构"><a href="#（1）传统得数据仓库体系结构" class="headerlink" title="（1）传统得数据仓库体系结构"></a>（1）传统得数据仓库体系结构</h6><p>传统数据仓库基于关系型数据库，通过数据的抽取、转换、加载后进入到数据仓库，最终为上层应用提供数据支持。</p><ul><li>面临的挑战：<ul><li>架构问题<ul><li>数据移动代价过高</li><li>无法快速适应变化</li><li>海量数据与系统处理能力之间存在鸿沟</li><li>系统开放性不够</li></ul></li><li>扩展性问题</li><li>数据组织方式问题<ul><li>关系模型描述能力有限</li><li>关系模型得扩展性支撑能力有限</li></ul></li><li>容错性问题</li></ul></li></ul><h6 id="（2）大数据时代的数据仓库"><a href="#（2）大数据时代的数据仓库" class="headerlink" title="（2）大数据时代的数据仓库"></a>（2）大数据时代的数据仓库</h6><ul><li>高度可扩展性</li><li>高性能</li><li>高度容错</li><li>支持异构环境</li><li>较低的分析时延</li><li>易用开放的接口</li><li>自调优</li><li>较低的成本</li><li>兼容性</li></ul><h6 id="（3）体系结构（主要记图）"><a href="#（3）体系结构（主要记图）" class="headerlink" title="（3）体系结构（主要记图）"></a>（3）体系结构（主要记图）</h6><p><img src="/2023/06/21/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%B8%8A%EF%BC%89/1.1.png"></p><ul><li><strong>可伸缩的云计算环境</strong>：可伸缩的云计算环境由所涉及的硬件、系统软件、网络设备以及各种存储等组成，实现的方式可以基于私有云的方式，也可以基于公有云的方式，从而实现自动化、虚拟化和标准化管理等。大数据时代的数据仓库建设在可伸缩的云计算环境之上，可以实现资源的按需分配，屏蔽掉底层硬件的差异，从而使焦点聚焦于数据仓库软件的实现上。</li><li><strong>数据源层</strong>：数据源层中的数据主要包括结构化、半结构化和非结构化数据源。结构化数据源主要指各种关系型数据库，例如DB2、Oracle、MySQL等。半结构化数据源主要是指各种包含半结构化数据（例如XML、Excel、文本和日志等）的数据源。非结构化数据源主要是指包含图像、音频、视频等非结构化数据的数据源。大数据时代数据仓库的数据源与传统的数据仓库的数据源相比，数据的类型更多，结构更加复杂。</li><li><strong>数据预处理层</strong>：数据预处理层主要完成数据的抽取、清洗、集成和变换、规约、装载等工作。数据抽取从数据源层中获取与主题相关的原始数据；数据清理主要负责去除冗余数据；数据集成负责按照主题对数据进行集成并删除一些不必要的字段；数据变换负责按照统一的表现形式(格式）对所有的数据进行规范化。大数据时代的数据预处理工作与传统的数据预处理并无本质上的差别，有的只是数据预处理方法上的不同，例如，对于字段缺失，传统的数据预处理工作更多的是使用比较固定的预处理规则来进行数据的补全，而大数据时代的数据预处理引入了大数据时代的处理方法（机器学习等)来对缺失数据进行预测，使得经过预处理后的结果更加合理准确。</li><li><strong>大数据存储与管理层</strong>：大数据存储与管理层与传统数据仓库体系结构中的数据存储与管理层的功能一致，都是存储历史数据以及管理数据仓库。不同的是大数据存储与管理所采取的存储方式以及仓库管理手段与传统数据仓库有所不同，主要是由于数据的规模大、数据类别（非结构化、半结构化、结构化）多导致关系型数据库无法应对。大数据时代的数据存储组织方式不仅仅包括传统数据仓库所采用的行存储，还包括有列存储（例如NoSQL）以及混合式存储两种方式。</li><li><strong>OLAP服务器层</strong>：传统的数据仓库体系结构中的OLAP 服务器层与大数据时代的数据仓库体系结构中的OLAP服务器层从功能上来看并没有本质区别。</li><li><strong>大数据处理层</strong>：解决传统数据仓库无法处理的大规模数据计算。大数据处理采用分布式的集群，设计适合分布式集群存储的数据存储方法并设计相应的分布式并行计算算法。大规模的分布式并行化计算算法是大数据处理和传统的数据处理之间本质的区别，大数据时代的数据仓库的OLAP服务器与传统的数据仓库的OLAP服务器的设计初衷以及思路基本是一致的，只不过由于底层的数据存储方式已经发展为了大规模分布式存储，因此，数据处理算法也需要向并行化改进。</li></ul><hr><h2 id="第二章-数据"><a href="#第二章-数据" class="headerlink" title="第二章 数据"></a>第二章 数据</h2><h4 id="1、数据的概念"><a href="#1、数据的概念" class="headerlink" title="1、数据的概念"></a>1、数据的概念</h4><p>数据是指对客观事件进行记录并可以鉴别的符号，是信息的表现形式和载体。<strong>数据所指代的并不仅是狭义上的数字，还可以包括符号、文字、语音、图形和视频等。</strong></p><ul><li>在计算机科学中，数据是指所有能输入到计算机中并被计算机程序处理的符号和介质的总称</li><li>数据经过加工后就成为信息</li></ul><h6 id="数据的属性"><a href="#数据的属性" class="headerlink" title="数据的属性"></a>数据的属性</h6><p>数据的属性是指数据在某方面的特征，我们根据属性的性质将属性分为四种类型：</p><ul><li>标称：如性别(男、女)、婚姻状况(已婚、未婚)、职业(教师、医生、电工)</li><li>序数：成绩等级(优、良、中、及格、不及格)、衣服尺码(S、M、L、XL)</li><li>区间：测量单位，如温度、日历日期等</li><li>比率：如绝对温度、年龄、长度、成绩分数等</li></ul><h6 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h6><p>数据集是待处理的数据对象的集合，在数据挖掘领域，数据集有三个重要的特性：维度、稀疏性和分辨率：</p><ul><li>维度：指数据集中的对象具有的属性个数总和</li><li>稀疏性：指在数据集中，有意义的数据的多少</li><li>分辨率：可以在不同的分辨率下或者粒度下得到数据，而且在不同的分辨率下对象的数据也不同</li></ul><h4 id="2、数据预处理"><a href="#2、数据预处理" class="headerlink" title="2、数据预处理"></a>2、数据预处理</h4><h6 id="（1）预处理的意义"><a href="#（1）预处理的意义" class="headerlink" title="（1）预处理的意义"></a>（1）预处理的意义</h6><p>数据质量问题：现实世界的数据一般是<strong>含噪声的、不完整的、不一致的，是“肮脏的”</strong>。</p><ul><li>不一致数据：缺乏统一的分类标准和编码方案。</li><li>重复数据：存在相同的记录，相同的信息存储在多个数据源中。</li><li>残缺数据：空值</li><li>噪声数据：错误值或孤立点</li><li>高维数据：存在无用属性</li></ul><p><strong>改进数据质量，提高其后的挖掘过程的精度和性能。数据预处理是知识发现过程的重要步骤。检测数据异常、尽早调整数据，并归约待分析数据，将得到较高决策回报。</strong></p><p>数据预处理是构建数据仓库或者进行数据挖掘的工作中占工作量最大的一个步骤。</p><h6 id="（2）基本方法"><a href="#（2）基本方法" class="headerlink" title="（2）基本方法"></a>（2）基本方法</h6><p><strong>数据清洗</strong>：除去噪声，纠正不一致性。</p><ul><li>填写空缺的值，平滑噪声数据，识别、删除孤立点，解决不一致性</li></ul><p><strong>数据集成</strong>：将多种数据源合并成一致的数据存储。</p><ul><li>集成多个数据库、数据立方体或文件</li></ul><p><strong>数据变换</strong>：即规范化，可以改进距离度量的挖掘算法的精度和有效性。</p><ul><li>规范化和聚集</li></ul><p><strong>数据归约</strong>：通过聚集、删除冗余特性或聚类方法来压缩数据。</p><ul><li>通过一些技术（概念分层上卷等）得到数据集的压缩表示，它小得多，但可以得到相同或相近的结果</li></ul><h4 id="3、数据清洗"><a href="#3、数据清洗" class="headerlink" title="3、数据清洗"></a>3、数据清洗</h4><p>数据清洗(Data cleaning)，就是按照一定的规则把“脏数据”“洗掉”，即填充空缺的值，识别孤立点、消除噪声，并纠正数据中的不一致。</p><p>通过对数据进行重新审查和校验的过程，<strong>发现并纠正数据文件中可识别的错误，包括检查数据一致性，处理无效值和缺失值，删除重复信息、纠正存在的错误，并提供数据一致性等。</strong></p><p><strong>目的是提高数据质量。</strong></p><p>数据清理一般是<strong>由计算机而不是人工完成</strong>。</p><p>业界对数据清洗的认识：<strong>数据清洗是数据仓库构建中最重要的问题</strong>。</p><h6 id="噪声处理之分箱方法"><a href="#噪声处理之分箱方法" class="headerlink" title="噪声处理之分箱方法"></a>噪声处理之分箱方法</h6><p>分箱(binning):通过考察周围的值来平滑存储数据的值，存储的值被分布到一些“桶”或箱中，实现连续数据的离散化。</p><p>箱子是按照属性值划分的子区间，如果属性处于某个子区间的范围，就把属性放进该区间代表的箱子。</p><p>分箱方法：<strong>统一权重、统一区间、最小熵法、自定义区间</strong>等。</p><ul><li>统一权重法（等深分箱法）：将数据集按记录行数分箱，每箱具有相同的记录数，每箱记录数称为箱子的深度。</li><li>统一区间法（等宽分箱法）：使数据集在整个属性值的区间上平均分布，即每个箱的区间范围是一个常量，称为箱子宽度。</li><li>自定义区间：如将收入划分为1000元以下、1000-2000、2000-3000、3000-4000和4000以上。</li></ul><p>分箱目的是对各个箱子中的数据进行处理，完成了分箱之后，就需要采用一种方法对数据进行平滑，使得箱中的数据更接近，目前通常使用的平滑方法有<strong>按平均值平滑、按边界值平滑和按中值平滑</strong>。下面对上例中统一区间法分箱后的结果，分别采用三种平滑方法进行处理。</p><h4 id="4、数据集成"><a href="#4、数据集成" class="headerlink" title="4、数据集成"></a>4、数据集成</h4><p>数据集成是把不同来源、格式、特点性质的数据在逻辑上或物理上有机地集中。这些数据源可以包括多个数据库、数据立方体或一般文件。数据集成可能出现的问题归结为以下几类：</p><ul><li><p>模式匹配：将多个数据源中的数据整合到一个一致的存储中；</p><ul><li>模式匹配即整合不同数据源中的元数据。在模式匹配过程中涉及实体识别问题。</li></ul></li><li><p>数据值冲突：来源不同的同一个实体具有不同的数据值；</p><ul><li>不同数据源中，表示同一实体的属性值可能存在不同，可能表现在单位不统一、数值类型不统一等方面。</li></ul></li><li><p>数据冗余：冗余是指重复存在的消息，在数据挖掘领域中，也指无用的信息；</p><ul><li>冗余是指重复存在的消息，在数据挖掘领域中，也指无用的信息。一个属性（例如，年收入）如果能由另一个或另一组属性“导出”，则这个属性可能是冗余的。属性或维命名的不一致也可能导致结果数据集中的冗余。</li></ul></li></ul><h4 id="5、数据变换"><a href="#5、数据变换" class="headerlink" title="5、数据变换"></a>5、数据变换</h4><p>数据变换是将数据转换成适合挖掘的形式（原始数据表并不适合直接用于数据挖掘，需变换之后才能使用），主要有：</p><ul><li><p><strong>平滑</strong>：除去数据中的噪声，如分箱、聚类和回归。</p><ul><li>增减少属性的取值个数，减少挖掘算法的工作量</li></ul></li><li><p><strong>聚集</strong>：对数据进行汇总和聚集。</p><ul><li>avg(), count(), sum(), min(), max()…</li></ul></li><li><p><strong>数据概化</strong>：使用概念分层，用高层概念替换低层“原始”数据。</p><ul><li>使用概念分层的方式，利用高层的概念来替换低层或原始数据。</li></ul></li><li><p><strong>规范化</strong>：将属性数据按比例缩放，使之落入一个小的特定区间。</p><ul><li>所用的度量单位可能影响数据分析。例如，把高度的度量单位从米变成英寸，把重量的度量单位从公斤改成磅，可能导致完全不同的结果。为了帮助避免对度量单位选择的依赖性，需要对数据进行规范化，对属性数据进行缩放，使之可以落入到一个较小的特定区域之间，如[-1，1]、[0，1]。</li><li>主要的数据规范化方法：<ul><li>最小-最大规范化（MIN-MAX ）</li><li>零-均值规范化（z-score）</li><li>小数定标规范化</li></ul></li></ul></li></ul><h4 id="6、数据归约"><a href="#6、数据归约" class="headerlink" title="6、数据归约"></a>6、数据归约</h4><p>数据归约的本质就是缩小数据的范围，是指在不破坏数据完整性的前提下，获得比原始数据小得多的挖掘数据集，该数据集可以得到和原始数据集相同的挖掘结果，进而减少数据挖掘所需要的时间。常用的数据归约方法：</p><ul><li>数据立方体聚集：减少数据的维度</li><li>维归约：删除不相关、弱相关或冗余属性</li><li>数据压缩：使用正确的编码压缩数据集</li><li>数值规约：用较小的数值表示数据，或采用较短的单位，或使用模型来表示数据</li><li>离散化和概念分层产生：离散化是用确定的有限个区段值代替原始值；概念分层是指用较高层次的概念替换低层次的概念</li></ul><blockquote><p>用于数据归约的时间不应当超过或“抵消”在归约后的数据上挖掘节省的时间</p></blockquote><hr><h2 id="第三章-数据存储"><a href="#第三章-数据存储" class="headerlink" title="第三章 数据存储"></a>第三章 数据存储</h2><h4 id="1、数据模型"><a href="#1、数据模型" class="headerlink" title="1、数据模型"></a>1、数据模型</h4><p>数据模型（Data Model）是对现实世界数据特征的抽象表达，是用来描述数据的一组概念和定义。在信息管理中需要将现实世界的事物转换为信息世界的数据才能对信息进行处理与管理，这就需要依靠数据模型作为这种转换的桥梁。</p><p>现实世界中的客观对象抽象为概念模型，然后把概念模型转化为数据仓库支持的数据模型。其转化过程如下：</p><p><img src="/2023/06/21/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%B8%8A%EF%BC%89/3.1.png"></p><h6 id="（1）概念模型"><a href="#（1）概念模型" class="headerlink" title="（1）概念模型"></a>（1）概念模型</h6><p>概念模型描述的是从客观世界到主观认识的映射，它是用于我们为一定的目标设计系统、收集信息而服务的一个概念性工具。</p><p>进行概念模型设计所要完成的工作有：</p><ul><li><p><strong>界定系统边界</strong>，即进行任务和环境评估、需求收集和分析，了解用户迫切需要解决的问题及解决这些问题所需要的信息，要对现有数据库中的内容有一个完整而清晰的认识。</p></li><li><p><strong>确定主要的主题域及其内容</strong>，即要确定系统所包含的主题域，然后对每一个主题域的公共码键、主题域之间的联系、充分代表主题的属性组进行较为明确的描述。</p></li></ul><h6 id="（2）逻辑模型"><a href="#（2）逻辑模型" class="headerlink" title="（2）逻辑模型"></a>（2）逻辑模型</h6><p>逻辑模型是对数据仓库中主题的逻辑实现，从支持决策的角度去定义数据实体，更适合大量复杂查询。通常有两种逻辑模型表示法：星型模型和雪花模型。进行逻辑模型设计所要完成的主要工作有：</p><ul><li>分析主题域，定义逻辑模型</li><li>数据粒度的层次划分</li><li>确定数据分割策略</li><li>增加导出字段</li></ul><h6 id="（3）物理模型"><a href="#（3）物理模型" class="headerlink" title="（3）物理模型"></a>（3）物理模型</h6><p>物理模型是逻辑模型在数据仓库中的具体实现。进行逻辑模型设计所要完成的主要工作有：</p><ul><li>确定数据的存储结构</li><li>确定数据的索引策略</li><li>确定数据的存储策略</li><li>存储分配优化</li></ul><h4 id="2、元数据存储"><a href="#2、元数据存储" class="headerlink" title="2、元数据存储"></a>2、元数据存储</h4><p>元数据（Metadata）就是描述数据的数据，用于建立、管理、维护和使用数据仓库。元数据管理是企业数据仓库的关键组件，贯穿与建立数据仓库的整个过程。</p><h6 id="（1）按类型分类"><a href="#（1）按类型分类" class="headerlink" title="（1）按类型分类"></a>（1）按类型分类</h6><p><strong>基础元数据</strong>：基础数据是指数据仓库系统中所有的数据源、数据集市、数据仓库和应用中的数据。</p><p><strong>数据处理元数据</strong>：数据处理元数据是数据仓库系统中与数据处理过程紧密相关的元数据，它包括数据加载、清理、更新、分析和管理信息。</p><h6 id="（2）按抽象层次分类"><a href="#（2）按抽象层次分类" class="headerlink" title="（2）按抽象层次分类"></a>（2）按抽象层次分类</h6><p><strong>概念元数据</strong>：应用系统、预定义查询和分析应用相关的信息</p><p><strong>逻辑元数据</strong>：应用数学语言的描述，它从某种程度是概念元数据的更深层次的描述</p><p><strong>物理元数据</strong>：关于数据仓库实现的最底层信息，包括事务规则、SQL编码、关系索引文件和分析应用代码等</p><h6 id="（3）按用户角度分类"><a href="#（3）按用户角度分类" class="headerlink" title="（3）按用户角度分类"></a>（3）按用户角度分类</h6><p><strong>管理元数据</strong>：是存储关于数据仓库系统技术细节的数据，用于开发和管理数据仓库。包括：</p><ul><li>数据仓库结构的描述</li><li>汇总用的算法</li><li>有操作环境到数据仓库环境的映射</li></ul><p><strong>用户元数据</strong>：从最终用户角度描述数据仓库包括：</p><ul><li>如何连接数据仓库</li><li>可以访问数据仓库的哪些数据</li><li>数据来自哪一个源系统</li></ul><h6 id="（4）按元数据来源分类"><a href="#（4）按元数据来源分类" class="headerlink" title="（4）按元数据来源分类"></a>（4）按元数据来源分类</h6><p><strong>工具元数据</strong>：指由ETL（数据抽取、数据转换、数据装载）组件、数据仓库设计工具等产生的元数据</p><p><strong>资源元数据</strong>：指由操作系统、数据集市、数据库和数据字典生成的元数据</p><p><strong>外部数据</strong>：指的是从本地数据仓库系统以外的其他系统输入的元数据。如业务系统数据库中的数据。</p><h6 id="（5）元数据的作用"><a href="#（5）元数据的作用" class="headerlink" title="（5）元数据的作用"></a>（5）元数据的作用</h6><p>元数据是进行数据集成所必需的</p><p>元数据定义的语义层可以帮助最终用户理解数据仓库中的数据。</p><p>元数据是保证数据质量的关键。</p><p>元数据可以支持需求变化。</p><h4 id="3、数据集市"><a href="#3、数据集市" class="headerlink" title="3、数据集市"></a>3、数据集市</h4><p>为了解决灵活性和性能之间的矛盾，数据仓库的体系结构中就增加了数据集市。</p><h6 id="（1）定义"><a href="#（1）定义" class="headerlink" title="（1）定义"></a>（1）定义</h6><p>数据集市是一种小型的部门级的数据仓库，主要面向部门级业务，并且只面向某个特定的主题，是为满足特定用户（一般是部门级别的）的需求而建立的一种分析型环境。</p><p>投资规模比较小，更关注在数据中构建复杂的业务规则来支持功能强大的分析</p><p>常称为“小数据仓库”或“部门级数据仓库”</p><h6 id="（2）误区"><a href="#（2）误区" class="headerlink" title="（2）误区"></a>（2）误区</h6><p>单纯用数据量大小来区分数据集市和数据仓库</p><p>数据集市容易建立</p><p><strong>数据集市容易升级到数据仓库</strong></p><h6 id="（3）特点"><a href="#（3）特点" class="headerlink" title="（3）特点"></a>（3）特点</h6><p>特定用户群体所需的信息通常是一个部门或一个特定组织的用户。</p><p>支持访问非易变的业务信息。</p><p>协调组织中多个运行系统的信息。</p><p>为即席分析和预定义报表提供合理的查询响应时间。</p><h6 id="（4）数据集市的类型"><a href="#（4）数据集市的类型" class="headerlink" title="（4）数据集市的类型"></a>（4）数据集市的类型</h6><p><strong>从属型数据集市</strong></p><ul><li>从属型数据集市的数据来自于企业级数据仓库，是企业级数据仓库的子集。各数据集市中数据的组织、格式和结构在整个系统中保持一致一般为那些访问数据仓库十分频繁的关键业务部门建立从属型数据集市，这样可以更好地提高查询反应速度。</li></ul><p><strong>独立型数据集市</strong></p><ul><li>独立型数据集市，是指它的数据直接来源于各操作数据环境，当为各个部门建立相关数据集市后，这些数据集市之间相互独立，可能具有不同的数据存储类型。</li></ul><h6 id="（5）建立方式"><a href="#（5）建立方式" class="headerlink" title="（5）建立方式"></a>（5）建立方式</h6><p><strong>自上而下的方法：</strong>从属型的数据集市采用的是自上而下的方法。首先建立企业的数据仓库，然后从企业级的数据仓库中为各个部门抽取必要的数据建立部门级的数据集市。</p><p><strong>自下而上的方法：</strong>自下而上的开发方法是先从数据集市入手，就某一个特定的主题，先构建独立的数据集市，当数据集市达到一定的规模，再从各个数据集市进行数据的再次抽取建立企业级的数据仓库。</p><h4 id="4、数据存储"><a href="#4、数据存储" class="headerlink" title="4、数据存储"></a>4、数据存储</h4><p>详见我<a href="https://www.fenrisx.icu/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/">大数据存储技术（《深入分布式缓存：从原理到实践》）</a>这篇博客</p><hr><h2 id="第四章-OLAP与数据立方体"><a href="#第四章-OLAP与数据立方体" class="headerlink" title="第四章 OLAP与数据立方体"></a>第四章 OLAP与数据立方体</h2><h4 id="1、OLAP"><a href="#1、OLAP" class="headerlink" title="1、OLAP"></a>1、OLAP</h4><h6 id="（1）基本思想"><a href="#（1）基本思想" class="headerlink" title="（1）基本思想"></a>（1）基本思想</h6><p>联机分析处理（OLAP），又称为多维分析处理。通过对多维信息以很多种可能的观察方式进行快速、稳定、一致和交互性的访问和存取，允许管理决策人员对数据进行深入的观察。</p><h6 id="（2）基本目标"><a href="#（2）基本目标" class="headerlink" title="（2）基本目标"></a>（2）基本目标</h6><p>满足决策支持或多维环境特定的查询和报表需求，它的技术核心是“维度”这个概念，因此OLAP也可以说是多维数据分析工具的集合。</p><h6 id="（3）OLAP与OLTP对比"><a href="#（3）OLAP与OLTP对比" class="headerlink" title="（3）OLAP与OLTP对比"></a>（3）OLAP与OLTP对比</h6><p><img src="/2023/06/21/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%B8%8A%EF%BC%89/4.1.png"></p><h6 id="（4）特征"><a href="#（4）特征" class="headerlink" title="（4）特征"></a>（4）特征</h6><p><strong>快速性（fast）</strong></p><ul><li>用户对OLAP的响应速度有着很高的要求，这正是联机分析处理“在线”特征的体现。</li></ul><p><strong>可分析性（analysis）</strong></p><ul><li>不同的用户会存在不同的需求、不同的分析请求，面对众多种类的分析请求，需要OLAP 系统应能处理用户的任何逻辑分析请求和统计分析请求。</li></ul><p><strong>多维性（multidimensional）</strong></p><ul><li>要求系统在完成多维数据分析之后，同时也能够将分析结果以多维视图的形式提供给用户。</li></ul><p><strong>信息性（information）</strong></p><ul><li>OLAP 应具备管理大容量信息的能力。</li></ul><h4 id="2、多维分析操作"><a href="#2、多维分析操作" class="headerlink" title="2、多维分析操作"></a>2、多维分析操作</h4><h6 id="（1）切片"><a href="#（1）切片" class="headerlink" title="（1）切片"></a>（1）切片</h6><p>在给定数据立方体的一个维上进行选择一个维度成员的操作就是切片，切片的结果是得到一个二维平面数据。</p><h6 id="（2）切块"><a href="#（2）切块" class="headerlink" title="（2）切块"></a>（2）切块</h6><p>在给定数据立方体的一个维上进行选择两个或多个维成员的操作就是切块，切块的结果得到一个子立方体。</p><h6 id="（3）钻取"><a href="#（3）钻取" class="headerlink" title="（3）钻取"></a>（3）钻取</h6><p>改变维的层次，变换分析的粒度。它包括向下钻取（drill-down)和向上钻取(drill-up)。</p><ul><li>向上钻取：向上钻取是在某一维上将低层次的细节数据概括到高层次的汇总数据，或者减少维数。</li><li>向上钻取：向上钻取是在某一维上，它从汇总数据深入到细节数据进行观察，或者增加新维。</li></ul><h6 id="（4）旋转"><a href="#（4）旋转" class="headerlink" title="（4）旋转"></a>（4）旋转</h6><p>旋转就是将维的位置进行互换。旋转操作的本质就是改变观察数据立方体的视角，通过交换行和列得到不同视角的数据。</p><h4 id="3、数据立方体"><a href="#3、数据立方体" class="headerlink" title="3、数据立方体"></a>3、数据立方体</h4><h6 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h6><p><strong>方体：</strong>在数据立方体中，它的每个维度都可能存在概念分层。从这些不同的概念层上创建出的数据立方体称为方体，实质上，一个方体就相当于一个group-by。</p><p><strong>基本方体：</strong>就是在抽象程度最低的层面上建立的数据立方体。基本方体的泛化程度是最小的。</p><p><strong>顶点方体：</strong>与基本方体恰恰相反，顶点方体是从抽象程度最高的层面上建立出来的，它的泛化程度也是最大的。</p><p>数据立方体中的单元所存储的值，与多维空间的数据点一一对应。它可以分为基本单元和聚集单元。</p><ul><li><p>聚集值：经过处理的数据。</p></li><li><p>基本单元：不含聚集值的单元。基本方体的单元就是基本单元。</p></li><li><p>聚集单元：非基本单元的单元是聚集单元。聚集单元在一个或多个维聚集。</p></li></ul><p>为了提高OLAP的查询效率，有时要预计算整个立方体，预计算的过程称为物化。物化也称为聚集。物化分为三类：</p><ul><li><p>完全物化 : 预先计算所有方体。完全物化在响应查询时会很迅速，但是需要海量的存储空间。</p></li><li><p>不物化 : 不预先计算任何“非基本方体”。在响应查询的时候会耗费大量计算资源，而且还很缓慢。</p></li><li><p>部分物化 :选择一部分进行预先计算。部分物化很好的调和了不物化的“响应慢，存储空间小”和完全物化的“响应快，存储空间大”。可以预先计算一些用户指定的维度或者单元。</p></li></ul><p></p>]]></content>
      
      
      <categories>
          
          <category> 我的大学 </category>
          
          <category> 大三下学期 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> 数据仓库 </tag>
            
            <tag> 元数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>过去2023/6/18未来</title>
      <link href="/2023/06/18/%E8%BF%87%E5%8E%BB2023-6-18%E6%9C%AA%E6%9D%A5/"/>
      <url>/2023/06/18/%E8%BF%87%E5%8E%BB2023-6-18%E6%9C%AA%E6%9D%A5/</url>
      
        <content type="html"><![CDATA[<p>今天是我21岁生日，突发奇想想对我大学生活想做而又不敢做、想做而又做不到的事进行一个总结，顺便从我当前的视角剖析了我的心理状态，也许过几年会显得十分幼稚。但当下，这就是我最真实的写照。主要讲讲我对专业的理解，以及目前我的状态。已经能预想到过几年我看到这段文字的时候爆笑到止不住发抖了。</p><p>首先是我的专业，数据科学与大数据技术，如果说现在的我迷茫与踌躇，那么有一半至少和我的专业挂钩。如果可以，我愿意称它为两个专业——“数据科学”与“大数据技术”。数据科学是偏数学性质的，我们专业主要开设的课程有：算法设计与分析、机器学习、计算智能、人工智能导论和最优化理论；大数据技术，顾名思义，就是研究大数据的技术，我们主要开设的课程有大数据平台基础（Hadoop生态体系）、大数据存储技术（分布式存储）、Spark数据分析、Python数据分析、数据仓库与数据挖掘还有未来还没上的课。</p><p>正如我对他们的介绍，这两个方向几乎是完全割裂的，数据科学集中在对算法、流程进行优化，例如最近的ChatGPT当然，其主要是强化学习生成式AI方向，不过套用我最近听到学长的一套理论：Open CV让计算机“看到”世界；机器学习让计算机“了解”世界，强化学习让计算机“控制”世界，那么说实在的，机器学习最终也会和其他方向殊途同归，大模型就是最好的印证。</p><p>而说到大数据技术，其实也存在一定的流程优化，但更多是在应用层面上的。如果说数据科学的流程优化是对不同算法的组合，那么大数据技术的流程优化就是对不同框架的整合，但很明显，学校教的内容完全不能支撑我们进行流程优化的技术体系。以比较经典的电商数仓（也就是我之前写过little tips的文档）举例，大数据技术的工作要求你至少从两件事中会干一件事：一是数据仓库的搭建；二是工作流的优化和部署。也就是常说的写SQL。第一件事技术性没有那么高，但是要求你会的组件多、会的方面全，基本上以异构数据源、Hadoop、Zookeeper、Kafka、MySQL、Hive等技术栈为主。说来惭愧，听说目前主流的技术栈是Flink，但是在下还没有抽出时间去学。附带的，你可能还需要会一些可视化工具，常用的可能有Superset和Echarts。第二件事则是在DolphinScheduler之类的可视化工作流系统上对Hive、Spark等SQL软件进行优化和部署，SQL其实并不难写，但是胜在熟练。学校虽然也教了数据库技术，但是侧重于概念的理解而非SQL语句的编写，稍稍复杂的SQL可能就很难应对。（这里我推荐《SQL必知必会》，针对各个阶段的人群都能快速巩固基础）</p><p>以上便是我对我自身专业的浅显的理解，也是目前导致我忧郁的主要原因：我的大学经历不算丰富，但确实是走了不少弯路，导致现在了一个高不成、低不就的状态，我大一致力于“享受”大学的生活，拿的出手的就是参与了不少社会实践和学校的活动，主要是在文体方面保持得不错。在大一下学期的时候，因为自己的放纵导致了数据结构只考了60分（其实就是老师捞起来的），这直接导致了我对自己的否定以及强烈的打击，以至于现在我仍然未能从中走出来，即便是现在，被问起算法、数据结构方面的问题时，我还是习惯性先否定自己。</p><p>为了解决学业上这种状况，我尝试在大二在提升自己的绩点，但是因为已经在大一注定了与保研无关，所以讲重心放在了技术上。为此我加入了TickNet工作室，但因为自己的自我否定并没有选择加入研发组，而是在运营组深耕，也没想到这一干就是两年半。技术上因为课程的设置，在大二上接触了Java、在大二下接触了JavaWeb，完成了SpringBoot、Mybatis Plus、Vue3等前后端的学习，也花了大量的时间在一些中间件上，例如Axios、Nginx、Git。但是我的学习过程一开始就已经偏离了正确的学习方向，我的学习主要是为了解决这种所遇到的问题，而非常解决规范化的问题，所以在学习过程中对代码并没有特别的规范，导致我现在也无法说自己的代码可读性非常高。在大二的暑假接受了学校老师的推荐，帮助湖南工程学院的老师开发了一个不难不易的教学任务管理系统，包括对教学任务的发布、统计，并使用可视化面板对结果进行反馈。在这个过程中前后端成为了我的一部分，我也具备了基本的开发能力，也成了我之后最大的梦魇。</p><p>前面说到前后端成为了我的一部分，但是我的本职是大数据，所以在大三，我还是选择了本源。即使是以同校同专业的角度来看，我现在开始大数据学习也算是其中的佼佼者，但是放到大环境下，我的起步也比别人慢了很多。而前后端又不舍得割舍，导致我学习路线很混乱，最终在整个大三阶段完成了Hadoop、MR、Spark、Kafka、Flume、Maxwell等的学习，同时也在大三上尝试自己搭建了一个离线数仓。曲折又来了：可以看出这些内容都是大数据技术方向，几乎完全不涉猎数据科学方向，于是在今年三月份春招开始的时候我还是很认真的去准备招聘实习，但是会的多反而没有什么优势，说明都不是很专精。同样赶上了今年就业“寒冬”，大数据类职务都比较少，而Java后端又非常的卷，因为大三几乎放下了前后端开发，所以Java后端也只能算半斤八两，在面试时捉襟见肘。最终还是受不了环境的压迫，也不愿意放弃我对大数据的兴趣，我开始考虑继续深造——考研。计划目前就不详细说了，考研的话对技术力要求并没有那么高，但是之后的复试和方向上更看重机器学习等方面的见解，所以不得已，我又需要捡起放弃的数据科学。目前已经学了一些大模型相关，也在强化学习、机器学习方面展现出了一些兴趣。但更多的是一种对现实的无奈妥协。</p><p>最后是我个人的一点项目预设，算是这些年来想做但是没能力做的一些事吧。当年我选择计算机也非本意，我其实想学数学的，但是高考分数不够选到好学校的数学，而我们学校的计算机大于数学，因此最终还是进了计算机的坑。学了计算机后我就一直在想我能用计算机做什么来实现我对生活的消遣。到现在也囤了不少我认为不错的奇思妙想了：</p><ol><li>哼歌编曲：市面上比较流行哼歌识曲，但是作为普通人的我们更可能在生活中不自觉的哼出一些自己觉得是“天籁”的曲子。这不是个大众的企划，但是能给每个人带来个性化服务，用你哼出来的那一段进行续写，让每一段都是属于你个人美妙绝伦对的乐曲。（支持乐器转换、重复生成）</li><li>老年人监控：市面上应该有些了，但和我想的稍有不同。</li><li>页面数据抓取：非格式化数据挖掘，通过嵌入Vue、React框架实现对用户数据的挖掘，提供给大数据服务（需要较强的前端技术，目前搁置）</li><li>在线开发、封包、部署网站（字面意思）</li></ol><p>这些项目大多存在构想，一些我也有书面表达的记录，但是碍于自身实力，都没能实现，如果你对这些感兴趣，也可以和我单独交流，在我的Github中可以找到我的联络方式。</p><p>这是我对大学生活的一个小结，也是我对当前状态的一个记录，希望未来的我看到这些，能够有新的感悟和行动，现在依旧迷茫，但我相信未来一定充满光明！</p>]]></content>
      
      
      
        <tags>
            
            <tag> 开始与结束 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>商务智能</title>
      <link href="/2023/05/12/%E5%95%86%E5%8A%A1%E6%99%BA%E8%83%BD/"/>
      <url>/2023/05/12/%E5%95%86%E5%8A%A1%E6%99%BA%E8%83%BD/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>前言：</strong></p><p>本文档的1、2、5、6章是老师考试要求的范围（我们这届），第五章因为范围比较大，老师上课也没有讲，所以准备单独做一个文档出来，正好《数据仓库与数据挖掘》的重点也是数据挖掘，就一起合并到那个文档中了。</p><p>其余的章节是我自己课余时间看完的，做了一个简单的摘要，清华的书还是挺有意思的，作为兴趣爱好可以推荐大家有时间去看看。</p></blockquote><h2 id="第一章-商务智能概论"><a href="#第一章-商务智能概论" class="headerlink" title="第一章 商务智能概论"></a>第一章 商务智能概论</h2><h4 id="1、商业决策需要商务智能"><a href="#1、商业决策需要商务智能" class="headerlink" title="1、商业决策需要商务智能"></a>1、商业决策需要商务智能</h4><h6 id="（1）数据、信息与知识"><a href="#（1）数据、信息与知识" class="headerlink" title="（1）数据、信息与知识"></a>（1）数据、信息与知识</h6><p>数据是记录、描述和识别事物的符号，通过数据有意义的组合可表达现实世界中某种实体的特征。<strong>数据多表现为简单的事实。</strong>数据也成为记录、案例、样本等。数据用属性描述，属性也成为变量、特征、字段或维等。</p><p>数据经过解释后可以转换为有用的信息，信息是经过某种提炼、加工和集成后的数据。信息是可以被人们理解和解释的，对不同的人可能价值不同。</p><p>数据和信息虽然不等同，却也是密不可分的。概括地讲，<strong>数据是信息的载体，而信息是对数据的解释。</strong></p><p><strong>知识就是对信息内容进行的提炼、比较、挖掘、分析、概括、判断和推论。</strong>知识分为事实性知识和经验知识：事实性知识是人类对客观事物和现象的认识结果；经验知识多是一种隐性知识，是存储在人们大脑中的经历、经验、技巧、体会和感悟等尚未公开的知识。</p><blockquote><p>我个人是将数据、信息、知识的关系代入到生产环境中：数据——》数据分析——》BI。数据分析对应信息，这是一个将不同源数据聚合的过程，将大量无用的数据转换为单条格式化的“信息”；BI对应的是知识，知识是方便人们进行理解的，所以同样的，大数据中最终呈现的BI报表也一定是让人容易理解的。</p></blockquote><h6 id="（2）决策"><a href="#（2）决策" class="headerlink" title="（2）决策"></a>（2）决策</h6><p><strong>管理就是决策。</strong>决策是企业管理的核心，贯穿管理的全过程。企业管理可分为战略层、中间管理层和运营层三个层次。</p><blockquote><p>简单来说就是三层分别负责：目的、计划、实施三个步骤。</p></blockquote><p>企业各层级决策都必须有足够的信息，越往高层，决策需要的信息粒度越大，而信息堆决策的影响也越大。决策 &#x3D; 信息 + 知识（经验） + 冒险，而充分的有价值的信息、知识以及经验可以降低决策风险。</p><h4 id="2、商务智能"><a href="#2、商务智能" class="headerlink" title="2、商务智能"></a>2、商务智能</h4><h6 id="（1）技术支持"><a href="#（1）技术支持" class="headerlink" title="（1）技术支持"></a>（1）技术支持</h6><p>商务智能的技术基础是数据仓库（data warehousing，DW）、在线分析处理（on-line analytical processing，OLAP）、数据挖掘（data mining，DM）。数据仓库用以存储和管理数据，数据仓库的数据从运营层而来。在线分析处理用于把这些数据转化成信息，支持各级决策人员复杂查询和在线分析处理，并以直观易懂的图标把结果展现出来。数据挖掘可以从海量的数据中提取出隐含在数据中有用的数据，以便做出更有效地决策，提高企业智能。</p><h6 id="（2）简介"><a href="#（2）简介" class="headerlink" title="（2）简介"></a>（2）简介</h6><p>商务智能把各种数据及时地转化为支持决策的信息和知识，帮助企业管理者了解客户的需求、消费习惯，预测市场的变化趋势以及行业的整体发展方向，进行有效的决策，进而在竞争中占据有利的地位。</p><p>商务智能可视为一个散装的概念，其内容包括分析应用、基础架构、平台以及实践。商务智能是融合了先进信息技术与创新管理理念的结合体，集成了企业内外的数据，经过加工并从中提取能够创造商业价值的信息，面向企业战略并服务于管理层、业务层，指导企业经营决策、管理思想，提升企业竞争力，涉及企业战略、管理思想、业务整合和技术体系等层面，促进信息到知识再到利润的转变，从而实现更好的绩效。<strong>应用的核心不在其功能，而在于对业务的优化。</strong></p><h6 id="（3）商务智能的价值"><a href="#（3）商务智能的价值" class="headerlink" title="（3）商务智能的价值"></a>（3）商务智能的价值</h6><ol><li><p><strong>制定合适的市场营销策略</strong></p><p>利用商务智能技术构建商业模型，确定合适的营销策略。</p></li><li><p><strong>改善顾客管理</strong></p><p>顾客智能是商务智能在顾客管理关系中的应用。企业正在逐渐由“以产品为中心”转化为“以顾客为中心”。</p></li><li><p><strong>降低经营成本提高收入</strong></p><p>应用商务智能企业的绩效管理功能，可以简便、快捷地制定各种成本收益报表，对不同的业务活动进行成本核算，深入分析偏差和改进方法，从而降低成本，提高收入。</p></li><li><p><strong>提高风险管理能力</strong></p></li><li><p><strong>改善业务洞察力</strong></p><p>商务智能减少管理者收集数据、获取信息所花费的时间，加速决策过程，使正确的信息在正确的的时间流向决策者。</p></li><li><p><strong>提高市场响应能力</strong></p><p>借助商务智能还可以预测市场变化，精简流程，确定需要改进的环节，以适应外部环境的变动。</p></li></ol><h6 id="（4）商务智能系统的功能"><a href="#（4）商务智能系统的功能" class="headerlink" title="（4）商务智能系统的功能"></a>（4）商务智能系统的功能</h6><ol><li><p><strong>数据集成</strong></p><p>数据是决策分析的基础。</p></li><li><p><strong>信息呈现</strong></p><p>信息呈现是指把收集的数据以报表的形式呈现出来，让用户了解到企业、市场的现状，这是商务智能的初步功能。</p></li><li><p><strong>运营分析</strong></p><p>运营分析包括运营指标分析、运营业绩分析和财务分析等。</p></li><li><p><strong>战略决策支持</strong></p><p>战略决策支持是指根据战略业务单元（strategic bussiness unit，SBU）的经营业绩和定位，选择一种合理的投资组合战略。</p></li></ol><h4 id="3、商务智能的应用"><a href="#3、商务智能的应用" class="headerlink" title="3、商务智能的应用"></a>3、商务智能的应用</h4><h6 id="（1）金融行业"><a href="#（1）金融行业" class="headerlink" title="（1）金融行业"></a>（1）金融行业</h6><ul><li>规范整合金融企业资源，进行成本控制、获利分析和绩效评估。</li><li>评估、模拟、分析与控制市场风险、信用风险以及运营风险。</li><li>开发、保留和利用金融顾客关系，发展增值服务和个性化服务。</li></ul><h6 id="（2）通信行业"><a href="#（2）通信行业" class="headerlink" title="（2）通信行业"></a>（2）通信行业</h6><p>从运营数据中获得反映市场状况的有效信息，适时推出新业务，争夺有限的客户资源，减少客户流失率。</p><blockquote><p>预警功能：如果实际绩效偏离了预定目标，仪表盘就会自动向管理人员报警。</p></blockquote><h6 id="（3）零售行业"><a href="#（3）零售行业" class="headerlink" title="（3）零售行业"></a>（3）零售行业</h6><p>零售行业能否对品牌、产品、市场和运营效率做出快速、有效的决策就显得非常重要。通过对运营数据进行分析，开展数据库营销，零售企业就可以把握顾客的购买习惯，辅助品牌标识、产品分类和营销计划的优化，赢得顾客的忠诚。</p><p>如何对来源于网络营销、电子邮件、传真和电话等不同渠道的顾客数据进行整合和加工，深入分析顾客价值，寻找新顾客、交叉销售和提升销售机会，开展关系营销和直复式营销是非常重要的。</p><h6 id="（4）保健行业"><a href="#（4）保健行业" class="headerlink" title="（4）保健行业"></a>（4）保健行业</h6><p>商务智能也通过集成和分析企业研发、顾客管理等相关数据，降低研发成本，改善保健企业的运营。</p><p>允许制药和生物医学企业迅速把生物医学数据转换成临床洞察力，分析运营数据以及管理风险，比能够把分析结果转换成有效的药品治疗方案，优化药品组合，最大限度地从开发、许可、销售和营销业务中盈利。</p><h6 id="（5）其他行业"><a href="#（5）其他行业" class="headerlink" title="（5）其他行业"></a>（5）其他行业</h6><p>略。</p><hr><h2 id="第二章-商务智能系统架构"><a href="#第二章-商务智能系统架构" class="headerlink" title="第二章 商务智能系统架构"></a>第二章 商务智能系统架构</h2><h4 id="1、商务智能系统的组成"><a href="#1、商务智能系统的组成" class="headerlink" title="1、商务智能系统的组成"></a>1、商务智能系统的组成</h4><h6 id="（1）架构图"><a href="#（1）架构图" class="headerlink" title="（1）架构图"></a>（1）架构图</h6><p><img src="/2023/05/12/%E5%95%86%E5%8A%A1%E6%99%BA%E8%83%BD/2.1.png"></p><h6 id="（2）数据源与数据提取"><a href="#（2）数据源与数据提取" class="headerlink" title="（2）数据源与数据提取"></a>（2）数据源与数据提取</h6><p>数据是商务智能系统的基础，通常包括企业内部数据和外部数据：内部数据包括企业各种应用系统、办公自动化系统等产生的业务数据、文档等；外部数据包括有关市场、竞争对手的数据以及各类外部统计数据等。</p><blockquote><p>ETL工具：抽取（extrat）、转换（transform）、装载（load）</p></blockquote><h6 id="（3）数据仓库"><a href="#（3）数据仓库" class="headerlink" title="（3）数据仓库"></a>（3）数据仓库</h6><p>数据仓库的数据包括元数据和经过ETL的业务数据。元数据是关于数据的数据，主要包括数据源的描述、数据的抽取规则、数据的转换规则、数据的加载频率、数据仓库模型等。数据源中的数据按照元数据库的规则，经过抽取、清理、转换、集成，按照决策主题重新组织、存储。</p><h6 id="（4）访问工具"><a href="#（4）访问工具" class="headerlink" title="（4）访问工具"></a>（4）访问工具</h6><p>访问工具包括应用接口和中间件服务器。数据库中间件允许用户透明的访问数据仓库服务器，用于即席查询（ad-hoc query）、在线分析处理和数据挖掘。</p><h6 id="（5）决策支持工具"><a href="#（5）决策支持工具" class="headerlink" title="（5）决策支持工具"></a>（5）决策支持工具</h6><p>决策支持工具由即席查询、报表，在线分析处理和数据挖掘等组成。</p><p><img src="/2023/05/12/%E5%95%86%E5%8A%A1%E6%99%BA%E8%83%BD/2.2.png"></p><h4 id="2、数据集成"><a href="#2、数据集成" class="headerlink" title="2、数据集成"></a>2、数据集成</h4><p>数据来源广泛，数据格式更加多样，企业数据主要集中在文件系统、数据库和消息队列。</p><p>早期数据分析阶段，多库系统存在以下问题：</p><ul><li>可用性差：源数据库或通信网络故障导致系统瘫痪</li><li>响应速度慢：全局查询延迟和低层效率影响响应速度</li><li>系统性能低：总体性能取决于数据源中性能最差的系统</li><li>系统开销大：每次查询要启动通过多个系统，通信和运行开销大</li></ul><p><strong>数据集成的目的是要运用一定的技术手段把分布在异构系统中的数据按一定的规则组织成一个整体，使用户能有效地对其进行共享、分析，因此数据集成是构建数据仓库的基础。</strong></p><p>主数据管理和数据仓库是相辅相成的。它们都是减少数据冗余和不一致性的跨部门集中式系统，都依赖ETL、元数据管理等技术保证数据质量。</p><hr><h2 id="第三章-数据仓库"><a href="#第三章-数据仓库" class="headerlink" title="第三章 数据仓库"></a>第三章 数据仓库</h2><h4 id="1、从数据库到数据仓库"><a href="#1、从数据库到数据仓库" class="headerlink" title="1、从数据库到数据仓库"></a>1、从数据库到数据仓库</h4><p>企业的数据处理大致分为两类：一类是操作型处理，即在线事务处理，它是针对具体业务在数据库联机的日常操作，通常对少数记录进行查询、修改。另一类是分析型处理，一般针对某些主题的历史数据进行处理，支持管理决策。</p><ul><li>处理性能：操作型性能要求高、时间短；分析型资源占用多、时间长</li><li>数据集成：操作型处理通常较为分散；分析型处理是面向主题的，数据全面、准确，可以有效支持分析。</li><li>数据更新：操作型处理主要由原子事务组成，数据更新频繁，需要并行控制和恢复机制；分析型处理包含复杂的查询，大部分是只读操作。</li><li>数据时限：操作型只关注当前的数据；分析型着重于对历史数据的分析处理。</li><li>数据综合</li></ul><h6 id="详细比较"><a href="#详细比较" class="headerlink" title="详细比较"></a>详细比较</h6><p><img src="/2023/05/12/%E5%95%86%E5%8A%A1%E6%99%BA%E8%83%BD/3.1.png"></p><h4 id="2、数据仓库的概念"><a href="#2、数据仓库的概念" class="headerlink" title="2、数据仓库的概念"></a>2、数据仓库的概念</h4><p><strong>数据仓库就是面向主题（subject-oriented）、集成的（integrated）、非易失的（non-volatile）和时变的（time-variant）的数据集合用以支持管理决策。</strong></p><h6 id="特征一：面向主题"><a href="#特征一：面向主题" class="headerlink" title="特征一：面向主题"></a>特征一：面向主题</h6><p>在操作型数据库中，各个业务系统可能是相互分离的。数据仓库是面向主题的。每一个商业主题都对应于企业决策包含的分析对象。</p><h6 id="特征二：集成性"><a href="#特征二：集成性" class="headerlink" title="特征二：集成性"></a>特征二：集成性</h6><p>数据一般是相互独立、异构的。而数据仓库中的数据是对分散的数据进行抽取、清洗、转换和汇总后得到的，这样就保证了数据仓库内的数据的一致性。</p><h6 id="特征三：数据的非易失性"><a href="#特征三：数据的非易失性" class="headerlink" title="特征三：数据的非易失性"></a>特征三：数据的非易失性</h6><p>主要服务于日常的业务操作，使得数据库需要不断地对数据进行实时更新，以便迅速获得当前的最新数据，不致影响正常的业务操作。在数据仓库中只需要保存过去的业务数据，不需要每一笔业务都实时更新数据仓库，而是根据商业需要每隔一段时间把一批较新的数据导入数据仓库。</p><blockquote><p>非易失性主要是针对应用而言的。</p></blockquote><h6 id="特征四：数据的时变性"><a href="#特征四：数据的时变性" class="headerlink" title="特征四：数据的时变性"></a>特征四：数据的时变性</h6><p>数据仓库包含各种粒度的历史数据。</p><ul><li>数据仓库的数据时限一般要远远长于操作型数据的数据时限</li><li>操作型系统存储的是当前数据，而数据仓库中的数据是历史数据</li><li>数据仓库中的数据是按照时间顺序追加的，它们都带有时间属性</li></ul><h4 id="3、数据集市"><a href="#3、数据集市" class="headerlink" title="3、数据集市"></a>3、数据集市</h4><h6 id="（1）数据仓库的问题"><a href="#（1）数据仓库的问题" class="headerlink" title="（1）数据仓库的问题"></a>（1）数据仓库的问题</h6><ul><li>如果按“自顶而下”的方法建立企业级数据仓库，建设规模往往较大，建设周期长、投资大</li><li>在数据仓库建好后，随着使用数据仓库的部门增多，对数据仓库资源的竞争将成为企业面临的一个难题</li><li>各个部门都希望能定制数据仓库中的数据，但数据仓库是面向企业的</li></ul><h6 id="（2）数据集市"><a href="#（2）数据集市" class="headerlink" title="（2）数据集市"></a>（2）数据集市</h6><p>数据集市面向部门、业务单元或特定应用，因而规模较小，便于快速实现，且成本低廉，短期内即可获得明显效果。数据集市的应用不仅满足了部门的数据处理需求，而且作为数据仓库的子集有助于构建完整的企业级数据仓库。</p><blockquote><p>我们可以将数据集市看成是数据仓库的子集，也可以将数据仓库看成是多个数据集市的聚合，虽然在数学上这两句话表达的内容可能一样，但在这里有一个设计的先后顺序。</p></blockquote><h4 id="4、元数据"><a href="#4、元数据" class="headerlink" title="4、元数据"></a>4、元数据</h4><h6 id="（1）定义"><a href="#（1）定义" class="headerlink" title="（1）定义"></a>（1）定义</h6><p>数据仓库中的元数据是关于数据仓库中数据的数据。它的作用类似于数据库管理系统的数据字典，用于保存逻辑数据结构、文件、地址和索引等信息。从广义上讲，在数据仓库中，元数据是描述数据仓库内数据的结构和建立方法的数据。</p><p>元数据可分为技术元数据和业务元数据。技术元数据为开发和管理数据仓库的IT人员使用，它描述了与数据仓库开发、管理和维护相关的数据，包括数据源信息、数据转换描述、数据仓库模型、数据清洗与更新规则、数据映射和访问权限等。而业务元数据为管理和业务分析人员服务，从业务角度描述数据，包括商业术语、数据仓库中有什么数据、数据的位置和数据的可用性等，使业务人员更好地理解数据仓库中哪些数据是可用的以及如何使用它们。</p><h6 id="（2）存储方式"><a href="#（2）存储方式" class="headerlink" title="（2）存储方式"></a>（2）存储方式</h6><p>元数据有两种常见的存储方式：一种是以数据集为基础，每一个数据集都有对应的元数据文件，每一个数据文件包含对应数据集的元数据内容；另一种是以数据库为基础的，即元数据库。</p><blockquote><p>Hive和maxwell大部分采用的是第二种数据库为基础（我猜的，并没有实际查），Hive需要在MySQL中先创建metastore，而maxwell需要在MySQL中创建maxwell，里面存储的是统一生成的源数据表。</p></blockquote><h6 id="（3）元数据的作用"><a href="#（3）元数据的作用" class="headerlink" title="（3）元数据的作用"></a>（3）元数据的作用</h6><ul><li>描述哪些数据在数据仓库中，帮助决策分析者对数据仓库中的数据定位</li><li>定义数据进入数据仓库的方式，作为数据汇总、映射和清洗等的指南</li><li>记录业务事件的发生和随之进行的数据抽取工作的时间安排</li><li>记录并检测系统数据一致性的要求和执行情况</li><li>评估数据质量</li></ul><h4 id="5、ETL"><a href="#5、ETL" class="headerlink" title="5、ETL"></a>5、ETL</h4><h6 id="（1）数据抽取"><a href="#（1）数据抽取" class="headerlink" title="（1）数据抽取"></a>（1）数据抽取</h6><ul><li>确认数据源的数据及其含义</li><li>抽取。确定访问元数据库中的哪些文件或表，需要提取其中哪些字段</li><li>抽取频率。需要定期更新数据仓库的数据，因此对于不同的数据源需要确定数据抽取的频率</li><li>输出。数据输出的目的地和输出的格式</li><li>异常处理。当需要的数据无法抽取时如何处理</li></ul><h6 id="（2）数据转换"><a href="#（2）数据转换" class="headerlink" title="（2）数据转换"></a>（2）数据转换</h6><p>不同的数据源可能由不同的平台开发，使用不同的数据库管理系统，因此数据格式也可能不同。<strong>数据转换的主要任务是对数据粒度不一致的数据进行转化。</strong></p><ul><li>不一致数据的转换</li><li>数据粒度的转换</li></ul><h6 id="（3）数据清洗"><a href="#（3）数据清洗" class="headerlink" title="（3）数据清洗"></a>（3）数据清洗</h6><ul><li>缺失（missing）数据，即数据值的缺失。</li><li>错误数据。常见的错误数据包括字段的虚假值、异常取值等。</li><li>数据重复。</li><li>数据冲突。源数据中一些相关字段的值必须是兼容的。</li></ul><h6 id="（4）数据装载"><a href="#（4）数据装载" class="headerlink" title="（4）数据装载"></a>（4）数据装载</h6><ul><li>初始装载。一次对整个数据仓库进行装载。</li><li>增量装载。在数据仓库中，增量装载可以保证数据仓库与源数据变化的同期性。</li><li>完全刷新。周期性地重写整个数据仓库，有时也可能只对一些特定的数据进行刷新。</li></ul><h4 id="6、操作型数据存储"><a href="#6、操作型数据存储" class="headerlink" title="6、操作型数据存储"></a>6、操作型数据存储</h4><h6 id="操作型数据库、操作型数据存储和数据仓库之间的比较"><a href="#操作型数据库、操作型数据存储和数据仓库之间的比较" class="headerlink" title="操作型数据库、操作型数据存储和数据仓库之间的比较"></a>操作型数据库、操作型数据存储和数据仓库之间的比较</h6><p><img src="/2023/05/12/%E5%95%86%E5%8A%A1%E6%99%BA%E8%83%BD/img/3.2.png"></p><h4 id="7、数据仓库模型"><a href="#7、数据仓库模型" class="headerlink" title="7、数据仓库模型"></a>7、数据仓库模型</h4><h6 id="（1）概念模型"><a href="#（1）概念模型" class="headerlink" title="（1）概念模型"></a>（1）概念模型</h6><p>概念模型是用来表达信息世界中的信息结构，通常人们利用概念模型定义实际的数据需求。<strong>一般采用实体-关系（E-R）图作为概念模型。</strong></p><h6 id="（2）逻辑模型"><a href="#（2）逻辑模型" class="headerlink" title="（2）逻辑模型"></a>（2）逻辑模型</h6><ul><li>星型模型<ul><li>星型模型的核心是事实表，事实表把各种不同的维表连接起来。</li></ul></li><li>雪花模型<ul><li>某些维表中的数据可以进一步分解到附加的表中，以便减少冗余，节省存储空间</li><li>进一步标准化、规范化处理</li></ul></li><li>衍生模型<ul><li>星系模型：描述了数据仓库中多个事实表共享一个或多个维表的情况</li></ul></li></ul><p>逻辑模型设计包括确定数据仓库中数据粒度、数据分割策略、关系模式以及记录系统定义等工作。</p><h6 id="（3）物理模型"><a href="#（3）物理模型" class="headerlink" title="（3）物理模型"></a>（3）物理模型</h6><p>物理模型是逻辑模型在数据仓库中的实现，即数据仓库的物理分布模型，主要包含数据仓库的软硬件配置，数据的存储结构与索引、数据存放位置和存储分配等。</p><ul><li>设计数据仓库的物理模型<ul><li>确定项目资源</li><li>确定软硬件配置</li><li>数据仓库存储设计</li><li>数据仓库ETL策略</li></ul></li></ul><h4 id="8、数据挖掘查询语言"><a href="#8、数据挖掘查询语言" class="headerlink" title="8、数据挖掘查询语言"></a>8、数据挖掘查询语言</h4><p>数据挖掘语言是有数据挖掘原语定义的，如数据挖掘查询语言（Data Mining Query Language，DMQL）。DMQL是一种基于SQL的数据挖掘查询语言，包括定义数据仓库与数据集市、挖掘概念&#x2F;类描述、关联和分类等数据挖掘原语。数据挖掘语言提供了交互式数据挖掘工具，具有类似SQL的语法，易于与SQL集成。</p><blockquote><p>简单来说就是诸如HiveQL、Spark SQL等SQL语句都是为了方便开发者使用进行的封装。虽然外观上都是极其简单的SQL语句，但是本质上做着数据处理&#x2F;数据挖掘的工作（毕竟再复杂的功能底层也逃不过CRUD），这类QL语句实际上还是转换为操作原语进行执行，并非由QL语句直接执行。例如Spark中的Spark SQL实际上是将内容转换为RDD后执行。</p></blockquote><h4 id="9、数据湖"><a href="#9、数据湖" class="headerlink" title="9、数据湖"></a>9、数据湖</h4><p>数据湖是在大数据环境下，针对传统数据仓库的不足，提出的一种集中式数据存储技术。</p><p>数据湖只需要较低成本，就可以存储任意规模的原始数据，不需要预定义模型或者结构化处理就能进行各种数据分析。</p><p>数据湖由多个数据池组成，其属性包括数据更新频率、数据来源、数据量、数据选择标准、数据关系等，可以使用键、索引等元数据描述。</p><blockquote><p>这里留个坑，看到尚硅谷出过数据湖Hudi的视频，不过应该半年后才有计划看了，先留个坑在这。</p></blockquote><h4 id="10、数据中台"><a href="#10、数据中台" class="headerlink" title="10、数据中台"></a>10、数据中台</h4><p>数据中台是一个企业级的逻辑概念，本质上是一种用于数据共享的企业级系统，处于企业前台和后台之间的中间层，一般分为数据中台和业务中台。前台开发主要完成应用开发，后台开发主要工作是数据管理，而数据中台主要为企业内部提供数据服务。</p><p>数据中台要把共性的资源、能力整合到一起，把面向客户的价值独立出来。</p><h6 id="模块"><a href="#模块" class="headerlink" title="模块"></a>模块</h6><ul><li>数据治理</li><li>数据采集和存储</li><li>数据共享</li><li>数据业务价值提供：使数据价值最大化</li><li>数据服务与管理</li></ul><hr><h2 id="第四章-在线分析处理"><a href="#第四章-在线分析处理" class="headerlink" title="第四章 在线分析处理"></a>第四章 在线分析处理</h2><p>在线分析处理（OLAP），也称多维分析。</p><p>OLAP用于支持复杂的多维分析操作，并最终以一种直观易懂的方式把查询结果返回给分析人员，OLAP侧重于对中高层管理人员的决策支持。</p><h4 id="1、定义"><a href="#1、定义" class="headerlink" title="1、定义"></a>1、定义</h4><p>OLAP是一种共享多维信息的快速分析的技术；OLAP利用多维数据库技术使用户可以从不同的角度观察数据；OLAP用于支持复杂的分析操作，侧重于对管理人员的决策支持，可以满足分析人员快速、灵活地进行大数据量的复杂查询的需求，并且以一种直观易懂的观察形式进行快速、稳定一致和交互性的存取，允许管理人员对数据进行深入观察。</p><h4 id="2、特点"><a href="#2、特点" class="headerlink" title="2、特点"></a>2、特点</h4><h6 id="（1）快速"><a href="#（1）快速" class="headerlink" title="（1）快速"></a>（1）快速</h6><p>终端用户对系统的快速响应有很高的要求。</p><h6 id="（2）可分析"><a href="#（2）可分析" class="headerlink" title="（2）可分析"></a>（2）可分析</h6><p>用户可以应用OLAP平台分析数据，也可以使用其他外部分析工具。</p><h6 id="（3）共享"><a href="#（3）共享" class="headerlink" title="（3）共享"></a>（3）共享</h6><p>OLAP是只读的，仅需要简单的安全管理。</p><h6 id="（4）多维"><a href="#（4）多维" class="headerlink" title="（4）多维"></a>（4）多维</h6><p>维是OLAP的核心概念，多维性是OLAP的关键属性。</p><h4 id="3、OLTP和OLAP的区别"><a href="#3、OLTP和OLAP的区别" class="headerlink" title="3、OLTP和OLAP的区别"></a>3、OLTP和OLAP的区别</h4><p>OLTP是事件驱动、面向应用的，其主要的特点是对性能要求高，用户数量大。</p><p><img src="/2023/05/12/%E5%95%86%E5%8A%A1%E6%99%BA%E8%83%BD/img/4.1.png"></p><h4 id="4、OLAP分类"><a href="#4、OLAP分类" class="headerlink" title="4、OLAP分类"></a>4、OLAP分类</h4><h6 id="（1）按照处理地点分类"><a href="#（1）按照处理地点分类" class="headerlink" title="（1）按照处理地点分类"></a>（1）按照处理地点分类</h6><p>OLAP按照数据处理的地点可以分为服务器端在线分析处理（Server-side OLAP或Server OLAP）和客户端在线分析处理（Client-side OLAP或Client OLAP）。</p><h6 id="（2）按照存储方式分类"><a href="#（2）按照存储方式分类" class="headerlink" title="（2）按照存储方式分类"></a>（2）按照存储方式分类</h6><p>OLAP按照存储器的多维数据存储方式可以分为关系在线分析处理（relational OLAP，ROLAP）、多位在线分析处理（multi-dimensional OLAP，MOLAP）、桌面在线分析处理（desktop OLAP，DOLAP）和混合在线分析处理（hybrid OLAP，HOLAP）等。</p><hr><h2 id="第五章-数据挖掘（重点）"><a href="#第五章-数据挖掘（重点）" class="headerlink" title="第五章 数据挖掘（重点）"></a>第五章 数据挖掘（重点）</h2><blockquote><p>老实说第五章在本书的占比蛮重的，但是计科等单独学了数据挖掘这门课，我们这边零基础但是需要考试，如果压缩在本书的篇幅中会显得很不重要，所以决定单开一章数据挖掘进行学习。因为不只是《商务智能》，期末的《数据仓库》和《机器学习》对数据挖掘都有要求。但是时间关系不会在考试前把这个文档出出来了，但是会在期末前出出来。</p><p>同样，关于第六章及之后的内容本来不准备敲出来的，毕竟考试只考1、2、5、6，但是我把这本书看完了，多少还是有点收益的，所以会考虑将后续的章节补齐。</p></blockquote><h2 id="第六章-移动商务智能"><a href="#第六章-移动商务智能" class="headerlink" title="第六章 移动商务智能"></a>第六章 移动商务智能</h2><h4 id="1、移动商务"><a href="#1、移动商务" class="headerlink" title="1、移动商务"></a>1、移动商务</h4><p>移动商务作为一种新的电子交易模式，其主要特点包括以下几个方面：</p><ul><li><p>使用方便，移动端随时在线，用户不受时间和地域的限制，尤其对于响应时间很高的移动应用（如股票或期货交易）来说特别重要。</p></li><li><p>安全性高。目前移动商务安全技术已经可以提供封闭式端到端的无线传输层安全协议（WTLS），该协议提供认证和加密服务，可以安装在移动设备内的SIM卡上，除了允许使用者随身携带、任意插入移动设备内外使用外，还提供PIN码或身份验证机制。</p></li><li><p>定位能力强。可以随时追踪和定位移动用户所在区域，提供用户可能需要的区域性服务信息，从而促成服务提供商与用户交易。</p></li><li><p>容易实现个性化服务。服务提供商可以根据用户的消费习惯、爱好、历史消费记录和所处位置，提供个性化服务。</p></li></ul><h4 id="2、移动商务智能"><a href="#2、移动商务智能" class="headerlink" title="2、移动商务智能"></a>2、移动商务智能</h4><h6 id="（1）概念"><a href="#（1）概念" class="headerlink" title="（1）概念"></a>（1）概念</h6><p>移动商务智能是商务智能在移动商务领域的应用，一般通过移动终端采集相关数据，经企业商务智能系统查询分析、在线分析处理或数据挖掘后把结果在移动终端显示，为顾客提供个性化的信息，辅助移动员工做出决策的过程。</p><h6 id="（2）特点"><a href="#（2）特点" class="headerlink" title="（2）特点"></a>（2）特点</h6><ul><li>智能性</li><li>移动性</li><li>个性化</li><li>主动性</li></ul><h6 id="（3）应用"><a href="#（3）应用" class="headerlink" title="（3）应用"></a>（3）应用</h6><ul><li>移动支付用户信用评估</li><li>移动支付用户利润分析</li><li>移动支付用户类别分析</li><li>用户消费行为分析</li></ul><hr><h2 id="第七章-商务智能与知识管理"><a href="#第七章-商务智能与知识管理" class="headerlink" title="第七章 商务智能与知识管理"></a>第七章 商务智能与知识管理</h2><h4 id="1、知识管理概念"><a href="#1、知识管理概念" class="headerlink" title="1、知识管理概念"></a>1、知识管理概念</h4><p>知识是一个内涵丰富，外延广泛的概念，学术界对其有不同的定义。在知识管理的研究中，知识是指结构化的经验、价值。情景信息和专家认识的混合，提供了评估、整合新经验和信息的框架。知识可以有效地提升组织运作的能力。知识可以被分为显性知识( explicit knowledge)和隐性知识(tacit knowledge)，其中，显性知识是能用语言、符号、规则、公式或对象等表达，可以记录在一定物质载体上并可以共享的知识，例如书刊、报纸和技术文档等资料中的知识，而隐性知识则是存储在大脑中的经历、经验、技巧、诀窍,体会和感悟等很难表达的知识，例如钢琴师的演奏技巧，医生的临床经验等因长期从事某项业务而形成的判断力，洞察力和直觉。</p><h4 id="2、商务智能和知识管理的关系"><a href="#2、商务智能和知识管理的关系" class="headerlink" title="2、商务智能和知识管理的关系"></a>2、商务智能和知识管理的关系</h4><p>知识管理是伴随知识经济出现的一种创新管理，知识管理综合运用战略、组织、流程、技术、变化等多种措施和管理工具，以富有效率的方式组织资源实现其管理目标。商务智能则注重运用相关的技术来帮助企业管理层对运营数据进行分析,以提高企业决策水平。</p><p><img src="/2023/05/12/%E5%95%86%E5%8A%A1%E6%99%BA%E8%83%BD/img/7.1.png"></p><h4 id="3、商务智能和知识管理的区别"><a href="#3、商务智能和知识管理的区别" class="headerlink" title="3、商务智能和知识管理的区别"></a>3、商务智能和知识管理的区别</h4><ul><li>内涵不同</li><li>知识的管理过程和技术不同</li><li>关注的知识类型不同</li><li>面向的用户不同</li></ul><h4 id="4、商务智能和知识管理的联系"><a href="#4、商务智能和知识管理的联系" class="headerlink" title="4、商务智能和知识管理的联系"></a>4、商务智能和知识管理的联系</h4><ul><li>辅助决策</li></ul><p>商务智能和知识管理在一定程度上都可以辅助决策者利用知识更好地进行决策。商务智能是对企业深层知识进行获取，沉淀的一种重要方法。这些知识通常隐藏在数据中，不易被发现，如消费者的购物习惯、偏好等知识，挖掘这些模式有效地辅助企业人员，尤其是辅助中、高层的管理人员进行决策，使企业的管理决策实现由主观经验型到科学型转变。</p><ul><li>商务智能是知识获取的一种手段</li></ul><p><img src="/2023/05/12/%E5%95%86%E5%8A%A1%E6%99%BA%E8%83%BD/img/7.2.png"></p><hr><h2 id="第八章-Web挖掘"><a href="#第八章-Web挖掘" class="headerlink" title="第八章 Web挖掘"></a>第八章 Web挖掘</h2><p>利用文本挖掘进行网页聚类，利用结构挖掘改进搜索引擎，利用日志挖掘研究用户的使用模式等都是Web挖掘的典型应用。</p><h4 id="1、Web挖掘基础"><a href="#1、Web挖掘基础" class="headerlink" title="1、Web挖掘基础"></a>1、Web挖掘基础</h4><h6 id="（1）概念-1"><a href="#（1）概念-1" class="headerlink" title="（1）概念"></a>（1）概念</h6><p>Web挖掘的主要作用是通过收集，加工和处理涉及消费者消费行为的大量数据，确定特定用户群体或个体的兴趣、习惯、倾向和需求，进而推断相应用户群体或个体未来的使用行为，然后对所识别的用户群体进行特定内容的定向营销，从而为企业带来更多的利润，并提高企业的效率。Web挖掘典型的作用包括优化Web网站的结构，根据用户的喜好设计个性化的网站，留住老顾客、吸引新顾客，并降低运营成本以及提高电子商务安全等。</p><h6 id="（2）基本步骤"><a href="#（2）基本步骤" class="headerlink" title="（2）基本步骤"></a>（2）基本步骤</h6><p>主要步骤：数据预处理、模式识别、模式分析和可视化等</p><p><img src="/2023/05/12/%E5%95%86%E5%8A%A1%E6%99%BA%E8%83%BD/img/8.1.png"></p><h4 id="2、Web内容挖掘"><a href="#2、Web内容挖掘" class="headerlink" title="2、Web内容挖掘"></a>2、Web内容挖掘</h4><h6 id="（1）文本挖掘"><a href="#（1）文本挖掘" class="headerlink" title="（1）文本挖掘"></a>（1）文本挖掘</h6><p>以Web文本分析对象的文本挖掘称为Web文本挖掘。</p><ul><li>挖掘过程<strong>（困难很大）</strong></li></ul><p><img src="/2023/05/12/%E5%95%86%E5%8A%A1%E6%99%BA%E8%83%BD/img/8.2.png"></p><ul><li>挖掘方法：文本概括（summary）、文本分类和文本聚类等<ul><li>文本概括：<strong>文本概括是指从文本(集)中抽取关键信息，用简洁的形式总结文本(集)的主题内容。这样用户不须要阅读全文就可以对文本(集)的内容有一个比较全面的认识,以决定是否深人阅读。</strong>当前绝大部分搜索引擎采用的方法是简单地截取文本的前几行，这种方法显然存在一些缺陷。</li><li>文本分类：<strong>文本分类是把一些被标记的文本作为训练集，找到文本属性和文本类别之间的关系模型，然后利用这种关系模型来判断新文本的类别。</strong></li><li>文本聚类：<strong>文本聚类是根据文本的不同特征划分为不同的类，目的是是属于同一类的文本之间的差别尽可能小，而不同类别的文本之间的差别尽可能大。</strong>文本聚类和文本分类的区别是分类学习的样本有类别标记，而聚类的样本没有确定的类别，需要采用聚类算法来确定。</li></ul></li></ul><h6 id="（2）多媒体挖掘"><a href="#（2）多媒体挖掘" class="headerlink" title="（2）多媒体挖掘"></a>（2）多媒体挖掘</h6><p>Web多媒体挖掘是指从大量多媒体数据中通过综合分析视听特性和语义，发现隐含的、有价值的和可理解的模式，得出事件的趋向和关联，为用户提供决策支持。对于多媒体挖掘而言，主要是针对图像、音频、视频以及综合的多媒体数据进行分析，多媒体挖掘包括图像挖掘、视频挖掘和音频挖掘等类别。</p><ul><li>主要方法：基本的多媒体挖掘方法包括多媒体索引和检索,多媒体数据多维分析﹑多媒体数据的分类与预测以及多媒体数据关联挖掘等方法</li><li>体系结构</li></ul><p><img src="/2023/05/12/%E5%95%86%E5%8A%A1%E6%99%BA%E8%83%BD/img/8.3.png"></p><h4 id="3、Web结构挖掘与日志挖掘"><a href="#3、Web结构挖掘与日志挖掘" class="headerlink" title="3、Web结构挖掘与日志挖掘"></a>3、Web结构挖掘与日志挖掘</h4><h6 id="（1）结构挖掘"><a href="#（1）结构挖掘" class="headerlink" title="（1）结构挖掘"></a>（1）结构挖掘</h6><ul><li>Web结构挖掘是指挖掘Web链接结构模式，即通过分析页面链接的数量和对象，建立Web 的链接结构模式。</li><li>Web结构挖掘的典型应用包括信息检索、社区识别、网站优化和搜索引擎。</li></ul><h6 id="（2）日志挖掘"><a href="#（2）日志挖掘" class="headerlink" title="（2）日志挖掘"></a>（2）日志挖掘</h6><ul><li>Web日志挖掘是指从用户访问日志中获取有价值的信息。即通过分析 Web日志数据,发现访问者存取Web页面的模式,识别访问者的兴趣、频率、满意度，从而发现潜在用户，增强网站的竞争力。</li><li>Web日志挖掘在网站个性化设计、商业决策、改善系统性能和网站网页结构优化等方面是很有用的。</li></ul><hr><h2 id="第九章-商务智能在企业绩效管理中的应用"><a href="#第九章-商务智能在企业绩效管理中的应用" class="headerlink" title="第九章 商务智能在企业绩效管理中的应用"></a>第九章 商务智能在企业绩效管理中的应用</h2><p>商务智能与企业绩效管理的整合，将使企业真正关注绩效管理。在这个意义上讲，商务智能是绩效管理的重要技术支持。商务智能在共享信息、有效控制企业增长，创造新的利润以及降低成本等方面为绩效管理带来价值。</p><p>商务智能允许用户获得企业运营状况，从而具备透彻的业务洞察力，对企业绩效的调整实施更加游刃有余，更加灵活。、</p><p>商务智能与企业绩效管理是殊途同归的：<strong>一个企业可能有很多绩效目标，用户通过商务智能工具从目标建立开始一直到实施结束，始终进行跟踪监控。一旦发生偏差，就会分析找出出现问题的根源，及时通知企业相关人员。</strong></p><hr><h2 id="第十章-数据挖掘在电子商务中的应用"><a href="#第十章-数据挖掘在电子商务中的应用" class="headerlink" title="第十章 数据挖掘在电子商务中的应用"></a>第十章 数据挖掘在电子商务中的应用</h2><h4 id="1、电子商务需要数据挖掘"><a href="#1、电子商务需要数据挖掘" class="headerlink" title="1、电子商务需要数据挖掘"></a>1、电子商务需要数据挖掘</h4><p>网站只是一个面向用户的窗口，顾客通过网站来了解企业提供的服务，而企业也需要通过网站了解顾客的需求。顾客在浏览电子商务网站、参与交易的过程中会留下很多有用的数据。通过分析这些数据,电子商务企业可以了解用户的消费喜好和行为模式，以及网站的结构应如何改进等信息，从而为顾客提供更有针对性的营销手段和服务，满足顾客的潜在需求。随着电子商务交易量的不断增加，与顾客有关数据的不断增长，如何从大量的数据中挖掘有用的知识是非常重要的。</p><p>数据挖掘在电子商务中的具体应用可以表现为电子商务推荐系统、基于Web的个性化服务、电子商务Web网站优化和用户浏览行为模式分析等。在这些应用中，<strong>数据挖掘可以帮助电子商务企业更好地了解用户的潜在兴趣，提高用户个性化的服务水平，提升顾客价值。</strong></p><h4 id="2、我比较感兴趣的几个顾客管理运用"><a href="#2、我比较感兴趣的几个顾客管理运用" class="headerlink" title="2、我比较感兴趣的几个顾客管理运用"></a>2、我比较感兴趣的几个顾客管理运用</h4><blockquote><p>这里有很多个顾客管理的应用，但是我知道很多就算敲出来也不会有人看，就敲几个我自己最感兴趣的吧。</p></blockquote><h6 id="（1）个性化推荐"><a href="#（1）个性化推荐" class="headerlink" title="（1）个性化推荐"></a>（1）个性化推荐</h6><p>推荐系统有两个特点：<strong>一是主动性。分类目录和搜索引擎都可以解决信息过载的问题，但需要用户提供明确需求。</strong>如果用户不能精确描述需求，则很难为用户提供准确的结果。不同的是推荐系统不需要用户提供明确的需求，而是分析用户特性与物品属性，获得用户的偏好模型，从而主动为用户推荐感兴趣的物品或信息。<strong>二是个性化。推荐系统能够更好地挖掘长尾信息，根据用户可能的兴趣，推荐冷门物品，满足小部分用户的个性化需求。</strong></p><p>推荐系统可以用于电商平台、新闻媒体、视频平台、社交平台等。</p><h6 id="（2）词云图"><a href="#（2）词云图" class="headerlink" title="（2）词云图"></a>（2）词云图</h6><p>词云图的分析主要是对顾客评价内容进行分词和去停词，将不同词语出现的频率进行统计。然后将不同的字体颜色、字体大小以图形化的方式展示。<strong>通过词云图，用户可以直观感受到文本数据所表达的主要意思。</strong></p><p>目前市场上主流的分析方式有：SnowNLP分词，jieba精准模式分词和jieba全模式分词。</p><h6 id="（3）情感语义分析"><a href="#（3）情感语义分析" class="headerlink" title="（3）情感语义分析"></a>（3）情感语义分析</h6><p>目前比较流行的情感语义分析方法有两种：基于字典的情感语义分析和基于机器学习的情感语义分析。前者通过定义情感字典，对文本内容进行分词、去停等操作以后，计算情感值来获取文本的情感倾向；后者则是通过人工标注训练文本，对其进行有监督的机器学习，从而获得情感分析模型。SnowNLP是基于字符的生成模型，主要包含词性标注,情感分析、文本分类等功能，可以计算出每个评价的情感得分，得分越高，则用户好感度越高。</p><h4 id="3、网站结构优化"><a href="#3、网站结构优化" class="headerlink" title="3、网站结构优化"></a>3、网站结构优化</h4><p>一个网站的有效性并不仅仅包括所有网页的内容本身，还应该包括网站的结构。一个设计合理的网站，不仅能带给顾客便捷的访问体验，加深顾客对该网站的印象，还可以指导网站设计人员根据顾客的访问时间、访问地点、访问兴趣和访问频率等信息动态地调整网站的页面结构，优化页面链接，改进现有的搜索引擎，修改网站的结构，实现资源优化，从而有针对性地向顾客提供更全面的、更便捷的服务。</p><h4 id="4、智能搜索引擎"><a href="#4、智能搜索引擎" class="headerlink" title="4、智能搜索引擎"></a>4、智能搜索引擎</h4><h6 id="（1）文档自动分类"><a href="#（1）文档自动分类" class="headerlink" title="（1）文档自动分类"></a>（1）文档自动分类</h6><p>现有的网页分类技术主要基于特征向量，也就是提取网页中的几个关键词——网页特征关键词，并以此作为分类的标准。虽然这种分类的方法不需要人工完成，高效而客观，但其最大的缺陷在于分类的准确性比较低。为了有效地解决这个问题，许多搜索引擎采用了半人工、半自动化的方式。</p><p>一个网页在整个网站中所处的位置以及其他网页对该网页的链接，都体现了网站的管理者对于这个网页的内容与类别的定位。充分利用这些信息，有助于更准确、更高效地分析该网页。</p><h6 id="（2）自动文摘的形成"><a href="#（2）自动文摘的形成" class="headerlink" title="（2）自动文摘的形成"></a>（2）自动文摘的形成</h6><p>自动文摘是在搜索引擎抓取网页之后，自动从原始的文档中提取的能够又映该网页内容的摘要信息。</p><h6 id="（3）检索结果的联机聚类"><a href="#（3）检索结果的联机聚类" class="headerlink" title="（3）检索结果的联机聚类"></a>（3）检索结果的联机聚类</h6><p>搜索引擎首先响应用户的请求，在检索到满足用户要求的网页后，使用聚类技术，把结果集分为若干个簇。这样的聚类技术，通过各项特征，例如，满足条件的网页的URL、标题和相关的包含关键词的文档片段等，对这些网页进行快速地聚类分析，从而得到一系列表示了各种主题的簇。</p><hr><h2 id="第十一章-工作流挖掘"><a href="#第十一章-工作流挖掘" class="headerlink" title="第十一章 工作流挖掘"></a>第十一章 工作流挖掘</h2><p>工作流挖掘( workflow mining)，也叫流程挖掘( process mining)，是数据挖掘在工作流管理领域的应用，主要思想是<strong>利用数据挖掘技术从工作流日志中重构工作流模型，达到流程分析和流程优化的目的。</strong></p><p>目前，工作流挖掘的研究主要包括工作流模型重构、工作流监控与评价和组织视图挖掘等方面，其中工作流模型重构研究成果较多。</p><h4 id="1、工作流挖掘的概念与作用"><a href="#1、工作流挖掘的概念与作用" class="headerlink" title="1、工作流挖掘的概念与作用"></a>1、工作流挖掘的概念与作用</h4><h6 id="（1）概念-2"><a href="#（1）概念-2" class="headerlink" title="（1）概念"></a>（1）概念</h6><p>工作流挖掘是一个结合流程管理和数据挖掘的研究领域，它的初衷是通过对工作流(业务流程)运行产生的日志进行分析，重现业务流程的真实过程。</p><p>工作流挖掘的内容不仅包括流程模型的重构，还包括对流程的监控、评价以及组织视图的挖掘。工作流挖掘的意义不仅在于流程管理，也是企业知识管理的重要手段。</p><h6 id="（2）作用"><a href="#（2）作用" class="headerlink" title="（2）作用"></a>（2）作用</h6><p>工作流挖掘的主要作用包括<strong>工作流柔性管理、工作流模型的优化和工作流的智能管理</strong>等。</p><ul><li>工作流柔性管理：工作流挖掘从工作流执行阶段提取日志，通过把重构的工作流模型与原模型进行对比，从而实现工作流的柔性管理。</li><li>工作流模型的优化：工作流的生命周期分为工作流设计、工作流部署、工作流运行和工作流改进等阶段。与传统的工作流管理不同，工作流挖掘的日志来源于工作流运行阶段，而工作流挖掘主要关注于生命周期中的后两个阶段，通过对工作流模型的监控和重构弥补了传统工作流管理的不足。</li></ul><h4 id="2、工作流监控"><a href="#2、工作流监控" class="headerlink" title="2、工作流监控"></a>2、工作流监控</h4><p>工作流监控可以通过频繁模式挖掘实现，频繁模式挖掘可以发现工作流中经常出现的活动及其关系，帮助管理者及时了解工作流的变化情况。</p><p>工作流的监控还包括对工作流性能的实时监控。工作流性能包括时间，资源等评价指标，通过工作流性能的分析可以计算工作流的整体效率，分析流程的运行瓶颈等。</p><h4 id="3、工作流挖掘的应用"><a href="#3、工作流挖掘的应用" class="headerlink" title="3、工作流挖掘的应用"></a>3、工作流挖掘的应用</h4><h6 id="（1）流程监控"><a href="#（1）流程监控" class="headerlink" title="（1）流程监控"></a>（1）流程监控</h6><p>流程管理软件可以对业务流程的执行过程进行记录，传统的流程管理软件主要侧重于流程的自动化而缺乏对流程信息的分析，利用工作流挖掘技术可以分析发现重要的知识，帮助企业分析流程的失效和缺陷信息，改进业务流程的质量。工作流挖掘可以发现非正常流程，是流程监控的重要手段。</p><h6 id="（2）流程优化"><a href="#（2）流程优化" class="headerlink" title="（2）流程优化"></a>（2）流程优化</h6><p>流程挖掘技术可以检测到发生在业务单元的真实流程，而不只是与设计流程进行比较；流程挖掘技术有能力检测到真实的数据是否流向了假设的内部工作流，而不仅仅面向系统；人的固定思维容易产生盲点，但透明的真实流程可以帮助执行人员客观地发现特殊的欺诈行为。</p><h6 id="（3）社会关系分析等其他领域"><a href="#（3）社会关系分析等其他领域" class="headerlink" title="（3）社会关系分析等其他领域"></a>（3）社会关系分析等其他领域</h6><hr><h2 id="第十四章-商务智能进展"><a href="#第十四章-商务智能进展" class="headerlink" title="第十四章 商务智能进展"></a>第十四章 商务智能进展</h2><h4 id="新的趋势"><a href="#新的趋势" class="headerlink" title="新的趋势"></a>新的趋势</h4><ul><li><p>自动分析</p><p>数据的迅速增加以及数据的多态性，使得数据分析的复杂性和难度相应增加。因此，如何使数据分析的过程实现自动化，或者尽量减少人工的参与就成为数据分析领域的热点话题之一。自动机器学习，为整个数据分析项目的自动化提供了技术基础，这就增强了商务智能平台的易用性，降低了用户的使用门槛以及对数据科学家和专业数据分析人才的依赖，使企业各级人员都能使用商务智能平台的各种分析功能，提高了效率，满足了企业各级人员对信息和决策支持的需求。</p></li><li><p>数据素养</p><p>随着企业的数字化发展，掌握一定的数据分析能力将成为所有岗位的一种基本要求，这就是数据素养，也是企业顺利实现数字化转型的重要支撑。同时，保护用户的数据隐私、防止数据的滥用等数字道德问题也会提上日程。</p></li><li><p>泛在智能</p><p>企业经营环境越来越复杂化，从互联网＋到智能＋，企业内部、与供应链管理相关的边缘端等场景都离不开商务智能，商务智能正在慢慢渗透到各个行业、各个领域，从传统企业到新型互联网创业公司，孵化了许多新业态、新模式、新场景。这对商务智能平台的架构和分析技术提出了更高的要求。人工智能技术的发展，尤其是对多态数据(图像、视频、声音、文本等)的处理算法的广泛使用，将增强商务智能的使用范围和功能。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 我的大学 </category>
          
          <category> 大三下学期 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> 商务智能 </tag>
            
            <tag> 数据仓库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从ResNet入门卷积神经网络</title>
      <link href="/2023/05/07/%E4%BB%8EResNet%E5%85%A5%E9%97%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>/2023/05/07/%E4%BB%8EResNet%E5%85%A5%E9%97%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<p>众所周知数据科学与大数据技术实际上是以科研性质的的数据科学和纯技术力的大数据技术组成，学一半尚且非常吃力，而我又偏偏选了大数据技术方向。但是学历太低了，大数据技术也找不到工作，刚巧老师布置了个小论文的作业，趁着五一假期，从零点一（毕竟就算有意不学，但多少还是耳目渲染了点）开始恶补数据科学部分。</p><p>拿到选题之前，我连ResNet是什么都不清楚，放以前应该是照着书猛看，但是现在有ChatGPT和NewBing等人工智能了，所以优先找它了解一些情况比较迅速。事实证明我是对的，我让NewBing给我列了个论文提纲和目录，一下子就把学习方向明了了。回答如下：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">## 摘要</span></span><br><span class="line">深度神经网络在图像分类等任务上取得了显著的效果，但是随着网络层数的增加，训练和优化变得越来越困难。为了解决这个问题，本文介绍了一种深度残差网络（ResNet），它通过引入残差学习的机制，使得网络可以更容易地拟合恒等映射，从而避免了梯度消失和退化问题。本文详细分析了ResNet的原理和结构，并在CIFAR-10数据集上进行了实验，结果表明，ResNet可以有效地提高分类准确率，并且具有较低的参数量和计算复杂度。</span><br><span class="line"><span class="section">## 目录</span></span><br><span class="line"><span class="bullet">1.</span> 引言</span><br><span class="line"><span class="bullet">2.</span> 深度神经网络的挑战</span><br><span class="line">   2.1 梯度消失和爆炸</span><br><span class="line">   2.2 退化问题</span><br><span class="line"><span class="bullet">3.</span> 深度残差网络</span><br><span class="line">   3.1 残差学习</span><br><span class="line">   3.2 网络结构</span><br><span class="line">   3.3 短路连接</span><br><span class="line"><span class="bullet">4.</span> 实验与结果</span><br><span class="line">   4.1 数据集和实验设置</span><br><span class="line">   4.2 分类准确率</span><br><span class="line">   4.3 参数量和计算复杂度</span><br><span class="line"><span class="bullet">5.</span> 结论与展望</span><br></pre></td></tr></table></figure><p>第二步是针对每个小节让NewBing进行回答，虽然看上去它能直接把小论文写完了，但是事实并非一帆风顺。NewBing的上下文连贯性并不算特别好，前面几个小点还能连贯，后面就转向科普了，而且一旦一次线程爆了，一切就得重来。为了保持一致性，最终我还是选择采用他的目录内容，先学习再自己写写。（毕竟它要是真的全能写好养成习惯后我也就废了）</p><p>可能有人觉得ChatGPT会在回答上优于NewBing，让它写效果和作用会好很多。不过我个人并不建议这样，一是因为ChatGPT太优秀了，并非阻挡了自身的进步，而是它是给出的答案但凡有一句假话，给人带来的成本都是巨大的，科研是严谨的，不应该在自己不擅长的领域随意采用别人的观点；二是NewBing本质上还是一个搜索引擎，它未必能给我非常好的答案，但它能给我很多非常好的作者的博客链接，能够让我自己动手去找答案。</p><p>第三步我也没有急于直接去学习ResNet，短时间学会本来就很难，花大量时间莽撞的学习效率会很低。我先去了解了下小论文的书写格式，毕竟最终应该出来的是一篇像模像样的论文，而不是东拼西凑的文段。</p><p>参照文章《[知网查重入口教您论文写作的字体格式规范](<a href="https://www.cnki.ac.cn/write/294.html#:~:text=%E7%9F%A5%E7%BD%91%E6%9F%A5%E9%87%8D%E5%85%A5%E5%8F%A3%E6%95%99%E6%82%A8%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C%E7%9A%84%E5%AD%97%E4%BD%93%E6%A0%BC%E5%BC%8F%E8%A7%84%E8%8C%83">https://www.cnki.ac.cn/write/294.html#:~:text=知网查重入口教您论文写作的字体格式规范</a> 1 1、论文标题 使用2号黑体加粗、居中。 2 2、论文副标题 使用小2号的字体，紧挨正标题下居中，文字前加破折号。 3,另起一页开始，标题使用4号黑体，内容使用5号宋体。 7 8、附录 标题使用4号黑体，内容使用5号宋体。 8 9、注释 标题使用4号黑体，内容使用5号宋体。 )》最终将格式确定如下：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">1、论文标题</span><br><span class="line"><span class="code">使用2号黑体加粗、居中。</span></span><br><span class="line"><span class="code">2、论文副标题</span></span><br><span class="line"><span class="code">使用小2号的字体，紧挨正标题下居中，文字前加破折号。</span></span><br><span class="line"><span class="code">3、个人信息</span></span><br><span class="line"><span class="code">填写姓名、专业、学号等项目时用3号楷体。</span></span><br><span class="line"><span class="code">4、目录</span></span><br><span class="line"><span class="code">目录要另起一页开始写作，标题为3号黑体，内容使用小4号仿宋，并且要罗列出页码。</span></span><br><span class="line"><span class="code">5、正文部分</span></span><br><span class="line"><span class="code">要保证另起一页，开始写作，论文的标题使用3号黑体完成；而主体的文字部分，一般采用用小4号宋体；并且还要注意，每段要空两个字的距离再开始写作，行距也需要保持一致。</span></span><br><span class="line"><span class="code">6、正文中不同等级的标题格式要求</span></span><br><span class="line"><span class="code">一级标题：标题前的序号为“一、”，4号黑体；独占一行；注意末尾不加标点符号。</span></span><br><span class="line"><span class="code">二级标题：标题前的序号为“(一)”同正文部分的字体大小相同；独占一行；注意末尾不加标点符号。</span></span><br><span class="line"><span class="code">三级标题：标题前的序号为“1.”同正文部分的字体大小、字体类型相同。</span></span><br><span class="line"><span class="code">四级标题：标题前的序号为“(1)”同正文部分的字体大小、字体类型相同。</span></span><br><span class="line"><span class="code">五级标题：标题前的序号为“①”同正文部分的字体大小、字体类型相同。</span></span><br><span class="line"><span class="code">7、参考文献</span></span><br><span class="line"><span class="code">另起一页开始，标题使用4号黑体，内容使用5号宋体。</span></span><br><span class="line"><span class="code">8、注释</span></span><br><span class="line"><span class="code">标题使用4号黑体，内容使用5号宋体。</span></span><br></pre></td></tr></table></figure><p>同样，我也找了两篇知网上的论文进行参照，不过ResNet科普的论文并不存在，大部分是使用其进行调优的，这里只是用作格式的参考。</p><p>第四步就比较枯燥无味了，主打一个查资料学习，在这里先吐槽一下我们组的选题人（虽然我不知道是谁），ResNet的前置知识有VGG使用块的网络，而想知道VGG就得去看看AlexNet，而学AlexNet就需要明白CNN到底想干嘛，而CNN是卷积神经网络的起点，也就是说你得先明白神经网络是什么，为什么要卷积。也就是说：如果这篇ResNet小论文能顺利写出来，那么写个VGG、AlexNet的问题也不大，这些是其他组的选题。回归正题，下面会记录下我在查资料过程中碰到的一些专业词汇（一般是你不知道干啥就会影响观感的），方便到时候写小论文的时候啪啪啪往上放。</p><p>那么，我最终决定以《<a href="https://zh.d2l.ai/index.html">动手学深度学习</a>》这本书的第六章卷积神经网络和第七章现代循环神经网络为起点，加上一些个博客（会在最后标注出来），开始我这从ResNet入门神经网络的文档。</p><h4 id="从全连接到卷积"><a href="#从全连接到卷积" class="headerlink" title="从全连接到卷积"></a>从全连接到卷积</h4><h6 id="（1）设计适合于计算机视觉的神经网络架构"><a href="#（1）设计适合于计算机视觉的神经网络架构" class="headerlink" title="（1）设计适合于计算机视觉的神经网络架构"></a>（1）设计适合于计算机视觉的神经网络架构</h6><ul><li>平移不变性（translation invariance）：不管检测对象出现在图像中的哪个位置，神经网络的前面几层应该对相同的图像区域具有相似的反应，即为“平移不变性”。</li><li>局部性（locality）：神经网络的前面几层应该只探索输入图像中的局部区域，而不过度在意图像中相隔较远区域的关系，这就是“局部性”原则。最终，可以聚合这些局部特征，以在整个图像级别进行预测。</li></ul><blockquote><p>如果你不能很好的理解这两句话的内涵，我建议作为科普看看我喜欢的一个UP主林亦LYi的《<a href="https://www.bilibili.com/video/BV19P4y1q7GD/?spm_id_from=333.999.0.0&vd_source=a81ef8427e696b92de364d833142bd10">【亦】手机杀死了摄影？</a>》，6分28秒开始讲解经典的人脸检测算法，很好的诠释了这两句话。</p></blockquote><h6 id="（2）【古早】全连接的多层感知机"><a href="#（2）【古早】全连接的多层感知机" class="headerlink" title="（2）【古早】全连接的多层感知机"></a>（2）【古早】全连接的多层感知机</h6><p>我不是很能很好的陈述数学上的表现形式，但书上大部分以公式来进行讲解，所以在这我用自己的口语化表达简单介绍下这些流程。</p><p>首先是多层感知机：以图像为例，在计算机处理中我们可以将一张图看成是二维矩阵。这里需要了解权重张量的概念，还记得在最优化&#x2F;计算智能学的梯度下降吗？简而言之，权重张量就是使用梯度下降之类算法得到的两组数据之间的关联性，比如一个红色向蓝色渐变的过程，只关注首尾（输入&#x2F;输出）的话你是只能看到红色和蓝色的，但是微观上来说，如果这两个颜色存在关联，那么就必然会有一个红色衰减、蓝色增强的过程，嗯，我认为叫做趋势&#x2F;极限可能比较合适，而这个变化的幅度，也就是数学上常说的斜率，就是权重张量。</p><blockquote><p>权重张量是神经网络中的一个重要概念。它是一个多维数组，用于存储神经网络中每个连接的权重。在神经网络的前向传播过程中，输入数据会与权重张量相乘，然后通过激活函数进行非线性变换，最终得到输出结果。在训练过程中，权重张量会不断更新，以便更好地拟合训练数据。</p></blockquote><p>那么再来看它的数学公式：</p><p><img src="/2023/05/07/%E4%BB%8EResNet%E5%85%A5%E9%97%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/7.png"></p><p>其实你很难想象他到底是想干什么，貌似这些参数该训练的都训练了，最终得到的也并不是有意义的结果。我在这里也纠结了很久，最终还是有了点头绪，别急，听我细细道来。</p><p>还是以红蓝渐变这个例子为中心，当你训练完成后，上面的每个参数应该都是已知的。这个时候我又来了一个白红蓝三色渐变的图片（不考虑缩放），你把上面训练好的二维数据往上面一贴，在误差范围内的，能够完全贴合的部分就能被“找到”，这就是识别出来了。</p><p>不过这个过程会比较漫长，因为公式中的（i，j）表示输出坐标，（k，l）表示输入坐标，四个自变量会导致计算过程指数级增长，而匹配过程又需要将输入的图从头扫到尾（极端情况下还需要反转、倒置），这种全扫描的方式就是全连接。</p><blockquote><p>我并不知道我讲的对不对，反正我也就学了一个下午，讲错了大家会见谅的吧！</p></blockquote><h6 id="（3）卷积"><a href="#（3）卷积" class="headerlink" title="（3）卷积"></a>（3）卷积</h6><p>关于卷积，我们让NewBing通俗易懂的讲讲？</p><blockquote><p>卷积是一种数学运算，它在图像处理和计算机视觉中非常常用。可以把它看作是一种“滤波器”，它能够提取图像中的某些特定特征。</p><p>举个例子，假设我们有一张数字图像，它由许多像素点组成。我们可以定义一个卷积核，它是一个小矩阵，包含一些数字。然后，我们将卷积核放在图像的左上角，将卷积核中的每个数字与其下方的像素值相乘，然后将所有乘积相加，得到一个新的数字。这个新数字就是卷积的结果。</p><p>接下来，我们将卷积核向右移动一个像素，重复上述过程，再得到一个新数字。我们继续这样做，直到卷积核移动到图像的右下角。最终，我们会得到一个新的矩阵，它包含了原图像经过卷积后的结果。</p><p>不同的卷积核能够提取不同的特征。例如，有些卷积核能够检测边缘，有些能够模糊图像，有些能够锐化图像等等。在卷积神经网络中，卷积核通常是通过训练学习得到的，能够自动提取图像中最有用的特征。</p></blockquote><blockquote><p>卷积是一种数学运算，它在信号处理和图像处理中非常常用。在数学上，卷积被定义为两个函数f和g的卷积，记为f∗g，其定义为：</p><p>(f∗g)(t) &#x3D; ∫f(τ)g(t-τ)dτ</p><p>在离散情况下，卷积可以表示为：</p><p>(f∗g)[n] &#x3D; ∑f[k]g[n-k]</p><p>在神经网络中，卷积通常用于处理图像数据。假设我们有一个图像I和一个卷积核K，它们的卷积可以表示为：</p><p>S[i,j] &#x3D; (I∗K)[i,j] &#x3D; ∑m∑nI[m,n]K[i-m,j-n]</p><p>其中S是卷积的结果。可以看到，卷积的过程就是将卷积核在图像上滑动，并计算每个位置上的加权和。</p><p>在卷积神经网络中，卷积层通常包含多个卷积核，每个卷积核都能够提取图像中的一种特定特征。通过堆叠多个卷积层，网络能够学习到越来越复杂的特征表示。</p></blockquote><p>看了NewBing说的你可能更加迷糊了，这仿佛和全连接没有区别啊？我们通过公式可以看出权重张量参数从4个下降到了两个，这代表了稳定性显著下降，但是训练时间也会下降。我们以一个人的头像来举例：如果我需要用全连接的方式来识别，那么我就需要知道两个眼睛之间的比例、眼睛和鼻子的比例等等各种比例，但是不同部位的比例越多，其实越不利于人脸的识别，因为不同部位的误差势必会被放大。这个时候卷积就发挥它的作用了：虽然单个卷积结果的精度会下降，但是如果将其用来表示更小的窗口，实际上精度是提升了的。还是这个例子：如果一个卷积只处理鼻子的比例，一个卷积只处理眼睛的比例，最后将其综合起来，那么关于单个部位的精度实际上是提升了。同样，因为窗口更小，训练集也能更小，时间和成本都能一定程度下降（我猜的），最关键的是根据优先级可以大幅减少无用计算：比如一个合格的人像一定要露出眼睛，那如果我检测不到眼睛的图像就可以直接抛弃了，并不需要去检测鼻子，但是全连接就做不到。</p><p>这个时候我们再回来看这个数学公式：</p><p><img src="/2023/05/07/%E4%BB%8EResNet%E5%85%A5%E9%97%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/8.png"></p><p>这时候卷积神经网络的雏形就出现了。</p><h6 id="（4）通道"><a href="#（4）通道" class="headerlink" title="（4）通道"></a>（4）通道</h6><p>书上虽然叫通道，但其实我更想将其称之为维度。还是以上面提到的红蓝渐变为例，我们都知道三原色红黄蓝在计算机中为RGB三个参数，那么图像其实就不只表示为二维，按书上说的至少是三维（长、宽、颜色），当然，不勉强的来说用长、宽、深举例更方便理解：比如一个红色的球在一个蓝色的幕布前面，那么“前面”就是图像的深度。既然如此，那多出来的维度怎么表示？</p><p>答案是回到全连接。当然并不是指全部回到从前，而是参数类似于全连接。我们知道全连接的权重张量会包含两点间的长、宽作为变量，一共是4个参数。通过卷积，我们可以将两点之间的关联交给其他卷积，只处理两个变量。会有两个变量是因为需要以一个坐标作为参照，即只取一点的长、宽。那么三维呢？每个点就有了长、宽、高的变量，全连接下两点之间的权重张量就有6个参数。之后在进行卷积，就能有效地减少参数。</p><blockquote><p>我猜理论上如果卷积分的足够多的话，那么最终就只剩下维度&#x2F;通道个参数了。</p></blockquote><h6 id="（5）卷积神经网络【LeNet】"><a href="#（5）卷积神经网络【LeNet】" class="headerlink" title="（5）卷积神经网络【LeNet】"></a>（5）卷积神经网络【LeNet】</h6><p>总体来看，LeNet（LeNet-5）由两个部分组成：</p><ul><li>卷积编码器：由两个卷积层组成;</li><li>全连接层密集块：由三个全连接层组成。</li></ul><p><img src="/2023/05/07/%E4%BB%8EResNet%E5%85%A5%E9%97%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/9.png"></p><h6 id="（5）总结"><a href="#（5）总结" class="headerlink" title="（5）总结"></a>（5）总结</h6><ul><li><p>图像的平移不变性使我们以相同的方式处理局部图像，而不在乎它的位置。</p></li><li><p>局部性意味着计算相应的隐藏表示只需一小部分局部图像像素。</p></li><li><p>在图像处理中，卷积层通常比全连接层需要更少的参数，但依旧获得高效用的模型。</p></li><li><p>卷积神经网络（CNN）是一类特殊的神经网络，它可以包含多个卷积层。</p></li><li><p>多个输入和输出通道使模型在每个空间位置可以获取图像的多方面特征。</p></li><li><p>在卷积神经网络中，我们组合使用卷积层、非线性激活函数和汇聚层。</p></li><li><p>为了构造高性能的卷积神经网络，我们通常对卷积层进行排列，逐渐降低其表示的空间分辨率，同时增加通道数。</p></li><li><p>在传统的卷积神经网络中，卷积块编码得到的表征在输出之前需由一个或多个全连接层进行处理。</p></li><li><p>LeNet是最早发布的卷积神经网络之一。</p></li></ul><hr><h2 id="小论文部分"><a href="#小论文部分" class="headerlink" title="小论文部分"></a>小论文部分</h2><blockquote><p>有了如上的基础，加上大量的查阅数据，最终得到小论文如下：</p></blockquote><h4 id="一、引言"><a href="#一、引言" class="headerlink" title="一、引言"></a>一、引言</h4><p>深度神经网络（DNN）是一种模仿生物神经系统的计算模型，它由多层非线性单元组成，能够从数据中学习抽象和复杂的特征表示。DNN在图像分类、语音识别、自然语言处理、计算机视觉等领域取得了令人瞩目的成果，成为人工智能的重要技术之一。</p><p>然而，DNN也面临着许多挑战，其中之一就是如何有效地训练和部署深层的网络结构。随着网络层数的增加，DNN往往会遇到梯度消失或爆炸、退化问题、过拟合问题等，导致训练困难和性能下降。此外，DNN也需要大量的计算资源和存储空间，给硬件平台和系统架构带来了巨大的压力和挑战。</p><p>为了解决这些问题，研究者们提出了许多有效的方法，其中最具代表性的就是残差网络（ResNet）。ResNet是由何恺明等人于2015年提出的一种创新的网络结构，它通过引入残差学习的机制，使得网络可以更容易地拟合恒等映射，从而避免了梯度消失和退化问题。ResNet在ILSVRC 2015图像分类比赛中获得了冠军，并在其他许多任务上也取得了优异的表现⁴。</p><p>本文旨在对ResNet进行全面的介绍和分析，主要包括以下几个方面：</p><p>第二部分介绍深度神经网络面临的主要挑战，包括梯度消失和爆炸、退化问题等，并分析其原因和影响。</p><p>第三部分介绍残差网络的原理和结构，包括残差学习、短路连接、网络设计等，并分析其优势和局限性。</p><p>第四部分介绍残差网络在CIFAR-10数据集上的实验结果，包括分类准确率、参数量和计算复杂度等，并与其他网络进行对比和分析。</p><p>第五部分总结本文的主要内容，并展望残差网络的未来发展方向和应用领域。</p><h4 id="二、深度神经网络的挑战"><a href="#二、深度神经网络的挑战" class="headerlink" title="二、深度神经网络的挑战"></a>二、深度神经网络的挑战</h4><h6 id="（一）梯度消失和爆炸"><a href="#（一）梯度消失和爆炸" class="headerlink" title="（一）梯度消失和爆炸"></a>（一）梯度消失和爆炸</h6><p>随着现代卷积神经网络的发展，各种网络卷积层次不断提高。在VGG中，卷积网络达到了19层，在GoogLeNet中，网络史无前例的达到了22层。在深度学习中，网络层数增多一般会伴着以下问题：计算资源的消耗、模型容易过拟合、梯度消失&#x2F;梯度爆炸问题的产生。</p><p>前两者分别可以通过GPU集群提高资源、配合Dropout正则化方法等方式解决。而对于第三者，在深度神经网络中，当网络的层数增加时，反向传播算法计算出来的梯度会不断缩小，甚至趋近于零，这就是所谓的“梯度消失”问题。当梯度接近于零时，权重更新变得非常缓慢，导致模型无法学习到正确的特征表示。与梯度消失相反，梯度爆炸是指在深度神经网络中，梯度变得非常大的情况。当梯度变得太大时，权重更新可能会变得非常剧烈，导致模型出现不稳定的训练行为。</p><h6 id="（二）退化问题"><a href="#（二）退化问题" class="headerlink" title="（二）退化问题"></a>（二）退化问题</h6><p>退化问题指的是深度神经网络的精度随着层数的增加而出现下降的情况。当网络的层数较浅时，网络可以通过学习简单的特征表示来实现分类或回归等任务。但当网络的层数增加时，由于输入输出的分布变得复杂，模型需要学习更多的特征表示才能够提高模型的性能。然而，当网络的层数增加到一定程度时，网络的性能反而开始下降，这就是所谓的“退化”问题。</p><p>造成退化问题的原因主要包括两个方面：（1）梯度消失和爆炸；（2）网络权重的预训练效果不佳。</p><p>解决方式之一就是使用残差网络的来解决。残差网络(ResNet)通过增加跨层连接来解决退化问题，使得网络可以学习到更复杂的特征表示。ResNet中使用了残差块(Residual Block)，在网络中添加跨层连接，可以使得信息在网络中更加流畅地传递，避免梯度消失和退化问题。</p><h4 id="三、深度残差网络"><a href="#三、深度残差网络" class="headerlink" title="三、深度残差网络"></a>三、深度残差网络</h4><h6 id="（一）理论研究"><a href="#（一）理论研究" class="headerlink" title="（一）理论研究"></a>（一）理论研究</h6><p><img src="/2023/05/07/%E4%BB%8EResNet%E5%85%A5%E9%97%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/1.jpg" alt="图1.1 函数类"></p><p>在没有残差的网络中，随着网络层数加深，网络的表征能力越来越强，但是网络表征能够学习到的最优点与实际中的最优点（图中的星号）往往是越来越远的，如上图中左边部分所示。</p><p>残差网络的目的是使得，随着网络深度的加深，模型的能够表征的最优点至少是不比浅层网络表征的最优点差，如上图中右边部分所示。</p><p>在实际的经验中，在神经网络的训练结果上体现为：随着搭建神经网络的层数的增加，错误率一开始下降，后来反而上升。上升的错误率不仅是在测试集上，同样也在训练集上，因此这种错误和过拟合无关。</p><h6 id="（二）网络结构"><a href="#（二）网络结构" class="headerlink" title="（二）网络结构"></a>（二）网络结构</h6><p>残差网络是由一系列残差块组成的（图1）。一个残差块可以用表示为：</p><p><img src="/2023/05/07/%E4%BB%8EResNet%E5%85%A5%E9%97%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2.png" alt="img"></p><p>残差块分成两部分直接映射部分和残差部分。<img src="/2023/05/07/%E4%BB%8EResNet%E5%85%A5%E9%97%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/3.png" alt="img">是直接映射，反应在图1中是左边的曲线；<img src="/2023/05/07/%E4%BB%8EResNet%E5%85%A5%E9%97%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/4.png" alt="img">是残差部分，一般由两个或者三个卷积操作构成，即下图中右侧包含卷积的部分。</p><p><img src="/2023/05/07/%E4%BB%8EResNet%E5%85%A5%E9%97%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/5.jpg" alt="图1.2 残差块"></p><p>ResNet采用了非常深的网络结构，其中包括多个残差块。每个残差块都由两个卷积层和一个跨层连接组成，如图所示。</p><p><img src="/2023/05/07/%E4%BB%8EResNet%E5%85%A5%E9%97%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/6.jpg" alt="图1.2 残差网络激活函数"></p><p>在传统的卷积神经网络中，每个卷积层都会对输入进行变换，从而得到新的特征表示。而在ResNet中，每个残差块通过跨层连接将输入的信息直接传递到输出中。这使得网络可以学习到更加复杂的特征表示，从而提高了模型的性能。</p><h6 id="（三）短路连接"><a href="#（三）短路连接" class="headerlink" title="（三）短路连接"></a>（三）短路连接</h6><p>短路连接（shortcut connections）是ResNet中非常重要的一部分。短路连接可以将输入的信息直接传递到输出中，从而避免了信息在网络中的损失。具体来说，在残差块中，短路连接可以让输入的信息直接绕过卷积层，并加到输出上。这样可以保留原始输入的信息，同时也增加了网络的深度。</p><p>除了在第一层和最后一层之外，ResNet中的每个卷积层都包含了短路连接。这种结构可以让信息在网络中更加流畅地传递，解决了传统卷积神经网络中的退化问题。同时，短路连接还可以使得网络更加容易优化，加快网络的收敛速度。</p><h4 id="四、实验与结果"><a href="#四、实验与结果" class="headerlink" title="四、实验与结果"></a>四、实验与结果</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义残差块</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResidualBlock</span>(nn.Module):</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels, stride=<span class="number">1</span></span>):</span><br><span class="line"><span class="built_in">super</span>(ResidualBlock, self).__init__()</span><br><span class="line"><span class="comment"># 第一个卷积层</span></span><br><span class="line">self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">3</span>, stride=stride, padding=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">self.bn1 = nn.BatchNorm2d(out_channels)</span><br><span class="line">self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 第二个卷积层</span></span><br><span class="line">self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">self.bn2 = nn.BatchNorm2d(out_channels)</span><br><span class="line"><span class="comment"># 短路连接</span></span><br><span class="line">self.shortcut = nn.Sequential()</span><br><span class="line"><span class="keyword">if</span> stride != <span class="number">1</span> <span class="keyword">or</span> in_channels != out_channels:</span><br><span class="line">self.shortcut = nn.Sequential(</span><br><span class="line">nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">1</span>, stride=stride, bias=<span class="literal">False</span>),</span><br><span class="line">nn.BatchNorm2d(out_channels)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">identity = x</span><br><span class="line">out = self.conv1(x)</span><br><span class="line">out = self.bn1(out)</span><br><span class="line">out = self.relu(out)</span><br><span class="line">out = self.conv2(out)</span><br><span class="line">out = self.bn2(out)</span><br><span class="line">out += self.shortcut(identity)   <span class="comment"># 短路连接</span></span><br><span class="line">out = self.relu(out)</span><br><span class="line"><span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义残差网络</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResNet</span>(nn.Module):</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, block, num_blocks, num_classes=<span class="number">10</span></span>):</span><br><span class="line"><span class="built_in">super</span>(ResNet, self).__init__()</span><br><span class="line">self.in_channels = <span class="number">16</span></span><br><span class="line"><span class="comment"># 第一层卷积层</span></span><br><span class="line">self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">16</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">self.bn1 = nn.BatchNorm2d(<span class="number">16</span>)</span><br><span class="line">self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 残差块</span></span><br><span class="line">self.layer1 = self.make_layer(block, <span class="number">16</span>, num_blocks[<span class="number">0</span>], stride=<span class="number">1</span>)</span><br><span class="line">self.layer2 = self.make_layer(block, <span class="number">32</span>, num_blocks[<span class="number">1</span>], stride=<span class="number">2</span>)</span><br><span class="line">self.layer3 = self.make_layer(block, <span class="number">64</span>, num_blocks[<span class="number">2</span>], stride=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># 全局平均池化层和全连接层</span></span><br><span class="line">self.avg_pool = nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">self.fc = nn.Linear(<span class="number">64</span>, num_classes)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_layer</span>(<span class="params">self, block, out_channels, num_blocks, stride</span>):</span><br><span class="line">strides = [stride] + [<span class="number">1</span>] * (num_blocks - <span class="number">1</span>)   <span class="comment"># 下采样的步长只在第一个残差块中使用</span></span><br><span class="line">layers = []</span><br><span class="line"><span class="keyword">for</span> stride <span class="keyword">in</span> strides:</span><br><span class="line">layers.append(block(self.in_channels, out_channels, stride))</span><br><span class="line">self.in_channels = out_channels</span><br><span class="line"><span class="keyword">return</span> nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">out = self.conv1(x)</span><br><span class="line">out = self.bn1(out)</span><br><span class="line">out = self.relu(out)</span><br><span class="line">out = self.layer1(out)</span><br><span class="line">out = self.layer2(out)</span><br><span class="line">out = self.layer3(out)</span><br><span class="line">out = self.avg_pool(out)</span><br><span class="line">out = out.view(out.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">out = self.fc(out)</span><br><span class="line"><span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建ResNet-18模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet18</span>():</span><br><span class="line"><span class="keyword">return</span> ResNet(ResidualBlock, [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试模型</span></span><br><span class="line">model = resnet18()</span><br><span class="line"><span class="built_in">print</span>(model)</span><br><span class="line">x = torch.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>)</span><br><span class="line">y = model(x)</span><br><span class="line"><span class="built_in">print</span>(y.size())</span><br></pre></td></tr></table></figure><p>ResidualBlock类中定义了一个ResNet的残差块，这里实现的是基本的残差块结构，由两个卷积层和一个短路连接组成。其中，第一个卷积层使用3x3的卷积核，stride&#x3D;1，padding&#x3D;1；第二个卷积层也使用3x3的卷积核，stride&#x3D;1，padding&#x3D;1。如果输入和输出维度不一致，则通过1x1的卷积操作（即短路连接）将输入调整为与输出维度相同。</p><p>ResNet类中定义了整个ResNet网络模型。该模型中包含了多个残差块层，并通过全局平均池化层和全连接层进行分类。<code>make_layer</code>函数用于构建多个残差块，并通过for循环来重复调用残差块，形成一个完整的残差块层。在训练过程中，可以根据需求修改残差块层数目或者变换每个残差块中的卷积核大小等参数。</p><p>对于正向计算，首先对输入数据进行预处理（即conv1和bn1），然后依次执行多个残差块层，最后通过全局平均池化层将输出转换为一维向量，并通过全连接层进行分类。</p><p>该代码的训练过程通常包括以下几个步骤：定义损失函数和优化器；设置超参数，如学习率、迭代次数等；对训练集进行数据增强操作；开始训练模型，并在每个epoch结束后对验证集进行测试并计算准确率。可以根据训练过程中的验证集精度调整模型的超参数。</p><h4 id="五、结论与展望"><a href="#五、结论与展望" class="headerlink" title="五、结论与展望"></a>五、结论与展望</h4><p>该代码实现了一个ResNet-18模型，并通过CIFAR10数据集对其进行了测试。该模型具有较强的分类能力和泛化能力，且训练过程中的收敛速度较快。从代码实现的角度来看，该模型的关键部分包括残差块和残差网络。残差块使用了短路连接的方法，在保证网络深度增加的同时避免了梯度消失问题，有效提高了模型性能。而残差网络则通过多个残差块层的组合，进一步增加了网络的深度和复杂度，使得模型在图像分类等任务中表现出色。</p><p>当前，ResNet已经成为了深度学习领域中广泛应用的模型之一，并在许多计算机视觉任务中取得了不俗的表现。未来，可以考虑利用ResNet的设计思想，进一步深化网络架构，提高模型的性能和效率。其中，可能的方向包括：</p><p>模型小型化：针对移动设备等资源受限的场景，可以尝试对ResNet进行精简，减少参数量和计算复杂度，提高模型的部署效率和速度。</p><p>跨域学习：将ResNet应用于不同领域的任务中，如语音识别、自然语言处理等，探索其在多个领域中的适用性和迁移性。</p><p>模型优化：通过集成学习、超参调优、模型剪枝等方法，进一步提高ResNet的性能和泛化能力。此外，也可以考虑结合其他深度学习模型或传统机器学习方法，以达到更好的效果。</p><h4 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h4><p>[1] 阿斯顿·张,李沐.动手学深度学习[M].人民邮电出版社.2023</p><p>[2] 张贤同学.PyTorch ResNet 使用与源码解析[EB&#x2F;OL].<a href="https://zhuanlan.zhihu.com/p/225597229,2021-11-28">https://zhuanlan.zhihu.com/p/225597229,2021-11-28</a>.</p><p>[3] 罗夏-felix.深度学习：残差网络（ResNet），理论及代码结构[EB&#x2F;OL].<a href="https://zhuanlan.zhihu.com/p/455442102.2022-01-14">https://zhuanlan.zhihu.com/p/455442102.2022-01-14</a></p><p>[4] 大师兄.详解残差网络[EB&#x2F;OL].<a href="https://zhuanlan.zhihu.com/p/42706477.2018-08-22">https://zhuanlan.zhihu.com/p/42706477.2018-08-22</a></p><p>[5] 晚饭吃什么.超级详细的ResNet代码解读（Pytorch）[EB&#x2F;OL].<a href="https://zhuanlan.zhihu.com/p/474790387.2023-01-14">https://zhuanlan.zhihu.com/p/474790387.2023-01-14</a></p>]]></content>
      
      
      <categories>
          
          <category> Little Tips </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 卷积神经网络 </tag>
            
            <tag> 残差网络 </tag>
            
            <tag> ResNet </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark从0到1（下）</title>
      <link href="/2023/04/20/Spark%E4%BB%8E0%E5%88%B01%EF%BC%88%E4%B8%8B%EF%BC%89/"/>
      <url>/2023/04/20/Spark%E4%BB%8E0%E5%88%B01%EF%BC%88%E4%B8%8B%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h2 id="第四章-Spark-Streaming：流计算"><a href="#第四章-Spark-Streaming：流计算" class="headerlink" title="第四章 Spark Streaming：流计算"></a>第四章 Spark Streaming：流计算</h2><h4 id="1、概述"><a href="#1、概述" class="headerlink" title="1、概述"></a>1、概述</h4><h6 id="（1）流计算"><a href="#（1）流计算" class="headerlink" title="（1）流计算"></a>（1）流计算</h6><p>流数据是一组顺序、大量、快速、连续可达的数据序列，可被视为一个随时间延续而不断增长的动态数据集合。具有以下特点：</p><ul><li>数据实时到达</li><li>数据到达次序独立，不受应用系统控制</li><li>数据规模宏大且不能预知其最大值</li><li>数据一经处理，除非特意保存，否则不能被再次取出处理，如果再次提取数据则代价昂贵</li></ul><h6 id="（2）批处理与流处理"><a href="#（2）批处理与流处理" class="headerlink" title="（2）批处理与流处理"></a>（2）批处理与流处理</h6><p>根据数据处理的时效性，大数据处理系统可分为批大数据处理系统和流大数据处理系统两类。</p><ul><li>批处理<ul><li>批处理主要操作大容量静态数据集，并在计算过程完成后返回结果。批处理模式中使用的数据集通常符合下列特征：<ul><li>有界，批处理数据集代表数据的有限集合</li><li>持久，数据通常始终存储在某种类型的持久存储位置中。</li><li>量大，批处理操作通常是处理极为海量的数据集的唯一方法。</li></ul></li><li>批处理非常适合需要访问全套记录才能完成的计算工作，例如在计算总数和平均数时，必须将数据集作为一个整体加以处理。</li></ul></li><li>流处理<ul><li>流处理系统会对随时进入系统的数据进行计算。相比批处理模式，这是一种截然不同的处理方式。流处理方式无须针对整个数据集执行操作，而是对系统传输的每个数据项执行操作。</li><li>流处理中的数据集是“无边界”的，完整数据集只能代表截至目前已经进入到系统中的数据总量；流处理工作是基于事件的，除非明确停止否则没有“尽头”；流处理结果立即可用；并会随着新数据的抵达持续更新。</li><li>流处理很适合用来处理必须对变动或者峰值做出响应，并且关注一段时间的变化趋势的数据。</li></ul></li></ul><h6 id="（3）Spark-Sreaming"><a href="#（3）Spark-Sreaming" class="headerlink" title="（3）Spark Sreaming"></a>（3）Spark Sreaming</h6><p>Spark Streaming 用于流式数据的处理。Spark Streaming 支持的数据输入源很多，例如：Kafka、 Flume、Twitter、ZeroMQ 和简单的 TCP 套接字等等。数据输入后可以用 Spark 的高度抽象原语 如：map、reduce、join、window 等进行运算。而结果也能保存在很多地方，如 HDFS，数据库等。</p><p>和 Spark 基于 RDD 的概念很相似，Spark Streaming 使用离散化流(discretized stream)作为抽象表示，叫作 DStream。DStream 是随时间推移而收到的数据的序列。在内部，每个时间区间收到的数据都作为 RDD 存在，而 DStream 是由这些 RDD 所组成的序列（因此得名“离散化”）。所以 简单来讲，DStream 就是对 RDD 在实时数据处理场景的一种封装。</p><h4 id="2、Spark-Streaming架构"><a href="#2、Spark-Streaming架构" class="headerlink" title="2、Spark Streaming架构"></a>2、Spark Streaming架构</h4><h6 id="（1）架构图"><a href="#（1）架构图" class="headerlink" title="（1）架构图"></a>（1）架构图</h6><p><img src="/2023/04/20/Spark%E4%BB%8E0%E5%88%B01%EF%BC%88%E4%B8%8B%EF%BC%89/4.1.png"></p><h6 id="（2）背压机制"><a href="#（2）背压机制" class="headerlink" title="（2）背压机制"></a>（2）背压机制</h6><p>Spark 1.5 以前版本，用户如果要限制 Receiver 的数据接收速率，可以通过设置静态配制参数“spark.streaming.receiver.maxRate”的值来实现，此举虽然可以通过限制接收速率，来适配当前的处理能力，防止内存溢出，但也会引入其它问题。比如：producer 数据生产高于 maxRate，当 前集群处理能力也高于 maxRate，这就会造成资源利用率下降等问题。</p><p>为了更好的协调数据接收速率与资源处理能力，1.5 版本开始 Spark Streaming 可以动态控制 数据接收速率来适配集群数据处理能力。<strong>背压机制（即 Spark Streaming Backpressure）: 根据 JobScheduler 反馈作业的执行信息来动态调整 Receiver 数据接收率。</strong></p><p>通过属性“spark.streaming.backpressure.enabled”来控制是否启用 backpressure 机制，默认值 false，即不启用。</p><h4 id="3、运行原理"><a href="#3、运行原理" class="headerlink" title="3、运行原理"></a>3、运行原理</h4><p>Spark Streaming是构建在Spark Core上的实时流计算框架，扩展了Spark Core处理流式大数据的能力。Spark Streaming将数据流以时间片为单位分割形成一系列RDD（一个RDD对应一块分割数据），这些RDD在Spark Streaming中用一个抽象数据模型DStream（Discretized Stream，离散流）来描述，DStream表示从数据源获取的持续性数据流和经过转换后的数据流。</p><h6 id="DStream和RDD的对应关系"><a href="#DStream和RDD的对应关系" class="headerlink" title="DStream和RDD的对应关系"></a>DStream和RDD的对应关系</h6><p><img src="/2023/04/20/Spark%E4%BB%8E0%E5%88%B01%EF%BC%88%E4%B8%8B%EF%BC%89/4.2.png"></p><p>DStream可以通过输入数据源来创建，比如Kafka、Flume和Kinesis；也可以通过对其他DStream应用进行map、reduce、join等操作来创建。使用RDD操作处理DStream中的每一个RDD，每个RDD都会生成一个Spark job，然后提交给Spark集群进行计算，批量生成最终的结果，最后将结果批量输出到HDFS或者数据库以及前端页面展示等。</p><h6 id="基本工作原理"><a href="#基本工作原理" class="headerlink" title="基本工作原理"></a>基本工作原理</h6><p><img src="/2023/04/20/Spark%E4%BB%8E0%E5%88%B01%EF%BC%88%E4%B8%8B%EF%BC%89/4.3.png"></p><p>Spark Streaming使用“微批次”的架构，即把流式计算当作一系列连续的小规模批处理来对待。Spark Streaming从输入源中读取数据，并把数据分组为小的批次。新的批次按均匀的时间间隔被创建出来，即在每个时间区间开始时，一个新的批次被创建出来，并且在该区间内收到的数据都会被添加到这个批次中；在时间区间结束时，批次停止增长。其中，时间区间的长短是由批处理间隔决定的，批处理间隔一般设为500ms到几秒，由应用开发者配置。每次输入批次都会生成一个RDD，Spark以作业的方式处理和生成其他的RDD，然后就可以对其他的RDD进行转换操作，最后将RDD经过行动操作生成的中间结果保存在内存中。整个流式计算根据业务的需求可以对中间的结果进行叠加，最后形成“批”形式的结果流给外部系统。</p><h4 id="4、以WordCount入门DStream"><a href="#4、以WordCount入门DStream" class="headerlink" title="4、以WordCount入门DStream"></a>4、以WordCount入门DStream</h4><blockquote><p>需求：使用 netcat 工具向 9999 端口不断的发送数据，通过 SparkStreaming 读取端口数据并统计不同单词出现的次数</p></blockquote><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">StreamWordCount</span> </span>&#123;</span><br><span class="line">     <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"> <span class="comment">//1.初始化 Spark 配置信息</span></span><br><span class="line"> <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;StreamWordCount&quot;</span>)</span><br><span class="line"> <span class="comment">//2.初始化 SparkStreamingContext</span></span><br><span class="line"> <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">3</span>))</span><br><span class="line"> <span class="comment">//3.通过监控端口创建 DStream，读进来的数据为一行行</span></span><br><span class="line"> <span class="keyword">val</span> lineStreams = ssc.socketTextStream(<span class="string">&quot;linux1&quot;</span>, <span class="number">9999</span>)</span><br><span class="line"> <span class="comment">//将每一行数据做切分，形成一个个单词</span></span><br><span class="line"> <span class="keyword">val</span> wordStreams = lineStreams.flatMap(_.split(<span class="string">&quot; &quot;</span>))</span><br><span class="line"> <span class="comment">//将单词映射成元组（word,1）</span></span><br><span class="line"> <span class="keyword">val</span> wordAndOneStreams = wordStreams.map((_, <span class="number">1</span>))</span><br><span class="line"> <span class="comment">//将相同的单词次数做统计</span></span><br><span class="line"> <span class="keyword">val</span> wordAndCountStreams = wordAndOneStreams.reduceByKey(_+_)</span><br><span class="line"> <span class="comment">//打印</span></span><br><span class="line"> wordAndCountStreams.print()</span><br><span class="line"> <span class="comment">//启动 SparkStreamingContext</span></span><br><span class="line"> ssc.start()</span><br><span class="line"> ssc.awaitTermination()</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="解析"><a href="#解析" class="headerlink" title="解析"></a>解析</h6><p>Discretized Stream 是 Spark Streaming 的基础抽象，代表持续性的数据流和经过各种 Spark 原语操作后的结果数据流。在内部实现上，DStream 是一系列连续的 RDD 来表示。每个 RDD 含有 一段时间间隔内的数据。</p><blockquote><p>因此，实际上可以将一段时间内的处理当成一个完整的RDD执行，以上述例子为例，Streaming监听3秒一打印，那么在这3秒内读取到的数据就是一个完整的RDD，各批次之间的数据互不干涉。比如你在前3秒发送了两个hello spark，一个hello streaming，第四秒发送了一个hello spark，那么实际上的输出是两个批次，第一批次为(hello, 3) (spark, 2) (streaming, 1)；第二批次为(hello, 1) (streaming, 1)。批次之间不会累计，但是我们任能通过构建RDD对各批次结果进行聚合。</p></blockquote><h4 id="5、不同数据源"><a href="#5、不同数据源" class="headerlink" title="5、不同数据源"></a>5、不同数据源</h4><h6 id="（1）自定义数据源"><a href="#（1）自定义数据源" class="headerlink" title="（1）自定义数据源"></a>（1）自定义数据源</h6><p>需求：自定义数据源，实现监控某个端口号，获取该端口号内容。</p><p>提示：需要继承 Receiver，并实现 onStart、onStop 方法来自定义数据源采集。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CustomerReceiver</span>(<span class="params">host: <span class="type">String</span>, port: <span class="type">Int</span></span>) <span class="keyword">extends</span> <span class="title">Receiver</span>[<span class="type">String</span>](<span class="params"><span class="type">StorageLevel</span>.<span class="type">MEMORY_ONLY</span></span>) </span>&#123;</span><br><span class="line">    <span class="comment">//最初启动的时候，调用该方法，作用为：读数据并将数据发送给 Spark</span></span><br><span class="line"> <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onStart</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line"> <span class="keyword">new</span> <span class="type">Thread</span>(<span class="string">&quot;Socket Receiver&quot;</span>) &#123;</span><br><span class="line"> <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>() &#123;</span><br><span class="line"> receive()</span><br><span class="line"> &#125;</span><br><span class="line"> &#125;.start()</span><br><span class="line"> &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">//读数据并将数据发送给 Spark</span></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">receive</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line"> <span class="comment">//创建一个 Socket</span></span><br><span class="line"> <span class="keyword">var</span> socket: <span class="type">Socket</span> = <span class="keyword">new</span> <span class="type">Socket</span>(host, port)</span><br><span class="line"> <span class="comment">//定义一个变量，用来接收端口传过来的数据</span></span><br><span class="line"> <span class="keyword">var</span> input: <span class="type">String</span> = <span class="literal">null</span></span><br><span class="line"> <span class="comment">//创建一个 BufferedReader 用于读取端口传来的数据</span></span><br><span class="line"> <span class="keyword">val</span> reader = <span class="keyword">new</span> <span class="type">BufferedReader</span>(<span class="keyword">new</span> <span class="type">InputStreamReader</span>(socket.getInputStream, </span><br><span class="line"><span class="type">StandardCharsets</span>.<span class="type">UTF_8</span>))</span><br><span class="line"> <span class="comment">//读取数据</span></span><br><span class="line"> input = reader.readLine()</span><br><span class="line"> <span class="comment">//当 receiver 没有关闭并且输入数据不为空，则循环发送数据给 Spark</span></span><br><span class="line"> <span class="keyword">while</span> (!isStopped() &amp;&amp; input != <span class="literal">null</span>) &#123;</span><br><span class="line"> store(input)</span><br><span class="line"> input = reader.readLine()</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="comment">//跳出循环则关闭资源</span></span><br><span class="line"> reader.close()</span><br><span class="line"> socket.close()</span><br><span class="line"> <span class="comment">//重启任务</span></span><br><span class="line"> restart(<span class="string">&quot;restart&quot;</span>)</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onStop</span></span>(): <span class="type">Unit</span> = &#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用方式：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//3.创建自定义 receiver 的 Streaming</span></span><br><span class="line"><span class="keyword">val</span> lineStream = ssc.receiverStream(<span class="keyword">new</span> <span class="type">CustomerReceiver</span>(<span class="string">&quot;hadoop102&quot;</span>, <span class="number">9999</span>))</span><br></pre></td></tr></table></figure><h6 id="（2）Kafka数据源（重点）"><a href="#（2）Kafka数据源（重点）" class="headerlink" title="（2）Kafka数据源（重点）"></a>（2）Kafka数据源（重点）</h6><p><strong>Kafka 0-10 Direct 模式</strong></p><p>需求：通过 SparkStreaming 从 Kafka 读取数据，并将读取过来的数据做简单计算，最终打印到控制台。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.&#123;<span class="type">ConsumerConfig</span>, <span class="type">ConsumerRecord</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.&#123;<span class="type">DStream</span>, <span class="type">InputDStream</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka010.&#123;<span class="type">ConsumerStrategies</span>, <span class="type">KafkaUtils</span>, <span class="type">LocationStrategies</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">DirectAPI</span> </span>&#123;</span><br><span class="line">     <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"> <span class="comment">//1.创建 SparkConf</span></span><br><span class="line"> <span class="keyword">val</span> sparkConf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;ReceiverWordCount&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line"> <span class="comment">//2.创建 StreamingContext</span></span><br><span class="line"> <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">3</span>))</span><br><span class="line"> <span class="comment">//3.定义 Kafka 参数</span></span><br><span class="line"> <span class="keyword">val</span> kafkaPara: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Object</span>] = <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Object</span>](</span><br><span class="line"> <span class="type">ConsumerConfig</span>.<span class="type">BOOTSTRAP_SERVERS_CONFIG</span> -&gt; </span><br><span class="line"><span class="string">&quot;linux1:9092,linux2:9092,linux3:9092&quot;</span>,</span><br><span class="line"> <span class="type">ConsumerConfig</span>.<span class="type">GROUP_ID_CONFIG</span> -&gt; <span class="string">&quot;atguigu&quot;</span>,</span><br><span class="line"> <span class="string">&quot;key.deserializer&quot;</span> -&gt; </span><br><span class="line"><span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>,</span><br><span class="line"> <span class="string">&quot;value.deserializer&quot;</span> -&gt; </span><br><span class="line"><span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span></span><br><span class="line"> )</span><br><span class="line"> <span class="comment">//4.读取 Kafka 数据创建 DStream</span></span><br><span class="line"> <span class="keyword">val</span> kafkaDStream: <span class="type">InputDStream</span>[<span class="type">ConsumerRecord</span>[<span class="type">String</span>, <span class="type">String</span>]] = </span><br><span class="line"><span class="type">KafkaUtils</span>.createDirectStream[<span class="type">String</span>, <span class="type">String</span>](ssc,</span><br><span class="line"> <span class="type">LocationStrategies</span>.<span class="type">PreferConsistent</span>,</span><br><span class="line"> <span class="type">ConsumerStrategies</span>.<span class="type">Subscribe</span>[<span class="type">String</span>, <span class="type">String</span>](<span class="type">Set</span>(<span class="string">&quot;atguigu&quot;</span>), kafkaPara))</span><br><span class="line"> <span class="comment">//5.将每条消息的 KV 取出</span></span><br><span class="line"> <span class="keyword">val</span> valueDStream: <span class="type">DStream</span>[<span class="type">String</span>] = kafkaDStream.map(record =&gt; record.value())</span><br><span class="line"> <span class="comment">//6.计算 WordCount</span></span><br><span class="line"> valueDStream.flatMap(_.split(<span class="string">&quot; &quot;</span>))</span><br><span class="line"> .map((_, <span class="number">1</span>))</span><br><span class="line"> .reduceByKey(_ + _)</span><br><span class="line"> .print()</span><br><span class="line"> <span class="comment">//7.开启任务</span></span><br><span class="line"> ssc.start()</span><br><span class="line"> ssc.awaitTermination()</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="6、操作DStream"><a href="#6、操作DStream" class="headerlink" title="6、操作DStream"></a>6、操作DStream</h4><p>DStream 上的操作与 RDD 的类似，分为 Transformations（转换）和 Output Operations（输 出）两种，此外转换操作中还有一些比较特殊的原语，如：updateStateByKey()、transform()以及 各种 Window 相关的原语。</p><blockquote><p>可以简单分为三类：无状态转换操作、有状态转换操作、输出操作</p></blockquote><p>这里只对各种操作进行一个简单的概述，并不对其中的代码做过多分析，开发环境中需要的时候可以针对性查找。</p><h6 id="（1）无状态转换操作"><a href="#（1）无状态转换操作" class="headerlink" title="（1）无状态转换操作"></a>（1）无状态转换操作</h6><p>无状态转化操作就是把简单的 RDD 转化操作应用到每个批次上，也就是转化 DStream 中的每 一个 RDD。注意，<strong>针对键值对的 DStream 转化操作(比如 reduceByKey())要添加 import StreamingContext._才能在 Scala 中使用。</strong></p><p><img src="/2023/04/20/Spark%E4%BB%8E0%E5%88%B01%EF%BC%88%E4%B8%8B%EF%BC%89/4.4.png"></p><p>需要记住的是，尽管这些函数看起来像作用在整个流上一样，但事实上每个 DStream 在内部是由许多 RDD（批次）组成，且无状态转化操作是分别应用到每个 RDD 上的。</p><p><strong>Transform</strong></p><p>Transform 允许 DStream 上执行任意的 RDD-to-RDD 函数。即使这些函数并没有在 DStream 的 API 中暴露出来，通过该函数可以方便的扩展 Spark API。该函数每一批次调度一次。其实也就是对 DStream 中的 RDD 应用转换。</p><p><strong>join</strong></p><p>两个流之间的 join 需要两个流的批次大小一致，这样才能做到同时触发计算。计算过程就是 对当前批次的两个流中各自的 RDD 进行 join，与两个 RDD 的 join 效果相同。</p><h6 id="（2）有状态转换操作"><a href="#（2）有状态转换操作" class="headerlink" title="（2）有状态转换操作"></a>（2）有状态转换操作</h6><p><strong>UpdateStateByKey</strong></p><p>UpdateStateByKey 原语用于记录历史记录，有时，我们需要在 DStream 中跨批次维护状态(例 如流计算中累加 wordcount)。针对这种情况，updateStateByKey()为我们提供了对一个状态变量的访问，用于键值对形式的 DStream。给定一个由(键，事件)对构成的 DStream，并传递一个指 定如何根据新的事件更新每个键对应状态的函数，它可以构建出一个新的 DStream，其内部数据为(键，状态) 对。</p><p>updateStateByKey() 的结果会是一个新的 DStream，其内部的 RDD 序列是由每个时间区间对应的(键，状态)对组成的。</p><p><strong>WindowOperations</strong></p><p>Window Operations 可以设置窗口的大小和滑动窗口的间隔来动态的获取当前 Steaming 的允许状态。所有基于窗口的操作都需要两个参数，分别为窗口时长以及滑动步长。</p><h6 id="（3）输出"><a href="#（3）输出" class="headerlink" title="（3）输出"></a>（3）输出</h6><p>输出操作指定了对流数据经转化操作得到的数据所要执行的操作(例如把结果推入外部数据库 或输出到屏幕上)。与 RDD 中的惰性求值类似，如果一个 DStream 及其派生出的 DStream 都没 有被执行输出操作，那么这些 DStream 就都不会被求值。如果 StreamingContext 中没有设定输出 操作，整个 context 就都不会启动。</p><hr><h2 id="第五章-Spark-GraphX：图计算-amp-amp-Spark-MLlib：机器学习"><a href="#第五章-Spark-GraphX：图计算-amp-amp-Spark-MLlib：机器学习" class="headerlink" title="第五章 Spark GraphX：图计算 &amp;&amp; Spark MLlib：机器学习"></a>第五章 Spark GraphX：图计算 &amp;&amp; Spark MLlib：机器学习</h2><h4 id="1、Spark-GraphX"><a href="#1、Spark-GraphX" class="headerlink" title="1、Spark GraphX"></a>1、Spark GraphX</h4><p><a href="https://juejin.cn/post/6926541204372848654">大数据开发-Spark-初识Spark-Graph &amp;&amp; 快速入门</a></p><h4 id="2、Spark-MLlib"><a href="#2、Spark-MLlib" class="headerlink" title="2、Spark MLlib"></a>2、Spark MLlib</h4><p><a href="https://juejin.cn/post/7069390174437769246">初识 Spark MLlib 机器学习</a></p><hr><blockquote><p>以下内容为进阶知识咯！虽说考试是考一点点的GraphX和MLlib，但是拜托，这是Spark从0到1，不是考试从0到100哦！所以后续重点介绍Spark内核和最最最常见的灵魂发问：数据倾斜的解决办法。</p><p>Spark内核会省略掉一些比较底层的调度策略（虽然确实很重要），主要从Shuffle和底层执行原理以及内存管理进行介绍。</p></blockquote><h2 id="第六章-Spark-Shuffle解析"><a href="#第六章-Spark-Shuffle解析" class="headerlink" title="第六章 Spark Shuffle解析"></a>第六章 Spark Shuffle解析</h2><p>在 MapReduce 框架中，Shuffle 阶段是连接 Map 与 Reduce 之间的桥梁，Map 阶段通过 Shuffle 过程将数据输出到 Reduce 阶段中。由<strong>于 Shuffle 涉及磁盘的读写和网络 I&#x2F;O，因此 Shuffle 性能的高低直接影响整个程序的性能。</strong> Spark 也有 Map 阶段和 Reduce 阶段，因此也会出现 Shuffle 。</p><h4 id="1、Shuffle-的核心要点"><a href="#1、Shuffle-的核心要点" class="headerlink" title="1、Shuffle 的核心要点"></a>1、Shuffle 的核心要点</h4><p><img src="/2023/04/20/Spark%E4%BB%8E0%E5%88%B01%EF%BC%88%E4%B8%8B%EF%BC%89/6.1.png"></p><p>在划分 stage 时，最后一个 stage 称为 finalStage，它本质上是一个 ResultStage 对象，前面的所有 stage 被称为 ShuffleMapStage。</p><p>ShuffleMapStage 的结束伴随着 shuffle 文件的写磁盘。</p><p>ResultStage 基本上对应代码中的 action 算子，即将一个函数应用在 RDD 的各个 partition 的数据集上，意味着一个 job 的运行结束。</p><h4 id="2、HashShuffle解析"><a href="#2、HashShuffle解析" class="headerlink" title="2、HashShuffle解析"></a>2、HashShuffle解析</h4><h6 id="（1）未优化的HashShuffle"><a href="#（1）未优化的HashShuffle" class="headerlink" title="（1）未优化的HashShuffle"></a>（1）未优化的HashShuffle</h6><p>这里我们先明确一个假设前提：每个 Executor 只有 1 个 CPU core，也就是说，无论这 个 Executor 上分配多少个 task 线程，同一时间都只能执行一个 task 线程。</p><p>有 3 个 Reducer，从 Task 开始那边各自把自己进行 Hash 计算(分区器： hash&#x2F;numreduce 取模)，分类出 3 个不同的类别，每个 Task 都分成 3 种类别的数据，想把不 同的数据汇聚然后计算出最终的结果，所以 Reducer 会在每个 Task 中把属于自己类别的数 据收集过来，汇聚成一个同类别的大集合，每 1 个 Task 输出 3 份本地文件，这里有 4 个 Mapper Tasks，所以总共输出了 4 个 Tasks x 3 个分类文件 &#x3D; 12 个本地小文件。</p><p><img src="/2023/04/20/Spark%E4%BB%8E0%E5%88%B01%EF%BC%88%E4%B8%8B%EF%BC%89/6.2.png"></p><h6 id="（2）优化后的HashShuffle"><a href="#（2）优化后的HashShuffle" class="headerlink" title="（2）优化后的HashShuffle"></a>（2）优化后的HashShuffle</h6><p>优化的 HashShuffle 过程就是启用合并机制，合并机制就是复用 buffer，开启合并机制 的配置是 spark.shuffle.consolidateFiles。该参数默认值为 false，将其设置为 true 即可开启优化机制。通常来说，如果我们使用 HashShuffleManager，那么都建议开启这个选项。</p><p>这里还是有 4 个 Tasks，数据类别还是分成 3 种类型，因为 Hash 算法会根据你的 Key  进行分类，在同一个进程中，无论是有多少过 Task，都会把同样的 Key 放在同一个 Buffer 里，然后把 Buffer 中的数据写入以 Core 数量为单位的本地文件中，(一个 Core 只有一种类 型的 Key 的数据)，每 1 个 Task 所在的进程中，分别写入共同进程中的 3 份本地文件，这里 有 4 个 Mapper Tasks，所以总共输出是 2 个 Cores x 3 个分类文件 &#x3D; 6 个本地小文件。</p><p><img src="/2023/04/20/Spark%E4%BB%8E0%E5%88%B01%EF%BC%88%E4%B8%8B%EF%BC%89/6.3.png"></p><blockquote><p>简单来说优化后的HashShuffle通过复用Buffer，减小了生成的文件数量，加快了后续的ReduceTask。</p></blockquote><p><strong>在 Spark 2.0 版本中， Hash Shuffle 方式己经不再使用。</strong></p><h4 id="3、基于HashShuffle机制的优缺点"><a href="#3、基于HashShuffle机制的优缺点" class="headerlink" title="3、基于HashShuffle机制的优缺点"></a>3、基于HashShuffle机制的优缺点</h4><p><strong>优点</strong></p><ul><li>可以省略不必要的排序开销。</li><li>避免了排序所需的内存开销。</li></ul><p><strong>缺点</strong></p><ul><li>生产的文件过多，会对文件系统造成压力。</li><li>大量小文件的随机读写带来一定的磁盘开销。</li><li>数据块写入时所需的缓存空间也会随之增加，对内存造成压力。</li></ul><h4 id="4、SortShuffle解析"><a href="#4、SortShuffle解析" class="headerlink" title="4、SortShuffle解析"></a>4、SortShuffle解析</h4><h6 id="（1）普通SortShuffle"><a href="#（1）普通SortShuffle" class="headerlink" title="（1）普通SortShuffle"></a>（1）普通SortShuffle</h6><p>在该模式下，数据会先写入一个数据结构，reduceByKey 写入 Map，一边通过 Map 局部聚合，一遍写入内存。Join 算子写入 ArrayList 直接写入内存中。然后需要判断是否达到阈值，如果达到就会将内存数据结构的数据写入到磁盘，清空内存数据结构。</p><p>在溢写磁盘前，先根据 key 进行排序，排序过后的数据，会分批写入到磁盘文件中。默认批次为 10000 条，数据会以每批一万条写入到磁盘文件。写入磁盘文件通过缓冲区溢写的方式，每次溢写都会产生一个磁盘文件，也就是说一个 Task 过程会产生多个临时文件。</p><p><strong>最后在每个 Task 中，将所有的临时文件合并，这就是 merge 过程，此过程将所有临时文件读取出来，一次写入到最终文件。</strong>意味着一个 Task 的所有数据都在这一个文件中。同时单独写一份索引文件，标识下游各个Task的数据在文件中的索引，start offset和end offset。</p><p><img src="/2023/04/20/Spark%E4%BB%8E0%E5%88%B01%EF%BC%88%E4%B8%8B%EF%BC%89/6.4.png"></p><h6 id="（2）bypass-SortShuffle"><a href="#（2）bypass-SortShuffle" class="headerlink" title="（2）bypass SortShuffle"></a>（2）bypass SortShuffle</h6><p>bypass 运行机制的触发条件如下：</p><ul><li>shuffle reduce task 数量小于等于 <strong>spark.shuffle.sort.bypassMergeThreshold</strong> 参数的值，默认为 200。</li><li>不是聚合类的 shuffle 算子（比如 reduceByKey）。</li></ul><p>此时 task 会为每个 reduce 端的 task 都创建一个临时磁盘文件，并将数据按 key 进行 hash 然后根据 key 的 hash 值，将 key 写入对应的磁盘文件之中。当然，写入磁盘文件时也是先写入内存缓冲，缓冲写满之后再溢写到磁盘文件的。最后，同样会将所有临时磁盘文件都合并成一个磁盘文件，并创建一个单独的索引文件。</p><p>该过程的磁盘写机制其实跟未经优化的 HashShuffleManager 是一模一样的，因为都要创建数量惊人的磁盘文件，只是在最后会做一个磁盘文件的合并而已。因此少量的最终磁盘文件，也让该机制相对未经优化的 HashShuffleManager 来说，shuffle read 的性能会更好。</p><p>而该机制与普通 SortShuffleManager 运行机制的不同在于：<strong>不会进行排序</strong>。也就是说， 启用该机制的最大好处在于，shuffle write 过程中，不需要进行数据的排序操作，也就节省掉了这部分的性能开销。</p><p><img src="/2023/04/20/Spark%E4%BB%8E0%E5%88%B01%EF%BC%88%E4%B8%8B%EF%BC%89/6.5.png"></p><h4 id="5、基于Sort-的-Shuffle-机制的优缺点"><a href="#5、基于Sort-的-Shuffle-机制的优缺点" class="headerlink" title="5、基于Sort 的 Shuffle 机制的优缺点"></a>5、基于Sort 的 Shuffle 机制的优缺点</h4><p><strong>优点</strong></p><ul><li>小文件的数量大量减少，Mapper 端的内存占用变少</li><li>Spark 不仅可以处理小规模的数据，即使处理大规模的数据，也不会很容易达到性能瓶颈。</li></ul><p><strong>缺点</strong></p><ul><li>如果 Mapper 中 Task 的数量过大，依旧会产生很多小文件，此时在 Shuffle 传数据的过程中到 Reducer 端，Reducer 会需要同时大量地记 录进行反序列化，导致大量内存消耗和 GC 负担巨大，造成系统缓慢，甚至崩溃</li><li>强制了在 Mapper 端必须要排序，即使数据本身并不需要排序</li><li>它要基于记录本身进行排序，这就是 Sort-Based Shuffle 最致命的性能 消耗。</li></ul><hr><h2 id="第七章-Spark内存管理"><a href="#第七章-Spark内存管理" class="headerlink" title="第七章 Spark内存管理"></a>第七章 Spark内存管理</h2><h4 id="1、堆内和堆外内存规划"><a href="#1、堆内和堆外内存规划" class="headerlink" title="1、堆内和堆外内存规划"></a>1、堆内和堆外内存规划</h4><p>作为一个 JVM 进程，Executor 的内存管理建立在 JVM 的内存管理之上，Spark 对 JVM 的堆内（On-heap）空间进行了更为详细的分配，以充分利用内存。同时，Spark 引入了堆外 （Off-heap）内存，使之可以直接在工作节点的系统内存中开辟空间，进一步优化了内存的使用。堆内内存受到 JVM 统一管理，堆外内存是直接向操作系统进行内存的申请和释放。</p><p><img src="/2023/04/20/Spark%E4%BB%8E0%E5%88%B01%EF%BC%88%E4%B8%8B%EF%BC%89/7.1.png"></p><h4 id="2、内存空间分配"><a href="#2、内存空间分配" class="headerlink" title="2、内存空间分配"></a>2、内存空间分配</h4><h6 id="（1）静态内存分配"><a href="#（1）静态内存分配" class="headerlink" title="（1）静态内存分配"></a>（1）静态内存分配</h6><p>在 Spark 最初采用的静态内存管理机制下，存储内存、执行内存和其他内存的大小在 Spark 应用程序运行期间均为固定的，但用户可以应用程序启动前进行配置。</p><p>Storage 内存和 Execution 内存都有预留空间，目的是防止 OOM，因为 Spark 堆内内存大小 的记录是不准确的，需要留出保险区域。</p><p>堆外的空间分配较为简单，只有存储内存和执行内存，如下图所示。可用的执行内存和存储 内存占用的空间大小直接由参数 spark.memory.storageFraction 决定，由于堆外内存占用的空 间可以被精确计算，所以无需再设定保险区域。</p><p><img src="/2023/04/20/Spark%E4%BB%8E0%E5%88%B01%EF%BC%88%E4%B8%8B%EF%BC%89/7.2.png"></p><h6 id="（2）统一内存管理"><a href="#（2）统一内存管理" class="headerlink" title="（2）统一内存管理"></a>（2）统一内存管理</h6><p>Spark1.6 之后引入的统一内存管理机制，与静态内存管理的区别在于存储内存和执行内存共享同一块空间，可以动态占用对方的空闲区域。</p><p><img src="/2023/04/20/Spark%E4%BB%8E0%E5%88%B01%EF%BC%88%E4%B8%8B%EF%BC%89/7.3.png"></p><p><img src="/2023/04/20/Spark%E4%BB%8E0%E5%88%B01%EF%BC%88%E4%B8%8B%EF%BC%89/7.4.png"></p><p><strong>动态占用机制规则</strong></p><ul><li>设定基本的存储内存和执行内存区域（spark.storage.storageFraction 参数），该设定确定了双方各自拥有的空间的范围；</li><li>双方的空间都不足时，则存储到硬盘；若己方空间不足而对方空余时，可借用对方的空间;（存储空间不足是指不足以放下一个完整的 Block）</li><li>执行内存的空间被对方占用后，可让对方将占用的部分转存到硬盘，然后”归还”借用的空间；</li><li>存储内存的空间被对方占用后，无法让对方”归还”，因为需要考虑 Shuffle 过程中的很多因素，实现起来较为复杂。</li></ul><p><img src="/2023/04/20/Spark%E4%BB%8E0%E5%88%B01%EF%BC%88%E4%B8%8B%EF%BC%89/7.5.png"></p><h4 id="3、存储内存管理"><a href="#3、存储内存管理" class="headerlink" title="3、存储内存管理"></a>3、存储内存管理</h4><h6 id="（1）RDD的持久化机制"><a href="#（1）RDD的持久化机制" class="headerlink" title="（1）RDD的持久化机制"></a>（1）RDD的持久化机制</h6><p>弹性分布式数据集（RDD）作为 Spark 最根本的数据抽象，是只读的分区记录（Partition）的集合，只能基于在稳定物理存储中的数据集上创建，或者在其他已有的 RDD 上执行转换（Transformation）操作产生一个新的 RDD。转换后的 RDD 与原始的 RDD 之间产生的依赖关系，构成了血统（Lineage）。凭借血统，Spark 保证了每一个 RDD 都可以被重新恢复。但 RDD 的所有转换都是惰性的，即只有当一个返回结果给 Driver 的行动（Action）发生时， Spark 才会创建任务读取 RDD，然后真正触发转换的执行。</p><p>RDD 的持久化由 Spark 的 Storage 模块负责，实现了 RDD 与物理存储的解耦合。Storage 模块负责管理 Spark 在计算过程中产生的数据，将那些在内存或磁盘、在本地或远程存取数据的功能封装了起来。在具体实现时 Driver 端和 Executor 端的 Storage 模块构成了主从式的架构，即 Driver 端的 BlockManager 为 Master，Executor 端的 BlockManager 为 Slave。 Storage 模块在逻辑上以 Block 为基本存储单位，RDD 的每个 Partition 经过处理后唯一对应 一个 Block（BlockId 的格式为 rdd_RDD-ID_PARTITION-ID ）。Driver 端的 Master 负责整个 Spark 应用程序的 Block 的元数据信息的管理和维护，而 Executor 端的 Slave 需要将 Block 的更新等状态上报到 Master，同时接收 Master 的命令，例如新增或删除一个 RDD。</p><h6 id="（2）RDD的缓存过程"><a href="#（2）RDD的缓存过程" class="headerlink" title="（2）RDD的缓存过程"></a>（2）RDD的缓存过程</h6><p>RDD 在缓存到存储内存之前，Partition 中的数据一般以迭代器（Iterator）的数据结构来访问，这是 Scala 语言中一种遍历数据集合的方法。通过 Iterator 可以获取分区中每一条序 列化或者非序列化的数据项(Record)，这些 Record 的对象实例在逻辑上占用了 JVM 堆内内 存的 other 部分的空间，同一 Partition 的不同 Record 的存储空间并不连续。</p><p>RDD 在缓存到存储内存之后，Partition 被转换成 Block，Record 在堆内或堆外存储内存中占用一块连续的空间。将 Partition 由不连续的存储空间转换为连续存储空间的过程，Spark 称之为”展开”（Unroll）。</p><p>采样估算其所需的 Unroll 空间并进行申请，空间不足时可以中断，释放已占用的 Unroll 空间。 如果最终 Unroll 成功，当前 Partition 所占用的 Unroll 空间被转换为正常的缓存 RDD 的存储空间。</p><h6 id="（3）淘汰与落盘"><a href="#（3）淘汰与落盘" class="headerlink" title="（3）淘汰与落盘"></a>（3）淘汰与落盘</h6><p>由于同一个 Executor 的所有的计算任务共享有限的存储内存空间，当有新的 Block 需 要缓存但是剩余空间不足且无法动态占用时，就要对 LinkedHashMap 中的旧 Block 进行淘 汰（Eviction），而被淘汰的 Block 如果其存储级别中同时包含存储到磁盘的要求，则要对其 进行落盘（Drop），否则直接删除该 Block。</p><p><strong>存储内存的淘汰规则</strong></p><ul><li>被淘汰的旧 Block 要与新 Block 的 MemoryMode 相同，即同属于堆外或堆内内存；</li><li>新旧 Block 不能属于同一个 RDD，避免循环淘汰；</li><li>旧 Block 所属 RDD 不能处于被读状态，避免引发一致性问题；</li><li>遍历 LinkedHashMap 中 Block，按照最近最少使用（LRU）的顺序淘汰，直到满足新 Block 所需的空间。其中 LRU 是 LinkedHashMap 的特性。</li></ul><p>落盘的流程则比较简单，如果其存储级别符合_useDisk 为 true 的条件，再根据其_deserialized 判断是否是非序列化的形式，若是则对其进行序列化，最后将数据存储到磁盘，在 Storage 模块中更新其信息</p><h4 id="4、执行内存管理"><a href="#4、执行内存管理" class="headerlink" title="4、执行内存管理"></a>4、执行内存管理</h4><p>执行内存主要用来存储任务在执行 Shuffle 时占用的内存，Shuffle 是按照一定规则对 RDD 数据重新分区的过程。</p><h6 id="（1）Shuffle-Writer"><a href="#（1）Shuffle-Writer" class="headerlink" title="（1）Shuffle Writer"></a>（1）Shuffle Writer</h6><p>若在 map 端选择普通的排序方式，会采用 ExternalSorter 进行外排，在内存中存储数据时主要占用堆内执行空间。</p><p>若在 map 端选择 Tungsten 的排序方式，则采用 ShuffleExternalSorter 直接对以序列化形式存储的数据排序，在内存中存储数据时可以占用堆外或堆内执行空间，取决于用户是否开启 了堆外内存以及堆外执行内存是否足够。</p><h6 id="（2）Shuffle-Read"><a href="#（2）Shuffle-Read" class="headerlink" title="（2）Shuffle Read"></a>（2）Shuffle Read</h6><p>在对 reduce 端的数据进行聚合时，要将数据交给 Aggregator 处理，在内存中存储数据时占用堆内执行空间。</p><p>如果需要进行最终结果排序，则要将再次将数据交给 ExternalSorter 处理，占用堆内执行空间。</p><p>在 ExternalSorter 和 Aggregator 中，Spark 会使用一种叫 AppendOnlyMap 的哈希表在堆内执 行内存中存储数据，但在 Shuffle 过程中所有数据并不能都保存到该哈希表中，当这个哈希表占用的内存会进行周期性地采样估算，当其大到一定程度，无法再从 MemoryManager 申请到新的执行内存时，Spark 就会将其全部内容存储到磁盘文件中，这个过程被称为溢存 (Spill)，溢存到磁盘的文件最后会被归并(Merge)。</p><h6 id="（3）总结"><a href="#（3）总结" class="headerlink" title="（3）总结"></a>（3）总结</h6><p>Spark 的存储内存和执行内存有着截然不同的管理方式：对于存储内存来说，Spark 用一个 LinkedHashMap 来集中管理所有的 Block，Block 由需要缓存的 RDD 的 Partition 转化而成； 而对于执行内存，Spark 用 AppendOnlyMap 来存储 Shuffle 过程中的数据，在 Tungsten 排序中甚至抽象成为页式内存管理，开辟了全新的 JVM 内存管理机制。</p><hr><h2 id="第八章-数据倾斜"><a href="#第八章-数据倾斜" class="headerlink" title="第八章 数据倾斜"></a>第八章 数据倾斜</h2><p>数据倾斜就是数据分到各个区的数量不太均匀，可以自定义分区器,想怎么分就怎么分。</p><p><strong>Spark 中的数据倾斜问题主要指 shuffle 过程中出现的数据倾斜问题，是由于不同的 key 对应的数据量不同导致的不同 task 所处理的数据量不同的问题。</strong></p><p>注意，要区分开<strong>数据倾斜与数据过量</strong>这两种情况，数据倾斜是指少数 task 被分配了绝大多数的数据，因此少数 task 运行缓慢；数据过量是指所有 task 被分配的数据量都很大，相差不多，所有 task 都运行缓慢。</p><h4 id="1、数据倾斜的表现"><a href="#1、数据倾斜的表现" class="headerlink" title="1、数据倾斜的表现"></a>1、数据倾斜的表现</h4><ul><li>Spark 作业的大部分 task 都执行迅速，只有有限的几个 task 执行的非常慢，此时可能出现了数据倾斜，作业可以运行，但是运行得非常慢；</li><li>Spark 作业的大部分 task 都执行迅速，但是有的 task 在运行过程中会突然报出 OOM，反复执行几次都在某一个 task 报出 OOM 错误，此时可能出现了数据倾斜，作业无法正常运行。</li><li>定位数据倾斜问题：查阅代码中的 shuffle 算子，例如 reduceByKey、countByKey、groupByKey、 join 等算子，根据代码逻辑判断此处是否会出现数据倾斜；</li><li>查看 Spark 作业的 log 文件，log 文件对于错误的记录会精确到代码的某一行，可以根据异常定位到的代码位置来明确错误发生在第几个 stage， 对应的 shuffle算子是哪一个。</li></ul><h4 id="2、方案一：预聚合原始数据"><a href="#2、方案一：预聚合原始数据" class="headerlink" title="2、方案一：预聚合原始数据"></a>2、方案一：预聚合原始数据</h4><h6 id="（1）避免shuffle过程"><a href="#（1）避免shuffle过程" class="headerlink" title="（1）避免shuffle过程"></a>（1）避免shuffle过程</h6><p>绝大多数情况下，Spark 作业的数据来源都是 Hive 表，这些 Hive 表基本都是经过 ETL 之后的昨天的数据。 为了避免数据倾斜，我们可以考虑避免 shuffle 过程，如果避免了 shuffle 过程，那么从根本上就消除了发生数据倾斜问题的可能。 如果 Spark 作业的数据来源于 Hive 表，那么可以先在 Hive 表中对数据进行聚合， 例如按照 key 进行分组，将同一 key 对应的所有 value 用一种特殊的格式拼接到 一个字符串里去，这样，一个 key 就只有一条数据了；之后，对一个 key 的所有 value 进行处理时，只需要进行 map 操作即可，无需再进行任何的 shuffle 操作。</p><p>通过上述方式就避免了执行 shuffle 操作，也就不可能会发生任何的数据倾斜问题。 对于 Hive 表中数据的操作，不一定是拼接成一个字符串，也可以是直接对 key 的每一条数据进行累计计算。 <strong>要区分开，处理的数据量大和数据倾斜的区别。</strong></p><h6 id="（2）增大Key粒度（减小数据倾斜的可能性，增大每个Task的数据量）"><a href="#（2）增大Key粒度（减小数据倾斜的可能性，增大每个Task的数据量）" class="headerlink" title="（2）增大Key粒度（减小数据倾斜的可能性，增大每个Task的数据量）"></a>（2）增大Key粒度（减小数据倾斜的可能性，增大每个Task的数据量）</h6><p>如果没有办法对每个 key 聚合出来一条数据，在特定场景下，可以考虑扩大 key 的聚合粒度。</p><p>例如，目前有 10 万条用户数据，当前 key 的粒度是（省，城市，区，日期）， 现在我们考虑扩大粒度，将 key 的粒度扩大为（省，城市，日期），这样的话， key 的数量会减少，key 之间的数据量差异也有可能会减少，由此可以减轻数据倾斜的现象和问题。（此方法只针对特定类型的数据有效，当应用场景不适宜时， 会加重数据倾斜）</p><h4 id="3、方案二：预处理导致倾斜的Key"><a href="#3、方案二：预处理导致倾斜的Key" class="headerlink" title="3、方案二：预处理导致倾斜的Key"></a>3、方案二：预处理导致倾斜的Key</h4><h6 id="（1）过滤"><a href="#（1）过滤" class="headerlink" title="（1）过滤"></a>（1）过滤</h6><p>如果在 Spark 作业中允许丢弃某些数据，那么可以考虑将可能导致数据倾斜的 key 进行过滤，滤除可能导致数据倾斜的 key 对应的数据，这样，在 Spark 作业中就不会发生数据倾斜了。</p><h6 id="（2）使用随机Key"><a href="#（2）使用随机Key" class="headerlink" title="（2）使用随机Key"></a>（2）使用随机Key</h6><p>当使用了类似于 groupByKey、reduceByKey 这样的算子时，可以考虑使用随机 key 实现双重聚合。</p><p>此方法对于由 groupByKey、reduceByKey 这类算子造成的数据倾斜有比较好的效果，仅仅适用于聚合类的 shuffle 操作，适用范围相对较窄。如果是 join 类的 shuffle 操作，还得用其他的解决方案。</p><h6 id="（3）sample-采样对倾斜-key-单独进行-join"><a href="#（3）sample-采样对倾斜-key-单独进行-join" class="headerlink" title="（3）sample 采样对倾斜 key 单独进行 join"></a>（3）sample 采样对倾斜 key 单独进行 join</h6><p>在 Spark 中，<strong>如果某个 RDD 只有一个 key，那么在 shuffle 过程中会默认将此 key 对应的数据打散，由不同的 reduce 端 task 进行处理。</strong></p><p>所以当由单个 key 导致数据倾斜时，可有将发生数据倾斜的 key 单独提取出来， 组成一个RDD，然后用这个原本会导致倾斜的key组成的RDD和其他RDD单独join， 此时，根据 Spark 的运行机制，此 RDD 中的数据会在 shuffle 阶段被分散到多个 task 。</p><p><img src="/2023/04/20/Spark%E4%BB%8E0%E5%88%B01%EF%BC%88%E4%B8%8B%EF%BC%89/8.1.png"></p><h4 id="4、方案三：提高reduce并行度"><a href="#4、方案三：提高reduce并行度" class="headerlink" title="4、方案三：提高reduce并行度"></a>4、方案三：提高reduce并行度</h4><p>当方案一和方案二对于数据倾斜的处理没有很好的效果时，可以考虑提高 shuffle 过程中的 reduce 端并行度，reduce 端并行度的提高就增加了 reduce 端 task 的数量，那么每个 task 分配到的数据量就会相应减少，由此缓解数据倾斜问题。</p><p><strong>缺陷</strong></p><p><strong>提高 reduce 端并行度并没有从根本上改变数据倾斜的本质和问题（方案一和方 案二从根本上避免了数据倾斜的发生）</strong>，只是尽可能地去缓解和减轻 shuffle reduce task 的数据压力，以及数据倾斜的问题，适用于有较多 key 对应的数据量都比较大的情况。</p><h4 id="5、方案四：使用map-join"><a href="#5、方案四：使用map-join" class="headerlink" title="5、方案四：使用map join"></a>5、方案四：使用map join</h4><p>正常情况下，join 操作都会执行 shuffle 过程，并且执行的是 reduce join，也就是先将所有相同的 key 和对应的 value 汇聚到一个 reduce task 中，然后再进行 join。</p><p><img src="/2023/04/20/Spark%E4%BB%8E0%E5%88%B01%EF%BC%88%E4%B8%8B%EF%BC%89/8.2.png"></p><p>普通的 join 是会走 shuffle 过程的，而一旦 shuffle，就相当于会将相同 key 的数据拉取到一个 shuffle read task 中再进行 join，此时就是 reduce join。 但是如果一个 RDD 是比较小的，则可以采用广播小 RDD 全量数据+map 算子来实现与 join 同样的效果，也就是 map join，此时就不会发生 shuffle 操作，也就不会发生数据倾斜。</p><p><strong>注意：RDD 是并不能直接进行广播的，只能将 RDD 内部的数据通过 collect 拉取到 Driver 内存然后再进行广播。</strong></p><blockquote><p>简单来说就是将少且散的数据全局到Driver端，直接消费到其他比较大的数据集中。</p></blockquote><hr><blockquote><p>应该不会有人真的看到这里吧~~</p><p>其实文档还有Spark调优没有写，但是碍于篇幅和我的精神状态，暂时就不准备夹在这个文档中间了。毕竟这也只是从0到1嘛，不是从1到1.5。</p><p>理论固然是重要的，但是千万别忘了代码实践。如果你想在简历上写了解Spark的话，上面这些基础基本上是吃透了的，同时还要熟读Spark的八股面经（认真脸）。当然，个人认为最好的提升方式就是直接写个项目，找找网上的Spark Streaming项目做一下，能够更加方便你了解Spark的工作原理。</p><p>如果你能在这学得比任课老师教的还好，那么我觉得该文档就有了它的价值。——Alexie-Z-Yevich 2023.4.20</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 我的大学 </category>
          
          <category> 大三下学期 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> 大数据组件 </tag>
            
            <tag> 从零到一系列 </tag>
            
            <tag> Spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark从0到1（上）</title>
      <link href="/2023/04/19/Spark%E4%BB%8E0%E5%88%B01%EF%BC%88%E4%B8%8A%EF%BC%89/"/>
      <url>/2023/04/19/Spark%E4%BB%8E0%E5%88%B01%EF%BC%88%E4%B8%8A%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>前言：</strong></p><p>这是结合书本和尚硅谷大数据课程的综合Spark入门文档，去除了大部分实操过程以追求在理论上一文解决所有疑惑。原书的第二章是Scala基础编程，但是如果真的想要使用Scala进行Spark工程开发的话，建议去单独学习下Scala（很多语言特性还是比较有意思的）。所以Scala的部分并不在《Spark从0到1》这篇文档中，之后会单独开一篇文档记录Scala的语言及面试重点。</p><p>由此，开始这篇文档默认已经入门Scala了。内容过多会分为上下两部分，上部分主要介绍Spark Core和Spark SQL，下部分主要介绍Spark的其他生态，主要是Streaming，GraphX和MLlib酌情考虑。</p></blockquote><h2 id="第一章-Spark概述"><a href="#第一章-Spark概述" class="headerlink" title="第一章 Spark概述"></a>第一章 Spark概述</h2><h4 id="1、Spark是什么？"><a href="#1、Spark是什么？" class="headerlink" title="1、Spark是什么？"></a>1、Spark是什么？</h4><ul><li><p>Spark 是一种由 Scala 语言开发的快速、通用、可扩展的大数据分析引擎</p></li><li><p>Spark Core 中提供了 Spark 最基础与最核心的功能</p></li><li><p>Spark SQL 是 Spark 用来操作结构化数据的组件。通过 Spark SQL，用户可以使用SQL 或者 Apache Hive 版本的 SQL 方言（HQL）来查询数据。</p></li><li><p>Spark Streaming 是 Spark 平台上针对实时数据进行流式计算的组件，提供了丰富的处理数据流的 API。</p></li></ul><p><strong>Spark 出现的时间相对较晚，并且主要功能主要是用于数据计算，所以其实 Spark 一直被认为是 Hadoop 框架的升级版。</strong></p><p><strong>Spark 和Hadoop 的根本差异是多个作业之间的数据通信问题 : Spark 多个作业之间数据通信是基于内存，而 Hadoop 是基于磁盘。</strong></p><h4 id="2、Spark与MapReduce"><a href="#2、Spark与MapReduce" class="headerlink" title="2、Spark与MapReduce"></a>2、Spark与MapReduce</h4><h6 id="（1）MapReduce的局限性"><a href="#（1）MapReduce的局限性" class="headerlink" title="（1）MapReduce的局限性"></a>（1）MapReduce的局限性</h6><ul><li><strong>仅支持Map和Reduce 两种操作。</strong>数据处理流程中的每一步都需要一个Map阶段和一个Reduce阶段，如果要利用这一解决方案，需要将所有用例都转换成MapReduce模式。</li><li><strong>处理效率低。</strong>Map中间结果写磁盘，Reduce中间结果写HDFS，多个MapReduce之间通过 HDFS交换数据，任务调度和启动开销大。开销具体表现在如下几方面：客户端需要把应用程序提交给ResourcesManager，ResourcesManager 去选择节点运行；当Map任务和Reduce 任务被ResourcesManager 调度的时候，会先启动一个container 进程，然后让任务运行起来，每一个任务都要经历Java虚拟机的启动、销毁等流程。</li><li>Map 和Reduce 均需要排序，但是因为有的任务处理完全不需要排序（比如求最大值和最小值等），所以就造成了<strong>低效的性能</strong>。</li><li>不适合做迭代计算（如机器学习、图计算等）、交互式处理（如数据挖掘）和流式处理（如日志分析）</li></ul><h6 id="（2）Spark解决MapReduce的不足"><a href="#（2）Spark解决MapReduce的不足" class="headerlink" title="（2）Spark解决MapReduce的不足"></a>（2）Spark解决MapReduce的不足</h6><ul><li>Spark可以基于内存也可以基于磁盘做迭代计算</li><li>Spark所处理的数据可以来自任何一种存储介质，如关系数据库、本地文件系统、分布式存储等</li><li>Spark装在需要处理的数据至内存，并将这些数据集抽象为RDD（弹性分布式数据集）对象，然后采用一系列RDD操作处理RDD，并将处理好的结果以RDD的形式输出到内存，以数据流的方式持久化写入其他存储介质中。</li><li>Spark使用Scala语言作为编程语言，它是一种面向对象、函数式编程语言，能够像操作本地集合一样轻松地操作分布式数据集。</li></ul><h6 id="（3）Spark优点"><a href="#（3）Spark优点" class="headerlink" title="（3）Spark优点"></a>（3）Spark优点</h6><ul><li><strong>运行速度快</strong>：Spark 基于磁盘做迭代计算比基于磁盘做迭代计算的MapReduce 快十余倍；Spark 基于内存做迭代计算则比基于磁盘做迭代计算的MapReduce快100倍以上。Spark实现了高效的DAG执行引擎，可以通过内存计算来高效处理数据流。</li><li><strong>易用性好</strong>：Spark 支持Java、Python、Scala等语言，支持80多种高级算法，可以使用户快速构建不同的应用。Spark 支持交互式的Python 和 Scala的shell，这意味着可以非常方便地在这些 shel中使用Spark集群来验证解决问题的方法，而不像以前，需要打包、上传集群、验证等。</li><li><strong>通用性强</strong>：Spark可用于批处理、交互式查询（通过SparkSQL组件）、实时流处理（通过Spark Streaming 组件）、机器学习（通过Spark MLJib缅件）和图计算（通过Spark GraphX组件）。④兼容性：Spark可以使用 Hadoop的YARN作为它的资源管理和调度器。Spark也可以不依赖于第三方的资源管理和调度器，它实现了Standalone 作为其内置的资源管理和调度框架，能够读取 HDFS、Cassandra、HBase、S3和Techyon中的数据。</li></ul><h4 id="3、Spark核心模块"><a href="#3、Spark核心模块" class="headerlink" title="3、Spark核心模块"></a>3、Spark核心模块</h4><h6 id="（1）Spark-Core"><a href="#（1）Spark-Core" class="headerlink" title="（1）Spark Core"></a>（1）Spark Core</h6><p>Spark Core 中提供了 Spark 最基础与最核心的功能，Spark 其他的功能如：Spark SQL，Spark Streaming，GraphX, MLlib 都是在 Spark Core 的基础上进行扩展的</p><h6 id="（2）Spark-SQL"><a href="#（2）Spark-SQL" class="headerlink" title="（2）Spark SQL"></a>（2）Spark SQL</h6><p>Spark SQL 是 Spark 用来操作结构化数据的组件。通过 Spark SQL，用户可以使用 SQL或者 Apache Hive 版本的 SQL 方言（HQL）来查询数据。</p><blockquote><p>Hive On Spark</p></blockquote><h6 id="（3）Spark-Streaming"><a href="#（3）Spark-Streaming" class="headerlink" title="（3）Spark Streaming"></a>（3）Spark Streaming</h6><p>Spark Streaming 是 Spark 平台上针对实时数据进行流式计算的组件，提供了丰富的处理数据流的 API。</p><h6 id="（4）Spark-MLlib"><a href="#（4）Spark-MLlib" class="headerlink" title="（4）Spark MLlib"></a>（4）Spark MLlib</h6><p>MLlib 是 Spark 提供的一个机器学习算法库。MLlib 不仅提供了模型评估、数据导入等额外的功能，还提供了一些更底层的机器学习原语。</p><h6 id="（5）Spark-GraphX"><a href="#（5）Spark-GraphX" class="headerlink" title="（5）Spark GraphX"></a>（5）Spark GraphX</h6><p>GraphX 是 Spark 面向图计算提供的框架与算法库。</p><h4 id="4、Spark执行流程（运行机制）"><a href="#4、Spark执行流程（运行机制）" class="headerlink" title="4、Spark执行流程（运行机制）"></a>4、Spark执行流程（运行机制）</h4><h6 id="（1）简单概念"><a href="#（1）简单概念" class="headerlink" title="（1）简单概念"></a>（1）简单概念</h6><ul><li>作业（Job)：一个应用程序以RDD行动操作(Action）为划分边界往往会产生多个作业。Spark对RDD采用情性求解机制，对RDD的创建和转换并不会立即执行，只有在遇到行动操作时才会生成一个作业，然后统一调度执行。一个作业包含多个RDD及作用于相应RDD上的各种操作。一个作业会被拆分为多组任务，每组任务被称为阶段（Stage)，或者被称为任务集(TaskSet）。</li><li>阶段（Stage)：一个作业会被拆分为多组任务，每组任务被称为阶段（Stage)，或者被称为任务集(TaskSet）。</li><li>任务集（TaskSet）：任务集是任务的集合，一个阶段创建一个任务集，阶段的每个RDD分区被创建为一个任务，多个任务封装形成任务集。</li><li>有向无环图（Directed Acycle graph)：有向无环图反映RDD之间的依赖关系。</li></ul><h6 id="（2）运行架构"><a href="#（2）运行架构" class="headerlink" title="（2）运行架构"></a>（2）运行架构</h6><p>Spark 框架的核心是一个计算引擎，整体来说，它采用了标准 master-slave 的结构。图形中的 Driver 表示 master，负责管理整个集群中的作业任务调度。图形中的 Executor 则是 slave，负责实际执行任务。</p><p><img src="/2023/04/19/Spark%E4%BB%8E0%E5%88%B01%EF%BC%88%E4%B8%8A%EF%BC%89/1.1.png"></p><h6 id="（3）核心组件"><a href="#（3）核心组件" class="headerlink" title="（3）核心组件"></a>（3）核心组件</h6><p><strong>Driver</strong></p><p>Spark 驱动器节点，用于执行 Spark 任务中的 main 方法，负责实际代码的执行工作。</p><p>Driver 在 Spark 作业执行时主要负责：</p><ul><li><p>将用户程序转化为作业（job）</p></li><li><p>在 Executor 之间调度任务(task)</p></li><li><p>跟踪 Executor 的执行情况</p></li><li><p>通过 UI 展示查询运行情况</p></li></ul><p>实际上，我们无法准确地描述 Driver 的定义，因为在整个的编程过程中没有看到任何有关Driver 的字眼。所以简单理解，所谓的 Driver 就是驱使整个应用运行起来的程序，也称之为Driver 类。</p><p><strong>Executor</strong></p><p>Spark Executor 是集群中工作节点（Worker）中的一个 JVM 进程，负责在 Spark 作业中运行具体任务（Task），任务彼此之间相互独立。Spark 应用启动时，Executor 节点被同时启动，并且始终伴随着整个 Spark 应用的生命周期而存在。如果有 Executor 节点发生了故障或崩溃，Spark 应用也可以继续执行，会将出错节点上的任务调度到其他 Executor 节点上继续运行。</p><p>Executor 有两个核心功能：</p><ul><li><p>负责运行组成 Spark 应用的任务，并将结果返回给驱动器进程</p></li><li><p>它们通过自身的块管理器（Block Manager）为用户程序中要求缓存的 RDD 提供内存式存储。RDD 是直接缓存在 Executor 进程内的，因此任务可以在运行时充分利用缓存数据加速运算。</p></li></ul><p><strong>Master &amp; Worker</strong></p><p>Spark 集群的独立部署环境中，不需要依赖其他的资源调度框架，自身就实现了资源调度的功能，所以环境中还有其他两个核心组件：Master 和 Worker，这里的 Master 是一个进程，主要负责资源的调度和分配，并进行集群的监控等职责，类似于 Yarn 环境中的 ResourceManager，而Worker 则是进程，一个 Worker 运行在集群中的一台服务器上，由 Master 分配资源对数据进行并行的处理和计算，类似于 Yarn 环境中 NodeManager。</p><p><strong>ApplicationMaster</strong></p><p>Hadoop 用户向 YARN 集群提交应用程序时,提交程序中应该包含 ApplicationMaster，用于向资源调度器申请执行任务的资源容器 Container，运行用户自己的程序任务 job，监控整个任务的执行，跟踪整个任务的状态，处理任务失败等异常情况。说的简单点就是，ResourceManager（资源）和 Driver（计算）之间的解耦合靠的就是ApplicationMaster。</p><h6 id="（4）DAG【Directed-Acycle-graph，有向无环图】"><a href="#（4）DAG【Directed-Acycle-graph，有向无环图】" class="headerlink" title="（4）DAG【Directed Acycle graph，有向无环图】"></a>（4）DAG【Directed Acycle graph，有向无环图】</h6><p>有向无环图，并不是真正意义的图形，而是由 Spark 程序直接映射成的数据流的高级抽象模型。简单理解就是将整个程序计算的执行过程用图形表示出来,这样更直观，更便于理解，可以用于表示程序的拓扑结构。</p><p>DAG 有向无环图是由点和线组成的拓扑图形，该图形具有方向，不会闭环。</p><h6 id="（5）应用执行的基本流程"><a href="#（5）应用执行的基本流程" class="headerlink" title="（5）应用执行的基本流程"></a>（5）应用执行的基本流程</h6><p><img src="/2023/04/19/Spark%E4%BB%8E0%E5%88%B01%EF%BC%88%E4%B8%8A%EF%BC%89/1.2.png"></p><ul><li>当一个Spark应用程序被提交时，首先需要为这个应用程序构建运行环境，即由驱动程序创建一个SparkContext 对象，SparkContext对象向集群资源管理器注册，之后SparkContext 对象负责和集群资源管理器进行通信以及进行资源申请、任务的分配和运行监控等，此外还包括申请运行执行器进程的资源。</li><li>集群资源管理器根据预先设定的算法，在资源池里为执行器进程分配合适的运行资源，并启动执行器进程。在运行过程中，执行器运行情况将随着心跳信息发送到资源管理。</li><li>SparkContext 对象根据RDD之间的依赖关系构建DAG图，然后提交给有向无环图调度器进行解析，将DAG图分解成多个阶段（每个阶段就是一个任务集），并计算出各Stage之间的依赖关系，然后把各个任务集提交给任务调度器进行处理。执行器进程向SparkCon text 对象申请任务，任务调度器将任务发放给执行器进程执行，同时SparkContext对象将应用程序代码发放给执行器进程，即将计算移到数据所在的节点上进行，移动计算比移动数据的网络开销要小得多。</li><li>Task在执行器进程上运行，把执行结果反馈给Task Scheduler，然后再反馈给有向无环图调度器。运行完毕后写入数据，SparkContext 对象向集群资源管理器注销并释放所有资源。</li></ul><hr><h2 id="第二章-Spark-Core：基于Scala的Spark编程"><a href="#第二章-Spark-Core：基于Scala的Spark编程" class="headerlink" title="第二章  Spark Core：基于Scala的Spark编程"></a>第二章  Spark Core：基于Scala的Spark编程</h2><h4 id="1、RDD"><a href="#1、RDD" class="headerlink" title="1、RDD"></a>1、RDD</h4><h6 id="（1）什么是RDD？"><a href="#（1）什么是RDD？" class="headerlink" title="（1）什么是RDD？"></a>（1）什么是RDD？</h6><p>RDD（Resilient Distributed Dataset）叫做弹性分布式数据集，是 Spark 中最基本的数据处理模型。代码中是一个抽象类，它代表一个弹性的、不可变、可分区、里面的元素可并行计算的集合。</p><ul><li><p>弹性</p><ul><li>存储的弹性：内存与磁盘的自动切换；</li><li>容错的弹性：数据丢失可以自动恢复；</li><li>计算的弹性：计算出错重试机制；</li><li>分片的弹性：可根据需要重新分片。</li></ul></li><li><p>分布式：数据存储在大数据集群不同节点上</p></li><li><p>数据集：RDD 封装了计算逻辑，并不保存数据</p></li><li><p>数据抽象：RDD 是一个抽象类，需要子类具体实现</p></li><li><p>不可变：RDD 封装了计算逻辑，是不可以改变的，想要改变，只能产生新的 RDD，在新的 RDD 里面封装计算逻辑</p></li><li><p>可分区、并行计算</p></li></ul><p>传统的MapReduce虽然具有自动容错、负载均衡和可拓展性的优点，但其最大的缺点是在迭代计算的时候，要进行大量的磁盘I&#x2F;O操作，RDD正是为了解决这一缺点而出现的。</p><p><strong>RDD屏蔽了底层对数据的复杂抽象和处理，为用户提供了一组方便的数据转换与求值方法。</strong></p><h6 id="（2）执行原理"><a href="#（2）执行原理" class="headerlink" title="（2）执行原理"></a>（2）执行原理</h6><p>从计算的角度来讲，数据处理过程中需要计算资源（内存 &amp; CPU）和计算模型（逻辑）。 执行时，需要将计算资源和计算模型进行协调和整合。</p><p>Spark 框架在执行时，先申请资源，然后将应用程序的数据处理逻辑分解成一个一个的 计算任务。然后将任务发到已经分配资源的计算节点上, 按照指定的计算模型进行数据计 算。最后得到计算结果。</p><ul><li><strong>RDD在YARN环境中的工作原理</strong></li></ul><table><thead><tr><th align="center">执行过程</th><th align="center">示意图</th></tr></thead><tbody><tr><td align="center">（1）启动YARN集群环境</td><td align="center"><img src="/2023/04/19/Spark%E4%BB%8E0%E5%88%B01%EF%BC%88%E4%B8%8A%EF%BC%89/2.1.png"></td></tr><tr><td align="center">（2）Spark申请资源调度节点和计算节点</td><td align="center"><img src="/2023/04/19/Spark%E4%BB%8E0%E5%88%B01%EF%BC%88%E4%B8%8A%EF%BC%89/2.2.png"></td></tr><tr><td align="center">（3）Spark 框架根据需求将计算逻辑根据分区划分成不同的任务</td><td align="center"><img src="/2023/04/19/Spark%E4%BB%8E0%E5%88%B01%EF%BC%88%E4%B8%8A%EF%BC%89/2.3.png"></td></tr><tr><td align="center">（4）调度节点将任务根据计算节点状态发送到对应的计算节点进行计算</td><td align="center"><img src="/2023/04/19/Spark%E4%BB%8E0%E5%88%B01%EF%BC%88%E4%B8%8A%EF%BC%89/2.4.png"></td></tr></tbody></table><h6 id="（3）创建RDD的方式"><a href="#（3）创建RDD的方式" class="headerlink" title="（3）创建RDD的方式"></a>（3）创建RDD的方式</h6><p>创建RDD的方式主要有两种：通过Spark应用程序中的数据集创建；使用本地及HDFS、HBase等外部存储系统上的文件创建。</p><ul><li>使用数据集：通过并行化数据集合来创建RDD，就是通过调用SparkContext中的parallelize()方法并行化数据集到集群的节点上形成一个分布式的数据集合，然后就可以采用并行的方式来操作这个分布式数据集合。</li><li>使用文本文件：调用SparkContext的textFile()方法读取文件的位置即可创建RDD。textFile()支持针对目录、文本文件、压缩文件以及通配符匹配的文件进行RDD创建。</li><li>使用JSON文件；</li><li>使用CSV文件（后两种本质上都是textFile()对不同格式的读取）</li></ul><h4 id="2、RDD操作（操作在一些地方又称为算子）"><a href="#2、RDD操作（操作在一些地方又称为算子）" class="headerlink" title="2、RDD操作（操作在一些地方又称为算子）"></a>2、RDD操作（操作在一些地方又称为算子）</h4><h6 id="（1）转换操作-amp-amp-行动操作"><a href="#（1）转换操作-amp-amp-行动操作" class="headerlink" title="（1）转换操作&amp;&amp;行动操作"></a>（1）转换操作&amp;&amp;行动操作</h6><ul><li><p>转换操作：RDD的转换操作是返回新的RDD的操作，转换操作是惰性求值的，真正的转换发生在RDD的行动操作中，也就是说对于行动操作之前的所有转换操作，Spark只是记录下转换的轨迹，即相互之间的依赖关系，并不会触发真正的转换。</p><ul><li>RDD 根据数据处理方式的不同将算子整体上分为 Value 类型、双 Value 类型和 Key-Value 类型。</li></ul></li><li><p>行动操作：行动操作是指向驱动器程序返回结果或把结果写入外部系统并触发实际计算的操作。行动操作接受RDD，但是返回一个非RDD，即输出一个结果值，并把结果值返回到驱动器的程序中。</p></li></ul><h6 id="（2）常见的转换操作"><a href="#（2）常见的转换操作" class="headerlink" title="（2）常见的转换操作"></a>（2）常见的转换操作</h6><p>常见的RDD转换操作有map、filter、flatMap、groupByKey、reduceByKey等。</p><ul><li>map是对RDD中的每个元素都执行一个指定的函数来产生一个新的RDD</li></ul><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 将处理的数据逐条进行映射转换，这里的转换可以是类型的转换，也可以是值的转换。</span></span><br><span class="line"><span class="keyword">val</span> dataRDD: <span class="type">RDD</span>[<span class="type">Int</span>] = sparkContext.makeRDD(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))  <span class="comment">// 创建RDD数据结构</span></span><br><span class="line"><span class="keyword">val</span> dataRDD1: <span class="type">RDD</span>[<span class="type">Int</span>] = dataRDD.map(</span><br><span class="line">   num =&gt; &#123;</span><br><span class="line">       num * <span class="number">2</span></span><br><span class="line">   &#125;</span><br><span class="line">)  <span class="comment">// 值转换</span></span><br><span class="line"><span class="keyword">val</span> dataRDD2: <span class="type">RDD</span>[<span class="type">String</span>] = dataRDD1.map(</span><br><span class="line">   num =&gt; &#123;</span><br><span class="line">       <span class="string">&quot;&quot;</span> + num</span><br><span class="line">   &#125;</span><br><span class="line">)  <span class="comment">// 类型转换</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果：</span></span><br><span class="line"><span class="comment">// dataRDD1：2 4 6 8</span></span><br><span class="line"><span class="comment">// dataRDD2：2 4 6 8</span></span><br></pre></td></tr></table></figure><ul><li>filter是对RDD中的每个元素都执行一个指定的函数，将返回值为true的元素组成一个新的RDD</li></ul><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 将数据根据指定的规则进行筛选过滤，符合规则的数据保留，不符合规则的数据丢弃。当数据进行筛选过滤后，分区不变，但是分区内的数据可能不均衡，生产环境下，可能会出现数据倾斜。</span></span><br><span class="line"><span class="keyword">val</span> dataRDD = sparkContext.makeRDD(<span class="type">List</span>(</span><br><span class="line">   <span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span></span><br><span class="line">),<span class="number">1</span>)</span><br><span class="line"><span class="keyword">val</span> dataRDD1 = dataRDD.filter(_%<span class="number">2</span> == <span class="number">0</span>) <span class="comment">// 过滤掉 _%2 != 0 的元素</span></span><br><span class="line"><span class="comment">// dataRDD1: 2 4</span></span><br></pre></td></tr></table></figure><ul><li>flatMap是将函数应用于RDD中的每个元素，将返回的迭代器的所有内容构成新的RDD</li></ul><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 将处理的数据进行扁平化后再进行映射处理，所以算子也称之为扁平映射</span></span><br><span class="line"><span class="keyword">val</span> dataRDD = sparkContext.makeRDD(<span class="type">List</span>(</span><br><span class="line">   <span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>),<span class="type">List</span>(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">),<span class="number">1</span>)</span><br><span class="line"><span class="keyword">val</span> dataRDD1 = dataRDD.flatMap(</span><br><span class="line">   list =&gt; list</span><br><span class="line">)</span><br><span class="line"><span class="comment">// dataRDD1：1 2 3 4</span></span><br></pre></td></tr></table></figure><blockquote><p>flatMap是非常常用的算子，它能将多维数据扁平化，比如说二维变为一维。常见在WordCount中，一句话被切分成多个词后使用flatMap进行展平。</p></blockquote><ul><li>groupBy</li></ul><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 将数据根据指定的规则进行分组, 分区默认不变，但是数据会被打乱重新组合，我们将这样的操作称之为 shuffle。极限情况下，数据可能被分在同一个分区中</span></span><br><span class="line"><span class="comment">// 一个组的数据在一个分区中，但是并不是说一个分区中只有一个组</span></span><br><span class="line"><span class="keyword">val</span> dataRDD = sparkContext.makeRDD(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>),<span class="number">1</span>)</span><br><span class="line"><span class="keyword">val</span> dataRDD1 = dataRDD.groupBy(</span><br><span class="line">   _%<span class="number">2</span></span><br><span class="line">) <span class="comment">// 通过对2取余进行分区</span></span><br><span class="line"><span class="comment">// 输出结果：</span></span><br><span class="line"><span class="comment">// (0,CompactBuffer(2, 4))</span></span><br><span class="line"><span class="comment">// (1,CompactBuffer(1, 3))</span></span><br></pre></td></tr></table></figure><blockquote><p>groupBy是非常常用的算子，它能通过条件对元素进行分组。常见在WordCount中，多句话扁平化之后可以将相同的词语分组聚合，以便后续进行计数。</p></blockquote><ul><li>groupByKey是将RDD中相同key的元素分组到一起，返回一个(K, Iterable[V])类型的RDD</li></ul><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 将数据源的数据根据 key 对 value 进行分组</span></span><br><span class="line"><span class="keyword">val</span> dataRDD1 = sparkContext.makeRDD(<span class="type">List</span>((<span class="string">&quot;a&quot;</span>,<span class="number">1</span>),(<span class="string">&quot;b&quot;</span>,<span class="number">2</span>),(<span class="string">&quot;c&quot;</span>,<span class="number">3</span>)))</span><br><span class="line"><span class="keyword">val</span> dataRDD2 = dataRDD1.groupByKey()</span><br><span class="line"><span class="keyword">val</span> dataRDD3 = dataRDD1.groupByKey(<span class="number">2</span>)</span><br><span class="line"><span class="keyword">val</span> dataRDD4 = dataRDD1.groupByKey(<span class="keyword">new</span> <span class="type">HashPartitioner</span>(<span class="number">2</span>))</span><br><span class="line"><span class="comment">// 输出结果:（内容一致，顺序不同）</span></span><br><span class="line"><span class="comment">// (a,CompactBuffer(1))</span></span><br><span class="line"><span class="comment">// (b,CompactBuffer(2))</span></span><br><span class="line"><span class="comment">// (c,CompactBuffer(3))</span></span><br></pre></td></tr></table></figure><ul><li>reduceByKey是对每个key对应的value进行reduce操作，返回一个(K, V)类型的RDD。</li></ul><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 可以将数据按照相同的 Key 对 Value 进行聚合</span></span><br><span class="line"><span class="keyword">val</span> dataRDD1 = sparkContext.makeRDD(<span class="type">List</span>((<span class="string">&quot;a&quot;</span>,<span class="number">1</span>),(<span class="string">&quot;b&quot;</span>,<span class="number">2</span>),(<span class="string">&quot;c&quot;</span>,<span class="number">3</span>)))</span><br><span class="line"><span class="keyword">val</span> dataRDD2 = dataRDD1.reduceByKey(_+_)</span><br><span class="line"><span class="keyword">val</span> dataRDD3 = dataRDD1.reduceByKey(_+_, <span class="number">2</span>)</span><br><span class="line"><span class="comment">// 输出结果:</span></span><br><span class="line"><span class="comment">// (a,1) (b,2) (c,3)</span></span><br><span class="line"><span class="comment">// (b,2) (a,1) (c,3)</span></span><br></pre></td></tr></table></figure><h6 id="（3）常见的行动操作"><a href="#（3）常见的行动操作" class="headerlink" title="（3）常见的行动操作"></a>（3）常见的行动操作</h6><p>常见的RDD行动操作有collect、count、first、take、reduce等。</p><ul><li>collect是将RDD中所有元素以数组的形式返回到Driver端；</li></ul><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 在驱动程序中，以数组 Array 的形式返回数据集的所有元素</span></span><br><span class="line"><span class="keyword">val</span> rdd: <span class="type">RDD</span>[<span class="type">Int</span>] = sc.makeRDD(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line"><span class="comment">// 收集数据到 Driver</span></span><br><span class="line">rdd.collect().foreach(println)  <span class="comment">// 收集到Driver端并循环打印</span></span><br></pre></td></tr></table></figure><ul><li>count是返回RDD中元素的个数；first是返回RDD中的第一个元素；</li></ul><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 返回 RDD 中元素的个数</span></span><br><span class="line"><span class="keyword">val</span> rdd: <span class="type">RDD</span>[<span class="type">Int</span>] = sc.makeRDD(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line"><span class="comment">// 返回 RDD 中元素的个数</span></span><br><span class="line"><span class="keyword">val</span> countResult: <span class="type">Long</span> = rdd.count() <span class="comment">// 记录元素个数</span></span><br><span class="line"><span class="comment">// 4</span></span><br></pre></td></tr></table></figure><ul><li>take是返回一个由RDD的前n个元素组成的数组；</li></ul><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 返回一个由 RDD 的前 n 个元素组成的数组</span></span><br><span class="line"><span class="keyword">val</span> rdd: <span class="type">RDD</span>[<span class="type">Int</span>] = sc.makeRDD(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line"><span class="comment">// 返回 RDD 中元素的个数</span></span><br><span class="line"><span class="keyword">val</span> takeResult: <span class="type">Array</span>[<span class="type">Int</span>] = rdd.take(<span class="number">2</span>)  <span class="comment">// 返回前两个元素</span></span><br><span class="line">println(takeResult.mkString(<span class="string">&quot;,&quot;</span>))  <span class="comment">// 用&quot;,&quot;将元素隔开</span></span><br><span class="line"><span class="comment">// 1,2</span></span><br></pre></td></tr></table></figure><ul><li>reduce是通过func函数聚集RDD中的所有元素，先聚合分区内数据，再聚合分区间数据。</li></ul><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 聚集 RDD 中的所有元素，先聚合分区内数据，再聚合分区间数据</span></span><br><span class="line"><span class="keyword">val</span> rdd: <span class="type">RDD</span>[<span class="type">Int</span>] = sc.makeRDD(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line"><span class="comment">// 聚合数据</span></span><br><span class="line"><span class="keyword">val</span> reduceResult: <span class="type">Int</span> = rdd.reduce(_+_)</span><br><span class="line"><span class="comment">// 10</span></span><br></pre></td></tr></table></figure><h6 id="（4）reduceByKey和groupByKey的区别？"><a href="#（4）reduceByKey和groupByKey的区别？" class="headerlink" title="（4）reduceByKey和groupByKey的区别？"></a>（4）reduceByKey和groupByKey的区别？</h6><p><strong>从 shuffle 的角度</strong>：reduceByKey 和 groupByKey 都存在 shuffle 的操作，但是 reduceByKey 可以在 shuffle 前对分区内相同 key 的数据进行预聚合（combine）功能，这样会减少落盘的 数据量，而 groupByKey 只是进行分组，不存在数据量减少的问题，reduceByKey 性能比较高。</p><p><strong>从功能的角度</strong>：reduceByKey 其实包含分组和聚合的功能。GroupByKey 只能分组，不能聚合，所以在分组聚合的场合下，推荐使用 reduceByKey，如果仅仅是分组而不需要聚合。那么还是只能使用 groupByKey。</p><p><strong>所以在进行大量数据的 reduce 操作时候建议使用 reduceByKey。不仅可以提高速度，还可以防止使用 groupByKey 造成的内存溢出问题。</strong></p><h6 id="（5）一种WordCount代码实现"><a href="#（5）一种WordCount代码实现" class="headerlink" title="（5）一种WordCount代码实现"></a>（5）一种WordCount代码实现</h6><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Spark03</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="comment">// 配置Driverp[设置本地master适配、application进程名字]</span></span><br><span class="line">        <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;WordCount&quot;</span>)</span><br><span class="line">        <span class="comment">// 装载</span></span><br><span class="line">        <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(sparkConf)</span><br><span class="line"><span class="comment">// 加载文件（按行读取）</span></span><br><span class="line">        <span class="keyword">val</span> lines: <span class="type">RDD</span>[<span class="type">String</span>] = sc.textFile(<span class="string">&quot;datas&quot;</span>)</span><br><span class="line">        <span class="comment">// 按照空格将每一行的句子扁平化成词语</span></span><br><span class="line">        <span class="keyword">val</span> word: <span class="type">RDD</span>[<span class="type">String</span>] = lines.flatMap(_.split(<span class="string">&quot; &quot;</span>))</span><br><span class="line"><span class="comment">// 对每一个词语设置由word转化为(word, 1)格式</span></span><br><span class="line">        <span class="keyword">val</span> wordToOne = word.map &#123;</span><br><span class="line">            word =&gt; (word, <span class="number">1</span>)</span><br><span class="line">        &#125;</span><br><span class="line"><span class="comment">// 通过相同的key进行聚合，value相加</span></span><br><span class="line">        <span class="keyword">val</span> wordToCount = wordToOne.reduceByKey(_+_)</span><br><span class="line"><span class="comment">// 将数据返回到Driver端</span></span><br><span class="line">        <span class="keyword">val</span> array: <span class="type">Array</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordToCount.collect()</span><br><span class="line">        <span class="comment">// 循环打印</span></span><br><span class="line">        array.foreach(println)</span><br><span class="line">        sc.stop()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="3、RDD序列化（了解）"><a href="#3、RDD序列化（了解）" class="headerlink" title="3、RDD序列化（了解）"></a>3、RDD序列化（了解）</h4><h6 id="（1）闭包检查"><a href="#（1）闭包检查" class="headerlink" title="（1）闭包检查"></a>（1）闭包检查</h6><p>从计算的角度, <strong>算子以外的代码都是在 Driver 端执行, 算子里面的代码都是在 Executor 端执行。</strong>那么在 Scala 的函数式编程中，就会导致算子内经常会用到算子外的数据，这样就形成了闭包的效果，如果使用的算子外的数据无法序列化，就意味着无法传值给 Executor 端执行，就会发生错误，所以需要在执行任务计算前，检测闭包内的对象是否可以进行序列化，这个操作我们称之为<strong>闭包检测。Scala2.12 版本后闭包编译方式发生了改变。</strong></p><h6 id="（2）序列化方法和属性"><a href="#（2）序列化方法和属性" class="headerlink" title="（2）序列化方法和属性"></a>（2）序列化方法和属性</h6><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">serializable02_function</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="comment">//1.创建 SparkConf 并设置 App 名称</span></span><br><span class="line">        <span class="keyword">val</span> conf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;SparkCoreTest&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">        <span class="comment">//2.创建 SparkContext，该对象是提交 Spark App 的入口</span></span><br><span class="line">        <span class="keyword">val</span> sc: <span class="type">SparkContext</span> = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">        <span class="comment">//3.创建一个 RDD</span></span><br><span class="line">        <span class="keyword">val</span> rdd: <span class="type">RDD</span>[<span class="type">String</span>] = sc.makeRDD(<span class="type">Array</span>(<span class="string">&quot;hello world&quot;</span>, <span class="string">&quot;hello spark&quot;</span>, <span class="string">&quot;hive&quot;</span>, <span class="string">&quot;atguigu&quot;</span>))</span><br><span class="line">        <span class="comment">//3.1 创建一个 Search 对象</span></span><br><span class="line">        <span class="keyword">val</span> search = <span class="keyword">new</span> <span class="type">Search</span>(<span class="string">&quot;hello&quot;</span>)</span><br><span class="line">        <span class="comment">//3.2 函数传递，打印：ERROR Task not serializable</span></span><br><span class="line">        search.getMatch1(rdd).collect().foreach(println)</span><br><span class="line">        <span class="comment">//3.3 属性传递，打印：ERROR Task not serializable</span></span><br><span class="line">        search.getMatch2(rdd).collect().foreach(println)</span><br><span class="line">        <span class="comment">//4.关闭连接</span></span><br><span class="line">        sc.stop()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Search</span>(<span class="params">query:<span class="type">String</span></span>) <span class="keyword">extends</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isMatch</span></span>(s: <span class="type">String</span>): <span class="type">Boolean</span> = &#123;</span><br><span class="line">        s.contains(query)</span><br><span class="line">    &#125;</span><br><span class="line"> <span class="comment">// 函数序列化案例</span></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">getMatch1</span> </span>(rdd: <span class="type">RDD</span>[<span class="type">String</span>]): <span class="type">RDD</span>[<span class="type">String</span>] = &#123;</span><br><span class="line"> <span class="comment">//rdd.filter(this.isMatch)</span></span><br><span class="line"> rdd.filter(isMatch)</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="comment">// 属性序列化案例</span></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">getMatch2</span></span>(rdd: <span class="type">RDD</span>[<span class="type">String</span>]): <span class="type">RDD</span>[<span class="type">String</span>] = &#123;</span><br><span class="line"> <span class="comment">//rdd.filter(x =&gt; x.contains(this.query))</span></span><br><span class="line"> rdd.filter(x =&gt; x.contains(query))</span><br><span class="line"> <span class="comment">//val q = query</span></span><br><span class="line"> <span class="comment">//rdd.filter(x =&gt; x.contains(q))</span></span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="（3）Kryo序列化框架"><a href="#（3）Kryo序列化框架" class="headerlink" title="（3）Kryo序列化框架"></a>（3）Kryo序列化框架</h6><p>参考地址: <a href="https://github.com/EsotericSoftware/kryo">https://github.com/EsotericSoftware/kryo</a></p><p>Java 的序列化能够序列化任何的类。但是比较重（字节多），序列化后，对象的提交也比较大。Spark 出于性能的考虑，Spark2.0 开始支持另外一种 Kryo 序列化机制。Kryo 速度 是 Serializable 的 10 倍。当 RDD 在 Shuffle 数据的时候，简单数据类型、数组和字符串类型 已经在 Spark 内部使用 Kryo 来序列化。</p><p><strong>注意：即使使用 Kryo 序列化，也要继承 Serializable 接口。</strong></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">serializable_Kryo</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"> <span class="keyword">val</span> conf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">        .setAppName(<span class="string">&quot;SerDemo&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line"> <span class="comment">// 替换默认的序列化机制</span></span><br><span class="line"> .set(<span class="string">&quot;spark.serializer&quot;</span>, </span><br><span class="line">                                     <span class="string">&quot;org.apache.spark.serializer.KryoSerializer&quot;</span>)</span><br><span class="line"> <span class="comment">// 注册需要使用 kryo 序列化的自定义类</span></span><br><span class="line"> .registerKryoClasses(<span class="type">Array</span>(classOf[<span class="type">Searcher</span>]))</span><br><span class="line"> <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line"> <span class="keyword">val</span> rdd: <span class="type">RDD</span>[<span class="type">String</span>] = sc.makeRDD(<span class="type">Array</span>(<span class="string">&quot;hello world&quot;</span>, <span class="string">&quot;hello atguigu&quot;</span>, <span class="string">&quot;atguigu&quot;</span>, <span class="string">&quot;hahah&quot;</span>), <span class="number">2</span>)</span><br><span class="line"> <span class="keyword">val</span> searcher = <span class="keyword">new</span> <span class="type">Searcher</span>(<span class="string">&quot;hello&quot;</span>)</span><br><span class="line"> <span class="keyword">val</span> result: <span class="type">RDD</span>[<span class="type">String</span>] = searcher.getMatchedRDD1(rdd)</span><br><span class="line"> result.collect.foreach(println)</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Searcher</span>(<span class="params">val query: <span class="type">String</span></span>) </span>&#123;</span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">isMatch</span></span>(s: <span class="type">String</span>) = &#123;</span><br><span class="line"> s.contains(query)</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">getMatchedRDD1</span></span>(rdd: <span class="type">RDD</span>[<span class="type">String</span>]) = &#123;</span><br><span class="line"> rdd.filter(isMatch) </span><br><span class="line"> &#125;</span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">getMatchedRDD2</span></span>(rdd: <span class="type">RDD</span>[<span class="type">String</span>]) = &#123;</span><br><span class="line"> <span class="keyword">val</span> q = query</span><br><span class="line"> rdd.filter(_.contains(q))</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="4、RDD依赖关系（重中之重）"><a href="#4、RDD依赖关系（重中之重）" class="headerlink" title="4、RDD依赖关系（重中之重）"></a>4、RDD依赖关系（重中之重）</h4><h6 id="（1）血缘关系"><a href="#（1）血缘关系" class="headerlink" title="（1）血缘关系"></a>（1）血缘关系</h6><p>RDD 只支持粗粒度转换，即在大量记录上执行的单个操作。将创建 RDD 的一系列 Lineage （血统）记录下来，以便恢复丢失的分区。RDD 的 Lineage 会记录 RDD 的元数据信息和转 换行为，当该 RDD 的部分分区数据丢失时，它可以根据这些信息来重新运算和恢复丢失的数据分区。</p><h6 id="（2）依赖关系"><a href="#（2）依赖关系" class="headerlink" title="（2）依赖关系"></a>（2）依赖关系</h6><blockquote><p>所谓的依赖关系，其实就是两个相邻 RDD 之间的关系。</p><p>通常使用.dependencies去查看RDD之间的关系。</p></blockquote><h6 id="（3）宽窄依赖"><a href="#（3）宽窄依赖" class="headerlink" title="（3）宽窄依赖"></a>（3）宽窄依赖</h6><p><strong>窄依赖</strong></p><ul><li>父 RDD 的一个分区只会被子 RDD 的一个分区依赖</li><li>窄依赖的多个分区可以并行计算； 窄依赖的一个分区的数据如果丢失只需要重新计算对应的分区的数据就可以了。</li></ul><p><strong>宽依赖</strong></p><ul><li><p>父 RDD 的一个分区会被子 RDD 的多个分区依赖(涉及到 shuffle)</p></li><li><p>划分 Stage(阶段)的依据：对于宽依赖,必须等到上一阶段计算完成才能计算下一阶段。</p></li></ul><h4 id="5、RDD持久化"><a href="#5、RDD持久化" class="headerlink" title="5、RDD持久化"></a>5、RDD持久化</h4><h6 id="（1）Cache缓存"><a href="#（1）Cache缓存" class="headerlink" title="（1）Cache缓存"></a>（1）Cache缓存</h6><p>RDD 通过 Cache 或者 Persist 方法将前面的计算结果缓存，默认情况下会把数据以缓存 在 JVM 的堆内存中。但是并不是这两个方法被调用时立即缓存，而是触发后面的 action 算 子时，该 RDD 将会被缓存在计算节点的内存中，并供后面重用。</p><p>Spark 会自动对一些 Shuffle 操作的中间数据做持久化操作(比如：reduceByKey)。这样 做的目的是为了当一个节点 Shuffle 失败了避免重新计算整个输入。但是，在实际使用的时候，如果想重用数据，仍然建议调用 persist 或 cache。</p><h6 id="（2）CheckPoint检查点"><a href="#（2）CheckPoint检查点" class="headerlink" title="（2）CheckPoint检查点"></a>（2）CheckPoint检查点</h6><p>所谓的检查点其实就是通过将 RDD 中间结果写入磁盘。由于血缘依赖过长会造成容错成本过高，这样就不如在中间阶段做检查点容错，如果检查点之后有节点出现问题，可以从检查点开始重做血缘，减少了开销。 对 RDD 进行 checkpoint 操作并不会马上被执行，必须执行 Action 操作才能触发。</p><h6 id="（3）缓存和检查点区别"><a href="#（3）缓存和检查点区别" class="headerlink" title="（3）缓存和检查点区别"></a>（3）缓存和检查点区别</h6><ul><li>Cache 缓存只是将数据保存起来，不切断血缘依赖。Checkpoint 检查点切断血缘依赖。</li><li>Cache 缓存的数据通常存储在磁盘、内存等地方，可靠性低。Checkpoint 的数据通常存 储在 HDFS 等容错、高可用的文件系统，可靠性高。</li><li>建议对 checkpoint()的 RDD 使用 Cache 缓存，这样 checkpoint 的 job 只需从 Cache 缓存中读取数据即可，否则需要再从头计算一次 RDD。</li></ul><hr><h2 id="第三章-Spark-SQL：结构化数据处理"><a href="#第三章-Spark-SQL：结构化数据处理" class="headerlink" title="第三章 Spark SQL：结构化数据处理"></a>第三章 Spark SQL：结构化数据处理</h2><h4 id="1、Spark-SQL概述"><a href="#1、Spark-SQL概述" class="headerlink" title="1、Spark SQL概述"></a>1、Spark SQL概述</h4><p><strong>Spark SQL 是 Spark 用于结构化数据(structured data)处理的 Spark 模块。</strong></p><p>SparkSQL 的前身是 Shark，给熟悉 RDBMS 但又不理解 MapReduce 的技术人员提供快速上手的工具。 Hive 是早期唯一运行在 Hadoop 上的 SQL-on-Hadoop 工具。但是 MapReduce 计算过程 中大量的中间磁盘落地过程消耗了大量的 I&#x2F;O，降低的运行效率，为了提高 SQL-on-Hadoop 的效率，大量的 SQL-on-Hadoop 工具开始产生，其中表现较为突出的是：Drill 、 Impala 、 Shark 。其中 Shark 是伯克利实验室 Spark 生态环境的组件之一，是基于 Hive 所开发的工具，它修改了Hive的内存管理、物理计划、执行三个模块，并使之能运行在 Spark 引擎上。</p><p>随着 Spark 的发展，SparkSQL 抛弃原有 Shark 的代码，汲取了 Shark 的一些优点，如内存列存储（In-Memory Columnar  Storage）、Hive兼容性等，重新开发了SparkSQL代码；由于摆脱了对Hive的依赖性，SparkSQL 无论在数据兼容、性能优化、组件扩展方面都得到了极大的方便。</p><ul><li><strong>数据兼容方面</strong> SparkSQL 不但兼容 Hive，还可以从 RDD、parquet 文件、JSON 文件中获取数据，未来版本甚至支持获取 RDBMS 数据以及 cassandra 等 NOSQL 数据</li><li><strong>性能优化方面</strong> 除了采取 In-Memory Columnar Storage、byte-code generation 等优化技术外、将会引进 Cost Model 对查询进行动态评估、获取最佳物理计划等等</li><li><strong>组件扩展方面</strong> 无论是 SQL 的语法解析器、分析器还是优化器都可以重新定义，进行扩展。</li></ul><p>其中 SparkSQL 作为 Spark 生态的一员继续发展，而不再受限于 Hive，只是兼容 Hive；而 Hive on Spark 是一个 Hive 的发展计划，该计划将 Spark 作为 Hive 的底层引擎之一，也就是 说，Hive 将不再受限于一个引擎，可以采用 Map-Reduce、Tez、Spark 等引擎。</p><blockquote><p>后续的文档计划中也将有Hive on Spark的内容，写该文档的时候题主还没学完，敬请期待！</p></blockquote><h4 id="2、Spark-SQL优点"><a href="#2、Spark-SQL优点" class="headerlink" title="2、Spark SQL优点"></a>2、Spark SQL优点</h4><ul><li><strong>易整合</strong>：无缝的整合了 SQL 查询和 Spark 编程</li><li><strong>统一的数据访问</strong>：使用相同的方式连接不同的数据源</li><li><strong>兼容Hive</strong>：在已有的仓库上直接运行 SQL 或者 HiveQL</li><li><strong>标准数据连接</strong>：通过 JDBC 或者ODBC来连接</li></ul><h4 id="3、DataFrame-amp-amp-DataSet"><a href="#3、DataFrame-amp-amp-DataSet" class="headerlink" title="3、DataFrame &amp;&amp; DataSet"></a>3、DataFrame &amp;&amp; DataSet</h4><h6 id="（1）DataFrame是什么？"><a href="#（1）DataFrame是什么？" class="headerlink" title="（1）DataFrame是什么？"></a>（1）DataFrame是什么？</h6><p>在 Spark 中，DataFrame 是一种以 RDD 为基础的分布式数据集，<strong>类似于传统数据库中的二维表格</strong>。DataFrame 与 RDD 的主要区别在于，前者带有 schema 元信息，即 DataFrame 所表示的二维表数据集的每一列都带有名称和类型。这使得 Spark SQL 得以洞察更多的结构信息，从而对藏于 DataFrame 背后的数据源以及作用于 DataFrame 之上的变换进行了针对性的优化，最终达到大幅提升运行时效率的目标。反观 RDD，由于无从得知所存数据元素的具体内部结构，Spark Core 只能在 stage 层面进行简单、通用的流水线优化。</p><p>同时，与 Hive 类似，DataFrame 也支持嵌套数据类型（struct、array 和 map）。从 API  易用性的角度上看，DataFrame API 提供的是一套高层的关系操作，比函数式的 RDD API 要更加友好，门槛更低。</p><p><img src="/2023/04/19/Spark%E4%BB%8E0%E5%88%B01%EF%BC%88%E4%B8%8A%EF%BC%89/3.1.png"></p><h6 id="（2）DataSet是什么？（课本比较久，没有这部分内容）"><a href="#（2）DataSet是什么？（课本比较久，没有这部分内容）" class="headerlink" title="（2）DataSet是什么？（课本比较久，没有这部分内容）"></a>（2）DataSet是什么？（课本比较久，没有这部分内容）</h6><p>DataSet 是分布式数据集合。DataSet 是 Spark 1.6 中添加的一个新抽象，是 DataFrame 的一个扩展。它提供了 RDD 的优势（强类型，使用强大的 lambda 函数的能力）以及 Spark  SQL 优化执行引擎的优点。DataSet 也可以使用功能性的转换（操作 map，flatMap，filter 等等）。</p><ul><li><p>DataSet 是 DataFrame API 的一个扩展，是 SparkSQL 最新的数据抽象</p></li><li><p>用户友好的 API 风格，既具有类型安全检查也具有 DataFrame 的查询优化特性；</p></li><li><p>用样例类来对 DataSet 中定义数据的结构信息，样例类中每个属性的名称直接映射到 DataSet 中的字段名称；</p></li><li><p>DataSet 是强类型的。比如可以有 DataSet[Car]，DataSet[Person]。</p></li><li><p>DataFrame 是 DataSet 的特列，DataFrame&#x3D;DataSet[Row] ，所以可以通过 as 方法将 DataFrame 转换为 DataSet。Row 是一个类型，跟 Car、Person 这些的类型一样，所有的 表结构信息都用 Row 来表示。获取数据时需要指定顺序。</p></li></ul><h4 id="4、Spark-SQL核心编程"><a href="#4、Spark-SQL核心编程" class="headerlink" title="4、Spark SQL核心编程"></a>4、Spark SQL核心编程</h4><p>Spark Core 中，如果想要执行应用程序，需要首先构建上下文环境对象 SparkContext， Spark SQL 其实可以理解为对 Spark Core 的一种封装，不仅仅在模型上进行了封装，上下文 环境对象也进行了封装。 在老的版本中，SparkSQL 提供两种 SQL 查询起始点：一个叫 SQLContext，用于 Spark 自己提供的 SQL 查询；一个叫 HiveContext，用于连接 Hive 的查询。</p><p><strong>SparkSession 是 Spark 最新的 SQL 查询起始点</strong>，实质上是 SQLContext 和 HiveContext 的组合，所以在 SQLContext 和 HiveContext 上可用的 API 在 SparkSession 上同样是可以使用 的。SparkSession 内部封装了 SparkContext，所以计算实际上是由 sparkContext 完成的。当 我们使用 spark-shell 的时候, spark 框架会自动的创建一个名称叫做 spark 的 SparkSession 对 象, 就像我们以前可以自动获取到一个 sc 来表示 SparkContext 对象一样。</p><h6 id="（1）DataFrame创建"><a href="#（1）DataFrame创建" class="headerlink" title="（1）DataFrame创建"></a>（1）DataFrame创建</h6><p>在 Spark SQL 中 SparkSession 是创建 DataFrame 和执行 SQL 的入口，创建 DataFrame 有三种方式：通过 Spark 的数据源进行创建；从一个存在的 RDD 进行转换；还可以从 Hive Table 进行查询返回。</p><p>使用数据源创建的方式最常见的是使用parquet文件创建和使用JSON文件创建。Parquet文件格式特点如下：</p><ul><li>可以跳过不符合条件的数据，只读取需要的数据，降低I&#x2F;O数据量。</li><li>可以压缩编码降低磁盘存储空间（悠羽同一列的数据类型一样，故可以使用更高效的压缩编码）。</li><li>只读取需要的列，支持向量运算，能够获取更好的扫描性能。</li><li>Parquet格式是Spark SQL的默认数据源格式，可通过spark.sql.sources.default配置。</li></ul><h6 id="（2）DSL语法"><a href="#（2）DSL语法" class="headerlink" title="（2）DSL语法"></a>（2）DSL语法</h6><p>DataFrame 提供一个特定领域语言(domain-specific language, DSL)去管理结构化的数据。 可以在 Scala, Java, Python 和 R 中使用 DSL，使用 DSL 语法风格不必去创建临时视图了。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"># 1) 创建一个 DataFrame</span><br><span class="line">scala&gt; val df = spark.read.json(&quot;data/user.json&quot;)</span><br><span class="line">df: org.apache.spark.sql.DataFrame = [age: bigint， name: string]</span><br><span class="line"></span><br><span class="line"># 2) 查看 DataFrame 的 Schema 信息</span><br><span class="line">scala&gt; df.printSchema</span><br><span class="line">root</span><br><span class="line">|-- age: Long (nullable = true)</span><br><span class="line">|-- username: string (nullable = true)</span><br><span class="line"></span><br><span class="line"># 3) 只查看&quot;username&quot;列数据，</span><br><span class="line">scala&gt; df.select(&quot;username&quot;).show()</span><br><span class="line">+--------+</span><br><span class="line">|username|</span><br><span class="line">+--------+</span><br><span class="line">|zhangsan|</span><br><span class="line">| lisi|</span><br><span class="line">| wangwu|</span><br><span class="line">+--------+</span><br><span class="line"></span><br><span class="line"># 4) 查看&quot;username&quot;列数据以及&quot;age+1&quot;数据</span><br><span class="line"># 注意:涉及到运算的时候, 每列都必须使用$, 或者采用引号表达式：单引号+字段名</span><br><span class="line">scala&gt; df.select($&quot;username&quot;,$&quot;age&quot; + 1).show</span><br><span class="line">scala&gt; df.select(&#x27;username, &#x27;age + 1).show()</span><br><span class="line">scala&gt; df.select(&#x27;username, &#x27;age + 1 as &quot;newage&quot;).show()</span><br><span class="line">+--------+---------+</span><br><span class="line">|username|(age + 1)|</span><br><span class="line">+--------+---------+</span><br><span class="line">|zhangsan|       21|</span><br><span class="line">|    lisi|       31|</span><br><span class="line">|  wangwu|       41|</span><br><span class="line">+--------+---------+</span><br></pre></td></tr></table></figure><h6 id="（3）RDD转化为DataFrame"><a href="#（3）RDD转化为DataFrame" class="headerlink" title="（3）RDD转化为DataFrame"></a>（3）RDD转化为DataFrame</h6><p>在 IDEA 中开发程序时，如果需要 RDD 与 DF 或者 DS 之间互相操作，那么需要引入 <strong>import spark.implicits._</strong></p><p>这里的 spark 不是 Scala 中的包名，而是创建的 sparkSession 对象的变量名称，所以必须先创建 SparkSession 对象再导入。这里的 spark 对象不能使用 var 声明，因为 Scala 只支持 val 修饰的对象的引入。 spark-shell 中无需导入，自动完成此操作。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; val idRDD = sc.textFile(&quot;data/id.txt&quot;)</span><br><span class="line">scala&gt; idRDD.toDF(&quot;id&quot;).show</span><br><span class="line">+---+</span><br><span class="line">| id|</span><br><span class="line">+---+</span><br><span class="line">|  1|</span><br><span class="line">|  2|</span><br><span class="line">|  3|</span><br><span class="line">|  4|</span><br><span class="line">+---+</span><br><span class="line"># 实际开发中，一般通过样例类将 RDD 转换为 DataFrame</span><br><span class="line"># toDF(to DataFrame)直接将RDD转化为DataFrame</span><br></pre></td></tr></table></figure><h6 id="（4）DataFrame转化为RDD"><a href="#（4）DataFrame转化为RDD" class="headerlink" title="（4）DataFrame转化为RDD"></a>（4）DataFrame转化为RDD</h6><p>DataFrame 其实就是对 RDD 的封装，所以可以直接获取内部的 RDD。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; val df = sc.makeRDD(List((&quot;zhangsan&quot;,30), (&quot;lisi&quot;,40))).map(t=&gt;User(t._1, t._2)).toDF</span><br><span class="line">df: org.apache.spark.sql.DataFrame = [name: string, age: int]</span><br><span class="line"></span><br><span class="line">scala&gt; val rdd = df.rdd</span><br><span class="line">rdd: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row] = MapPartitionsRDD[46] at rdd at &lt;console&gt;:25</span><br><span class="line"></span><br><span class="line">scala&gt; val array = rdd.collect</span><br><span class="line">array: Array[org.apache.spark.sql.Row] = Array([zhangsan,30], [lisi,40])</span><br></pre></td></tr></table></figure><h6 id="（5）DataFrame和DataSet转换"><a href="#（5）DataFrame和DataSet转换" class="headerlink" title="（5）DataFrame和DataSet转换"></a>（5）DataFrame和DataSet转换</h6><p><strong>声明：DataSet 是具有强类型的数据集合，需要提供对应的类型信息。DataFrame 其实是 DataSet 的特例，所以它们之间是可以互相转换的。</strong></p><blockquote><p>RDD与DataSet的互转和RDD与DataFrame的互转一模一样，区别仅仅只是toDF改为了toDS。</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># DataFrame 转换为 DataSet</span><br><span class="line">scala&gt; case class User(name:String, age:Int)</span><br><span class="line">defined class User</span><br><span class="line">scala&gt; val df = sc.makeRDD(List((&quot;zhangsan&quot;,30), </span><br><span class="line">(&quot;lisi&quot;,49))).toDF(&quot;name&quot;,&quot;age&quot;)</span><br><span class="line">df: org.apache.spark.sql.DataFrame = [name: string, age: int]</span><br><span class="line">scala&gt; val ds = df.as[User]</span><br><span class="line">ds: org.apache.spark.sql.Dataset[User] = [name: string, age: int]</span><br><span class="line"></span><br><span class="line"># DataSet 转换为 DataFrame</span><br><span class="line">scala&gt; val ds = df.as[User]</span><br><span class="line">ds: org.apache.spark.sql.Dataset[User] = [name: string, age: int]</span><br><span class="line">scala&gt; val df = ds.toDF</span><br><span class="line">df: org.apache.spark.sql.DataFrame = [name: string, age: int]</span><br><span class="line"></span><br><span class="line"># 首先使用as严格数据类型，再进行转换</span><br></pre></td></tr></table></figure><h4 id="5、RDD、DataFrame、DataSet三者的关系"><a href="#5、RDD、DataFrame、DataSet三者的关系" class="headerlink" title="5、RDD、DataFrame、DataSet三者的关系"></a>5、RDD、DataFrame、DataSet三者的关系</h4><h6 id="（1）版本上来看"><a href="#（1）版本上来看" class="headerlink" title="（1）版本上来看"></a>（1）版本上来看</h6><p>Spark1.0 &#x3D;&gt; RDD</p><p>Spark1.3 &#x3D;&gt; DataFrame</p><p>Spark1.6 &#x3D;&gt; Dataset</p><p>如果同样的数据都给到这三个数据结构，他们分别计算之后，都会给出相同的结果。不同是的他们的执行效率和执行方式。在后期的 Spark 版本中，<strong>DataSet 有可能会逐步取代 RDD 和 DataFrame 成为唯一的 API 接口。</strong></p><h6 id="（2）三者的共性"><a href="#（2）三者的共性" class="headerlink" title="（2）三者的共性"></a>（2）三者的共性</h6><ul><li>RDD、DataFrame、DataSet 全都是 spark 平台下的分布式弹性数据集，为处理超大型数 据提供便利；</li><li>三者都有惰性机制，在进行创建、转换，如 map 方法时，不会立即执行，只有在遇到 Action 如 foreach 时，三者才会开始遍历运算；</li><li>三者有许多共同的函数，如 filter，排序等；</li><li>在对 DataFrame 和 Dataset 进行操作许多操作都需要这个包：import spark.implicits._（在 创建好 SparkSession 对象后尽量直接导入）</li><li>三者都会根据 Spark 的内存情况自动缓存运算，这样即使数据量很大，也不用担心会内存溢出</li><li>三者都有 partition 分区的概念</li><li>DataFrame 和 DataSet 均可使用模式匹配获取各个字段的值和类型</li></ul><h6 id="（3）三者的区别"><a href="#（3）三者的区别" class="headerlink" title="（3）三者的区别"></a>（3）三者的区别</h6><p><strong>RDD</strong></p><ul><li>RDD 一般和 spark mllib 同时使用</li><li>RDD 不支持 Spark SQL 操作</li></ul><p><strong>DataFrame</strong></p><ul><li><p>与 RDD 和 DataSet 不同，DataFrame 每一行的类型固定为 Row，每一列的值没法直接访问，只有通过解析才能获取各个字段的值</p></li><li><p>DataFrame 与 DataSet 一般不与 spark mllib 同时使用</p></li><li><p>DataFrame 与 DataSet 均支持 SparkSQL 的操作，比如 select，group by 之类，还能注册临时表&#x2F;视窗，进行 sql 语句操作</p></li><li><p>DataFrame 与 DataSet 支持一些特别方便的保存方式，比如保存成 csv，可以带上表头，这样每一列的字段名一目了然</p></li></ul><p><strong>DataSet</strong></p><ul><li>Dataset 和 DataFrame 拥有完全相同的成员函数，区别只是每一行的数据类型不同。 DataFrame 其实就是 DataSet 的一个特例 type DataFrame &#x3D; Dataset[Row]</li><li>DataFrame 也可以叫 Dataset[Row]，每一行的类型是 Row，不解析，每一行究竟有哪些字段，各个字段又是什么类型都无从得知，只能用上面提到的 getAS 方法或者共性中的第七条提到的模式匹配拿出特定字段。而 Dataset 中，每一行是什么类型是不一定的，在自定义了 case class 之后可以很自由的获得每一行的信息。</li></ul><h6 id="（3）三者的互相转换"><a href="#（3）三者的互相转换" class="headerlink" title="（3）三者的互相转换"></a>（3）三者的互相转换</h6><p><img src="/2023/04/19/Spark%E4%BB%8E0%E5%88%B01%EF%BC%88%E4%B8%8A%EF%BC%89/3.2.png"></p><h4 id="6、用户自定义函数"><a href="#6、用户自定义函数" class="headerlink" title="6、用户自定义函数"></a>6、用户自定义函数</h4><p>用户可以通过 <strong>spark.udf</strong> 功能添加自定义函数，实现自定义功能。</p><h6 id="（1）UDF-User-Defined-Function，用户自定义函数"><a href="#（1）UDF-User-Defined-Function，用户自定义函数" class="headerlink" title="（1）UDF[User-Defined Function，用户自定义函数]"></a>（1）UDF[User-Defined Function，用户自定义函数]</h6><blockquote><p>UDF相当于对已经有的函数，比如说：count等进行一个封装，在Spark中注册后就能够直接使用。主打的是将普通的函数包装成按行执行的函数。</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 1) 创建 DataFrame</span><br><span class="line">scala&gt; val df = spark.read.json(&quot;data/user.json&quot;)</span><br><span class="line">df: org.apache.spark.sql.DataFrame = [age: bigint， username: string]</span><br><span class="line"></span><br><span class="line"># 2) 注册 UDF</span><br><span class="line">scala&gt; spark.udf.register(&quot;addName&quot;,(x:String)=&gt; &quot;Name:&quot;+x)</span><br><span class="line">res9: org.apache.spark.sql.expressions.UserDefinedFunction = </span><br><span class="line">UserDefinedFunction(&lt;function1&gt;,StringType,Some(List(StringType)))</span><br><span class="line"></span><br><span class="line"># 3) 创建临时表</span><br><span class="line">scala&gt; df.createOrReplaceTempView(&quot;people&quot;)</span><br><span class="line"></span><br><span class="line"># 4) 应用 UDF</span><br><span class="line">scala&gt; spark.sql(&quot;Select addName(name),age from people&quot;).show()</span><br></pre></td></tr></table></figure><h6 id="2-UDAF-User-Defined-Aggregation-Function，用户自定义聚合函数"><a href="#2-UDAF-User-Defined-Aggregation-Function，用户自定义聚合函数" class="headerlink" title="(2)UDAF[User-Defined Aggregation Function，用户自定义聚合函数]"></a>(2)UDAF[User-Defined Aggregation Function，用户自定义聚合函数]</h6><blockquote><p>UDAF相当于用户自定义SQL中没有的函数，这里只记录下Spark3.0之后最新的Aggregator的实现方式，以后在生产开发中遇到再进行详细学习。</p></blockquote><p>用户可以设定自己的自定义聚合函数。通 过继承 UserDefinedAggregateFunction 来实现用户自定义弱类型聚合函数。从 Spark3.0 版本 后，UserDefinedAggregateFunction 已经不推荐使用了。可以统一采用强类型聚合函数 Aggregator。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 需求：计算平均工资</span></span><br><span class="line"><span class="comment">// TODO 创建 UDAF 函数</span></span><br><span class="line"><span class="keyword">val</span> udaf = <span class="keyword">new</span> <span class="type">MyAvgAgeUDAF</span></span><br><span class="line"><span class="comment">// TODO 注册到 SparkSQL 中</span></span><br><span class="line">spark.udf.register(<span class="string">&quot;avgAge&quot;</span>, functions.udaf(udaf))</span><br><span class="line"><span class="comment">// TODO 在 SQL 中使用聚合函数</span></span><br><span class="line"><span class="comment">// 定义用户的自定义聚合函数</span></span><br><span class="line">spark.sql(<span class="string">&quot;select avgAge(age) from user&quot;</span>).show</span><br><span class="line"><span class="comment">// **************************************************</span></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Buff</span>(<span class="params"> var sum:<span class="type">Long</span>, var cnt:<span class="type">Long</span> </span>)</span></span><br><span class="line"><span class="comment">// totalage, count</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyAvgAgeUDAF</span> <span class="keyword">extends</span> <span class="title">Aggregator</span>[<span class="type">Long</span>, <span class="type">Buff</span>, <span class="type">Double</span>]</span>&#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">zero</span></span>: <span class="type">Buff</span> = <span class="type">Buff</span>(<span class="number">0</span>,<span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">reduce</span></span>(b: <span class="type">Buff</span>, a: <span class="type">Long</span>): <span class="type">Buff</span> = &#123;</span><br><span class="line">b.sum += a</span><br><span class="line"> b.cnt += <span class="number">1</span></span><br><span class="line"> b</span><br><span class="line"> &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">merge</span></span>(b1: <span class="type">Buff</span>, b2: <span class="type">Buff</span>): <span class="type">Buff</span> = &#123;</span><br><span class="line"> b1.sum += b2.sum</span><br><span class="line"> b1.cnt += b2.cnt</span><br><span class="line"> b1</span><br><span class="line"> &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">finish</span></span>(reduction: <span class="type">Buff</span>): <span class="type">Double</span> = &#123;</span><br><span class="line"> reduction.sum.toDouble/reduction.cnt</span><br><span class="line"> &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">bufferEncoder</span></span>: <span class="type">Encoder</span>[<span class="type">Buff</span>] = <span class="type">Encoders</span>.product</span><br><span class="line"> <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">outputEncoder</span></span>: <span class="type">Encoder</span>[<span class="type">Double</span>] = <span class="type">Encoders</span>.scalaDouble</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="7、Spark-SQL执行的流程（面试）"><a href="#7、Spark-SQL执行的流程（面试）" class="headerlink" title="7、Spark SQL执行的流程（面试）"></a>7、Spark SQL执行的流程（面试）</h4><ol><li>parser：基于 antlr 框架对 sql 解析，生成抽象语法树。</li><li>变量替换：通过正则表达式找出符合规则的字符串，替换成系统缓存环境的变量。 SQLConf 中的 spark.sql.variable.substitute，默认是可用的；参考 SparkSqlParser</li><li>parser：将 antlr 的 tree 转成 spark catalyst 的 LogicPlan，也就是未解析的逻辑计划；详细参考 AstBuild, ParseDriver</li><li>analyzer：通过分析器，结合 catalog，把 logical plan 和实际的数据绑定起来，将 未解析的逻辑计划 生成 逻辑计划；详细参考 QureyExecution</li><li>缓存替换：通过 CacheManager，替换有相同结果的 logical plan（逻辑计划）</li><li>logical plan 优化，基于规则的优化；优化规则参考 Optimizer，优化 执行器 RuleExecutor</li><li>生成 spark plan，也就是物理计划；参考QueryPlanner和SparkStrategies</li><li>spark plan 准备阶段</li><li>构造 RDD 执行，涉及 spark 的 wholeStageCodegenExec 机制，基于 janino 框架生成 java 代码并编译</li></ol>]]></content>
      
      
      <categories>
          
          <category> 我的大学 </category>
          
          <category> 大三下学期 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> 大数据组件 </tag>
            
            <tag> 从零到一系列 </tag>
            
            <tag> Spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flume从0到1</title>
      <link href="/2023/04/15/Flume%E4%BB%8E0%E5%88%B01/"/>
      <url>/2023/04/15/Flume%E4%BB%8E0%E5%88%B01/</url>
      
        <content type="html"><![CDATA[<blockquote><p>简单介绍下Flume日志采集系统，内容不多大概一天就学完了，但是正所谓学得快忘得也快，所以把其中一些常用的、配置类的内容进行一个记录，方便每次温习。</p></blockquote><h2 id="第一章-Flume概述"><a href="#第一章-Flume概述" class="headerlink" title="第一章 Flume概述"></a>第一章 Flume概述</h2><h4 id="1、定义"><a href="#1、定义" class="headerlink" title="1、定义"></a>1、定义</h4><p>Flume 是 Cloudera 提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统。Flume 基于流式架构，灵活简单。</p><h4 id="2、基础架构"><a href="#2、基础架构" class="headerlink" title="2、基础架构"></a>2、基础架构</h4><p><img src="/2023/04/15/Flume%E4%BB%8E0%E5%88%B01/1.1.png"></p><h6 id="（1）Agent"><a href="#（1）Agent" class="headerlink" title="（1）Agent"></a>（1）Agent</h6><p>Agent 是一个 JVM 进程，它以事件的形式将数据从源头送至目的。 Agent 主要有 3 个部分组成，Source、Channel、Sink。</p><h6 id="（2）Source"><a href="#（2）Source" class="headerlink" title="（2）Source"></a>（2）Source</h6><p>Source 是负责接收数据到 Flume Agent 的组件。Source 组件可以处理各种类型、各种 格式的日志数据，包括 <strong>avro</strong>、thrift、<strong>exec</strong>、jms、<strong>spooling directory、netcat、taildir</strong>、 sequence generator、syslog、http、legacy。</p><blockquote><p>Arvo是一种数据序列化系统，它是流式处理领域中常用的数据序列化系统之一。它支持多种编程语言，包括Java、Python、C、C++和C#等。Avro格式的数据是二进制的，它可以在不同的平台和语言之间进行交换。Avro格式的数据可以存储在Apache Kafka中，也可以存储在Hadoop中。</p><p>Avro格式的数据有以下优点：</p><ul><li>支持二进制序列化方式，可以便捷、快速地处理大量数据。</li><li>动态语言友好，Avro提供的机制使动态语言可以方便地处理Avro数据。</li><li>可排序的，这使得Avro格式的数据可以更容易地进行排序操作。</li><li>可扩展性强，Avro格式的数据可以很容易地进行扩展，而不需要修改现有的数据结构。</li></ul></blockquote><h6 id="（3）Sink"><a href="#（3）Sink" class="headerlink" title="（3）Sink"></a>（3）Sink</h6><p>Sink 不断地轮询 Channel 中的事件且批量地移除它们，并将这些事件批量写入到存储或索引系统、或者被发送到另一个 Flume Agent。</p><p>Sink 组件目的地包括 <strong>hdfs、logger、avro</strong>、thrift、ipc、<strong>file、HBase</strong>、solr、自定义。</p><h6 id="（4）Channnel"><a href="#（4）Channnel" class="headerlink" title="（4）Channnel"></a>（4）Channnel</h6><p>Channel 是位于 Source 和 Sink 之间的缓冲区。因此，Channel 允许 Source 和 Sink 运作在不同的速率上。Channel 是线程安全的，可以同时处理几个 Source 的写入操作和几个 Sink 的读取操作。 Flume 自带两种 Channel：Memory Channel 和 File Channel。</p><ul><li>Memory Channel 是内存中的队列。Memory Channel 在不需要关心数据丢失的情景下适 用。如果需要关心数据丢失，那么 Memory Channel 就不应该使用，因为程序死亡、机器宕 机或者重启都会导致数据丢失。</li><li>File Channel 将所有事件写到磁盘。因此在程序关闭或机器宕机的情况下不会丢失数据。</li></ul><h6 id="（5）Event"><a href="#（5）Event" class="headerlink" title="（5）Event"></a>（5）Event</h6><p>传输单元，Flume 数据传输的基本单元，以 Event 的形式将数据从源头送至目的地。 Event 由 Header 和 Body 两部分组成，Header 用来存放该 event 的一些属性，为 K-V 结构， Body 用来存放该条数据，形式为字节数组。</p><hr><h2 id="第二章-Flume入门"><a href="#第二章-Flume入门" class="headerlink" title="第二章 Flume入门"></a>第二章 Flume入门</h2><h4 id="1、案例一"><a href="#1、案例一" class="headerlink" title="1、案例一"></a>1、案例一</h4><blockquote><p>从官方案例入手，详解Flume配置文件的构成。</p><p>需求分析：</p><ul><li>通过netcat工具向本机的44444端口发送数据</li><li>Flume监控本机的44444端口，通过Flume的source端读取数据</li><li>Flume将获取的数据通过Sink端打印到控制台</li></ul></blockquote><h6 id="（1）配置文件"><a href="#（1）配置文件" class="headerlink" title="（1）配置文件"></a>（1）配置文件</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Name the components on this agent</span></span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe/configure the <span class="built_in">source</span></span></span><br><span class="line">a1.sources.r1.type = netcat</span><br><span class="line">a1.sources.r1.bind = localhost</span><br><span class="line">a1.sources.r1.port = 44444</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe the sink</span></span><br><span class="line">a1.sinks.k1.type = logger</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Use a channel <span class="built_in">which</span> buffers events <span class="keyword">in</span> memory</span></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Bind the <span class="built_in">source</span> and sink to the channel</span></span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure><blockquote><p>我们将配置文件分为5个部分：</p><p>（1）配置命名：a1表示agent的名字；r1表示a1的source的名字，因为可以命名多个，所以这里是sources；k1是sink的名字，同理可以一次命名多个；c1是channel的名字。</p><p>（2）配置source：source用做接收输入数据，所以首先配置的是输入数据来源type，其他配置则根据官方文档中的黑体进行配置，比如这里来源是netcat，需要配置监听主机和端口号。</p><p>（3）配置sink：sink用作输出数据，同样首先需要配置输出源type，其他配置同上，这里是输出到控制台所以没有其他配置。</p><p>（4）配置channel：配置channel的类型，主要为第一章说的memory内存型和file文件型；capacity和transactionCapacity代表event的总容量和单个事务的容量，transactionCapacity不能大于capacity否则事务回滚是无效的。</p><p>（5）绑定：将配置好的source和sink与channel进行绑定。其中：一个source可以输出到多个channel，但是一个sink只能接收一个channel的数据（但是一个channel可以将数据分发给不同的sink，需要建组实现）</p></blockquote><h6 id="（2）启动代码"><a href="#（2）启动代码" class="headerlink" title="（2）启动代码"></a>（2）启动代码</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">flume主目录下</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">写法一：</span></span><br><span class="line">bin/flume-ng agent --conf conf/ --name a1 --conf-file job/flume-netcat-logger.conf -Dflume.root.logger=INFO,console</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">写法二：</span></span><br><span class="line">bin/flume-ng agent -c conf/ -n a1 -f job/flume-netcat-logger.conf -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure><p>参数说明：</p><p>–conf&#x2F;-c：表示配置文件存储在 conf&#x2F;目录</p><p>–name&#x2F;-n：表示给 agent 起名为 a1</p><p>–conf-file&#x2F;-f：flume 本次启动读取的配置文件是在 job 文件夹下的 flume-telnet.conf 文件。</p><p>-Dflume.root.logger&#x3D;INFO,console ：-D 表示 flume 运行时动态修改 flume.root.logger 参数属性值，并将控制台日志打印级别设置为 INFO 级别。日志级别包括:log、info、warn、 error。</p><h4 id="2、案例二"><a href="#2、案例二" class="headerlink" title="2、案例二"></a>2、案例二</h4><blockquote><p><strong>使用 Flume 监听整个目录的文件，并上传至 HDFS</strong></p><p>需求分析：</p><ul><li>向指定目录中添加文件</li><li>查看HDFS 上数据</li><li>查看&#x2F;opt&#x2F;module&#x2F;flume&#x2F;upload 目录中上传的文件是否已经标记 为.COMPLETED结尾；.tmp后缀 结尾文件没有上传。</li></ul></blockquote><h6 id="（1）配置文件-1"><a href="#（1）配置文件-1" class="headerlink" title="（1）配置文件"></a>（1）配置文件</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">a3.sources = r3</span><br><span class="line">a3.sinks = k3</span><br><span class="line">a3.channels = c3</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe/configure the <span class="built_in">source</span></span></span><br><span class="line">a3.sources.r3.type = spooldir</span><br><span class="line">a3.sources.r3.spoolDir = /opt/module/flume/upload</span><br><span class="line">a3.sources.r3.fileSuffix = .COMPLETED</span><br><span class="line">a3.sources.r3.fileHeader = true</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">忽略所有以.tmp 结尾的文件，不上传</span></span><br><span class="line">a3.sources.r3.ignorePattern = ([^ ]*\.tmp)</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe the sink</span></span><br><span class="line">a3.sinks.k3.type = hdfs</span><br><span class="line">a3.sinks.k3.hdfs.path = hdfs://hadoop102:9820/flume/upload/%Y%m%d/%H</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">上传文件的前缀</span></span><br><span class="line">a3.sinks.k3.hdfs.filePrefix = upload-</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">是否按照时间滚动文件夹</span></span><br><span class="line">a3.sinks.k3.hdfs.round = true</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">多少时间单位创建一个新的文件夹</span></span><br><span class="line">a3.sinks.k3.hdfs.roundValue = 1</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">重新定义时间单位</span></span><br><span class="line">a3.sinks.k3.hdfs.roundUnit = hour</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">是否使用本地时间戳</span></span><br><span class="line">a3.sinks.k3.hdfs.useLocalTimeStamp = true</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">积攒多少个 Event 才 flush 到 HDFS 一次</span></span><br><span class="line">a3.sinks.k3.hdfs.batchSize = 100</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">设置文件类型，可支持压缩</span></span><br><span class="line">a3.sinks.k3.hdfs.fileType = DataStream</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">多久生成一个新的文件</span></span><br><span class="line">a3.sinks.k3.hdfs.rollInterval = 60</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">设置每个文件的滚动大小大概是 128M</span></span><br><span class="line">a3.sinks.k3.hdfs.rollSize = 134217700</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">文件的滚动与 Event 数量无关</span></span><br><span class="line">a3.sinks.k3.hdfs.rollCount = 0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Use a channel <span class="built_in">which</span> buffers events <span class="keyword">in</span> memory</span></span><br><span class="line">a3.channels.c3.type = memory</span><br><span class="line">a3.channels.c3.capacity = 1000</span><br><span class="line">a3.channels.c3.transactionCapacity = 100</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Bind the <span class="built_in">source</span> and sink to the channel</span></span><br><span class="line">a3.sources.r3.channels = c3</span><br><span class="line">a3.sinks.k3.channel = c3</span><br></pre></td></tr></table></figure><p><strong>说明：</strong>在使用 Spooling Directory Source 时，不要在监控目录中创建并持续修改文 件；上传完成的文件会以.COMPLETED 结尾；被监控文件夹每 500 毫秒扫描一次文件变动。</p><h4 id="3、案例三"><a href="#3、案例三" class="headerlink" title="3、案例三"></a>3、案例三</h4><blockquote><p>使用 Flume 监听整个目录的实时追加文件，并上传至 HDFS</p><p>需求分析：</p><ul><li>向监控文件追加内容 echo hello &gt;&gt; files&#x2F;file1.txt 、 echo hello &gt;&gt; files&#x2F;file2.txt</li><li>查看HDFS 上数据</li></ul></blockquote><p>Exec source 适用于监控一个实时追加的文件，不能实现断点续传；Spooldir Source 适合用于同步新文件，但不适合对实时追加日志的文件进行监听并同步；而 Taildir Source 适合用于监听多个实时追加的文件，并且能够实现断点续传。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">主要修改为<span class="built_in">source</span>部分，故只记录<span class="built_in">source</span>部分配置</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe/configure the <span class="built_in">source</span></span></span><br><span class="line">a3.sources.r3.type = TAILDIR</span><br><span class="line">a3.sources.r3.positionFile = /opt/module/flume/tail_dir.json</span><br><span class="line">a3.sources.r3.filegroups = f1 f2</span><br><span class="line">a3.sources.r3.filegroups.f1 = /opt/module/flume/files/.*file.*</span><br><span class="line">a3.sources.r3.filegroups.f2 = /opt/module/flume/files2/.*log.*</span><br></pre></td></tr></table></figure><p><strong>说明：</strong>.*类似于通配符（占位符），代表可以有0~任意个字符在占位。</p><p>Taildir Source 维护了一个 json 格式的 position File，其会定期的往 position File 中更新每个文件读取到的最新的位置，因此能够实现断点续传。</p><hr><h2 id="第三章-Flume进阶"><a href="#第三章-Flume进阶" class="headerlink" title="第三章 Flume进阶"></a>第三章 Flume进阶</h2><h4 id="1、事务"><a href="#1、事务" class="headerlink" title="1、事务"></a>1、事务</h4><p><img src="/2023/04/15/Flume%E4%BB%8E0%E5%88%B01/3.1.png"></p><p>Flume的事务有put和take机制，两者保证数据传输的准确性。Put事务是指从Source到Channel，Take事务是指从Channel到Sink。¹²³</p><p>Put事务流程如下：</p><ul><li>将数据从source写入临时缓冲区putList。</li><li>检查Channel内存队列是否足够合并。</li><li>如果内存队列空间不足，则回滚数据。</li></ul><p>Take事务流程如下：</p><ul><li>sink不断从channel中拉取event，没拉取一个event，这个event会先放入takeList中。</li><li>当一个batchSize的event全部拉取到takeList中之后，此时由sink执行写出处理。</li><li>假如在写出过程中，发送了异常，此时执行回滚。</li><li>将takeList中所有的event全部回滚到channel。</li></ul><blockquote><p><strong>Put事务</strong>开始的时候会调用一个doPut方法，doPut方法的会将这批数据batch data，也就是一批event放到putList中。（doPut传递的数据的大小可以通过参数bathchSize配置。putList的大小则通过channel的参数transactionCapacity进行配置。）</p><p>当数据成功存放到putList之后，调用doCommit()方法,putList中所有的event进入channel()中，</p><ul><li><p>成功则清空putList.</p></li><li><p>不成功的情况</p><ul><li><p>从putList传输到channel过程出问题，在doCommit提交之后，事务在向channel放的过程中，遇到问题。例如：sink那边取数据速度要比Source这边放数据速度慢，导致channel中的数据积压，这个时候就会造成putList中的数据放不进去。这时会进行事务的回滚操作，调用doRollback方法，doRollback方法会做两个事情：<br>1、清空putList中的数据；<br>2、抛出channelException异常。</p><p><strong>当source捕捉到doRollback抛出的异常，就会把刚才的一批数据重新采集一下，采集完之后重新走事务的流程。</strong></p></li><li><p>在数据采集的过程中也有可能出现问题，同样是调用doRollback方法来对事务进行回滚。</p></li></ul></li></ul></blockquote><blockquote><p><strong>Take事务</strong>开始时，调用doTake方法,将channel中的event提取到(剪切)takeList中，如果后面的sink是HDFS Sink，同时在写入HDFS的IO缓冲流中放一份event。</p><p>当takeList中存放的Event达到约定数量(batchSize) ，就会调用doCommit方法：</p><ul><li><p>成功执行情况下：如果是HDFS Sink，那么手动调用IO流的flush方法，将IO流缓冲区的数据写入到HDFS磁盘中，同时清空takeList中的数据</p></li><li><p>失败情况下:</p><ul><li><p>1.网络延迟等原因导致传输数据失败：调用doRollback方法来进行回滚，takeList中还有备份数据，所以<strong>将takeList中的数据原封不动地还给channel，这时候就完成了事务的回滚</strong>。</p></li><li><p>2.如果takeList数据有一部分传输成功了，剩下的因为网络延迟传输失败了：同样会调用doRollback方法来进行回滚，它会把整个takeList中的数据返回给channel，然后继续进行数据的读写。如此一来，<strong>再次进行事务时候，就会存在数据重复的可能。</strong></p></li></ul></li></ul></blockquote><p>总结来说就是：Put事务会在回滚的时候丢弃原本采集到的数据并进行重新采集；Take事务会将sink中已经拿到的event组成逆序队列还给channel，如果出现写了一半的情况，会将一整个全部还给channel，这样会导致数据可能重复。</p><h4 id="2、Agent内部原理"><a href="#2、Agent内部原理" class="headerlink" title="2、Agent内部原理"></a>2、Agent内部原理</h4><p><img src="/2023/04/15/Flume%E4%BB%8E0%E5%88%B01/3.2.png"></p><p><strong>重要组件：</strong></p><ul><li>ChannelSelector<ul><li>ChannelSelector 的作用就是选出 Event 将要被发往哪个 Channel。其共有两种类型， 分别是 Replicating（复制）和 Multiplexing（多路复用）。</li><li>ReplicatingSelector 会将同一个 Event 发往所有的 Channel，Multiplexing 会根据相 应的原则，将不同的 Event 发往不同的 Channel。</li></ul></li><li>SinkProcessor<ul><li>SinkProcessor 共 有 三 种 类 型 ， 分 别 是 DefaultSinkProcessor （默认）、 LoadBalancingSinkProcessor（负载均衡） 和 FailoverSinkProcessor （故障转移）</li><li>DefaultSinkProcessor 对 应 的 是 单 个 的 Sink ， LoadBalancingSinkProcessor 和 FailoverSinkProcessor 对应的是 Sink Group，LoadBalancingSinkProcessor 可以实现负 载均衡的功能，FailoverSinkProcessor 可以错误恢复的功能。</li></ul></li></ul><blockquote><p>完整的Flume Agent流程并不止有Source、Channel、Sink三个部分，正确的流程包括：</p><ul><li>Source读取数据并发送给Channel Processor</li><li>Channel Processor将数据发给Channel Interceptor进行（条件）过滤，过滤完回到Channel Processor</li><li>Channel Processor将数据交给Channel Selector，按条件分发到各个Channel上</li><li>各个Channel上的数据由SinkProcessor进行汇总，并确定分发到不同的Sink</li></ul></blockquote><h4 id="3、详解ChannelSelector复制"><a href="#3、详解ChannelSelector复制" class="headerlink" title="3、详解ChannelSelector复制"></a>3、详解ChannelSelector复制</h4><p>使用 Flume-1 监控文件变动，Flume-1 将变动内容传递给 Flume-2，Flume-2 负责存储 到 HDFS。同时 Flume-1 将变动内容传递给 Flume-3，Flume-3 负责输出到 Local  FileSystem。<strong>实现单数据源多出口。</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">主要代码（Flume-1）</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Name the components on this agent</span></span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1 k2</span><br><span class="line">a1.channels = c1 c2</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将数据流复制给所有 channel</span></span><br><span class="line">a1.sources.r1.selector.type = replicating  # 区别只在于对selector的类型进行了设置</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe/configure the <span class="built_in">source</span></span></span><br><span class="line">a1.sources.r1.type = exec</span><br><span class="line">a1.sources.r1.command = tail -F /opt/module/hive/logs/hive.log</span><br><span class="line">a1.sources.r1.shell = /bin/bash -c</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe the sink</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">sink 端的 avro 是一个数据发送者</span></span><br><span class="line">a1.sinks.k1.type = avro</span><br><span class="line">a1.sinks.k1.hostname = hadoop102</span><br><span class="line">a1.sinks.k1.port = 4141</span><br><span class="line">a1.sinks.k2.type = avro</span><br><span class="line">a1.sinks.k2.hostname = hadoop102</span><br><span class="line">a1.sinks.k2.port = 4142</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe the channel</span></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line">a1.channels.c2.type = memory</span><br><span class="line">a1.channels.c2.capacity = 1000</span><br><span class="line">a1.channels.c2.transactionCapacity = 100</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Bind the <span class="built_in">source</span> and sink to the channel</span></span><br><span class="line">a1.sources.r1.channels = c1 c2</span><br><span class="line">a1.sinks.k1.channel = c1</span><br><span class="line">a1.sinks.k2.channel = c2</span><br></pre></td></tr></table></figure><h4 id="4、详解SinkProcessor故障转移"><a href="#4、详解SinkProcessor故障转移" class="headerlink" title="4、详解SinkProcessor故障转移"></a>4、详解SinkProcessor故障转移</h4><p>使用 Flume1 监控一个端口，其 sink 组中的 sink 分别对接 Flume2 和 Flume3，采用 FailoverSinkProcessor，实现故障转移的功能。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">主要代码（Flume1）</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Name the components on this agent</span></span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.channels = c1</span><br><span class="line">a1.sinkgroups = g1</span><br><span class="line">a1.sinks = k1 k2</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe/configure the <span class="built_in">source</span></span></span><br><span class="line">a1.sources.r1.type = netcat</span><br><span class="line">a1.sources.r1.bind = localhost</span><br><span class="line">a1.sources.r1.port = 44444</span><br><span class="line">a1.sinkgroups.g1.processor.type = failover  # 主要区别在于采用processor类型</span><br><span class="line">a1.sinkgroups.g1.processor.priority.k1 = 5  # 设置优先级实现动态调整（负载均衡也可）</span><br><span class="line">a1.sinkgroups.g1.processor.priority.k2 = 10</span><br><span class="line">a1.sinkgroups.g1.processor.maxpenalty = 10000</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe the sink</span></span><br><span class="line">a1.sinks.k1.type = avro</span><br><span class="line">a1.sinks.k1.hostname = hadoop102</span><br><span class="line">a1.sinks.k1.port = 4141</span><br><span class="line">a1.sinks.k2.type = avro</span><br><span class="line">a1.sinks.k2.hostname = hadoop102</span><br><span class="line">a1.sinks.k2.port = 4142</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe the channel</span></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Bind the <span class="built_in">source</span> and sink to the channel</span></span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinkgroups.g1.sinks = k1 k2</span><br><span class="line">a1.sinks.k1.channel = c1</span><br><span class="line">a1.sinks.k2.channel = c1</span><br></pre></td></tr></table></figure><h4 id="5、自定义Interceptor"><a href="#5、自定义Interceptor" class="headerlink" title="5、自定义Interceptor"></a>5、自定义Interceptor</h4><p>在实际的开发中，一台服务器产生的日志类型可能有很多种，不同类型的日志可能需要发送到不同的分析系统。此时会用到 Flume 拓扑结构中的 Multiplexing 结构，Multiplexing 的原理是，根据 event 中 Header 的某个 key 的值，将不同的 event 发送到不同的 Channel中，所以我们需要自定义一个 Interceptor，为不同类型的 event 的 Header 中的 key 赋予不同的值。 在该案例中，我们以端口数据模拟日志，以是否包含”atguigu”模拟不同类型的日志， 我们需要自定义 interceptor 区分数据中是否包含”atguigu”，将其分别发往不同的分析系统（Channel）。</p><p><img src="/2023/04/15/Flume%E4%BB%8E0%E5%88%B01/3.3.png"></p><h6 id="（1）自定义Jar包拦截文件"><a href="#（1）自定义Jar包拦截文件" class="headerlink" title="（1）自定义Jar包拦截文件"></a>（1）自定义Jar包拦截文件</h6><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flume.Context;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.Event;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.interceptor.Interceptor;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TypeInterceptor</span> <span class="keyword">implements</span> <span class="title class_">Interceptor</span> &#123;</span><br><span class="line">     <span class="comment">//声明一个存放事件的集合</span></span><br><span class="line">     <span class="keyword">private</span> List&lt;Event&gt; addHeaderEvents;</span><br><span class="line">     <span class="meta">@Override</span></span><br><span class="line">     <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">initialize</span><span class="params">()</span> &#123;</span><br><span class="line">     <span class="comment">//初始化存放事件的集合</span></span><br><span class="line">     addHeaderEvents = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">     &#125;</span><br><span class="line">    </span><br><span class="line">     <span class="comment">//单个事件拦截</span></span><br><span class="line">     <span class="meta">@Override</span></span><br><span class="line">     <span class="keyword">public</span> Event <span class="title function_">intercept</span><span class="params">(Event event)</span> &#123;</span><br><span class="line">     <span class="comment">//1.获取事件中的头信息</span></span><br><span class="line">     Map&lt;String, String&gt; headers = event.getHeaders();</span><br><span class="line">     <span class="comment">//2.获取事件中的 body 信息</span></span><br><span class="line">     <span class="type">String</span> <span class="variable">body</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">String</span>(event.getBody());</span><br><span class="line">     <span class="comment">//3.根据 body 中是否有&quot;atguigu&quot;来决定添加怎样的头信息</span></span><br><span class="line">     <span class="keyword">if</span> (body.contains(<span class="string">&quot;atguigu&quot;</span>)) &#123;</span><br><span class="line">     <span class="comment">//4.添加头信息</span></span><br><span class="line">     headers.put(<span class="string">&quot;type&quot;</span>, <span class="string">&quot;first&quot;</span>);</span><br><span class="line">     &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">     <span class="comment">//4.添加头信息</span></span><br><span class="line">     headers.put(<span class="string">&quot;type&quot;</span>, <span class="string">&quot;second&quot;</span>);</span><br><span class="line">     &#125;</span><br><span class="line">     <span class="keyword">return</span> event;</span><br><span class="line">     &#125;</span><br><span class="line">     </span><br><span class="line">    <span class="comment">//批量事件拦截</span></span><br><span class="line">     <span class="meta">@Override</span></span><br><span class="line">     <span class="keyword">public</span> List&lt;Event&gt; <span class="title function_">intercept</span><span class="params">(List&lt;Event&gt; events)</span> &#123;</span><br><span class="line">     <span class="comment">//1.清空集合</span></span><br><span class="line">     addHeaderEvents.clear();</span><br><span class="line">     <span class="comment">//2.遍历 events</span></span><br><span class="line">     <span class="keyword">for</span> (Event event : events) &#123;</span><br><span class="line">     <span class="comment">//3.给每一个事件添加头信息</span></span><br><span class="line">     addHeaderEvents.add(intercept(event));</span><br><span class="line">     &#125;</span><br><span class="line">     <span class="comment">//4.返回结果</span></span><br><span class="line">     <span class="keyword">return</span> addHeaderEvents;</span><br><span class="line">     &#125;</span><br><span class="line">    </span><br><span class="line">     <span class="meta">@Override</span></span><br><span class="line">     <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> &#123;&#125;</span><br><span class="line">    </span><br><span class="line">     <span class="comment">// 创建构造方法</span></span><br><span class="line">     <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Builder</span> <span class="keyword">implements</span> <span class="title class_">Interceptor</span>.Builder &#123;</span><br><span class="line">         <span class="meta">@Override</span></span><br><span class="line">     <span class="keyword">public</span> Interceptor <span class="title function_">build</span><span class="params">()</span> &#123;</span><br><span class="line">     <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">TypeInterceptor</span>();</span><br><span class="line">     &#125;</span><br><span class="line">     <span class="meta">@Override</span></span><br><span class="line">     <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">configure</span><span class="params">(Context context)</span> &#123;</span><br><span class="line">     &#125;</span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="（2）配置文件"><a href="#（2）配置文件" class="headerlink" title="（2）配置文件"></a>（2）配置文件</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">主要变动在<span class="built_in">source</span>中（从<span class="built_in">source</span>到channel进行拦截处理数据），所以主要展示<span class="built_in">source</span>代码</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe/configure the <span class="built_in">source</span></span></span><br><span class="line">a1.sources.r1.type = netcat</span><br><span class="line">a1.sources.r1.bind = localhost</span><br><span class="line">a1.sources.r1.port = 44444</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">给拦截器命名</span></span><br><span class="line">a1.sources.r1.interceptors = i1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">调用lib中的拦截器，找到构造方法</span></span><br><span class="line">a1.sources.r1.interceptors.i1.type = com.atguigu.flume.interceptor.CustomInterceptor$Builder</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使用多路复用方法进行过滤</span></span><br><span class="line">a1.sources.r1.selector.type = multiplexing</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">找到名为<span class="built_in">type</span>的过滤头</span></span><br><span class="line">a1.sources.r1.selector.header = type</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">type</span>为first走channel c1</span></span><br><span class="line">a1.sources.r1.selector.mapping.first = c1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">type</span>为second走channel c2</span></span><br><span class="line">a1.sources.r1.selector.mapping.second = c2</span><br></pre></td></tr></table></figure><p><strong>自定义Source和自定义Sink在学生阶段用得并不多（因为大部分数据源是固定的比如HDFS等），并不需要自定义数据源，所以这里暂不记录。同时，目前阶段对于数据流监控并没有实际的应用，因此对于使用Ganglia等软件进行Flume数据监控的方式不做详解。</strong></p><hr><h2 id="第四章-常见面试题"><a href="#第四章-常见面试题" class="headerlink" title="第四章 常见面试题"></a>第四章 常见面试题</h2><h4 id="1、Flume-参数调优"><a href="#1、Flume-参数调优" class="headerlink" title="1、Flume 参数调优"></a>1、Flume 参数调优</h4><h6 id="（1）Source"><a href="#（1）Source" class="headerlink" title="（1）Source"></a>（1）Source</h6><p>增加 Source 个数（使用 Tair Dir Source 时可增加 FileGroups 个数）可以增大 Source 的读取数据的能力。例如：当某一个目录产生的文件过多时需要将这个文件目录拆分成多个 文件目录，同时配置好多个 Source 以保证 Source 有足够的能力获取到新产生的数据。</p><p>batchSize 参数决定 Source 一次批量运输到 Channel 的 event 条数，适当调大这个参数可以提高 Source 搬运 Event 到 Channel 时的性能。</p><h6 id="（2）Channel"><a href="#（2）Channel" class="headerlink" title="（2）Channel"></a>（2）Channel</h6><p>type 选择 memory 时 Channel 的性能最好，但是如果 Flume 进程意外挂掉可能会丢失数据。type 选择 file 时 Channel 的容错性更好，但是性能上会比 memory channel 差。 使用 file Channel 时 dataDirs 配置多个不同盘下的目录可以提高性能。</p><p>Capacity 参数决定 Channel 可容纳最大的 event 条数。transactionCapacity 参数决定每次 Source 往 channel 里面写的最大 event 条数和每次 Sink 从 channel 里面读的最大 event 条数。<strong>transactionCapacity 需要大于 Source 和 Sink 的 batchSize 参数。</strong></p><h6 id="（3）Sink-1"><a href="#（3）Sink-1" class="headerlink" title="（3）Sink"></a>（3）Sink</h6><p>增加 Sink 的个数可以增加 Sink 消费 event 的能力。Sink 也不是越多越好够用就行，过多的 Sink 会占用系统资源，造成系统资源不必要的浪费。</p><p>batchSize 参数决定 Sink 一次批量从 Channel 读取的 event 条数，适当调大这个参数 可以提高 Sink 从 Channel 搬出 event 的性能。</p><h4 id="2、Flume-的事务机制"><a href="#2、Flume-的事务机制" class="headerlink" title="2、Flume 的事务机制"></a>2、Flume 的事务机制</h4><p>Flume 的事务机制（类似数据库的事务机制）：<strong>Flume 使用两个独立的事务分别负责从 Soucrce 到 Channel，以及从 Channel 到 Sink 的事件传递。</strong> 比如 spooling directory source 为文件的每一行创建一个事件，一旦事务中所有的 事件全部传递到 Channel 且提交成功，那么 Soucrce 就将该文件标记为完成。</p><p>同理，事务以类似的方式处理从 Channel 到 Sink 的传递过程，如果因为某种原因使得 事件无法记录，那么事务将会回滚。且所有的事件都会保持到 Channel 中，等待重新传递。</p><h4 id="3、Flume-采集数据会丢失吗"><a href="#3、Flume-采集数据会丢失吗" class="headerlink" title="3、Flume 采集数据会丢失吗?"></a>3、Flume 采集数据会丢失吗?</h4><p>根据 Flume 的架构原理，Flume 是不可能丢失数据的，其内部有完善的事务机制， Source 到 Channel 是事务性的，Channel 到 Sink 是事务性的，因此这两个环节不会出现数据的丢失，唯一可能丢失数据的情况是 Channel 采用 memoryChannel，agent 宕机导致数据丢失，或者 Channel 存储数据已满，导致 Source 不再写入，未写入的数据丢失。</p><p><strong>Flume 不会丢失数据，但是有可能造成数据的重复，例如数据已经成功由 Sink 发出， 但是没有接收到响应，Sink 会再次发送数据，此时可能会导致数据的重复。</strong></p>]]></content>
      
      
      <categories>
          
          <category> Little Tips </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Flume </tag>
            
            <tag> 大数据组件 </tag>
            
            <tag> 从零到一系列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>离线数仓总结（下）</title>
      <link href="/2023/03/30/%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E6%80%BB%E7%BB%93%E4%B8%8B/"/>
      <url>/2023/03/30/%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E6%80%BB%E7%BB%93%E4%B8%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="第三章-电商业务介绍"><a href="#第三章-电商业务介绍" class="headerlink" title="第三章 电商业务介绍"></a>第三章 电商业务介绍</h2><h4 id="1、简介"><a href="#1、简介" class="headerlink" title="1、简介"></a>1、简介</h4><p>电商的业务流程可以以一个普通用户的浏览足迹为例进行说明，用户点开电商首页开始浏览，可能会通过分类查询也可能通过全文搜索寻找自己中意的商品，这些商品无疑都是存储在后台的管理系统中的。</p><p>当用户寻找到自己中意的商品，可能会想要购买，将商品添加到购物车后发现需要登录，登录后对商品进行结算，这时候购物车的管理和商品订单信息的生成都会对业务数据库产生影响，会生成相应的订单数据和支付数据。</p><p>订单正式生成之后，还会对订单进行跟踪处理，直到订单全部完成。</p><p>电商的主要业务流程包括用户前台浏览商品时的商品详情的管理，用户商品加入购物车进行支付时用户个人中心&amp;支付服务的管理，用户支付完成后订单后台服务的管理，这些流程涉及到了十几个甚至几十个业务数据表，甚至更多。</p><h4 id="2、常识概念"><a href="#2、常识概念" class="headerlink" title="2、常识概念"></a>2、常识概念</h4><p><strong>SKU</strong>（Stock Keeping Unit，库存量基本单位）：现在已经被引申为产品统一编号的简称，每种产品均对应有唯一的SKU号。</p><p><strong>SPU</strong>（Standard Product Unit）：是商品信息聚合的最小单位，是一组可复用、易检索的标准化信息集合。</p><blockquote><p>简单说明就是商品是SKU，商品含属性是SPU，例如一台iPhone是一个SKU，但是64G版本和128G版本的iPhone是两个不同的SPU。</p></blockquote><p><strong>平台属性：</strong>相当于过滤条件，方便用户定位想要的产品参数。</p><p><strong>销售属性：</strong>相当于商品属性，代表一个商品SPU的参数。</p><h4 id="3、业务数据关系图"><a href="#3、业务数据关系图" class="headerlink" title="3、业务数据关系图"></a>3、业务数据关系图</h4><p><img src="/2023/03/30/%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E6%80%BB%E7%BB%93%E4%B8%8B/2.png"></p><h4 id="4、后台数据关系图"><a href="#4、后台数据关系图" class="headerlink" title="4、后台数据关系图"></a>4、后台数据关系图</h4><p><img src="/2023/03/30/%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E6%80%BB%E7%BB%93%E4%B8%8B/3.png"></p><hr><h2 id="第四章-数据同步策略"><a href="#第四章-数据同步策略" class="headerlink" title="第四章 数据同步策略"></a>第四章 数据同步策略</h2><table><thead><tr><th>同步策略</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td><strong>全量同步</strong></td><td>逻辑简单</td><td>在某些情况下效率较低。例如某张表数据量较大，但是每天数据的变化比例很低，若对其采用每日全量同步，则会重复同步和存储大量相同的数据。</td></tr><tr><td><strong>增量同步</strong></td><td>效率高，无需同步和存储重复数据</td><td>逻辑复杂，需要将每日的新增及变化数据同原来的数据进行整合，才能使用</td></tr></tbody></table><p>通常情况，业务表数据量比较大，优先考虑增量，数据量比较小，优先考虑全量；具体选择由数仓模型决定。</p><h4 id="0、同步工具"><a href="#0、同步工具" class="headerlink" title="0、同步工具"></a>0、同步工具</h4><p>数据同步工具种类繁多，大致可分为两类，一类是以DataX、Sqoop为代表的基于Select查询的离线、批量同步工具，另一类是以Maxwell、Canal为代表的基于数据库数据变更日志（例如MySQL的binlog，其会实时记录所有的insert、update以及delete操作）的实时流式同步工具。</p><p>全量同步通常使用DataX、Sqoop等基于查询的离线同步工具。而增量同步既可以使用DataX、Sqoop等工具，也可使用Maxwell、Canal等工具，下面对增量同步不同方案进行简要对比。</p><table><thead><tr><th>增量同步方案</th><th>DataX&#x2F;Sqoop</th><th>Maxwell&#x2F;Canal</th></tr></thead><tbody><tr><td><strong>对数据库的要求</strong></td><td>原理是基于查询，故若想通过select查询获取新增及变化数据，就要求数据表中存在create_time、update_time等字段，然后根据这些字段获取变更数据。</td><td>要求数据库记录变更操作，例如MySQL需开启binlog。</td></tr><tr><td><strong>数据的中间状态</strong></td><td>由于是离线批量同步，故若一条数据在一天中变化多次，该方案只能获取最后一个状态，中间状态无法获取。</td><td>由于是实时获取所有的数据变更操作，所以可以获取变更数据的所有中间状态。</td></tr></tbody></table><h4 id="1、全量同步"><a href="#1、全量同步" class="headerlink" title="1、全量同步"></a>1、全量同步</h4><p>全量同步是指将源端数据全部同步到目标端，而不管数据是否发生变化。全量同步的优点是可以保证目标端数据的完整性，缺点是同步时间长，占用带宽大。全量同步一般用于首次同步或者源端数据发生重大变化时。</p><blockquote><p>全量同步是对数据进行完整备份，一般消耗的资源大，速度慢。在没有建设数仓时，全量同步兼具了</p><ul><li>对变动较大的数据全量拷贝</li><li>对建库前数据进行统计</li></ul><p>的功能，简单来说就是：我在2023&#x2F;3&#x2F;30创建数据仓库，但是我本地存储了2023&#x2F;3&#x2F;1到2023&#x2F;3&#x2F;30的数据，这时候就需要全量同步到HDFS。</p><p>使用方式是使用DataX对需要进行全量同步的MySQL表进行拷贝到HDFS，DataX可以使用Reader&#x2F;Writer机制将不同数据源的数据读出&#x2F;写入，保证了格式的一致性。</p></blockquote><h4 id="2、增量同步"><a href="#2、增量同步" class="headerlink" title="2、增量同步"></a>2、增量同步</h4><p>增量同步是指在数据同步的过程中，只将新增或修改的数据进行同步。增量同步的优点是同步时间短，占用带宽小，缺点是需要保证全量同步已经完成，否则增量同步会出现数据不完整的情况。增量同步一般用于全量同步之后的增量更新。</p><blockquote><p>增量同步一般对新增数据进行同步，针对两种同步举个简单的例子：一个快产快销的商店拥有每天不同的商品种类和相对稳定的用户群体，那么针对商品我们采取全量同步来维持正在售卖的最新状态（变动大）；而对于用户我们采取增量同步的方式记录用户信息，因为不会出现一天时间大量的用户改名之类的操作。</p><p>使用方式是Maxwell+Kafka+Flume的方式将数据从MySQL抽取到HDFS，简单讲述下就是：Maxwell伪装成MySQL的server从机使用主从复制的方式读取MySQL的binlog日志进行数据拷贝，同时在Kafka中注册topic监听Maxwell，Maxwell作为生产者发送数据给Kafka，在Flume中建立消费者程序消费这些数据到HDFS的inc增量表中。</p></blockquote><hr><h2 id="第五章-数据仓库概述与建模"><a href="#第五章-数据仓库概述与建模" class="headerlink" title="第五章 数据仓库概述与建模"></a>第五章 数据仓库概述与建模</h2><h4 id="1、概念"><a href="#1、概念" class="headerlink" title="1、概念"></a>1、概念</h4><p>数据仓库是一个为数据分析而设计的企业级数据管理系统。数据仓库可集中、整合多个信息源的大量数据，借助数据仓库的分析能力，企业可从数据中获得宝贵的信息进而改进决策。同时，随着时间的推移，数据仓库中积累的大量历史数据对于数据科学家和业务分析师也是十分宝贵的。</p><h4 id="2、核心架构"><a href="#2、核心架构" class="headerlink" title="2、核心架构"></a>2、核心架构</h4><p><img src="/2023/03/30/%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E6%80%BB%E7%BB%93%E4%B8%8B/4.png"></p><h4 id="3、数据仓库建模方法论"><a href="#3、数据仓库建模方法论" class="headerlink" title="3、数据仓库建模方法论"></a>3、数据仓库建模方法论</h4><h6 id="（1）E-R模型"><a href="#（1）E-R模型" class="headerlink" title="（1）E-R模型"></a>（1）E-R模型</h6><p>数据仓库之父Bill Inmon提出的建模方法是从全企业的高度，用实体关系（Entity Relationship，ER）模型来描述企业业务，并用规范化的方式表示出来，在范式理论上符合3NF。</p><ul><li>实体关系模型</li></ul><p>实体关系模型将复杂的数据抽象为两个概念——实体和关系。实体表示一个对象，例如学生、班级，关系是指两个实体之间的关系，例如学生和班级之间的从属关系。</p><ul><li>数据库规范化</li></ul><p>数据库规范化是使用一系列范式设计数据库（通常是关系型数据库）的过程，其目的是减少数据冗余，增强数据的一致性。</p><p>这一系列范式就是指在设计关系型数据库时，需要遵从的不同的规范。关系型数据库的范式一共有六种，分别是第一范式（1NF）、第二范式（2NF）、第三范式（3NF）、巴斯-科德范式（BCNF）、第四范式(4NF）和第五范式（5NF）。遵循的范式级别越高，数据冗余性就越低。</p><ul><li>三范式<ul><li>函数依赖<ul><li>完全函数依赖：通过AB能得出C，但是AB单独得不出C，那么C完全依赖于AB</li><li>部分函数依赖：通过AB能得出C，通过A或B也能得出C，那么C部分依赖于AB</li><li>传递函数依赖：通过A得到B，通过B得到C，但是通过C得不到A，那么C传递依赖于A</li></ul></li><li>第一范式<ul><li>属性不可切割</li><li>例：5台电脑 –&gt; 5、电脑 -x-&gt;不可再分</li></ul></li><li>第二范式<ul><li>不能存在不分函数依赖</li><li>（简单来说就是分拆主键）</li></ul></li><li>第三范式<ul><li>不能存在传递函数依赖</li><li>（简单来说就是将具有两层关系【总三层+】的表分拆到不同表）</li><li>例：学号=&#x3D;学院=&#x3D;院长，学号可以推出学院，学院可以推出院长，但是院长无法推出学生关系，所以应该分拆到两张表中。</li></ul></li></ul></li></ul><p><strong>这种建模方法的出发点是整合数据，其目的是将整个企业的数据进行组合和合并，并进行规范处理，减少数据冗余性，保证数据的一致性。这种模型并不适合直接用于分析统计。</strong></p><h6 id="（2）维度模型"><a href="#（2）维度模型" class="headerlink" title="（2）维度模型"></a>（2）维度模型</h6><p>维度模型将复杂的业务通过事实和维度两个概念进行呈现。事实通常对应业务过程，而维度通常对应业务过程发生时所处的环境。</p><p><strong>注：</strong>业务过程可以概括为一个个不可拆分的行为事件，例如电商交易中的下单，取消订单，付款，退单等，都是业务过程。</p><p><strong>维度建模以数据分析作为出发点，为数据分析服务，因此它关注的重点的用户如何更快的完成需求分析以及如何实现较好的大规模复杂查询的响应性能。</strong></p><p>因此，我们通常的数仓建模采用的是维度建模。</p><h2 id="第六章-维度建模"><a href="#第六章-维度建模" class="headerlink" title="第六章 维度建模"></a>第六章 维度建模</h2><blockquote><p>虽然尚硅谷的文档中将事实表放在了前面，但是不得不说，应该先介绍下维度表再讲解事实表，一方面是根据阿里系的《大数据之路》的介绍流程，另一方面是选用的五层建模中DIM层确实是在DWD层之前，因此更换下顺序方便阅读。</p></blockquote><h4 id="1、维度表"><a href="#1、维度表" class="headerlink" title="1、维度表"></a>1、维度表</h4><h6 id="（1）概述"><a href="#（1）概述" class="headerlink" title="（1）概述"></a>（1）概述</h6><p>维度表是维度建模的基础和灵魂。前文提到，事实表紧紧围绕业务过程进行设计，而维度表则围绕业务过程所处的环境进行设计。维度表主要包含一个主键和各种维度字段，维度字段称为维度属性。</p><h6 id="（2）设计流程"><a href="#（2）设计流程" class="headerlink" title="（2）设计流程"></a>（2）设计流程</h6><ul><li><p>确定维度（表）</p><blockquote><ul><li>原文这里是从事实表中得到的维度，但是如果优先创建维度表的话那么我们应该怎么创建呢？个人认为是根据以下几种方式创建维度：<ul><li>根据数据库表中的公有字段创建。例如：如果每张表中都有记录时间信息，那么一定会有时间维度。</li><li>根据物理实体创建维度。例如：用户、商品是真实的实体，那么用户就有了用户维度、商品就有了商品维度。</li><li>相似结果进行聚合。例如：一张表中同时具有几种语言、地区的编码格式，那么就可以将这几种编码进行聚合，形成地区维度&#x2F;编码维度。<strong>但是如果只有少量数据（比如一种编码），那么不必要单独创建一个维度，而是直接放进共用表&#x2F;融入部分维度字段传递给事实表部分。</strong></li></ul></li></ul></blockquote></li><li><p>确定主维表和相关维表</p><ul><li>此处的主维表和相关维表均指<strong>业务系统</strong>中与某维度相关的表。维度表的粒度通常与主维表相同。</li></ul></li><li><p>确定维度属性</p><ul><li>确定维度属性即确定维度表字段。维度属性主要来自于业务系统中与该维度对应的主维表和相关维表。维度属性可直接从主维表或相关维表中选择，也可通过进一步加工得到。<ul><li>尽可能生成丰富的维度属性</li><li>尽量不使用编码，而使用明确的文字说明，一般可以编码和文字共存</li><li>尽量沉淀出通用的维度属性</li></ul></li></ul></li></ul><h6 id="（3）规范化和反规范化"><a href="#（3）规范化和反规范化" class="headerlink" title="（3）规范化和反规范化"></a>（3）规范化和反规范化</h6><p><strong>规范化</strong>是指使用一系列范式设计数据库的过程，其目的是减少数据冗余，增强数据的一致性。通常情况下，规范化之后，一张表的字段会拆分到多张表。</p><p><strong>反规范化</strong>是指将多张表的数据冗余到一张表，其目的是减少join操作，提高查询性能。</p><p>在设计维度表时，如果对其进行规范化，得到的维度模型称为雪花模型，如果对其进行反规范化，得到的模型称为星型模型。</p><h6 id="（4）维度变化"><a href="#（4）维度变化" class="headerlink" title="（4）维度变化"></a>（4）维度变化</h6><p>维度属性通常不是静态的，而是会随时间变化的，数据仓库的一个重要特点就是反映历史的变化，所以如何保存维度的历史状态是维度设计的重要工作之一。保存维度数据的历史状态，通常有以下两种做法，分别是全量快照表和拉链表。</p><ul><li><p>全量快照表</p><ul><li><strong>优点</strong>是简单而有效，开发和维护成本低，且方便理解和使用。</li><li><strong>缺点</strong>是浪费存储空间，尤其是当数据的变化比例比较低时。</li></ul></li><li><p>拉链表</p><ul><li><p><strong>什么是拉链表？</strong>拉链表记录每一条数据的生命周期，一旦一条数据的生命周期结束，就重新开始一条新的记录，并把当前日期放入生效开始日期。</p><p>例：以小艾改名小艾同学为例，在用户维度表中会有以下变化：</p></li></ul></li></ul><table><thead><tr><th>用户ID</th><th>姓名</th><th>开始日期</th><th>结束日期</th></tr></thead><tbody><tr><td>1</td><td>小艾</td><td>2020-06-18</td><td>2023-03-30</td></tr><tr><td>1</td><td>小艾同学</td><td>2023-03-30</td><td>9999-12-31</td></tr></tbody></table><blockquote><p>可以看出，拉链表中ID不会作为主键，所有相同ID共同记录了一个用户的数据变更，不同于全量快照表，拉链表比较麻烦的是：</p><ul><li>需要对修改数据维护一个结束时间，并插入新状态和时间</li><li>需要对新插入数据维护一个结束日期（一般采用单独缓存表&#x2F;固定字段维护）</li></ul></blockquote><ul><li>拉链表适合于：数据会发生变化，但是变化频率并不高的维度（缓慢变化维）</li></ul><h6 id="（5）多值维度-amp-amp-多值属性的解决"><a href="#（5）多值维度-amp-amp-多值属性的解决" class="headerlink" title="（5）多值维度 &amp;&amp; 多值属性的解决"></a>（5）多值维度 &amp;&amp; 多值属性的解决</h6><ul><li><p>多值维度</p><ul><li>如果事实表中一条记录在某个维度表中有多条记录与之对应，称为多值维度。解决方案：<ul><li>降低事实表的粒度，例如将订单事实表的粒度由一个订单降低为一个订单中的一个商品项。<strong>（建议）</strong></li><li>在事实表中采用多字段保存多个维度值，每个字段保存一个维度id。这种方案只适用于多值维度个数固定的情况。</li></ul></li></ul></li><li><p>多值属性</p><ul><li>维表中的某个属性同时有多个值，称之为“多值属性”。解决方案：<ul><li>将多值属性放到一个字段，该字段内容为key1:value1，key2:value2的形式，例如一个手机商品的平台属性值为“品牌:华为，系统:鸿蒙，CPU:麒麟990”。</li><li>将多值属性放到多个字段，每个字段对应一个属性。这种方案只适用于多值属性个数固定的情况。</li></ul></li></ul></li></ul><h4 id="2、事实表"><a href="#2、事实表" class="headerlink" title="2、事实表"></a>2、事实表</h4><h6 id="（1）概述-1"><a href="#（1）概述-1" class="headerlink" title="（1）概述"></a>（1）概述</h6><p>事实表作为数据仓库维度建模的核心，紧紧围绕着业务过程来设计。其包含与该业务过程有关的维度引用（维度表外键）以及该业务过程的度量（通常是可累加的数字类型字段）。事实表具有如下特点：</p><ul><li>事实表通常比较“细长”，即列较少，但行较多，且行的增速快。</li></ul><h6 id="（2）分类"><a href="#（2）分类" class="headerlink" title="（2）分类"></a>（2）分类</h6><ul><li><p>事务型事实表</p><ul><li><p>事务型事实表用来记录各业务过程，它保存的是各业务过程的原子操作事件，即最细粒度的操作事件。粒度是指事实表中一行数据所表达的业务细节程度。</p><p>事务型事实表可用于分析与各业务过程相关的各项统计指标，由于其保存了最细粒度的记录，可以提供最大限度的灵活性，可以支持无法预期的各种细节层次的统计需求。</p></li><li><p><strong>设计流程：</strong>选择业务过程→声明粒度→确认维度→确认事实</p></li><li><p><strong>不足：</strong>事务型事实表可以保存所有业务过程的最细粒度的操作事件，故理论上其可以支撑与各业务过程相关的各种统计粒度的需求。但对于某些特定类型的需求，其逻辑可能会比较复杂，或者效率会比较低下。</p><ul><li>存量型指标</li><li>多事务关联统计</li></ul></li></ul></li><li><p>周期型快照事实表</p><ul><li>周期快照事实表以具有规律性的、可预见的时间间隔来记录事实，主要用于分析一些存量型（例如商品库存，账户余额）或者状态型（空气温度，行驶速度）指标。</li><li><strong>设计流程</strong><ul><li>确定粒度</li><li>确定事实</li></ul></li><li><strong>事实类型：</strong>事实类型是指度量值的类型<ul><li>可加事实：可以按照与事实表相关的所有维度进行累加，例如事务型事实表中的事实</li><li>半可加事实：只能按照与事实表相关的一部分维度进行累加，例如周期型快照事实表中的事实。</li><li>不可加事实：完全不具备可加性，例如比率型事实。</li></ul></li></ul></li><li><p>累积型快照事实表</p><ul><li>累计快照事实表是基于一个业务流程中的多个关键业务过程联合处理而构建的事实表，如交易流程中的下单、支付、发货、确认收货业务过程。累积型快照事实表主要用于分析业务过程（里程碑）之间的时间间隔等需求。</li><li><strong>设计流程：</strong>选择业务过程→声明粒度→确认维度→确认事实</li></ul></li></ul><hr><h2 id="第七章-数据仓库设计与开发"><a href="#第七章-数据仓库设计与开发" class="headerlink" title="第七章 数据仓库设计与开发"></a>第七章 数据仓库设计与开发</h2><h4 id="1、构建流程"><a href="#1、构建流程" class="headerlink" title="1、构建流程"></a>1、构建流程</h4><p><img src="/2023/03/30/%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E6%80%BB%E7%BB%93%E4%B8%8B/5.png"></p><h4 id="2、统计指标概述"><a href="#2、统计指标概述" class="headerlink" title="2、统计指标概述"></a>2、统计指标概述</h4><h6 id="（1）指标体系相关概念"><a href="#（1）指标体系相关概念" class="headerlink" title="（1）指标体系相关概念"></a>（1）指标体系相关概念</h6><ul><li><p>原子指标：基于某一<strong>业务过程</strong>的<strong>度量值</strong>，是业务定义中不可再拆解的指标，原子指标的核心功能就是对指标的<strong>聚合逻辑</strong>进行了定义。我们可以得出结论，原子指标包含三要素，分别是业务过程、度量值和聚合逻辑。</p></li><li><p>派生指标</p><ul><li><img src="/2023/03/30/%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E6%80%BB%E7%BB%93%E4%B8%8B/6.png"></li></ul></li><li><p>衍生指标：在一个或多个派生指标的基础上，通过各种逻辑运算复合而成的。例如比率、比例等类型的指标。衍生指标也会对应实际的统计需求。</p><ul><li><img src="/2023/03/30/%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E6%80%BB%E7%BB%93%E4%B8%8B/7.png"></li></ul></li></ul><h6 id="（2）指标体系对于数仓建模的意义"><a href="#（2）指标体系对于数仓建模的意义" class="headerlink" title="（2）指标体系对于数仓建模的意义"></a>（2）指标体系对于数仓建模的意义</h6><p>绝大多数的统计需求，都可以使用原子指标、派生指标以及衍生指标这套标准去定义。同时能够发现这些统计需求都直接的或间接的对应一个或者是多个派生指标。</p><p>当统计需求足够多时，必然会出现部分统计需求对应的派生指标相同的情况。这种情况下，我们就可以考虑将这些公共的派生指标保存下来，这样做的主要目的就是减少重复计算，提高数据的复用性。</p><p>这些公共的派生指标统一保存在数据仓库的DWS层。因此DWS层设计，就可以参考我们根据现有的统计需求整理出的派生指标。</p><h4 id="3、数仓分层"><a href="#3、数仓分层" class="headerlink" title="3、数仓分层"></a>3、数仓分层</h4><blockquote><p>下面给出数据流转的脚本图并进行简单讲解</p><p><img src="/2023/03/30/%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E6%80%BB%E7%BB%93%E4%B8%8B/9.png"></p><ul><li>ODS层是源数据的汇总，因此可以看到有HDFS中的业务数据（log）和后台数据（db）的集合，HDFS收集不同的数据来源&#x2F;全量与增量数据，在ODS中汇合。</li><li>一般后台数据是持久化到数据库的，变动的数据量并不大且通常为物理实体，所以一般作为全量备份，满足我之前说的维度表设计方式，所以使用db中的数据作为DIM层。</li><li>DWD作为明细数据，就是将业务数据进行“解包”操作，本来业务数据（log）是一块一块的，粒度比较高，这是时候就在DWD中拆分成粒度更小的数据库表，同样后台数据（db）也有部分数据是可以更好地描述数据状态（根据DWD需求，明细表最好是中文，能直接看懂的），所以同样将需要的DIM纳入DWD层。</li><li>DWS汇总数据层则是将DIM和DWD的数据以主题的形式进行汇总，这个时候DWS层的数据就是ADS的大表形式，可以说是对于粒度相同、相似的ADS需求将DIM、DWD数据表进行聚合。</li><li>ADS就是最终BI业务需求的展示表，表结构和形式不需要再修改（空值等之类的格式问题不在此列），能够实现导出之后一张表就是一个数据监控。</li></ul></blockquote><p>之后会详细介绍每个表的建表格式和数据装载，每一层举一个例子。</p><h6 id="（1）ODS层（Operation-Data-Store，原始数据层）"><a href="#（1）ODS层（Operation-Data-Store，原始数据层）" class="headerlink" title="（1）ODS层（Operation Data Store，原始数据层）"></a>（1）ODS层（Operation Data Store，原始数据层）</h6><p>存储未处理过的原始数据，结构上与源数据保持一致，是数据仓库的数据准备区。</p><p>ODS层的设计要点如下：</p><ul><li>ODS层的表结构设计依托于从业务系统同步过来的数据结构。</li><li>ODS层要保存全部历史数据，故其压缩格式应选择压缩比较高的，此处选择gzip。</li><li>ODS层表名的命名规范为：ods_表名_单分区增量全量标识（inc&#x2F;full）。</li></ul><blockquote><p>ODS层的数据就是增量&#x2F;全量同步过来的原生数据，并对格式进行统一。将全量表和增量表从HDFS转到Hive。</p></blockquote><p>【1】建表</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 活动信息表（全量表）</span></span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> IF <span class="keyword">EXISTS</span> ods_activity_info_full;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> ods_activity_info_full</span><br><span class="line">(</span><br><span class="line">    `id`            STRING COMMENT <span class="string">&#x27;活动id&#x27;</span>,</span><br><span class="line">    `activity_name` STRING COMMENT <span class="string">&#x27;活动名称&#x27;</span>,</span><br><span class="line">    `activity_type` STRING COMMENT <span class="string">&#x27;活动类型&#x27;</span>,</span><br><span class="line">    `activity_desc` STRING COMMENT <span class="string">&#x27;活动描述&#x27;</span>,</span><br><span class="line">    `start_time`    STRING COMMENT <span class="string">&#x27;开始时间&#x27;</span>,</span><br><span class="line">    `end_time`      STRING COMMENT <span class="string">&#x27;结束时间&#x27;</span>,</span><br><span class="line">    `create_time`   STRING COMMENT <span class="string">&#x27;创建时间&#x27;</span></span><br><span class="line">) COMMENT <span class="string">&#x27;活动信息表&#x27;</span></span><br><span class="line">    PARTITIONED <span class="keyword">BY</span> (`dt` STRING)</span><br><span class="line">    <span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;\t&#x27;</span></span><br><span class="line">    <span class="keyword">NULL</span> DEFINED <span class="keyword">AS</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line">    LOCATION <span class="string">&#x27;/warehouse/gmall/ods/ods_activity_info_full/&#x27;</span>;</span><br><span class="line">    </span><br><span class="line"><span class="comment">-- 第一部分是删除表的语句，如果表不存在则不执行删除操作。</span></span><br><span class="line"><span class="comment">-- 第二部分是创建一个外部表，名为ods_activity_info_full，包含id、activity_name、activity_type、activity_desc、start_time、end_time和create_time等字段。这个表的注释是“活动信息表”，按照dt字段进行分区。</span></span><br><span class="line"><span class="comment">-- 外部表是指在Hive中定义的表，但是数据并不存储在Hive中，而是存储在其他地方（如HDFS或HBase）中。外部表的数据可以被多个Hive表共享。</span></span><br><span class="line"><span class="comment">-- 分区是指将数据按照某个字段进行划分，以便更快地查询数据。在这个例子中，按照dt字段进行分区。</span></span><br><span class="line"><span class="comment">-- ROW FORMAT DELIMITED FIELDS TERMINATED BY &#x27;\t&#x27;是指使用制表符（\t）作为字段分隔符。在这个例子中，数据文件中的每一行都是一个记录，每个字段之间用制表符分隔。这个语句告诉Hive如何解析数据文件中的每一行。</span></span><br></pre></td></tr></table></figure><p>【2】数据装载</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">load data inpath <span class="string">&#x27;/origin_data/gmall/db/activity_info_full/2023-03-30&#x27;</span> OVERWRITE <span class="keyword">into</span> <span class="keyword">table</span> gmall.ods_activity_info_full <span class="keyword">partition</span>(dt<span class="operator">=</span><span class="string">&#x27;2023-03-30&#x27;</span>);</span><br><span class="line"><span class="comment">-- 将`/origin_data/gmall/db/activity_info_full/2023-03-30`目录下的数据加载到名为`gmall.ods_activity_info_full`的Hive表中，分区字段为`dt`，值为`2023-03-30`。如果表中已经存在相同分区的数据，则会覆盖原有数据。</span></span><br></pre></td></tr></table></figure><h6 id="（2）DIM层（Dimension，公共维度层）"><a href="#（2）DIM层（Dimension，公共维度层）" class="headerlink" title="（2）DIM层（Dimension，公共维度层）"></a>（2）DIM层（Dimension，公共维度层）</h6><p>基于维度建模理论进行构建，<strong>存放维度模型中的维度表</strong>，保持一致性维度信息。</p><p>DIM层设计要点：</p><ul><li><p>DIM层的设计依据是维度建模理论，该层存储维度模型的维度表。</p></li><li><p>DIM层的数据存储格式为orc列式存储+snappy压缩。</p></li><li><p>DIM层表名的命名规范为dim_表名_全量表或者拉链表标识（full&#x2F;zip）</p></li></ul><p>【1】建表</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 商品维度表</span></span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> IF <span class="keyword">EXISTS</span> dim_sku_full;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> dim_sku_full</span><br><span class="line">(</span><br><span class="line">    `id`                   STRING COMMENT <span class="string">&#x27;sku_id&#x27;</span>,</span><br><span class="line">    `price`                <span class="type">DECIMAL</span>(<span class="number">16</span>, <span class="number">2</span>) COMMENT <span class="string">&#x27;商品价格&#x27;</span>,</span><br><span class="line">    `sku_name`             STRING COMMENT <span class="string">&#x27;商品名称&#x27;</span>,</span><br><span class="line">    `sku_desc`             STRING COMMENT <span class="string">&#x27;商品描述&#x27;</span>,</span><br><span class="line">    `weight`               <span class="type">DECIMAL</span>(<span class="number">16</span>, <span class="number">2</span>) COMMENT <span class="string">&#x27;重量&#x27;</span>,</span><br><span class="line">    `is_sale`              <span class="type">BOOLEAN</span> COMMENT <span class="string">&#x27;是否在售&#x27;</span>,</span><br><span class="line">    `spu_id`               STRING COMMENT <span class="string">&#x27;spu编号&#x27;</span>,</span><br><span class="line">    `spu_name`             STRING COMMENT <span class="string">&#x27;spu名称&#x27;</span>,</span><br><span class="line">    `category3_id`         STRING COMMENT <span class="string">&#x27;三级分类id&#x27;</span>,</span><br><span class="line">    `category3_name`       STRING COMMENT <span class="string">&#x27;三级分类名称&#x27;</span>,</span><br><span class="line">    `category2_id`         STRING COMMENT <span class="string">&#x27;二级分类id&#x27;</span>,</span><br><span class="line">    `category2_name`       STRING COMMENT <span class="string">&#x27;二级分类名称&#x27;</span>,</span><br><span class="line">    `category1_id`         STRING COMMENT <span class="string">&#x27;一级分类id&#x27;</span>,</span><br><span class="line">    `category1_name`       STRING COMMENT <span class="string">&#x27;一级分类名称&#x27;</span>,</span><br><span class="line">    `tm_id`                STRING COMMENT <span class="string">&#x27;品牌id&#x27;</span>,</span><br><span class="line">    `tm_name`              STRING COMMENT <span class="string">&#x27;品牌名称&#x27;</span>,</span><br><span class="line">    `sku_attr_values`      <span class="keyword">ARRAY</span><span class="operator">&lt;</span>STRUCT<span class="operator">&lt;</span>attr_id :STRING,value_id :STRING,attr_name :STRING,value_name:STRING<span class="operator">&gt;&gt;</span> COMMENT <span class="string">&#x27;平台属性&#x27;</span>,</span><br><span class="line">    `sku_sale_attr_values` <span class="keyword">ARRAY</span><span class="operator">&lt;</span>STRUCT<span class="operator">&lt;</span>sale_attr_id :STRING,sale_attr_value_id :STRING,sale_attr_name :STRING,sale_attr_value_name:STRING<span class="operator">&gt;&gt;</span> COMMENT <span class="string">&#x27;销售属性&#x27;</span>,</span><br><span class="line">    `create_time`          STRING COMMENT <span class="string">&#x27;创建时间&#x27;</span></span><br><span class="line">) COMMENT <span class="string">&#x27;商品维度表&#x27;</span></span><br><span class="line">    PARTITIONED <span class="keyword">BY</span> (`dt` STRING)</span><br><span class="line">    STORED <span class="keyword">AS</span> ORC</span><br><span class="line">    LOCATION <span class="string">&#x27;/warehouse/gmall/dim/dim_sku_full/&#x27;</span></span><br><span class="line">    TBLPROPERTIES (<span class="string">&#x27;orc.compress&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;snappy&#x27;</span>);</span><br><span class="line">    </span><br><span class="line"><span class="comment">-- 数据存储格式为orc列式存储+snappy压缩</span></span><br></pre></td></tr></table></figure><p>【2】数据装载</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span></span><br><span class="line">sku <span class="keyword">as</span></span><br><span class="line">(</span><br><span class="line">    <span class="keyword">select</span></span><br><span class="line">        id,</span><br><span class="line">        price,</span><br><span class="line">        sku_name,</span><br><span class="line">        sku_desc,</span><br><span class="line">        weight,</span><br><span class="line">        is_sale,</span><br><span class="line">        spu_id,</span><br><span class="line">        category3_id,</span><br><span class="line">        tm_id,</span><br><span class="line">        create_time</span><br><span class="line">    <span class="keyword">from</span> ods_sku_info_full</span><br><span class="line">    <span class="keyword">where</span> dt<span class="operator">=</span><span class="string">&#x27;2023-03-30&#x27;</span></span><br><span class="line">),</span><br><span class="line">spu <span class="keyword">as</span></span><br><span class="line">(</span><br><span class="line">    <span class="keyword">select</span></span><br><span class="line">        id,</span><br><span class="line">        spu_name</span><br><span class="line">    <span class="keyword">from</span> ods_spu_info_full</span><br><span class="line">    <span class="keyword">where</span> dt<span class="operator">=</span><span class="string">&#x27;2023-03-30&#x27;</span></span><br><span class="line">),</span><br><span class="line">c3 <span class="keyword">as</span></span><br><span class="line">(</span><br><span class="line">    <span class="keyword">select</span></span><br><span class="line">        id,</span><br><span class="line">        name,</span><br><span class="line">        category2_id</span><br><span class="line">    <span class="keyword">from</span> ods_base_category3_full</span><br><span class="line">    <span class="keyword">where</span> dt<span class="operator">=</span><span class="string">&#x27;2023-03-30&#x27;</span></span><br><span class="line">),</span><br><span class="line">c2 <span class="keyword">as</span></span><br><span class="line">(</span><br><span class="line">    <span class="keyword">select</span></span><br><span class="line">        id,</span><br><span class="line">        name,</span><br><span class="line">        category1_id</span><br><span class="line">    <span class="keyword">from</span> ods_base_category2_full</span><br><span class="line">    <span class="keyword">where</span> dt<span class="operator">=</span><span class="string">&#x27;2023-03-30&#x27;</span></span><br><span class="line">),</span><br><span class="line">c1 <span class="keyword">as</span></span><br><span class="line">(</span><br><span class="line">    <span class="keyword">select</span></span><br><span class="line">        id,</span><br><span class="line">        name</span><br><span class="line">    <span class="keyword">from</span> ods_base_category1_full</span><br><span class="line">    <span class="keyword">where</span> dt<span class="operator">=</span><span class="string">&#x27;2023-03-30&#x27;</span></span><br><span class="line">),</span><br><span class="line">tm <span class="keyword">as</span></span><br><span class="line">(</span><br><span class="line">    <span class="keyword">select</span></span><br><span class="line">        id,</span><br><span class="line">        tm_name</span><br><span class="line">    <span class="keyword">from</span> ods_base_trademark_full</span><br><span class="line">    <span class="keyword">where</span> dt<span class="operator">=</span><span class="string">&#x27;2023-03-30&#x27;</span></span><br><span class="line">),</span><br><span class="line">attr <span class="keyword">as</span></span><br><span class="line">(</span><br><span class="line">    <span class="keyword">select</span></span><br><span class="line">        sku_id,</span><br><span class="line">        collect_set(named_struct(<span class="string">&#x27;attr_id&#x27;</span>,attr_id,<span class="string">&#x27;value_id&#x27;</span>,value_id,<span class="string">&#x27;attr_name&#x27;</span>,attr_name,<span class="string">&#x27;value_name&#x27;</span>,value_name)) attrs</span><br><span class="line">    <span class="keyword">from</span> ods_sku_attr_value_full</span><br><span class="line">    <span class="keyword">where</span> dt<span class="operator">=</span><span class="string">&#x27;2023-03-30&#x27;</span></span><br><span class="line">    <span class="keyword">group</span> <span class="keyword">by</span> sku_id</span><br><span class="line">),</span><br><span class="line">sale_attr <span class="keyword">as</span></span><br><span class="line">(</span><br><span class="line">    <span class="keyword">select</span></span><br><span class="line">        sku_id,</span><br><span class="line">        collect_set(named_struct(<span class="string">&#x27;sale_attr_id&#x27;</span>,sale_attr_id,<span class="string">&#x27;sale_attr_value_id&#x27;</span>,sale_attr_value_id,<span class="string">&#x27;sale_attr_name&#x27;</span>,sale_attr_name,<span class="string">&#x27;sale_attr_value_name&#x27;</span>,sale_attr_value_name)) sale_attrs</span><br><span class="line">    <span class="keyword">from</span> ods_sku_sale_attr_value_full</span><br><span class="line">    <span class="keyword">where</span> dt<span class="operator">=</span><span class="string">&#x27;2023-03-30&#x27;</span></span><br><span class="line">    <span class="keyword">group</span> <span class="keyword">by</span> sku_id</span><br><span class="line">)</span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> dim_sku_full <span class="keyword">partition</span>(dt<span class="operator">=</span><span class="string">&#x27;2023-03-30&#x27;</span>)</span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    sku.id,</span><br><span class="line">    sku.price,</span><br><span class="line">    sku.sku_name,</span><br><span class="line">    sku.sku_desc,</span><br><span class="line">    sku.weight,</span><br><span class="line">    sku.is_sale,</span><br><span class="line">    sku.spu_id,</span><br><span class="line">    spu.spu_name,</span><br><span class="line">    sku.category3_id,</span><br><span class="line">    c3.name,</span><br><span class="line">    c3.category2_id,</span><br><span class="line">    c2.name,</span><br><span class="line">    c2.category1_id,</span><br><span class="line">    c1.name,</span><br><span class="line">    sku.tm_id,</span><br><span class="line">    tm.tm_name,</span><br><span class="line">    attr.attrs,</span><br><span class="line">    sale_attr.sale_attrs,</span><br><span class="line">    sku.create_time</span><br><span class="line"><span class="keyword">from</span> sku</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> spu <span class="keyword">on</span> sku.spu_id<span class="operator">=</span>spu.id</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> c3 <span class="keyword">on</span> sku.category3_id<span class="operator">=</span>c3.id</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> c2 <span class="keyword">on</span> c3.category2_id<span class="operator">=</span>c2.id</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> c1 <span class="keyword">on</span> c2.category1_id<span class="operator">=</span>c1.id</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> tm <span class="keyword">on</span> sku.tm_id<span class="operator">=</span>tm.id</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> attr <span class="keyword">on</span> sku.id<span class="operator">=</span>attr.sku_id</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> sale_attr <span class="keyword">on</span> sku.id<span class="operator">=</span>sale_attr.sku_id;</span><br></pre></td></tr></table></figure><h6 id="（3）DWD层（Data-Warehouse-Detail，明细数据层）"><a href="#（3）DWD层（Data-Warehouse-Detail，明细数据层）" class="headerlink" title="（3）DWD层（Data Warehouse Detail，明细数据层）"></a>（3）DWD层（Data Warehouse Detail，明细数据层）</h6><p>基于维度建模理论进行构建，<strong>存放维度模型中的事实表</strong>，保存各业务过程中最小粒度的操作记录。</p><p>DWD层设计要点：</p><ul><li>DWD层的设计依据是维度建模理论，该层存储维度模型的事实表。</li><li>DWD层的数据存储格式为orc列式存储+snappy压缩。</li><li>DWD层表名的命名规范为dwd_数据域_表名_单分区增量全量标识（inc&#x2F;full）</li></ul><p>【1】建表</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 交易域加购事务事实表</span></span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> IF <span class="keyword">EXISTS</span> dwd_trade_cart_add_inc;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> dwd_trade_cart_add_inc</span><br><span class="line">(</span><br><span class="line">    `id`               STRING COMMENT <span class="string">&#x27;编号&#x27;</span>,</span><br><span class="line">    `user_id`          STRING COMMENT <span class="string">&#x27;用户id&#x27;</span>,</span><br><span class="line">    `sku_id`           STRING COMMENT <span class="string">&#x27;商品id&#x27;</span>,</span><br><span class="line">    `date_id`          STRING COMMENT <span class="string">&#x27;时间id&#x27;</span>,</span><br><span class="line">    `create_time`      STRING COMMENT <span class="string">&#x27;加购时间&#x27;</span>,</span><br><span class="line">    `source_id`        STRING COMMENT <span class="string">&#x27;来源类型ID&#x27;</span>,</span><br><span class="line">    `source_type_code` STRING COMMENT <span class="string">&#x27;来源类型编码&#x27;</span>,</span><br><span class="line">    `source_type_name` STRING COMMENT <span class="string">&#x27;来源类型名称&#x27;</span>,</span><br><span class="line">    `sku_num`          <span class="type">BIGINT</span> COMMENT <span class="string">&#x27;加购物车件数&#x27;</span></span><br><span class="line">) COMMENT <span class="string">&#x27;交易域加购物车事务事实表&#x27;</span></span><br><span class="line">    PARTITIONED <span class="keyword">BY</span> (`dt` STRING)</span><br><span class="line">    <span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;\t&#x27;</span></span><br><span class="line">    STORED <span class="keyword">AS</span> ORC</span><br><span class="line">    LOCATION <span class="string">&#x27;/warehouse/gmall/dwd/dwd_trade_cart_add_inc/&#x27;</span></span><br><span class="line">    TBLPROPERTIES (<span class="string">&#x27;orc.compress&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;snappy&#x27;</span>);</span><br></pre></td></tr></table></figure><p>【2】数据装载</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 设置Hive分区模式为不严格</span></span><br><span class="line"><span class="keyword">set</span> hive.exec.dynamic.partition.mode<span class="operator">=</span>nonstrict;</span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> dwd_trade_cart_add_inc <span class="keyword">partition</span> (dt)</span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    id,</span><br><span class="line">    user_id,</span><br><span class="line">    sku_id,</span><br><span class="line">    date_format(create_time,<span class="string">&#x27;yyyy-MM-dd&#x27;</span>) date_id,</span><br><span class="line">    create_time,</span><br><span class="line">    source_id,</span><br><span class="line">    source_type,</span><br><span class="line">    dic.dic_name,</span><br><span class="line">    sku_num,</span><br><span class="line">    date_format(create_time, <span class="string">&#x27;yyyy-MM-dd&#x27;</span>)</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">(</span><br><span class="line">    <span class="keyword">select</span></span><br><span class="line">        data.id,</span><br><span class="line">        data.user_id,</span><br><span class="line">        data.sku_id,</span><br><span class="line">        data.create_time,</span><br><span class="line">        data.source_id,</span><br><span class="line">        data.source_type,</span><br><span class="line">        data.sku_num</span><br><span class="line">    <span class="keyword">from</span> ods_cart_info_inc</span><br><span class="line">    <span class="keyword">where</span> dt <span class="operator">=</span> <span class="string">&#x27;2023-03-30&#x27;</span></span><br><span class="line">    <span class="keyword">and</span> type <span class="operator">=</span> <span class="string">&#x27;bootstrap-insert&#x27;</span>  <span class="comment">-- 设置类型为“全量插入” </span></span><br><span class="line">)ci</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span></span><br><span class="line">(</span><br><span class="line">    <span class="keyword">select</span></span><br><span class="line">        dic_code,</span><br><span class="line">        dic_name</span><br><span class="line">    <span class="keyword">from</span> ods_base_dic_full</span><br><span class="line">    <span class="keyword">where</span> dt<span class="operator">=</span><span class="string">&#x27;2023-03-30&#x27;</span></span><br><span class="line">    <span class="keyword">and</span> parent_code<span class="operator">=</span><span class="string">&#x27;24&#x27;</span></span><br><span class="line">)dic</span><br><span class="line"><span class="keyword">on</span> ci.source_type<span class="operator">=</span>dic.dic_code;</span><br></pre></td></tr></table></figure><h6 id="（4）DWS层（Data-Warehouse-Summary，汇总数据层）"><a href="#（4）DWS层（Data-Warehouse-Summary，汇总数据层）" class="headerlink" title="（4）DWS层（Data Warehouse Summary，汇总数据层）"></a>（4）DWS层（Data Warehouse Summary，汇总数据层）</h6><p>基于上层的指标需求，以分析的主题对象作为建模驱动，构建公共统计粒度的汇总表。</p><p>设计要点：</p><ul><li><p>DWS层的设计参考指标体系。</p></li><li><p>DWS层的数据存储格式为ORC列式存储 + snappy压缩。</p></li><li><p>DWS层表名的命名规范为dws_数据域_统计粒_业务过程_统计周期（1d&#x2F;nd&#x2F;td）</p></li></ul><p>注：1d表示最近1日，nd表示最近n日，td表示历史至今。</p><p>【1】建表</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 交易域用户商品粒度订单最近1日汇总表</span></span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> IF <span class="keyword">EXISTS</span> dws_trade_user_sku_order_1d;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> dws_trade_user_sku_order_1d</span><br><span class="line">(</span><br><span class="line">    `user_id`                   STRING COMMENT <span class="string">&#x27;用户id&#x27;</span>,</span><br><span class="line">    `sku_id`                    STRING COMMENT <span class="string">&#x27;sku_id&#x27;</span>,</span><br><span class="line">    `sku_name`                  STRING COMMENT <span class="string">&#x27;sku名称&#x27;</span>,</span><br><span class="line">    `category1_id`              STRING COMMENT <span class="string">&#x27;一级分类id&#x27;</span>,</span><br><span class="line">    `category1_name`            STRING COMMENT <span class="string">&#x27;一级分类名称&#x27;</span>,</span><br><span class="line">    `category2_id`              STRING COMMENT <span class="string">&#x27;一级分类id&#x27;</span>,</span><br><span class="line">    `category2_name`            STRING COMMENT <span class="string">&#x27;一级分类名称&#x27;</span>,</span><br><span class="line">    `category3_id`              STRING COMMENT <span class="string">&#x27;一级分类id&#x27;</span>,</span><br><span class="line">    `category3_name`            STRING COMMENT <span class="string">&#x27;一级分类名称&#x27;</span>,</span><br><span class="line">    `tm_id`                     STRING COMMENT <span class="string">&#x27;品牌id&#x27;</span>,</span><br><span class="line">    `tm_name`                   STRING COMMENT <span class="string">&#x27;品牌名称&#x27;</span>,</span><br><span class="line">    `order_count_1d`            <span class="type">BIGINT</span> COMMENT <span class="string">&#x27;最近1日下单次数&#x27;</span>,</span><br><span class="line">    `order_num_1d`              <span class="type">BIGINT</span> COMMENT <span class="string">&#x27;最近1日下单件数&#x27;</span>,</span><br><span class="line">    `order_original_amount_1d`  <span class="type">DECIMAL</span>(<span class="number">16</span>, <span class="number">2</span>) COMMENT <span class="string">&#x27;最近1日下单原始金额&#x27;</span>,</span><br><span class="line">    `activity_reduce_amount_1d` <span class="type">DECIMAL</span>(<span class="number">16</span>, <span class="number">2</span>) COMMENT <span class="string">&#x27;最近1日活动优惠金额&#x27;</span>,</span><br><span class="line">    `coupon_reduce_amount_1d`   <span class="type">DECIMAL</span>(<span class="number">16</span>, <span class="number">2</span>) COMMENT <span class="string">&#x27;最近1日优惠券优惠金额&#x27;</span>,</span><br><span class="line">    `order_total_amount_1d`     <span class="type">DECIMAL</span>(<span class="number">16</span>, <span class="number">2</span>) COMMENT <span class="string">&#x27;最近1日下单最终金额&#x27;</span></span><br><span class="line">) COMMENT <span class="string">&#x27;交易域用户商品粒度订单最近1日汇总事实表&#x27;</span></span><br><span class="line">    PARTITIONED <span class="keyword">BY</span> (`dt` STRING)</span><br><span class="line">    STORED <span class="keyword">AS</span> ORC</span><br><span class="line">    LOCATION <span class="string">&#x27;/warehouse/gmall/dws/dws_trade_user_sku_order_1d&#x27;</span></span><br><span class="line">    TBLPROPERTIES (<span class="string">&#x27;orc.compress&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;snappy&#x27;</span>);</span><br></pre></td></tr></table></figure><p>【2】数据装载</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.exec.dynamic.partition.mode<span class="operator">=</span>nonstrict;</span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> dws_trade_user_sku_order_1d <span class="keyword">partition</span>(dt)</span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    user_id,</span><br><span class="line">    id,</span><br><span class="line">    sku_name,</span><br><span class="line">    category1_id,</span><br><span class="line">    category1_name,</span><br><span class="line">    category2_id,</span><br><span class="line">    category2_name,</span><br><span class="line">    category3_id,</span><br><span class="line">    category3_name,</span><br><span class="line">    tm_id,</span><br><span class="line">    tm_name,</span><br><span class="line">    order_count_1d,</span><br><span class="line">    order_num_1d,</span><br><span class="line">    order_original_amount_1d,</span><br><span class="line">    activity_reduce_amount_1d,</span><br><span class="line">    coupon_reduce_amount_1d,</span><br><span class="line">    order_total_amount_1d,</span><br><span class="line">    dt</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">(</span><br><span class="line">    <span class="keyword">select</span></span><br><span class="line">        dt,</span><br><span class="line">        user_id,</span><br><span class="line">        sku_id,</span><br><span class="line">        <span class="built_in">count</span>(<span class="operator">*</span>) order_count_1d,</span><br><span class="line">        <span class="built_in">sum</span>(sku_num) order_num_1d,</span><br><span class="line">        <span class="built_in">sum</span>(split_original_amount) order_original_amount_1d,</span><br><span class="line">        <span class="built_in">sum</span>(nvl(split_activity_amount,<span class="number">0.0</span>)) activity_reduce_amount_1d,</span><br><span class="line">        <span class="built_in">sum</span>(nvl(split_coupon_amount,<span class="number">0.0</span>)) coupon_reduce_amount_1d,</span><br><span class="line">        <span class="built_in">sum</span>(split_total_amount) order_total_amount_1d</span><br><span class="line">    <span class="keyword">from</span> dwd_trade_order_detail_inc</span><br><span class="line">    <span class="keyword">group</span> <span class="keyword">by</span> dt,user_id,sku_id</span><br><span class="line">)od</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span></span><br><span class="line">(</span><br><span class="line">    <span class="keyword">select</span></span><br><span class="line">        id,</span><br><span class="line">        sku_name,</span><br><span class="line">        category1_id,</span><br><span class="line">        category1_name,</span><br><span class="line">        category2_id,</span><br><span class="line">        category2_name,</span><br><span class="line">        category3_id,</span><br><span class="line">        category3_name,</span><br><span class="line">        tm_id,</span><br><span class="line">        tm_name</span><br><span class="line">    <span class="keyword">from</span> dim_sku_full</span><br><span class="line">    <span class="keyword">where</span> dt<span class="operator">=</span><span class="string">&#x27;2020-06-14&#x27;</span></span><br><span class="line">)sku</span><br><span class="line"><span class="keyword">on</span> od.sku_id<span class="operator">=</span>sku.id;</span><br></pre></td></tr></table></figure><h6 id="（5）ADS层（Application-Data-Service，数据应用层）"><a href="#（5）ADS层（Application-Data-Service，数据应用层）" class="headerlink" title="（5）ADS层（Application Data Service，数据应用层）"></a>（5）ADS层（Application Data Service，数据应用层）</h6><table><thead><tr><th>统计周期</th><th>统计粒度</th><th>指标</th><th>说明</th></tr></thead><tbody><tr><td>最近1&#x2F;7&#x2F;30日</td><td>渠道</td><td>访客数</td><td>统计访问人数</td></tr><tr><td>最近1&#x2F;7&#x2F;30日</td><td>渠道</td><td>会话平均停留时长</td><td>统计每个会话平均停留时长</td></tr><tr><td>最近1&#x2F;7&#x2F;30日</td><td>渠道</td><td>会话平均浏览页面数</td><td>统计每个会话平均浏览页面数</td></tr><tr><td>最近1&#x2F;7&#x2F;30日</td><td>渠道</td><td>会话总数</td><td>统计会话总数</td></tr><tr><td>最近1&#x2F;7&#x2F;30日</td><td>渠道</td><td>跳出率</td><td>只有一个页面的会话的比例</td></tr></tbody></table><p>【1】建表</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 各渠道流量统计</span></span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> IF <span class="keyword">EXISTS</span> ads_traffic_stats_by_channel;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> ads_traffic_stats_by_channel</span><br><span class="line">(</span><br><span class="line">    `dt`               STRING COMMENT <span class="string">&#x27;统计日期&#x27;</span>,</span><br><span class="line">    `recent_days`      <span class="type">BIGINT</span> COMMENT <span class="string">&#x27;最近天数,1:最近1天,7:最近7天,30:最近30天&#x27;</span>,</span><br><span class="line">    `channel`          STRING COMMENT <span class="string">&#x27;渠道&#x27;</span>,</span><br><span class="line">    `uv_count`         <span class="type">BIGINT</span> COMMENT <span class="string">&#x27;访客人数&#x27;</span>,</span><br><span class="line">    `avg_duration_sec` <span class="type">BIGINT</span> COMMENT <span class="string">&#x27;会话平均停留时长，单位为秒&#x27;</span>,</span><br><span class="line">    `avg_page_count`   <span class="type">BIGINT</span> COMMENT <span class="string">&#x27;会话平均浏览页面数&#x27;</span>,</span><br><span class="line">    `sv_count`         <span class="type">BIGINT</span> COMMENT <span class="string">&#x27;会话数&#x27;</span>,</span><br><span class="line">    `bounce_rate`      <span class="type">DECIMAL</span>(<span class="number">16</span>, <span class="number">2</span>) COMMENT <span class="string">&#x27;跳出率&#x27;</span></span><br><span class="line">) COMMENT <span class="string">&#x27;各渠道流量统计&#x27;</span></span><br><span class="line">    <span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;\t&#x27;</span></span><br><span class="line">    LOCATION <span class="string">&#x27;/warehouse/gmall/ads/ads_traffic_stats_by_channel/&#x27;</span>;</span><br></pre></td></tr></table></figure><p>【2】数据装载</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> ads_traffic_stats_by_channel</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> ads_traffic_stats_by_channel</span><br><span class="line"><span class="keyword">union</span></span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    <span class="string">&#x27;2020-06-14&#x27;</span> dt,</span><br><span class="line">    recent_days,</span><br><span class="line">    channel,</span><br><span class="line">    <span class="built_in">cast</span>(<span class="built_in">count</span>(<span class="keyword">distinct</span>(mid_id)) <span class="keyword">as</span> <span class="type">bigint</span>) uv_count,</span><br><span class="line">    <span class="built_in">cast</span>(<span class="built_in">avg</span>(during_time_1d)<span class="operator">/</span><span class="number">1000</span> <span class="keyword">as</span> <span class="type">bigint</span>) avg_duration_sec,</span><br><span class="line">    <span class="built_in">cast</span>(<span class="built_in">avg</span>(page_count_1d) <span class="keyword">as</span> <span class="type">bigint</span>) avg_page_count,</span><br><span class="line">    <span class="built_in">cast</span>(<span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">as</span> <span class="type">bigint</span>) sv_count,</span><br><span class="line">    <span class="built_in">cast</span>(<span class="built_in">sum</span>(if(page_count_1d<span class="operator">=</span><span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>))<span class="operator">/</span><span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">as</span> <span class="type">decimal</span>(<span class="number">16</span>,<span class="number">2</span>)) bounce_rate</span><br><span class="line"><span class="keyword">from</span> dws_traffic_session_page_view_1d <span class="keyword">lateral</span> <span class="keyword">view</span> explode(<span class="keyword">array</span>(<span class="number">1</span>,<span class="number">7</span>,<span class="number">30</span>)) tmp <span class="keyword">as</span> recent_days</span><br><span class="line"><span class="keyword">where</span> dt<span class="operator">&gt;=</span>date_add(<span class="string">&#x27;2023-03-30&#x27;</span>,<span class="operator">-</span>recent_days<span class="operator">+</span><span class="number">1</span>)</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> recent_days,channel;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Little Tips </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> 大数据组件 </tag>
            
            <tag> 数据仓库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>离线数仓总结（上）</title>
      <link href="/2023/03/29/%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E6%80%BB%E7%BB%93%E4%B8%8A/"/>
      <url>/2023/03/29/%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E6%80%BB%E7%BB%93%E4%B8%8A/</url>
      
        <content type="html"><![CDATA[<h2 id="第一章-数据仓库的概念及架构选型"><a href="#第一章-数据仓库的概念及架构选型" class="headerlink" title="第一章 数据仓库的概念及架构选型"></a>第一章 数据仓库的概念及架构选型</h2><p>数据仓库（Data Warehouse），是为企业制定决策，提供数据支持的。可以帮助企业，改进业务流程、提高产品质量等。</p><h4 id="1、数据仓库的输入数据"><a href="#1、数据仓库的输入数据" class="headerlink" title="1、数据仓库的输入数据"></a>1、数据仓库的输入数据</h4><h6 id="业务数据"><a href="#业务数据" class="headerlink" title="业务数据"></a>业务数据</h6><p>就是各行业在处理事务过程中产生的数据。比如用户在电商网站中登录、下单、支付等过程中，需要和网站后台数据库进行增删改查交互，产生的数据就是业务数据。业务数据通常存储在MySQL、Oracle等数据库中。</p><h6 id="用户行为数据"><a href="#用户行为数据" class="headerlink" title="用户行为数据"></a>用户行为数据</h6><p>用户在使用产品过程中，通过埋点收集与客户端产品交互过程中产生的数据，并发往日志服务器进行保存。比如页面浏览、点击、停留、评论、点赞、收藏等。用户行为数据通常存储在日志文件中。</p><h6 id="爬虫数据"><a href="#爬虫数据" class="headerlink" title="爬虫数据"></a>爬虫数据</h6><p>通常是通过技术手段获取其他公司网站的数据。不建议同学们这样去做。</p><blockquote><p>通常来说，业务数据就是后端持久化到数据库的日志记录，例如Mysql的Binlog日志；用户行为数据主要是前端进行埋点采集到的数据，嗯，简单让new bing来介绍下采集流程吧：</p><p>前端埋点到大数据采集的完整流程包括数据采集层、数据接入层、数据处理层、数据应用层这四个层次。在数据采集层，可以通过传统的埋点方式，在需要上报的位置组织数据、调用API、将数据传给后端，也可以通过“无埋点”概念，在底层hook所有的点击事件，自动采集全部事件并上报埋点数据。在数据接入层，可以通过Flume、Kafka等工具将数据接入到Hadoop生态圈中。在数据处理层，可以使用Hive、Spark SQL等工具进行数据清洗、转换和计算。在数据应用层，可以使用Tableau、Echarts等工具进行可视化展示。</p><p>(1) 一个埋点的求生之路——数据处理全流程解析 - 知乎. <a href="https://zhuanlan.zhihu.com/p/133090030">https://zhuanlan.zhihu.com/p/133090030</a></p><p>(2) 数据采集：埋点、采集、存储及分析 - Hider1214 - 博客园. <a href="https://www.cnblogs.com/hider/p/13967167.html">https://www.cnblogs.com/hider/p/13967167.html</a></p><p>(3) 前端埋点简单实现方式 - 掘金. <a href="https://juejin.cn/post/7047710777507053582">https://juejin.cn/post/7047710777507053582</a></p></blockquote><h4 id="2、项目框架"><a href="#2、项目框架" class="headerlink" title="2、项目框架"></a>2、项目框架</h4><p>关于选用版本的详细解释，组件详细介绍单开一栏说明。</p><table><thead><tr><th>框架</th><th>版本</th><th>说明</th></tr></thead><tbody><tr><td>jdk</td><td>1.8</td><td>Java版本，Hadoop体系建议使用1.8，虽然兼容Java11但是Hive除了最新的4.0.0alpha版本以外，其他的都只支持到1.8。Java11以上不支持。</td></tr><tr><td>Hadoop</td><td>3.1.3</td><td>选用视频配套版本，选择太旧的2.x可能出现依赖缺失，最新的3.4.3则存在依赖改名的问题</td></tr><tr><td>Zookeeper</td><td>3.5.7</td><td></td></tr><tr><td>Mysql</td><td>5.7.16</td><td>可以选用8系列，但是不能低于5.7版本，5.7.8之后支持Json，同时对InnoDB和一些强政策进行了更改。详情可看<a href="https://zhuanlan.zhihu.com/p/29726382">数据库MySQL 5.7版本介绍</a></td></tr><tr><td>Hive</td><td>3.1.2</td><td>Hive和Spark以及Hadoop版本要互相兼容，采用自编译等方式可以自定义版本</td></tr><tr><td>Flume</td><td>1.9.0</td><td>不建议选用2.0.0以上版本，配置文件有点改动（大概是.properties-&gt;.xml）</td></tr><tr><td>Kafka</td><td>3.0.0</td><td></td></tr><tr><td>Spark</td><td>3.0.0</td><td></td></tr><tr><td>DataX</td><td>3.0.0</td><td></td></tr><tr><td>Superset</td><td><strong>1.4.2</strong></td><td>推荐版本很搞，更新之后很多依赖都没了，不建议使用2.0.0，如果需要2.0.0+可以使用网上的一键部署版本，不然自己调整配置会很麻烦（需要一定conda、python知识）</td></tr><tr><td>DolphinScheduler</td><td>2.0.3</td><td></td></tr><tr><td>Maxwell</td><td>1.29.2</td><td></td></tr></tbody></table><h4 id="3、测试集群服务器规划"><a href="#3、测试集群服务器规划" class="headerlink" title="3、测试集群服务器规划"></a>3、测试集群服务器规划</h4><table><thead><tr><th>服务名称</th><th>子服务</th><th>服务器hadoop102</th><th>服务器hadoop1</th><th>服务器hadoop104</th></tr></thead><tbody><tr><td>HDFS</td><td>NameNode</td><td>√</td><td></td><td></td></tr><tr><td></td><td>DataNode</td><td>√</td><td>√</td><td>√</td></tr><tr><td></td><td>SecondaryNameNode</td><td></td><td></td><td>√</td></tr><tr><td>Yarn</td><td>NodeManager</td><td>√</td><td>√</td><td>√</td></tr><tr><td></td><td>Resourcemanager</td><td></td><td>√</td><td></td></tr><tr><td>Zookeeper</td><td>Zookeeper Server</td><td>√</td><td>√</td><td>√</td></tr><tr><td>Flume（采集日志）</td><td>Flume</td><td>√</td><td>√</td><td></td></tr><tr><td>Kafka</td><td>Kafka</td><td>√</td><td>√</td><td>√</td></tr><tr><td>Flume（消费Kafka日志）</td><td>Flume</td><td></td><td></td><td>√</td></tr><tr><td>Flume（消费Kafka业务）</td><td>Flume</td><td></td><td></td><td>√</td></tr><tr><td>Hive</td><td></td><td>√</td><td>√</td><td>√</td></tr><tr><td>MySQL</td><td>MySQL</td><td>√</td><td></td><td></td></tr><tr><td>DataX</td><td></td><td>√</td><td>√</td><td>√</td></tr><tr><td>Spark</td><td></td><td>√</td><td>√</td><td>√</td></tr><tr><td>DolphinScheduler</td><td>ApiApplicationServer</td><td>√</td><td></td><td></td></tr><tr><td></td><td>AlertServer</td><td>√</td><td></td><td></td></tr><tr><td></td><td>MasterServer</td><td>√</td><td></td><td></td></tr><tr><td></td><td>WorkerServer</td><td>√</td><td>√</td><td>√</td></tr><tr><td></td><td>LoggerServer</td><td>√</td><td>√</td><td>√</td></tr><tr><td>Superset</td><td>Superset</td><td>√</td><td></td><td></td></tr><tr><td>服务数总计</td><td></td><td>16</td><td>11</td><td>12</td></tr></tbody></table><hr><h2 id="第二章-组件及常见问题"><a href="#第二章-组件及常见问题" class="headerlink" title="第二章 组件及常见问题"></a>第二章 组件及常见问题</h2><h4 id="0、虚拟机"><a href="#0、虚拟机" class="headerlink" title="0、虚拟机"></a>0、虚拟机</h4><p>能上哪个版本的VMware就上那个版本的VMware，虚拟机版本选用对环境影响并不大，不同Linux发行版之间基本是配置相同，包管理工具不同罢了，值得注意的是：选用CentOS Stream 9的配置项会和CentOS7之类的差别较大，在配置CentOS Stream 9作为虚拟机的时候可以参考以下文章：<a href="https://www.hxstrive.com/article/1053.htm">CentOS Stream9 设置静态IP</a>。</p><p><strong>！！注意一下内存分配</strong>：HiveServer2启动查询功能大概率是将结果暂存在内存中，开8G很容易OOM，而DolphinScheduler更加离谱，全节点启动的情况下，8G内存甚至任务都无法执行，推荐配置16G、8G、8G，最低配置如下：</p><p>Hadoop102：8G+（我配的10G，结束时约空闲1~2G）</p><p>Hadoop103&#x2F;Hadoop104：6G+（我配的8G，结束时约空闲1~3G）</p><h4 id="0-1、Jdk"><a href="#0-1、Jdk" class="headerlink" title="0.1、Jdk"></a>0.1、Jdk</h4><p>版本选择1.8，以所有组件中要求版本最高的那个作为适配版本，所有组件中Hive只能在1.8中启动，故选择1.8版本；当然如果想采用最新版本体验或是仍然想用更高级Java版本中的语法糖，那么可以安装多个Java，让Hive执行其他Java即可。</p><h4 id="0-2、Mock模拟数据准备"><a href="#0-2、Mock模拟数据准备" class="headerlink" title="0.2、Mock模拟数据准备"></a>0.2、Mock模拟数据准备</h4><h6 id="（1）生成日志数据"><a href="#（1）生成日志数据" class="headerlink" title="（1）生成日志数据"></a>（1）生成日志数据</h6><p>这里使用文档中准备的Java程序执行即可，使用基本流程是：</p><ul><li>依次启动Zookeeper、Kafka、Flume（采集日志）；</li><li>执行Java程序，在选定目录下生成Json日志；</li><li>Flume将生成的日志数据采集到HDFS上。</li></ul><h6 id="（2）生成业务数据"><a href="#（2）生成业务数据" class="headerlink" title="（2）生成业务数据"></a>（2）生成业务数据</h6><p>这里使用文档中准备的Java程序执行即可，使用基本流程是：</p><ul><li>修改application.properties中的mock.clear和mock.clear.user数据</li><li>执行Java程序，在MySQL数据库中生成业务数据</li></ul><h4 id="0-3、Source环境总览"><a href="#0-3、Source环境总览" class="headerlink" title="0.3、Source环境总览"></a>0.3、Source环境总览</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">JAVA_HOME</span></span><br><span class="line">export JAVA_HOME=/opt/module/jdk</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">HADOOP_HOME</span></span><br><span class="line">export HADOOP_HOME=/opt/module/hadoop</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">KAFKA_HOME</span></span><br><span class="line">export KAFKA_HOME=/opt/module/kafka</span><br><span class="line">export PATH=$PATH:$KAFKA_HOME/bin</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">HIVE_HOME</span></span><br><span class="line">export HIVE_HOME=/opt/module/hive</span><br><span class="line">export PATH=$PATH:$HIVE_HOME/bin</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">SPARK_HOME</span></span><br><span class="line">export SPARK_HOME=/opt/module/spark</span><br><span class="line">export PATH=$PATH:$SPARK_HOME/bin</span><br></pre></td></tr></table></figure><h4 id="1、Hadoop"><a href="#1、Hadoop" class="headerlink" title="1、Hadoop"></a>1、Hadoop</h4><p>Hadoop是一个由Apache基金会所开发的分布式系统基础架构，是一个存储系统 + 计算框架的软件框架。主要解决海量数据存储与计算的问题，是大数据技术中的基石。Hadoop以一种可靠、高效、可伸缩的方式进行数据处理，用户可以在不了解分布式底层细节的情况下，开发出分布式程序。</p><h6 id="（1）配置流程："><a href="#（1）配置流程：" class="headerlink" title="（1）配置流程："></a>（1）配置流程：</h6><ul><li><p>核心配置文件core-site.xml</p><ul><li>配置NameNode地址</li><li>指定Hadoop数据存储目录</li><li>配置HDFS网页登录使用的静态用户</li><li>配置用户允许通过代理访问的主机节点</li><li>配置用户允许通过代理用户所属组</li><li>配置用户允许通过代理的用户</li></ul></li><li><p>HDFS配置文件hdfs-site.xml</p><ul><li>配置NameNode Web端访问端口</li><li>配置Secondary NameNode Web端访问端口</li><li>指定HDFS副本的数量</li></ul></li><li><p>YARN配置文件yarn-site.xml</p><ul><li>指定MapReduce走shuffle</li><li>指定ResourceManager地址</li><li>配置环境变量继承</li><li>配置YARN单个容器允许分配的最大最小内存</li><li>配置YARN容器允许管理的物理内存大小</li><li>关闭YARN对物理内存和虚拟内存的限制检查</li><li>开启日志聚集功能</li><li>设置日志聚集服务器地址</li><li>设置日志保留时间为7天</li></ul></li><li><p>MapReduce配置文件mapred-site.xml</p><ul><li>指定MapReduce程序运行在YARN上</li><li>配置历史服务器端地址</li><li>配置历史服务器Web端地址</li></ul></li><li><p>配置workers（集群）</p></li><li><p>分发到所有集群机器上</p></li><li><p>初始化NameNode节点</p></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format</span><br></pre></td></tr></table></figure><h6 id="（2）常见启停命令"><a href="#（2）常见启停命令" class="headerlink" title="（2）常见启停命令"></a>（2）常见启停命令</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh                        # 启动HDFS</span><br><span class="line">start-yarn.sh                       # 启动YARN</span><br><span class="line">mapred --daemon start historyserver # 启动历史日志采集</span><br></pre></td></tr></table></figure><h6 id="（3）参数调优"><a href="#（3）参数调优" class="headerlink" title="（3）参数调优"></a>（3）参数调优</h6><ul><li><p>hdfs-site.xml</p><ul><li>NameNode有一个工作线程池，用来处理不同DataNode的并发心跳以及客户端并发的元数据操作。对于大集群或者有大量客户端的集群来说，通常需要增大参数dfs.namenode.handler.count的默认值10。</li></ul></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.handler.count&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;10&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p>  $$<br>  dfs.namenode.handler.count&#x3D;20 × log_e^ClusterSize， 比如集群规模为8台时，此参数设置为41。<br>  $$</p><ul><li><p>yarn-site.xml</p><ul><li><p>数据统计主要用HiveSQL，没有数据倾斜，小文件已经做了合并处理，开启的JVM重用，而且IO没有阻塞，内存用了不到50%。但是还是跑的非常慢，而且数据量洪峰过来时，整个集群都会宕掉。</p></li><li><p>内存利用率不够。这个一般是Yarn的2个配置造成的，单个任务可以申请的最大内存大小，和Hadoop单个节点可用内存大小。调节这两个参数能提高系统内存的利用率。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">（a）yarn.nodemanager.resource.memory-mb</span><br><span class="line">表示该节点上YARN可使用的物理内存总量，默认是8192（MB），注意，如果你的节点内存资源不够8GB，则需要调减小这个值，而YARN不会智能的探测节点的物理内存总量。</span><br><span class="line">（b）yarn.scheduler.maximum-allocation-mb</span><br><span class="line">单个任务可申请的最多物理内存量，默认是8192（MB）。</span><br></pre></td></tr></table></figure></li></ul></li></ul><h4 id="2、Zookeeper"><a href="#2、Zookeeper" class="headerlink" title="2、Zookeeper"></a>2、Zookeeper</h4><p>ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，它包含一个简单的原语集，分布式应用程序可以基于它实现同步服务，配置维护和命名服务等。ZooKeeper作为一个分布式的服务框架，主要用来解决分布式集群中应用系统的一致性问题，它能提供基于类似于文件系统的目录节点树方式的数据存储，Zookeeper作用主要是用来维护和监控存储的数据的状态变化，通过监控这些数据状态的变化，从而达到基于数据的集群管理。</p><h6 id="（1）配置流程"><a href="#（1）配置流程" class="headerlink" title="（1）配置流程"></a>（1）配置流程</h6><ul><li><p>配置myid文件，每个服务器上的myid是唯一编号，代表单独的Zookeeper server。</p></li><li><p>配置*&#x2F;conf目录下的zoo_sample.cfg文件</p><ul><li><p>改名，去掉sample启用配置</p></li><li><p>修改数据存储路径，配置到myid对应的目录</p></li><li><p>增加server.*配置。例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">server.2=hadoop102:2888:3888 # .2就是myid中的server编号</span><br></pre></td></tr></table></figure></li></ul></li><li><p>同步配置到其他服务器（一定记得修改myid）</p></li></ul><h6 id="（2）常见启停脚本"><a href="#（2）常见启停脚本" class="headerlink" title="（2）常见启停脚本"></a>（2）常见启停脚本</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">zkServer.sh start  # 启动Zookeeper</span><br><span class="line">zkServer.sh status # 查看Zookeeper状态</span><br><span class="line">zkServer.sh stop   # 停止Zookeeper进程</span><br></pre></td></tr></table></figure><h4 id="3、Kafka"><a href="#3、Kafka" class="headerlink" title="3、Kafka"></a>3、Kafka</h4><p>Kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者在网站中的所有动作流数据。Kafka最初由LinkedIn公司发布，使用Scala语言编写，与2010年12月份开源，成为Apache的顶级子项目。</p><p>Kafka是一种高吞吐量、持久性、分布式的发布订阅的消息队列系统。它可以在廉价的PC Server上搭建起大规模消息系统。</p><h6 id="（1）配置流程-1"><a href="#（1）配置流程-1" class="headerlink" title="（1）配置流程"></a>（1）配置流程</h6><ul><li><p>配置*&#x2F;config&#x2F;目录下的server.properties文件</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#broker的全局唯一编号，不能重复，只能是数字。每个服务器上的数字不能一样。</span><br><span class="line">broker.id=0</span><br><span class="line">#kafka运行日志(数据)存放的路径，路径不需要提前创建，kafka自动帮你创建，可以配置多个磁盘路径，路径与路径之间可以用&quot;,&quot;分隔</span><br><span class="line">log.dirs=/opt/module/kafka/datas</span><br><span class="line">#配置连接Zookeeper集群地址（在zk根目录下创建/kafka，方便管理）</span><br><span class="line">zookeeper.connect=hadoop102:2181,hadoop103:2181,hadoop104:2181/kafka</span><br></pre></td></tr></table></figure></li><li><p>分发软件包，记得修改broker.id</p></li></ul><h6 id="（2）常见启停脚本-1"><a href="#（2）常见启停脚本-1" class="headerlink" title="（2）常见启停脚本"></a>（2）常见启停脚本</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">配置过zookeeper.connect之后需要先启动Zookeeper服务</span></span><br><span class="line">kafka-server-start.sh -daemon config/server.properties  # 根据配置文件启动Kafka</span><br><span class="line">kafka-server-stop.sh                                    # 关闭Kafka</span><br></pre></td></tr></table></figure><h6 id="（3）常见命令行操作"><a href="#（3）常见命令行操作" class="headerlink" title="（3）常见命令行操作"></a>（3）常见命令行操作</h6><ul><li><p>主题命令操作</p><ul><li><p>Kafka中的数据单元是消息，可以把它当作数据库里的一行“数据”或者一条“记录”来理解。Kafka通过主题来进行分类，主题就好比数据库中的表，每个主题包含多个分区，分区可以分布在不同的服务器上，也就是说通过这种方式来实现分布式数据的存储和读取。</p><p>主题是Kafka中的基础概念，是一切消息处理的基础。主题属于Kafka元数据的一部分，会存储在Zookeeper中。生产者发布消息到某一特定主题上，由消费者去消费特定主题的消息。消费者可以订阅一个或多个主题。</p></li></ul>  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh  # 查看操作命令主题</span><br></pre></td></tr></table></figure></li></ul><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>–bootstrap-server &lt;String: server toconnect to&gt;</td><td>连接的Kafka Broker主机名称和端口号。</td></tr><tr><td>–topic &lt;String: topic&gt;</td><td>操作的topic名称。</td></tr><tr><td>–create</td><td>创建主题。</td></tr><tr><td>–delete</td><td>删除主题。</td></tr><tr><td>–alter</td><td>修改主题。</td></tr><tr><td>–list</td><td>查看所有主题。</td></tr><tr><td>–describe</td><td>查看主题详细描述。</td></tr><tr><td>–partitions &lt;Integer: # of partitions&gt;</td><td>设置分区数。</td></tr><tr><td>–replication-factor&lt;Integer: replication factor&gt;</td><td>设置分区副本。</td></tr><tr><td>–config &lt;String: name&#x3D;value&gt;</td><td>更新系统默认的配置。</td></tr></tbody></table><ul><li><p>生产者命令操作</p><ul><li>Kafka生产者是指向Kafka集群发送消息的客户端应用程序。生产者将消息封装成一个ProducerRecord向Kafka集群中的某个主题发送消息。发送的消息首先会经过序列化器进行序列化，以便在网络中传输。发送的消息需要经过分区器来决定该消息会分发到主题对应的分区，当然如果指定了分区，那么就不需要分区器来决定。</li></ul>  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-producer.sh  # 查看操作生产者</span><br></pre></td></tr></table></figure></li></ul><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>–bootstrap-server &lt;String: server toconnect to&gt;</td><td>连接的Kafka Broker主机名称和端口号。</td></tr><tr><td>–topic &lt;String: topic&gt;</td><td>操作的topic名称。</td></tr></tbody></table><ul><li><p>消费者命令操作</p><ul><li>Kafka消费者是指从Kafka集群中读取消息的客户端应用程序。消费者将从一个或多个主题订阅消息，并在消费者组中进行组织。当多个消费者形成一个消费组来消费主题时，每个消费者会收到不同分区的消息。消费者可以控制消息的读取位置，从而实现对消息的重复读取或跳过。</li></ul>  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-consumer.sh  # 查看操作消费者</span><br></pre></td></tr></table></figure></li></ul><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>–bootstrap-server &lt;String: server toconnect to&gt;</td><td>连接的Kafka Broker主机名称和端口号。</td></tr><tr><td>–topic &lt;String: topic&gt;</td><td>操作的topic名称。</td></tr><tr><td>–from-beginning</td><td>从头开始消费。</td></tr><tr><td>–group &lt;String: consumer group id&gt;</td><td>指定消费者组名称。</td></tr></tbody></table><h4 id="4、Flume"><a href="#4、Flume" class="headerlink" title="4、Flume"></a>4、Flume</h4><p>Flume是一个分布式、可靠、和高可用的海量日志采集、聚合和传输的系统。它的主要作用是将数据从各种数据源（如Web服务器）收集到Hadoop的HDFS中，或者将数据从一个地方传输到另一个地方。Flume的核心概念包括：Source、Channel和Sink。Source是数据源，可以是Avro、Thrift、JMS、Netcat、Exec等；Channel是缓存区，用于存储Source产生的数据；Sink是数据目的地，可以是HDFS、HBase、Solr、Elasticsearch等。</p><ul><li>删除lib目录下的guava.jar以兼容Hadoop</li></ul><h6 id="（1）整体流程"><a href="#（1）整体流程" class="headerlink" title="（1）整体流程"></a>（1）整体流程</h6><p>日志采集Flume需要采集日志文件内容，并对日志格式（JSON）进行校验，然后将校验通过的日志发送到Kafka。此处可选择TaildirSource和KafkaChannel，并配置日志校验拦截器。</p><ul><li>TailDirSource相比ExecSource、SpoolingDirectorySource的优势<ul><li>TailDirSource：断点续传、多目录。Flume1.6以前需要自己自定义Source记录每次读取文件位置，实现断点续传。</li><li>ExecSource可以实时搜集数据，但是在Flume不运行或者Shell命令出错的情况下，数据将会丢失。</li><li>SpoolingDirectorySource监控目录，支持断点续传。</li></ul></li><li>Kafka Channel<ul><li>采用Kafka Channel，省去了Sink，提高了效率。</li></ul></li></ul><blockquote><p>Flume执行job实现日志的采集，因此无需就行过多的原生配置，只需要针对每个任务写对应的job即可。</p></blockquote><h6 id="（2）配置实操"><a href="#（2）配置实操" class="headerlink" title="（2）配置实操"></a>（2）配置实操</h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"># job/file_to_kafka.conf</span><br><span class="line"># 定义组件</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"># 配置source</span><br><span class="line">a1.sources.r1.type = TAILDIR</span><br><span class="line">a1.sources.r1.filegroups = f1</span><br><span class="line">a1.sources.r1.filegroups.f1 = /opt/module/applog/log/app.*</span><br><span class="line">a1.sources.r1.positionFile = /opt/module/flume/taildir_position.json</span><br><span class="line">a1.sources.r1.interceptors =  i1</span><br><span class="line">a1.sources.r1.interceptors.i1.type = xxx.ETLInterceptor$Builder  # 自定义拦截器jar包</span><br><span class="line"></span><br><span class="line"># 配置channel</span><br><span class="line">a1.channels.c1.type = org.apache.flume.channel.kafka.KafkaChannel</span><br><span class="line">a1.channels.c1.kafka.bootstrap.servers = hadoop102:9092,hadoop103:9092</span><br><span class="line">a1.channels.c1.kafka.topic = topic_log</span><br><span class="line">a1.channels.c1.parseAsFlumeEvent = false</span><br><span class="line"></span><br><span class="line"># 组装 </span><br><span class="line">a1.sources.r1.channels = c1</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">flume-ng agent -n a1 -c conf/ -f job/file_to_kafka.conf -Dflume.root.logger=info,console</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">这段代码是用于启动Flume的命令行。其中，`flume-ng`是启动Flume的命令，`agent`表示启动的是一个agent，`-n a1`表示agent的名称为a1，`-c conf/`表示配置文件所在的目录为conf，`-f job/file_to_kafka.conf`表示使用名为file_to_kafka.conf的配置文件，`-Dflume.root.logger=info,console`表示设置日志级别为info，并将日志输出到控制台。</span></span><br></pre></td></tr></table></figure><h4 id="5、MySQL"><a href="#5、MySQL" class="headerlink" title="5、MySQL"></a>5、MySQL</h4><h6 id="配置流程"><a href="#配置流程" class="headerlink" title="配置流程"></a>配置流程</h6><ul><li>安装MySQL依赖</li><li>安装mysql-client</li><li>安装mysql-server</li><li>配置MySQL<ul><li>设置复杂密码</li><li>更改MySQL密码策略</li><li>设置简单密码</li></ul></li></ul><h4 id="6、Maxwell"><a href="#6、Maxwell" class="headerlink" title="6、Maxwell"></a>6、Maxwell</h4><p>Maxwell是一个能实时读取MySQL二进制日志binlog，并生成 JSON 格式的消息，作为生产者发送给 Kafka、Kinesis、RabbitMQ、Redis、Google Cloud Pub&#x2F;Sub、文件或其它平台的应用程序³。它的主要作用是将MySQL数据库中的数据变更事件转换成JSON格式的消息，以便于在分布式系统中进行数据同步。Maxwell可以通过配置文件来指定需要同步的表，以及需要过滤掉的字段等信息。</p><p><strong>原理：</strong>将自己伪装成slave，并遵循MySQL主从复制的协议，从master同步数据。</p><h6 id="（1）配置流程-2"><a href="#（1）配置流程-2" class="headerlink" title="（1）配置流程"></a>（1）配置流程</h6><ul><li><p>修改MySQL配置，启用Binglog日志（默认不开启）后重启MySQL服务。</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line"></span><br><span class="line">#数据库id</span><br><span class="line">server-id = 1</span><br><span class="line">#启动binlog，该参数的值会作为binlog的文件名</span><br><span class="line">log-bin=mysql-bin</span><br><span class="line">#binlog类型，maxwell要求为row类型</span><br><span class="line">binlog_format=row</span><br><span class="line">#启用binlog的数据库，需根据实际情况作出修改</span><br><span class="line">binlog-do-db=gmall</span><br></pre></td></tr></table></figure><ul><li><p>几种常见的Binlog模式</p><ul><li><p><strong>Statement-based：</strong>基于语句，Binlog会记录所有写操作的SQL语句，包括insert、update、delete等。</p><p>优点： 节省空间</p><p>缺点： 有可能造成数据不一致，例如insert语句中包含now()函数。</p></li><li><p><strong>Row-based：</strong>基于行，Binlog会记录每次写操作后被操作行记录的变化。</p><p>优点：保持数据的绝对一致性。</p><p>缺点：占用较大空间。</p></li><li><p><strong>mixed：</strong>混合模式，默认是Statement-based，如果SQL语句可能导致数据不一致，就自动切换到Row-based。</p></li></ul></li><li><p><strong>Maxwell要求Binlog采用Row-based模式。</strong></p></li></ul></li><li><p>配置maxwell目录下的config.properties.example文件（元数据库、生产者、集群配置）</p><ul><li>重命名为config.properties</li></ul>  <figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Maxwell数据发送目的地，可选配置有stdout|file|kafka|kinesis|pubsub|sqs|rabbitmq|redis</span></span><br><span class="line"><span class="attr">producer</span>=<span class="string">kafka</span></span><br><span class="line"><span class="comment">#目标Kafka集群地址</span></span><br><span class="line"><span class="attr">kafka.bootstrap.servers</span>=<span class="string">hadoop102:9092,hadoop103:9092</span></span><br><span class="line"><span class="comment">#目标Kafka topic，可静态配置，例如:maxwell，也可动态配置，例如：%&#123;database&#125;_%&#123;table&#125;</span></span><br><span class="line"><span class="attr">kafka_topic</span>=<span class="string">maxwell</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#MySQL相关配置</span></span><br><span class="line"><span class="attr">host</span>=<span class="string">hadoop102</span></span><br><span class="line"><span class="attr">user</span>=<span class="string">maxwell</span></span><br><span class="line"><span class="attr">password</span>=<span class="string">maxwell</span></span><br><span class="line"><span class="attr">jdbc_options</span>=<span class="string">useSSL=false&amp;serverTimezone=Asia/Shanghai</span></span><br></pre></td></tr></table></figure></li></ul><h6 id="（2）常见启停脚本-2"><a href="#（2）常见启停脚本-2" class="headerlink" title="（2）常见启停脚本"></a>（2）常见启停脚本</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">maxwell --config /opt/module/maxwell/config.properties --daemon                         # 启动maxwell</span><br><span class="line">ps -ef | grep maxwell | grep -v grep | grep maxwell | awk &#x27;&#123;print $2&#125;&#x27; | xargs kill -9  # 停止maxwell</span><br></pre></td></tr></table></figure><h6 id="（3）增量同步和全量同步"><a href="#（3）增量同步和全量同步" class="headerlink" title="（3）增量同步和全量同步"></a>（3）增量同步和全量同步</h6><ul><li><p>增量同步：启用Kafka消费者、maxwell，Mock业务数据即可在Kafka中观察到生成的数据；</p></li><li><p>全量同步：</p><ul><li>Maxwell提供了bootstrap功能来进行历史数据的全量同步，输出结果为Json格式</li></ul>  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">maxwell-bootstrap --database gmall --table user_info --config /opt/module/maxwell/config.properties</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">这段代码是在运行maxwell-bootstrap命令，它会将gmall数据库中的user_info表的数据导入到另一个数据库中。其中，--config /opt/module/maxwell/config.properties是指定了配置文件的路径。</span></span><br></pre></td></tr></table></figure></li></ul><h4 id="7、DataX"><a href="#7、DataX" class="headerlink" title="7、DataX"></a>7、DataX</h4><p>DataX 是阿里巴巴开源的一个异构数据源离线同步工具，致力于实现包括关系型数据库(MySQL、Oracle等)、HDFS、Hive、ODPS、HBase、FTP等各种异构数据源之间稳定高效的数据同步功能。源码地址：<a href="https://github.com/alibaba/DataX">https://github.com/alibaba/DataX</a></p><p>为了解决异构数据源同步问题，DataX将复杂的网状的同步链路变成了星型数据链路，DataX作为中间传输载体负责连接各种数据源。当需要接入一个新的数据源的时候，只需要将此数据源对接到DataX，便能跟已有的数据源做到无缝数据同步。</p><h6 id="（1）配置流程-3"><a href="#（1）配置流程-3" class="headerlink" title="（1）配置流程"></a>（1）配置流程</h6><ul><li><p>解压自检</p>  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">python /opt/module/datax/bin/datax.py /opt/module/datax/job/job.json</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">出现如下反馈代表安装成功</span></span><br><span class="line">……</span><br><span class="line">2021-10-12 21:51:12.335 [job-0] INFO  JobContainer - </span><br><span class="line">任务启动时刻                    : 2021-10-12 21:51:02</span><br><span class="line">任务结束时刻                    : 2021-10-12 21:51:12</span><br><span class="line">任务总计耗时                    :                 10s</span><br><span class="line">任务平均流量                    :          253.91KB/s</span><br><span class="line">记录写入速度                    :          10000rec/s</span><br><span class="line">读出记录总数                    :              100000</span><br><span class="line">读写失败总数                    :                   0</span><br></pre></td></tr></table></figure></li></ul><h6 id="（2）配置说明"><a href="#（2）配置说明" class="headerlink" title="（2）配置说明"></a>（2）配置说明</h6><p>配置文件模板为json，json最外层是一个job，job包含setting和content两部分，其中setting用于对整个job进行配置，content用户配置数据源和目的地。</p><p><img src="/2023/03/29/%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E6%80%BB%E7%BB%93%E4%B8%8A/%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E6%80%BB%E7%BB%93%EF%BC%88%E4%B8%8A%EF%BC%89/1.png"></p><h6 id="（3）DataX优化"><a href="#（3）DataX优化" class="headerlink" title="（3）DataX优化"></a>（3）DataX优化</h6><p>DataX3.0提供了包括通道(并发)、记录流、字节流三种流控模式，可以随意控制你的作业速度，让你的作业在数据库可以承受的范围内达到最佳的同步速度。</p><table><thead><tr><th>参数</th><th>说明</th></tr></thead><tbody><tr><td>job.setting.speed.channel</td><td>并发数</td></tr><tr><td>job.setting.speed.record</td><td>总record限速</td></tr><tr><td>job.setting.speed.byte</td><td>总byte限速</td></tr><tr><td>core.transport.channel.speed.record</td><td>单个channel的record限速，默认值为10000（10000条&#x2F;s）</td></tr><tr><td>core.transport.channel.speed.byte</td><td>单个channel的byte限速，默认值1024*1024（1M&#x2F;s）</td></tr></tbody></table><p><strong>注意事项：</strong></p><p>1.若配置了总record限速，则必须配置单个channel的record限速</p><p>2.若配置了总byte限速，则必须配置单个channe的byte限速</p><p>3.若配置了总record限速和总byte限速，channel并发数参数就会失效。因为配置了总record限速和总byte限速之后，实际channel并发数是通过计算得到的：</p><p><strong>计算公式为:</strong></p><p>min(总byte限速&#x2F;单个channel的byte限速，总record限速&#x2F;单个channel的record限速)</p><h4 id="8、Hive"><a href="#8、Hive" class="headerlink" title="8、Hive"></a>8、Hive</h4><p>Hive是一个基于Hadoop的数据仓库工具，用于处理结构化数据。它可以将结构化的数据文件映射为一张数据库表，并提供类SQL查询功能。Hive的操作接口采用类SQL语法，提供快速开发的能力，避免了写MapReduce，减少开发人员的学习成本，功能扩展很方便。</p><p>你可以使用Hive来进行数据提取、转化、加载，这是一种可以存储、查询和分析存储在Hadoop中的大规模数据的机制。你可以在Hive中使用类SQL语句来查询数据，这些语句会被转换成MapReduce任务来执行。你需要安装Hive并配置它以便使用它。你可以在网上找到很多关于如何使用Hive的教程和指南。</p><h6 id="配置流程-1"><a href="#配置流程-1" class="headerlink" title="配置流程"></a>配置流程</h6><ul><li><p>解决日志包冲突，删除lib下的log4j-slf4j-impl.jar包</p></li><li><p>拷贝对应版本的mysql驱动到lib目录 mysql-connector-java-5.1.27-bin.jar</p></li><li><p>新建hive-site.xml</p>  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://hadoop102:3306/metastore?useSSL=false<span class="symbol">&amp;amp;</span>useUnicode=true<span class="symbol">&amp;amp;</span>characterEncoding=UTF-8<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>000000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.schema.verification<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>10000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.bind.host<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.event.db.notification.api.auth<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.cli.print.header<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.cli.print.current.db<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>在MySQL创建Hive元数据库metastore</p></li><li><p>初始化Hive元数据库</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">schematool <span class="operator">-</span>initSchema <span class="operator">-</span>dbType mysql <span class="operator">-</span>verbose</span><br></pre></td></tr></table></figure></li><li><p>修改元数据库字符集</p><ul><li>Hive元数据库的字符集默认为Latin1，由于其不支持中文字符，故若建表语句中包含中文注释，会出现乱码现象。修改Hive元数据库中存储注释的字段的字符集为utf-8。</li></ul>  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> COLUMNS_V2 modify <span class="keyword">column</span> COMMENT <span class="type">varchar</span>(<span class="number">256</span>) <span class="type">character</span> <span class="keyword">set</span> utf8;</span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> TABLE_PARAMS modify <span class="keyword">column</span> PARAM_VALUE mediumtext <span class="type">character</span> <span class="keyword">set</span> utf8;</span><br></pre></td></tr></table></figure></li></ul><h4 id="9、Spark"><a href="#9、Spark" class="headerlink" title="9、Spark"></a>9、Spark</h4><p>Spark是一个快速的、通用的、基于内存的分布式计算系统，用于大规模数据处理。它是UC Berkeley AMP lab所开源的类Hadoop MapReduce的通用并行框架，拥有Hadoop MapReduce所具有的优点；但不同于MapReduce的是Job中间输出和结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的MapReduce的算法。</p><h6 id="（1）兼容性说明"><a href="#（1）兼容性说明" class="headerlink" title="（1）兼容性说明"></a>（1）兼容性说明</h6><p>官网下载的Hive3.1.2和Spark3.0.0默认是不兼容的。因为Hive3.1.2支持的Spark版本是2.4.5，所以需要我们重新编译Hive3.1.2版本。</p><p>编译步骤：官网下载Hive3.1.2源码，修改pom文件中引用的Spark版本为3.0.0，如果编译通过，直接打包获取jar包。如果报错，就根据提示，修改相关方法，直到不报错，打包获取jar包。</p><blockquote><p>这里我试过了hive4.0.0alpha去兼容jdk11，但是无疾而终（默认启动的是beeline不是hive，这个时候我还没学hive，不太好大刀阔斧上手）。spark也试了从3.0.0到最新版中的几个版本，但是hive没有自编译，所以总会报错。</p><p>另外，hadoop版本也要考虑，Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.spark.SparkTask. RPC channel is closed.这个问题在YARN日志报的$GetFileInfoRequestProto无法强制转换为com.google.protobuf.Message，主要就是hadoop版本导致的。</p></blockquote><h6 id="（2）配置流程"><a href="#（2）配置流程" class="headerlink" title="（2）配置流程"></a>（2）配置流程</h6><ul><li><p>在hive中创建spark配置文件</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># spark-defaults.conf</span><br><span class="line">spark.master                             yarn</span><br><span class="line">spark.eventLog.enabled                   true</span><br><span class="line">spark.eventLog.dir              hdfs://hadoop102:8020/spark-history</span><br><span class="line">spark.executor.memory                    1g</span><br><span class="line">spark.driver.memory     1g</span><br></pre></td></tr></table></figure></li><li><p>修改hive-site.xml文件，更改为spark引擎</p>  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--Spark依赖位置（注意：端口号8020必须和namenode的端口号一致）--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>spark.yarn.jars<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop102:8020/spark-jars/*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  </span><br><span class="line"><span class="comment">&lt;!--Hive执行引擎--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.execution.engine<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>spark<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>增加Application Master资源比例</p><ul><li>修改YARN配置文件yarn-site.xml</li></ul>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.capacity.maximum-am-resource-percent&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;0.8&lt;/value&gt;</span><br><span class="line">&lt;/property</span><br></pre></td></tr></table></figure></li></ul><h4 id="10、DolphinScheduler"><a href="#10、DolphinScheduler" class="headerlink" title="10、DolphinScheduler"></a>10、DolphinScheduler</h4><p>Apache DolphinScheduler是一个分布式、易扩展的可视化DAG工作流任务调度平台。致力于解决数据处理流程中错综复杂的依赖关系，使调度系统在数据处理流程中开箱即用。</p><h6 id="（1）核心架构"><a href="#（1）核心架构" class="headerlink" title="（1）核心架构"></a>（1）核心架构</h6><ul><li><p><strong>MasterServer</strong>采用分布式无中心设计理念，MasterServer主要负责 DAG 任务切分、任务提交、任务监控，并同时监听其它MasterServer和WorkerServer的健康状态。</p></li><li><p><strong>WorkerServer</strong>也采用分布式无中心设计理念，WorkerServer主要负责任务的执行和提供日志服务。</p></li><li><p><strong>ZooKeeper</strong>服务，系统中的MasterServer和WorkerServer节点都通过ZooKeeper来进行集群管理和容错。</p></li><li><p><strong>Alert</strong>服务，提供告警相关服务。</p></li><li><p><strong>API</strong>接口层，主要负责处理前端UI层的请求。</p></li><li><p><strong>UI</strong>，系统的前端页面，提供系统的各种可视化操作界面。</p></li></ul><h6 id="（2）前置准备"><a href="#（2）前置准备" class="headerlink" title="（2）前置准备"></a>（2）前置准备</h6><ul><li><p>三台节点均需部署JDK（1.8+），并配置相关环境变量。</p></li><li><p>需部署数据库，支持MySQL（5.7+）或者PostgreSQL（8.2.15+）。如 MySQL 则需要 JDBC Driver 8.0.16。</p></li><li><p>需部署Zookeeper（3.4.6+）。</p></li><li><p>如果启用 HDFS 文件系统，则需要 Hadoop（2.6+）环境。</p></li><li><p>三台节点均需安装进程管理工具包psmisc。</p></li></ul><h6 id="（3）配置流程"><a href="#（3）配置流程" class="headerlink" title="（3）配置流程"></a>（3）配置流程</h6><ul><li><p>配置一键部署脚本</p><ul><li><p>修改解压目录下的conf&#x2F;config目录下的install_config.conf文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line">ips=&quot;hadoop102,hadoop103,hadoop104&quot; </span><br><span class="line"># 将要部署任一 DolphinScheduler 服务的服务器主机名或 ip 列表</span><br><span class="line"></span><br><span class="line">masters=&quot;hadoop102&quot; </span><br><span class="line"># master 所在主机名列表，必须是 ips 的子集</span><br><span class="line"></span><br><span class="line">workers=&quot;hadoop102:default,hadoop103:default,hadoop104:default&quot; </span><br><span class="line"># worker主机名及队列，此处的 ip 必须在 ips 列表中</span><br><span class="line"></span><br><span class="line">alertServer=&quot;hadoop102&quot;</span><br><span class="line"># 告警服务所在服务器主机名</span><br><span class="line"></span><br><span class="line">apiServers=&quot;hadoop102&quot;</span><br><span class="line"># api服务所在服务器主机名</span><br><span class="line"></span><br><span class="line">installPath=&quot;/opt/module/dolphinscheduler&quot;</span><br><span class="line"># DS 安装路径，如果不存在会创建</span><br><span class="line"></span><br><span class="line">deployUser=&quot;atguigu&quot;</span><br><span class="line"># 部署用户，任务执行服务是以 sudo -u &#123;linux-user&#125; 切换不同 Linux 用户的方式来实现多租户运行作业，因此该用户必须有免密的 sudo 权限。</span><br><span class="line"></span><br><span class="line">javaHome=&quot;/opt/module/jdk&quot;</span><br><span class="line"># JAVA_HOME 路径</span><br><span class="line"></span><br><span class="line">DATABASE_TYPE=&quot;mysql&quot;</span><br><span class="line"># 数据库类型</span><br><span class="line"></span><br><span class="line">SPRING_DATASOURCE_URL=&quot;jdbc:mysql://hadoop102:3306/dolphinscheduler?useUnicode=true&amp;characterEncoding=UTF-8&quot;</span><br><span class="line"># 数据库 URL</span><br><span class="line"></span><br><span class="line">SPRING_DATASOURCE_USERNAME=&quot;dolphinscheduler&quot;</span><br><span class="line"># 数据库用户名</span><br><span class="line"></span><br><span class="line">SPRING_DATASOURCE_PASSWORD=&quot;dolphinscheduler&quot;</span><br><span class="line"># 数据库密码</span><br><span class="line"></span><br><span class="line">registryPluginName=&quot;zookeeper&quot;</span><br><span class="line"># 注册中心插件名称，DS 通过注册中心来确保集群配置的一致性</span><br><span class="line"></span><br><span class="line">registryServers=&quot;hadoop102:2181,hadoop103:2181,hadoop104:2181&quot;</span><br><span class="line"># 注册中心地址，即 Zookeeper 集群的地址</span><br><span class="line"></span><br><span class="line">registryNamespace=&quot;dolphinscheduler&quot;</span><br><span class="line"># DS 在 Zookeeper 的结点名称</span><br><span class="line"></span><br><span class="line">resourceStorageType=&quot;HDFS&quot;</span><br><span class="line"># 资源存储类型</span><br><span class="line"></span><br><span class="line">resourceUploadPath=&quot;/dolphinscheduler&quot;</span><br><span class="line"># 资源上传路径</span><br><span class="line"></span><br><span class="line">defaultFS=&quot;hdfs://hadoop102:8020&quot;</span><br><span class="line"># 默认文件系统</span><br><span class="line"></span><br><span class="line">resourceManagerHttpAddressPort=&quot;8088&quot;</span><br><span class="line"># yarn RM http 访问端口</span><br><span class="line"></span><br><span class="line">yarnHaIps=</span><br><span class="line"># Yarn RM 高可用 ip，若未启用 RM 高可用，则将该值置空</span><br><span class="line"></span><br><span class="line">singleYarnIp=&quot;hadoop103&quot;</span><br><span class="line"># Yarn RM 主机名，若启用了 HA 或未启用 RM，保留默认值</span><br><span class="line"></span><br><span class="line">hdfsRootUser=&quot;atguigu&quot;</span><br><span class="line"># 拥有 HDFS 根目录操作权限的用户</span><br></pre></td></tr></table></figure></li></ul></li><li><p>初始化数据库</p><ul><li><p>创建数据库</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> DATABASE dolphinscheduler <span class="keyword">DEFAULT</span> <span class="type">CHARACTER</span> <span class="keyword">SET</span> utf8 <span class="keyword">DEFAULT</span> <span class="keyword">COLLATE</span> utf8_general_ci;</span><br></pre></td></tr></table></figure></li><li><p>创建用户</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">USER</span> <span class="string">&#x27;dolphinscheduler&#x27;</span>@<span class="string">&#x27;%&#x27;</span> IDENTIFIED <span class="keyword">BY</span> <span class="string">&#x27;dolphinscheduler&#x27;</span>;</span><br></pre></td></tr></table></figure></li><li><p>赋予用户相应权限</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">GRANT</span> <span class="keyword">ALL</span> PRIVILEGES <span class="keyword">ON</span> dolphinscheduler.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;dolphinscheduler&#x27;</span>@<span class="string">&#x27;%&#x27;</span>;</span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure></li><li><p>拷贝MySQL驱动到DolphinScheduler的解压目录下的lib中</p></li><li><p>执行数据库初始化脚本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">script/create-dolphinscheduler.sh</span><br></pre></td></tr></table></figure></li></ul></li></ul><h6 id="（3）常见启停脚本"><a href="#（3）常见启停脚本" class="headerlink" title="（3）常见启停脚本"></a>（3）常见启停脚本</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">./install.sh  # 一键部署并启动</span><br><span class="line">./bin/start-all.sh  # 启动所有服务（区别于Hadoop）</span><br><span class="line">./bin/stop-all.sh  # 关闭所有服务（区别于Hadoop）</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启停Master</span></span><br><span class="line">./bin/dolphinscheduler-daemon.sh start master-server</span><br><span class="line">./bin/dolphinscheduler-daemon.sh stop master-server</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启停Worker</span></span><br><span class="line">./bin/dolphinscheduler-daemon.sh start worker-server</span><br><span class="line">./bin/dolphinscheduler-daemon.sh stop worker-server</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启停Api</span></span><br><span class="line">./bin/dolphinscheduler-daemon.sh start api-server</span><br><span class="line">./bin/dolphinscheduler-daemon.sh stop api-server</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动Logger</span></span><br><span class="line">./bin/dolphinscheduler-daemon.sh start logger-server</span><br><span class="line">./bin/dolphinscheduler-daemon.sh stop logger-server</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启停Alert</span></span><br><span class="line">./bin/dolphinscheduler-daemon.sh start alert-server</span><br><span class="line">./bin/dolphinscheduler-daemon.sh stop alert-server</span><br></pre></td></tr></table></figure><blockquote><p>对于每个节点的配置在部署后的目录中，针对每个进程都有一个conf文件</p></blockquote><h4 id="11、Superset"><a href="#11、Superset" class="headerlink" title="11、Superset"></a>11、Superset</h4><blockquote><p>强烈斥责Superset的开发人员，兼容性屌差，我曾经尝试过用Docker、Miniconda安装过Superset，但是安装成功的次数寥寥无几，所以在这里着重介绍下。尤其我大一的时候，那时候B站UP主鱼皮还介绍过十分钟搭建Superset，结果放到现在这种方式不太行了（看着官方文档还是可以，但是那个依赖版本维护极差，对小白其实很不友好，尤其当时我还没学数据库），现在Superset最新版都2.0.0+了，不胜唏嘘啊。</p></blockquote><h6 id="（1）安装流程"><a href="#（1）安装流程" class="headerlink" title="（1）安装流程"></a>（1）安装流程</h6><ul><li><p>安装Miniconda</p></li><li><p>创建虚拟环境</p><ul><li>配置conda国内镜像</li><li>创建<strong>Python3.8</strong>环境</li></ul></li><li><p>安装依赖</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install -y gcc gcc-c++ libffi-devel python-devel python-pip python-wheel python-setuptools openssl-devel cyrus-sasl-devel openldap-devel</span><br></pre></td></tr></table></figure></li><li><p>安装（更新）setuptools和pip</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install --upgrade setuptools pip -i https://pypi.douban.com/simple/</span><br></pre></td></tr></table></figure></li><li><p>指定安装版本：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install apache-superset==1.4.2 -i https://pypi.douban.com/simple/</span><br></pre></td></tr></table></figure></li><li><p>依赖降级：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">pip uninstall werkzeyg</span><br><span class="line">pip uninstall markupsafe</span><br><span class="line">pip install markupsafe==2.0.1</span><br><span class="line">pip install flask==1.1.2</span><br><span class="line">pip install Werkzeug==1.0.1</span><br><span class="line">pip install --upgrade cryptography==3.2</span><br></pre></td></tr></table></figure></li><li><p>初始化数据库之前先执行：export FLASK_APP&#x3D;superset</p></li><li><p>初始化Superset</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">superset db upgrade</span><br></pre></td></tr></table></figure></li><li><p>安装gunicorn</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install gunicorn -i https://pypi.douban.com/simple/</span><br></pre></td></tr></table></figure></li></ul><h6 id="（2）常见启停脚本-3"><a href="#（2）常见启停脚本-3" class="headerlink" title="（2）常见启停脚本"></a>（2）常见启停脚本</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">gunicorn --workers 5 --timeout 120 --bind hadoop102:8787  &quot;superset.app:create_app()&quot; --daemon</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动Superset</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">workers：指定进程个数</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">timeout</span>：worker进程超时时间，超时会自动重启</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">bind</span>：绑定本机地址，即为Superset访问地址</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">daemon：后台运行</span></span><br></pre></td></tr></table></figure><h6 id="（3）安装MySQL依赖项"><a href="#（3）安装MySQL依赖项" class="headerlink" title="（3）安装MySQL依赖项"></a>（3）安装MySQL依赖项</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install mysqlclient</span><br></pre></td></tr></table></figure><p><strong>对接不同的数据源，需安装不同的依赖，以下地址为官网说明。</strong></p><p><a href="https://superset.apache.org/docs/databases/installing-database-drivers">https://superset.apache.org/docs/databases/installing-database-drivers</a></p>]]></content>
      
      
      <categories>
          
          <category> Little Tips </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> 大数据组件 </tag>
            
            <tag> 数据仓库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>22腾讯音乐暑期实习海笔复盘</title>
      <link href="/2023/03/23/%E8%85%BE%E8%AE%AF%E9%9F%B3%E4%B9%90%E6%B5%B7%E7%AC%94%E5%A4%8D%E7%9B%98/"/>
      <url>/2023/03/23/%E8%85%BE%E8%AE%AF%E9%9F%B3%E4%B9%90%E6%B5%B7%E7%AC%94%E5%A4%8D%E7%9B%98/</url>
      
        <content type="html"><![CDATA[<p>今天进行了腾讯音乐的数据工程海笔，一个都没写出来真的臊得慌。趁着还记得来进行一下简单的复盘。</p><p>首先数据工程和前后端的试题都不同，前后端是3+1，三个算法+一个结构性思维题；数据工程是2+1+2，两个SQL题+一个算法题+两个组件的结构性思维题。两个SQL其实比较简单，但是我SQL并没有想象中的熟练，且听说ac机有点点怪（这不是主要原因），所以没有写出来。题目不太好描述，所以后续搜集到了题目会进行更新。算法是个dfs算法，我算法也不强，想到了递归、想到了指针但是没想到dfs，真该死。。。</p><p>两个组件的题也是，简单描述下就是：</p><ul><li>手写Kafka消费者工程代码，写一个固定格式的5分钟定时消费的代码</li><li>flume<ul><li>维护一个实时排序用什么算法？手写关键代码</li><li>遇到海量数据时flume背压了，可能的情况和解决方案？</li><li>结合存储和性能给出的调优、选择方案</li></ul></li></ul><p>很遗憾，我这两个组件的面经都没背，甚至于flume都没有学，所以最后半小时在那一个字都憋不出。下面就对这个算法进行简单复盘。</p><h4 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h4><p>给定一个字符串和一个字符串数组，输出所有能用字符串数组拼接成字符串的情况。数组中的字符串可重复使用。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">例1：</span><br><span class="line">输入：String s = &quot;nowcoder&quot;; String[] arr = &#123;&quot;now&quot;, &quot;coder&quot;, &quot;no&quot;, &quot;wcoder&quot;&#125;;</span><br><span class="line">输出：&#123;&quot;now coder&quot;, &quot;no wcoder&quot;&#125;</span><br><span class="line"></span><br><span class="line">例2：</span><br><span class="line">输入：String s = &quot;nownowcoder&quot;; String[] arr = &#123;&quot;now&quot;, &quot;coder&quot;, &quot;no&quot;, &quot;wcoder&quot;&#125;;</span><br><span class="line">输出：&#123;&quot;now now coder&quot;, &quot;now no wcoder&quot;&#125;</span><br><span class="line"></span><br><span class="line">例3：</span><br><span class="line">输入：String s = &quot;nowcoder&quot;; String[] arr = &#123;&quot;nowcoder&quot;&#125;;</span><br><span class="line">输出：&#123;&quot;nowcoder&quot;&#125;</span><br><span class="line"></span><br><span class="line">例4：</span><br><span class="line">输入：String s = &quot;nowcoder&quot;; String[] arr = &#123;&quot;now&quot;, &quot;wcoder&quot;&#125;;</span><br><span class="line">输出：&#123;&#125;</span><br></pre></td></tr></table></figure><p>为了显著提高我自己的技术，以后的算法笔记采用双版本进行书写。</p><p>Java版本：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Main</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">Solution</span> <span class="variable">s</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Solution</span>();</span><br><span class="line">        <span class="type">String</span> <span class="variable">s1</span> <span class="operator">=</span> <span class="string">&quot;nowcoder&quot;</span>;</span><br><span class="line">        String[] s2 = &#123;<span class="string">&quot;now&quot;</span>, <span class="string">&quot;coder&quot;</span>, <span class="string">&quot;no&quot;</span>, <span class="string">&quot;wcoder&quot;</span>&#125;;</span><br><span class="line">        String[] s3 = s.maxIn(s1, s2);</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; s3.length; i++) &#123;</span><br><span class="line">            System.out.println(s3[i]);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line">    List&lt;String&gt; res = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">    String a;</span><br><span class="line">    String[] ss;</span><br><span class="line">    <span class="keyword">public</span> String[] maxIn(String s, String[] arr) &#123;</span><br><span class="line">        a = s;</span><br><span class="line">        ss = arr;</span><br><span class="line">        dfs(<span class="number">0</span>, <span class="string">&quot;&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> res.toArray(<span class="keyword">new</span> <span class="title class_">String</span>[res.size()]);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">dfs</span><span class="params">(<span class="type">int</span> parm, String s)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (parm &gt;= a.length()) res.add(s);</span><br><span class="line">        <span class="keyword">if</span> (parm &lt; a.length()) &#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; ss.length; i++) &#123;</span><br><span class="line">                <span class="type">int</span> <span class="variable">len</span> <span class="operator">=</span> parm + ss[i].length();</span><br><span class="line">                <span class="keyword">if</span>(len &lt;= a.length() &amp;&amp; a.substring(parm, len).equals(ss[i]))&#123;</span><br><span class="line">                    <span class="keyword">if</span>(parm == <span class="number">0</span>) dfs(len, ss[i]);</span><br><span class="line">                    <span class="keyword">else</span> dfs(len, s + <span class="string">&quot; &quot;</span> + ss[i]);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Scala版本：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.collection.mutable.<span class="type">ArrayBuffer</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> s: <span class="type">Solution</span> = <span class="keyword">new</span> <span class="type">Solution</span></span><br><span class="line">    <span class="keyword">val</span> s1: <span class="type">String</span> = <span class="string">&quot;nownowcoder&quot;</span></span><br><span class="line">    <span class="keyword">val</span> s2: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(<span class="string">&quot;now&quot;</span>, <span class="string">&quot;coder&quot;</span>, <span class="string">&quot;no&quot;</span>, <span class="string">&quot;wcoder&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> s3: <span class="type">Array</span>[<span class="type">String</span>] = s.maxIn(s1, s2)</span><br><span class="line">    <span class="keyword">for</span> (i &lt;- s3.indices) &#123;</span><br><span class="line">      println(s3(i))</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> res = <span class="type">ArrayBuffer</span>[<span class="type">String</span>]()</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> a: <span class="type">String</span> = <span class="literal">null</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> ss: <span class="type">Array</span>[<span class="type">String</span>] = <span class="literal">null</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">maxIn</span></span>(s: <span class="type">String</span>, arr: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Array</span>[<span class="type">String</span>] = &#123;</span><br><span class="line">    a = s</span><br><span class="line">    ss = arr</span><br><span class="line">    dfs(<span class="number">0</span>, <span class="string">&quot;&quot;</span>)</span><br><span class="line">    res.toArray</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">dfs</span></span>(param: <span class="type">Int</span>, s: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (param &gt;= a.length) res += s</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (param &lt; a.length) <span class="keyword">for</span> (i &lt;- ss.indices) &#123;</span><br><span class="line">      <span class="keyword">val</span> len: <span class="type">Int</span> = param + ss(i).length</span><br><span class="line">      <span class="keyword">if</span> (len &lt;= a.length &amp;&amp; a.substring(param, len) == ss(i)) &#123;</span><br><span class="line">        <span class="keyword">if</span> (param == <span class="number">0</span>) dfs(len, ss(i))</span><br><span class="line">        <span class="keyword">else</span> dfs(len, s + <span class="string">&quot; &quot;</span> + ss(i))</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>友人提供的C++版本</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line">string s;</span><br><span class="line"><span class="type">int</span> n;</span><br><span class="line">vector &lt;string&gt; v;</span><br><span class="line">vector &lt;vector&lt;string&gt;&gt; ans;</span><br><span class="line"><span class="type">int</span> st[<span class="number">30</span>];</span><br><span class="line"><span class="type">int</span> len;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">getAns</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    vector &lt;string&gt; vi;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; len; i++) &#123;</span><br><span class="line">        vi.<span class="built_in">push_back</span>(v[st[i]]);</span><br><span class="line">    &#125;</span><br><span class="line">    ans.<span class="built_in">push_back</span>(vi);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">dfs</span><span class="params">(<span class="type">int</span> p)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (p == s.<span class="built_in">size</span>()) &#123;</span><br><span class="line">        <span class="built_in">getAns</span>();</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">        <span class="type">int</span> pi = p;</span><br><span class="line">        <span class="type">int</span> si = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span> (pi &lt; s.<span class="built_in">size</span>() &amp;&amp; si &lt; v[i].<span class="built_in">size</span>() &amp;&amp; s[pi] == v[i][si]) &#123;</span><br><span class="line">            pi++;</span><br><span class="line">            si++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (si &gt;= v[i].<span class="built_in">size</span>()) &#123;</span><br><span class="line">            st[len++] = i;</span><br><span class="line">            <span class="built_in">dfs</span>(pi);</span><br><span class="line">            len--;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    cin &gt;&gt; s;</span><br><span class="line">    cin &gt;&gt; n;</span><br><span class="line">    v.<span class="built_in">resize</span>(n);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">        cin &gt;&gt; v[i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">dfs</span>(<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; ans.<span class="built_in">size</span>(); i++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; ans[i].<span class="built_in">size</span>(); j++) &#123;</span><br><span class="line">            cout &lt;&lt; ans[i][j] &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        cout &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Little Tips </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 腾讯 </tag>
            
            <tag> 笔试 </tag>
            
            <tag> 算法 </tag>
            
            <tag> DFS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大数据入门《大数据之路：阿里巴巴大数据实践》</title>
      <link href="/2023/03/20/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A8%E3%80%8A%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%9A%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E8%B7%B5%E3%80%8B/"/>
      <url>/2023/03/20/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A8%E3%80%8A%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%9A%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E8%B7%B5%E3%80%8B/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>前言：</strong></p><p>简单看完了第一遍写的前言，大数据真的是一门需要知识沉淀的巨大工程，无论你看什么类型的书，对于大数据的理解都是有帮助的。这本主要是阿里系的大数据开发全套，很浅但是很真诚（当然指的是技术面很浅，思想上已经很深入了）。截至现在，我也就体验过阿里系的DataX（开源），确实解决了不同数据源之间数据结构不同步的痛点，未来肯定依旧会做大做强，咳咳扯远了。</p><p>这绝对是一本值得N刷的书，奉之为教材也不为过，虽然对接的是阿里系的企业理念，但是对于整体开发流程的阐述十分到位，尤其是第十章、十一章关于维度设计和事实表设计，让我受益匪浅，希望你也能有所收获。——Alexie-Z-Yevich 2023.3.20</p></blockquote><h2 id="第一章-总述"><a href="#第一章-总述" class="headerlink" title="第一章 总述"></a>第一章 总述</h2><p>IT时代是以自我控制、自我管理为主，那么到了DT(Data Technology) 时代，则是以服务大众、激发生产力为主。以互联网（或者物联网）、云计算、大数据和人工智能为代表的新技术革命正在渗透至各行各业，悄悄地改变着我们的生活。</p><h4 id="1、阿里巴巴大数据系统体系架构图"><a href="#1、阿里巴巴大数据系统体系架构图" class="headerlink" title="1、阿里巴巴大数据系统体系架构图"></a>1、阿里巴巴大数据系统体系架构图</h4><p><img src="/2023/03/20/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A8%E3%80%8A%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%9A%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E8%B7%B5%E3%80%8B/1.1.png"></p><h4 id="2、应用四大层次"><a href="#2、应用四大层次" class="headerlink" title="2、应用四大层次"></a>2、应用四大层次</h4><h6 id="（1）数据采集层"><a href="#（1）数据采集层" class="headerlink" title="（1）数据采集层"></a>（1）数据采集层</h6><p>Aplus.JS是Web端日志采集技术方案；UserTrack是APP端日志采集技术方案。在传输方面，采用TimeTunnel (TT），它既包括数据库的增量数据传输，也包括日志数据的传输；TT作为数据传输服务的基础架构，既支持实时流式计算，也支持各种时间窗口的批量计算。另外，也通过数据同步工具直连异构数据库（备库）来抽取各种时间窗口的数据。</p><h6 id="（2）数据计算层"><a href="#（2）数据计算层" class="headerlink" title="（2）数据计算层"></a>（2）数据计算层</h6><p>数据只有被整合和计算，才能被用于洞察商业规律，挖掘潜在信息，从而实现大数据价值，达到赋能于商业和创造价值的目的。从采集系统中收集到的大量原始数据，将进入数据计算层中被进一步整合与计算。</p><p>数据存储及计算云平台（离线计算平台MaxCompute和实时计算平台StreamCompute）和数据整合及管理体系（内部称之为“OneData”）。</p><p>阿里数据仓库的数据加工链路也是遵循业界的分层理念，包括操作数据层（OperationalData Store, ODS）、明细数据层（DataWa rehouse Detail, DWD）、汇总数据层（DataWarehouse Summary, DWS）和应用数据层（ApplicationData Store, ADS）。通过数据仓库不同层次之间的加工过程实现从数据资产向信息资产的转化，并且对整个过程进行有效的元数据管理及数据质量处理。</p><h6 id="（3）数据服务层"><a href="#（3）数据服务层" class="headerlink" title="（3）数据服务层"></a>（3）数据服务层</h6><p>当数据已被整合和计算好之后，需要提供给产品和应用进行数据消费。针对不同的需求，数据服务层的数据源架构在多种数据库之上，如MySQL和HBase等。</p><p>数据服务可以使应用对底层数据存储透明，将海量数据方便高效地放给集团内部各应用使用。数据服务层对外提供数据服务主要是通过统一的数据服务平台。OneService以数据仓库整合计算好的数据作为数据源，对外通过接口的方式提供数据服务，主要提供简单数据查询服务、复杂数据查询服务（承接集团用户识别、用户画像等复杂数据查询服务）和实时数据推送服务三大特色数据服务。</p><h6 id="（4）数据应用层"><a href="#（4）数据应用层" class="headerlink" title="（4）数据应用层"></a>（4）数据应用层</h6><p>数据已经准备好，需要通过合适的应用提供给用户，让数据最大化地发挥价值。数据作为新能源，为产业注人的变革是显而易见的。我们对数据新能源的探索也不仅仅停留在狭义的技术、服务和应用上。我们正在挖掘大数据更深层次的价值，为社会经济和民生基础建设等提供创新方法。</p><hr><h2 id="第二章-日志采集"><a href="#第二章-日志采集" class="headerlink" title="第二章 日志采集"></a>第二章 日志采集</h2><h4 id="1、浏览器的页面日志采集"><a href="#1、浏览器的页面日志采集" class="headerlink" title="1、浏览器的页面日志采集"></a>1、浏览器的页面日志采集</h4><h6 id="（1）页面浏览（展现）日志采集"><a href="#（1）页面浏览（展现）日志采集" class="headerlink" title="（1）页面浏览（展现）日志采集"></a>（1）页面浏览（展现）日志采集</h6><p>最基础的互联网日志，也是目前所有互联网产品的两大基本指标：页面浏览量（PageView, PV）和访客数（UniqueVisitors, UV）的统计基础。页面浏览日志是目前成熟度和完备度最高，同时也是最具挑战性的日志来集任务。</p><ul><li>流程<ul><li>在HTML文档内的适当位置增加一个日志采集节点，当浏览器解析到这个节点时，将自动触发一个特定的HTTP请求到日志采集服务器。如此一来，当日志采集服务器接收到这个请求时，就可以确定浏览器已经成功地接收和打开了页面。</li><li><img src="/2023/03/20/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A8%E3%80%8A%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%9A%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E8%B7%B5%E3%80%8B/2.1.png"></li></ul></li><li>主要过程<ul><li>客户端日志采集：日志采集工作一般由一小段被植人页面HTML文档内的JavaScript脚本来执行。采集脚本被浏览器加载解析后执行，在执行时采集当前页面参数、浏览行为的上下文信息（如读取用户访问当前页面时的上一步页面）以及一些运行环境信息（如当前的浏览器和分辨率等）。</li><li>客户端日志发送：采集脚本执行时，会向日志服务器发起一个日志请求，以将采集到的数据发送到日志服务器。</li><li>服务器端日志采集。</li><li>服务器端日志解析存档：服务器接收到的浏览日志进人缓冲区后，会被一段专门的日志处理程序顺序读出并按照约定的日志处理逻辑解析。</li></ul></li></ul><h6 id="（2）页面交互日志采集"><a href="#（2）页面交互日志采集" class="headerlink" title="（2）页面交互日志采集"></a>（2）页面交互日志采集</h6><p>当页面加载和渲染完成之后，用户可以在页面上执行各类操作。互动设计都要求采集用户的互动行为数据，以便通过量化获知用户的兴趣点或者体验优化点。交互日志采集就是为此类业务场景而生的。</p><ul><li>“黄金令箭”采集方案：基于HTTP协议的日志服务<ul><li>业务方在“黄金令箭”的元数据管理界面依次注册需要采集交互日志的业务、具体的业务场景以及场景下的具体交互采集点，在注册完成之后，系统将生成与之对应的交互日志来集代码模板。</li><li>业务方将交互日志采集代码植入目标页面，并将采集代码与需要监测的交互行为做绑定。</li><li>当用户在页面上产生指定行为时，采集代码和正常的业务互动响应代码一起被触发和执行。</li><li>采集代码在采集动作完成后将对应的日志通过HTTP协议发送到日志服务器，日志服务器接收到日志后原则上不做解析处理，只做简单的转储。</li></ul></li></ul><h6 id="（3）服务器端清洗和预处理"><a href="#（3）服务器端清洗和预处理" class="headerlink" title="（3）服务器端清洗和预处理"></a>（3）服务器端清洗和预处理</h6><ul><li>识别流量攻击、网络爬虫和流量作弊（虚假流量）<ul><li>需要对所采集的日志进行合法性校验，依托算法识别非正常的流量并归纳出对应的过滤规则集加以滤除。这是一个长期而艰苦的对抗过程。</li></ul></li><li>数据缺项补正<ul><li>大多数情况下，需要对日志中的一些公用且重要的数据项做取值归一、标准化处理或反向补正。反向补正，即根据新日志对稍早收集的日志中的个别数据项做回补或修订。</li></ul></li><li>无效数据剔除<ul><li>定时检查配置并依照配置将因业务变更或配置不当，在采集到的日志中会存在一些无意义、已经失效或者冗余的数据项剔除。</li></ul></li><li>日志隔离分发<ul><li>基于数据安全或者业务特性的考虑，某些日志在进入公共数据环境之前需要做隔离。</li></ul></li></ul><h4 id="2、无线客户端的日志采集"><a href="#2、无线客户端的日志采集" class="headerlink" title="2、无线客户端的日志采集"></a>2、无线客户端的日志采集</h4><p>无线客户端的日志采集采用采集SDK来完成，在阿里巴巴内部，多使用名为UserTrack的SDK来进行无线客户端的日志采集。</p><p>基于常规的分析，UserTrack (UT）把事件分成了几类，常用的包括页面事件（同前述的页面浏览）和控件点击事件（同前述的页面交互）等。</p><p>在阿里系内，使用SPM(Super Position Model ，超级位置模型）进行来源去向的追踪，在无线客户端也同样使用SPM，SPM信息就可以通过透传机制带人到下一步甚至下下一步的浏览页面，这样整个用户行为路径还原就轻松实现了。</p><h6 id="特殊场景"><a href="#特殊场景" class="headerlink" title="特殊场景"></a>特殊场景</h6><p>为了平衡日志大小，减小流量消耗、采集服务器压力、网络传输压力等，采集SDK提供了聚合功能，对某些场景如曝光或一些性能技术类日志，我们提倡在客户端对这类日志进行适当聚合，以减少对日志采集服务器端的请求，适当减小日志大小。总体思路就是每个曝光的元素一般都属于一个页面，利用页面的生命周期来实现适当的聚合及确定发送时机。</p><h6 id="日志传输"><a href="#日志传输" class="headerlink" title="日志传输"></a>日志传输</h6><p>无线客户端日志的上传，不是产生一条日志上传一条，而是无线客户端产生日志后，先存储在客户端本地，然后再伺机上传。</p><p>客户端数据上传时是向服务器发送POST请求，服务器端处理上传请求，对请求进行相关校验，将数据追加到本地文件中进行存储，存储方式使用Nginx的access_log，access_log的切分维度为天，即当天接收的日志存储到当天的日志文件中。考虑到后续的数据处理，以及特殊时期不同日志的保障级别，还对日志进行了分流。</p><h4 id="3、日志处理"><a href="#3、日志处理" class="headerlink" title="3、日志处理"></a>3、日志处理</h4><h6 id="（1）日志分流和定制处理"><a href="#（1）日志分流和定制处理" class="headerlink" title="（1）日志分流和定制处理"></a>（1）日志分流和定制处理</h6><p>大型互联网网站的日志类型和日志规模都呈现出高速增长的态势，而且往往会出现短时间的流量热点爆发。这一特点，使得在日志服务器端采用集中统一的解析处理方案变得不可能，其要求在日志解析和处理过程中必须考虑业务分流（、日志优先级控制，以及根据业务特点实现定制处理。</p><h6 id="（2）采集与计算一体化设计"><a href="#（2）采集与计算一体化设计" class="headerlink" title="（2）采集与计算一体化设计"></a>（2）采集与计算一体化设计</h6><p>日志采集方案必须将来集与计算作为一个系统来考量，进行一体化设计。在当前的互联网环境下，互联网日志的规模化采集方案必须具备一个与终端设备的技术特点无关，具有高度扩展弹性和适应性，同时深入契合应用需求的业务逻辑模型，并基于此制定对应的采集规范交由产品开发人员执行。</p><h6 id="（3）数据处理全链路"><a href="#（3）数据处理全链路" class="headerlink" title="（3）数据处理全链路"></a>（3）数据处理全链路</h6><p><img src="/2023/03/20/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A8%E3%80%8A%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%9A%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E8%B7%B5%E3%80%8B/2.2.png"></p><hr><h2 id="第三章-数据同步"><a href="#第三章-数据同步" class="headerlink" title="第三章 数据同步"></a>第三章 数据同步</h2><p>数据同步需要针对不同的数据类型及业务场景选择不同的同步方式。总的来说，同步方式可以分为三种：直连同步、数据文件同步和数据库日志解析同步。</p><h4 id="1、直连同步"><a href="#1、直连同步" class="headerlink" title="1、直连同步"></a>1、直连同步</h4><p>直连同步是指通过定义好的规范接口API和基于动态链接库的方式直接连接业务库，如ODBC&#x2F;JDBC等规定了统一规范的标准接口（驱动）</p><ul><li>配置简单，实现容易</li><li>适合操作型业务系统的数据同步</li><li>业务库直连的方式对源系统的性能影响较大，当执行大批量数据同步时会降低甚至拖垮业务系统的性能（主备策略-学校二课服务器就是这种同步方式）</li></ul><h4 id="2、数据文件同步"><a href="#2、数据文件同步" class="headerlink" title="2、数据文件同步"></a>2、数据文件同步</h4><p>数据文件同步通过约定好的文件编码、大小、格式等，直接从源系统生成数据的文本文件，由专门的文件服务器，如FTP服务器传输到目标系统后，加载到目标数据库系统中。</p><ul><li>主要存储日志类（文本文件）数据</li><li>异构数据源（多台数据库）采用这种策略</li><li>上传下载容易造成丢包或错误，需要额外发送校验文件</li></ul><h4 id="3、数据库日志解析同步"><a href="#3、数据库日志解析同步" class="headerlink" title="3、数据库日志解析同步"></a>3、数据库日志解析同步</h4><p>数据文件被传输到目标系统后，可通过数据加载模块完成数据的导人，从而实现数据从源系统到目标系统的同步。（通过TCP&#x2F;IP协议）</p><ul><li>实时与准实时同步的能力（延迟低）</li><li>对业务系统的性能影响也比较小</li></ul><h6 id="删除数据变更的三种同步方式"><a href="#删除数据变更的三种同步方式" class="headerlink" title="删除数据变更的三种同步方式"></a>删除数据变更的三种同步方式</h6><ul><li>不过滤删除流水。不管是否是删除操作，都获取同一主键最后变更的那条流水。</li><li>过滤最后一条删除流水。如果同一主键最后变更的那条流水是删除操作，就获取倒数第二条流水。</li><li>过滤删除流水和之前的流水。如果在同一主键变更的过程中有删除操作，则根据操作时间将该删除操作对应的流水和之前的流水都过滤掉。</li></ul><h6 id="存在的问题"><a href="#存在的问题" class="headerlink" title="存在的问题"></a>存在的问题</h6><ul><li>数据延迟。</li><li>投人较大。</li><li>数据漂移和遗漏。（数据漂移，一般是对增量表而言的，通常是指该表的同一个业务日期数据中包含前一天或后一天凌晨附近的数据或者丢失当天的变更数据。）</li></ul><h4 id="4、阿里数仓的同步策略"><a href="#4、阿里数仓的同步策略" class="headerlink" title="4、阿里数仓的同步策略"></a>4、阿里数仓的同步策略</h4><h6 id="（1）批量数据同步"><a href="#（1）批量数据同步" class="headerlink" title="（1）批量数据同步"></a>（1）批量数据同步</h6><p>先将数据转换为中间状态，统一数据格式。由于这类数据都是结构化的，且均支持标准的SQL语言查询，所以所有的数据类型都可以转换为字符串类型。因此，我们可以通过将各类源数据库系统的数据类型统一转换为字符串类型的方式，实现数据格式的统一。</p><p>阿里巴巴的DataX就是这样一个能满足多方向高自由度的异构数据交换服务产品。对于不同的数据源，DataX通过插件的形式提供支持，将数据从数据源读出并转换为中间状态，同时维护好数据的传输、缓存等工作。</p><p><img src="/2023/03/20/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A8%E3%80%8A%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%9A%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E8%B7%B5%E3%80%8B/3.1.png"></p><p>DataX采用Framework+Plugin的开放式框架实现，Framework处理缓冲、流程控制、并发、上下文加载等高速数据交换的大部分技术问题，并提供简单的接口与插件接入。</p><h6 id="（2）实时数据同步"><a href="#（2）实时数据同步" class="headerlink" title="（2）实时数据同步"></a>（2）实时数据同步</h6><p>通过解析MySQL的binlog日志（相当于Oracle的归档日志）来实时获得增量的数据更新，并通过消息订阅模式来实现数据的实时同步的。具体来说，就是建立一个日志数据交换中心，通过专门的模块从每台服务器源源不断地读取日志数据，或者解析业务数据库系统的binlog或归档日志，将增量数据以数据流的方式不断同步到日志交换中心，然后通知所有订阅了这些数据的数据仓库系统来获取。</p><p>TimeTunnel（TT）是一种基于生产者、消费者和Topic消息标识的消息中间件，将消息数据持久化到HBase的高可用、分布式数据交互系统。</p><h4 id="5、数据同步遇到的问题和解决办法"><a href="#5、数据同步遇到的问题和解决办法" class="headerlink" title="5、数据同步遇到的问题和解决办法"></a>5、数据同步遇到的问题和解决办法</h4><h6 id="（1）分库分表的处理"><a href="#（1）分库分表的处理" class="headerlink" title="（1）分库分表的处理"></a>（1）分库分表的处理</h6><p>阿里巴巴的TDDL( Taobao Distributed  Data Layer）是一个具备将分布在不同数据库中的不同表集成为一个表的能力，能让下游应用像访问单库单表一样方便的分布式数据库的访问引擎，通过建立中间状态的逻辑表来整合统一分库分表的访问。</p><h6 id="（2）高效同步和批量同步"><a href="#（2）高效同步和批量同步" class="headerlink" title="（2）高效同步和批量同步"></a>（2）高效同步和批量同步</h6><p>阿里巴巴OneClick产品：</p><ul><li>对不同数据源的数据同步配置透明化，可以通过库名和表名唯一定位，通过IDB接口获取元数据信息自动生成配置信息。</li><li>简化了数据同步的操作步骤，实现了与数据同步相关的建表、配置任务、发布、测试操作一键化处理，并且封装成Web接口进一步达到批量化的效果。</li><li>降低了数据同步的技能门槛，让数据需求方更加方便地获取和使用数据。</li></ul><p>真正实现了数据的一键化和批量化同步，一键完成DDL和DML的生成、数据的冒烟测试以及在生产环境中测试等。</p><h6 id="（3）增量和全量同步的合并"><a href="#（3）增量和全量同步的合并" class="headerlink" title="（3）增量和全量同步的合并"></a>（3）增量和全量同步的合并</h6><p>在传统的数据整合方案中，合并技术大多采用merge方式( update+insert）：当前流行的大数据平台基本都不支持update操作，现在我们比较推荐的方式是<strong>全外连接（full outer join)＋数据全量覆盖重新加载（insert overwrite），即如日调度</strong>，则将当天的增量数据和前一天的全量数据做全外连接，重新加载最新的全量数据。在大数据量规模下，全量更新的性能比update要高得多。此外，如果担心数据更新错误问题，可以采用分区方式，每天保持一个最新的全量版本，保留较短的时间周期（如3～7天）。</p><p>另外，当业务系统的表有物理删除数据的操作，而数据仓库需要保留所有历史数据时，也可以选择这种方式，在数据仓库中永久保留最新的全量数据快照。</p><h6 id="（4）基于负载均衡思想的新型数据同步方案"><a href="#（4）基于负载均衡思想的新型数据同步方案" class="headerlink" title="（4）基于负载均衡思想的新型数据同步方案"></a>（4）基于负载均衡思想的新型数据同步方案</h6><p>核心思想是通过目标数据库的元数据估算同步任务的总线程数，以及通过系统预先定义的期望同步速度估算首轮同步的线程数，同时通过数据同步任务的业务优先级决定同步线程的优先级，最终提升同步任务的执行效率和稳定性。</p><ul><li>用户创建数据同步任务，并提交该同步任务。</li><li>根据系统提前获知及设定的数据，估算该同步任务需要同步的数据量、平均同步速度、首轮运行期望的线程数、需要同步的总线程数。</li><li>根据需要同步的总线程数将待同步的数据拆分成相等数量的数据块，一个线程处理一个数据块，并将该任务对应的所有线程提交至同步控制器。</li><li>同步控制器判断需要同步的总线程数是否大于首轮运行期望的线程数，若大于，则跳转至2；若不大于，则跳转至5。</li><li>同步控制器采用多机多线程的数据同步模式，准备该任务第一轮线程的调度，优先发送等待时间最长、优先级最高且同一任务的线程。</li><li>同步控制器准备一定数据量（期望首轮线程数－总线程数）的虚拟线程，采用单机多线程的数据同步模式，准备该任务相应实体线程和虚拟线程的调度，优先发送等待时间最长、优先级最高且单机CPU剩余资源可以支持首轮所有线程数且同一任务的线程，如果没有满足条件的机器，则选择CPU剩余资源最多的机器进行首轮发送。</li><li>数据任务开始同步，并等待完成。</li><li>数据任务同步结束。</li></ul><h6 id="（5）数据漂移的处理"><a href="#（5）数据漂移的处理" class="headerlink" title="（5）数据漂移的处理"></a>（5）数据漂移的处理</h6><p>数据漂移是ODS数据（从源系统同步进入数据仓库的第一层数据称为ODS或者staging层数据，阿里巴巴统称为ODS）的一个顽疾，通常是指ODS表的同一个业务日期数据中包含前一天或后一天凌晨附近的数据或者丢失当天的变更数据。</p><p>无论根据哪一个单一时间戳获取数据，都有可能导致数据漂移，处理方法如下：</p><ul><li>多获取后一天的数据，保障数据只多不少（但是会存在一定的数据误差）</li><li>通过多个时间戳字段限制时间来获取相对准确的数据（限制时间范围，做全外连接回补数据）</li></ul><hr><h2 id="第四章-离线数据开发"><a href="#第四章-离线数据开发" class="headerlink" title="第四章 离线数据开发"></a>第四章 离线数据开发</h2><h4 id="1、数据开发平台"><a href="#1、数据开发平台" class="headerlink" title="1、数据开发平台"></a>1、数据开发平台</h4><p>阿里数据研发岗位的工作大致可以概括为：了解需求→模型设计→ETL开发→测试→发布上线→日常运维→任务下线。相较于传统数仓开发（ETL），有以下特点：</p><ul><li>业务变更频繁</li><li>需要快速交付</li><li>频繁发布上线</li><li>运维任务多</li><li>系统环境复杂</li></ul><h6 id="（1）统一计算平台"><a href="#（1）统一计算平台" class="headerlink" title="（1）统一计算平台"></a>（1）统一计算平台</h6><p>大数据计算服务MaxCompute是由阿里云自主研发的海量数据处理平台，主要服务于海量数据的存储和计算，提供完善的数据导入方案，以及多种经典的分布式计算模型，提供海量数据仓库的解决方案，能够更快速地解决用户的海量数据计算问题，有效降低企业成本，并保障数据安全。</p><p>MaxCompute采用抽象的作业处理框架，将不同场景的各种计算任务统一在同一个平台之上，共享安全、存储、数据管理和资源调度，为来自不同用户需求的各种数据处理任务提供统一的编程接口和界面。它提供数据上传／下载通道、SQL、MapReduce、机器学习算法、图编程模型和流式计算模型多种计算分析服务，并且提供完善的安全解决方案。</p><p><img src="/2023/03/20/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A8%E3%80%8A%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%9A%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E8%B7%B5%E3%80%8B/4.1.png"></p><p>MaxCompute特点：</p><ul><li><p>计算性能高且更加普惠</p></li><li><p>集群规模大且稳定性高</p></li><li><p>功能组件非常强大</p><ul><li>MaxCompute SQL：标准SQL的语法，提供各类操作和函数来处理数据。</li><li>MaxCompute MapReduce：提供JavaMapReduce编程模型，通过接口编写MR程序处理MaxCompute中的数据。还提供基于MapReduce的扩展模型MR2，在该模型下，一个Map函数后可以接人连续多个Reduce函数，执行效率比普通的MapReduce模型高。</li><li>MaxCompute Graph ：面向迭代的图计算处理框架，典型应用有PageRank、单源最短距离算法、K-均值聚类算法。</li><li>Spark：使用Spark接口编程处理存储在MaxCompute中的数据。</li><li>RMaxCompute：使用R处理MaxCompute中的数据。</li><li>Volume: MaxCompute以Volume的形式支持文件，管理非二维表数据。</li></ul></li><li><p>安全性高</p></li></ul><h6 id="（2）统一开发平台"><a href="#（2）统一开发平台" class="headerlink" title="（2）统一开发平台"></a>（2）统一开发平台</h6><p>数据研发人员完成需求了解和模型设计之后，进入开发环节，开发工作流如下：</p><p><img src="/2023/03/20/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A8%E3%80%8A%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%9A%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E8%B7%B5%E3%80%8B/4.2.png"></p><ul><li><p>在云端（D2）</p><ul><li>D2是集成任务开发、调试及发布，生产任务调度及大数据运维，数据权限申请及管理等功能的一站式数据开发平台，并能承担数据分析工作台的功能。</li></ul></li><li><p>SQLSCAN</p><ul><li>SQLSCAN将在任务开发中遇到的各种问题，如用户编写的SQL质量差、性能低、不遵守规范等，总结后形成规则，并通过系统及研发流程保障，事前解决故障隐患，避免事后处理。</li><li>三类规则校验<ul><li>代码规范类规则，如表命名规范、生命周期设置、表注释等。</li><li>代码质量类规则，如调度参数使用检查、分母为0提醒、NULL值参与计算影响结果提醒、插入字段顺序错误等。</li><li>代码性能类规则，如分区裁剪失效、扫描大表提醒、重复计算检测等。</li></ul></li></ul></li><li><p>DQC</p><ul><li>DQC (Data Quality Center，数据质量中心）主要关注数据质量，通过配置数据质量校验规则，自动在数据处理任务过程中进行数据质量方面的监控。</li><li>DQC主要有数据监控和数据清洗两大功能。<ul><li>数据清洗采用非侵入式的清洗策略，在数据同步过程中不进行数据清洗，避免影响数据同步的效率，其过程在数据进入ODS层之后执行。对于需要清洗的表，首先在DQC配置清洗规则；对于离线任务，每隔固定的时间间隔，数据入仓之后，启动清洗任务，调用DQC配置的清洗规则，将符合清洗规则的数据清洗掉，并保存至DIRTY表归档。如果清洗掉的数据量大于预设的阐值，则阻断任务的执行；否则不会阻断。</li><li><img src="/2023/03/20/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A8%E3%80%8A%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%9A%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E8%B7%B5%E3%80%8B/4.3.png"></li></ul></li></ul></li><li><p>在彼岸</p><ul><li>数据测试的典型测试方法是功能测试，主要验证目标数据是否符合预期。<ul><li>新增业务需求</li><li>数据迁移、重构和修改</li></ul></li><li>在彼岸主要包含如下组件，除满足数据测试的数据对比组件之外，还有数据分布和数据脱敏组件。<ul><li>数据对比：支持不同集群、异构数据库的表做数据对比。表级对比规则主要包括数据量和全文对比；字段级对比规则主要包括字段的统计值（如SUM、AVG、MAX、MIN等）、枚举值、空值、去重数、长度值等。</li><li>数据分布：提取表和字段的一些特征值，并将这些特征值与预期值进行比对。表级数据特征提取主要包括数据量、主键等；字段级数据特征提取主要包括字段枚举值分布、空值分布、统计值（如SUM、AVG、MAX、MIN等）、去重数、长度值等。</li><li>数据脱敏：将敏感数据模糊化。在数据安全的大前提下，实现线上数据脱敏，在保证数据安全的同时又保持数据形态的分布，以便业务联调、数据调研和数据交换。</li><li><img src="/2023/03/20/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A8%E3%80%8A%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%9A%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E8%B7%B5%E3%80%8B/4.4.png"></li></ul></li></ul></li></ul><h4 id="2、任务调度系统"><a href="#2、任务调度系统" class="headerlink" title="2、任务调度系统"></a>2、任务调度系统</h4><p>度系统中的各类任务互相依赖，形成一个典型的有向无环图。在传统的数据仓库系统中，很多是依靠Crontab定时任务功能进行任务调度处理的。这种方式有很多弊端：①各任务之间的依赖基于执行时间实现，容易造成前面的任务未结束或失败而后面的任务已经运行；②任务难以并发执行，增加了整体的处理时间：③无法设置任务优先级；④任务的管理维护很不方便，无法进行执行效果分析等。</p><h6 id="核心设计模型"><a href="#核心设计模型" class="headerlink" title="核心设计模型"></a>核心设计模型</h6><p>整个调度系统共有两个核心模块：调度引擎（PhoenixEngine）和执行引擎（Alisa）。简单来说，调度引擎的作用是根据任务节点属性以及依赖关系进行实例化，生成各类参数的实值，并生成调度树z执行引擎的作用是根据调度引擎生成的具体任务实例和配置信息，分配CPU、内存、运行节点等资源，在任务对应的执行环境中运行节点代码。</p><h6 id="调度引擎工作原理"><a href="#调度引擎工作原理" class="headerlink" title="调度引擎工作原理"></a>调度引擎工作原理</h6><p>调度引擎（Phoenix Engine）基于以上两个状态机模型原理，以事件驱动的方式运行，为数据任务节点生成实例，并在调度树中生成具体执行的工作流。任务节点实例在工作流状态机、任务状态机和事件处理器之间转换，其中调度引擎只涉及任务状态机的未运行和等待运行两种状态，其他5种状态存在于执行引擎中。</p><h6 id="执行引擎"><a href="#执行引擎" class="headerlink" title="执行引擎"></a>执行引擎</h6><p>Alisa的用户系统包括上文的工作流服务、数据同步服务，以及调度引擎生成的各类数据处理任务的调度服务。同时其任务可以共享同一个物理集群资源，提高了资源的利用效率。</p><hr><h2 id="第五章-实时技术"><a href="#第五章-实时技术" class="headerlink" title="第五章 实时技术"></a>第五章 实时技术</h2><p>数据价值是具有时效性的，在一条数据产生的时候，如果不能及时处理并在业务系统中使用，就不能让数据保持最高的“新鲜度”和价值最大化。</p><p>相对于离线批处理技术，流式实时处理技术作为一个非常重要的技术补充，在阿里巴巴集团内被广泛使用。在大数据业界中，流计算技术的研究是近年来非常热门的课题。流式数据处理一般具有以下特征：</p><ul><li>时效性高：数据实时采集、实时处理，延时粒度在秒级甚至毫秒级，业务方能够在第一时间拿到经过加工处理后的数据。</li><li>常驻任务：区别于离线任务的周期调度，流式任务属于常驻进程任务，一旦启动后就会一直运行，直到人为地终止，因此计算成本会相对比较高。</li><li>性能要求高：实时计算对数据处理的性能要求非常严格，如果处理吞吐量跟不上采集吞吐量，计算出来的数据就失去了实时的特性。</li><li>应用局限性：实时数据处理不能替代离线处理，除了计算成本较大这个因素外，对于业务逻辑复杂的场景（比如双流关联或者需要数据回滚的情况），其局限性导致支持不足。</li></ul><h4 id="1、流式技术架构"><a href="#1、流式技术架构" class="headerlink" title="1、流式技术架构"></a>1、流式技术架构</h4><h6 id="（1）数据采集"><a href="#（1）数据采集" class="headerlink" title="（1）数据采集"></a>（1）数据采集</h6><p>既然需要做到实时计算，那么自然就需要做到实时采集了。所采集的数据都来自于业务服务器，从所采集的数据种类来看，主要可以划分为两种：</p><ul><li>数据库变更日志，比如MySQL的binlog日志、HBase的hlog日志、OceanBase的变更日志、Oracle的变更日志等。</li><li>引擎访问日志，比如用户访问网站产生的Apache引擎日志、搜索引擎的接口查询日志等。</li></ul><p>一般情况下，基于以下原则按批次对数据进行采集：</p><ul><li>数据大小限制：当达到限制条件时，把目前采集到的新数据作为一批（例如512KB写一批）。</li><li>时间阐值限制：当时间达到一定条件时，也会把目前采集到的新数据作为一批，避免在数据量少的情况下一直不采集（例如30秒写一批）。</li></ul><h6 id="（2）数据处理"><a href="#（2）数据处理" class="headerlink" title="（2）数据处理"></a>（2）数据处理</h6><p>实时计算任务部署在流式计算系统上，通过数据中间件获取到实时源数据后进行实时加工处理。</p><p>实时数据处理应用出于性能考虑，计算任务往往是多线程的。一般会根据业务主键进行分桶处理，并且大部分计算过程需要的数据都会放在内存中，这样会大大提高应用的吞吐量。为了避免内存溢出，内存中过期的数据需要定时清理，可以按照LRU（最近最少使用）算法或者业务时间集合归类清理（比如业务时间属于T-1的，会在今天凌晨进行清理）。</p><p>典型问题：</p><ul><li>去重指标<ul><li>精确去重。在这种情况下，明细数据是必须要保存下来的，当遇到内存问题时，可以通过数据倾斜来进行处理，把一个节点的内存压力分到多个节点上。</li><li>模糊去重。在去重的明细数据量非常大，而业务的精度要求不高的情况下，可以使用相关的去重算法，把内存的使用量降到千分之一甚至万分之一，以提高内存的利用率。</li><li>布隆过滤器<ul><li>该算法是位数组算法的应用，不保存真实的明细数据，只保存明细数据对应哈希值的标记位。</li><li>适用场景：统计精度要求不高，统计维度值非常多的情况。</li></ul></li><li>基数估计<ul><li>利用哈希的原理，按照数据的分散程度来估算现有数集的边界，从而得出大概的去重值总和。</li><li>适用场景：统计精度要求不高，统计维度非常粗的情况。</li></ul></li></ul></li><li>数据倾斜<ul><li>在数据量非常大的时候，单个节点的处理能力是有限的，必然会遇到性能瓶颈。这时就需要对数据进行分桶处理，分桶处理和离线处理的思路是一样的。</li></ul></li><li>事务处理<ul><li>由于实时计算是分布式处理的，系统的不稳定性必然会导致数据的处理有可能出现失败的情况。个流计算系统几乎都提供了数据自动ACK、失败重发以及事务信息等机制。<ul><li>超时时间：由于数据处理是按照批次来进行的，当一批数据处理超时时，会从拓扑的spout端重发数据。另外，批次处理的数据量不宜过大，应该增加一个限流的功能（限定一批数据的记录数或者容量等），避免数据处理超时。</li><li>事务信息：每批数据都会附带一个事务ID的信息，在重发的情况下，让开发者自己根据事务信息去判断数据第一次到达和重发时不同的处理逻辑。</li><li>备份机制：开发人员需要保证内存数据可以通过外部存储恢复，因此在计算中用到的中间结果数据需要备份到外部存储中。</li></ul></li><li>上面的这些机制都是为了保证数据的幕等性。</li></ul></li></ul><h6 id="（3）数据存储"><a href="#（3）数据存储" class="headerlink" title="（3）数据存储"></a>（3）数据存储</h6><p>数据存储系统必须能够比较好地支持多并发读写，并且延时需要在毫秒级才能满足实时的性能要求。在实践中，一般使用HBase、Tair、MongoDB等列式存储系统。由于这些系统在写数据时是先写内存再落磁盘，因此写延时在毫秒级：读请求也有缓存机制，重要的是多并发读时也可以达到毫秒级延时。</p><h6 id="（4）数据服务"><a href="#（4）数据服务" class="headerlink" title="（4）数据服务"></a>（4）数据服务</h6><p>数据服务工具例如OneService的特点：</p><ul><li>不需要直连数据库，数据源等信息在数据服务层维护，这样当存储系统迁移时，对下游是透明的。</li><li>调用方只需要使用服务层暴露的接口，不需要关心底层取数逻辑的实现。</li><li>屏蔽存储系统间的差异，统一的调用日志输出，便于分析和监控下游使用情况。</li></ul><h4 id="2、流式数据模型"><a href="#2、流式数据模型" class="headerlink" title="2、流式数据模型"></a>2、流式数据模型</h4><p>数据模型设计是贯通数据处理过程的，流式数据处理也一样，需要对数据流建模分层。实时建模跟离线建模非常类似，数据模型整体上分为五层（ODS、DWD、DWS、ADS、DIM）。</p><p>整体来看，实时数据模型是离线数据模型的一个子集，在实时数据处理过程中，很多模型设计就是参考离线数据模型实现的。</p><h6 id="（1）数据分层"><a href="#（1）数据分层" class="headerlink" title="（1）数据分层"></a>（1）数据分层</h6><ul><li>ODS层（Operational Data Store）<ul><li>ODS层属于操作数据层，是直接从业务系统采集过来的最原始数据，包含了所有业务的变更过程，数据粒度也是最细的。</li><li>在这一层，实时和离线在源头上是统一的，这样的好处是用同一份数据加工出来的指标，口径基本是统一的，可以更方便进行实时和离线间数据比对。</li></ul></li><li>DWD层（Data Warehouse Detail）<ul><li>DWD层是在ODS层基础上，根据业务过程建模出来的实时事实明细层，对于访问日志这种数据（没有上下文关系，并且不需要等待过程的记录），会回流到离线系统供下游使用，最大程度地保证实时和离线数据在ODS层和DWD层是一致的。</li></ul></li><li>DWS层（Data WareHouse Servce）<ul><li>订阅明细层的数据后，会在实时任务中计算各个维度的汇总指标。如果维度是各个垂直业务线通用的，则会放在实时通用汇总层，作为通用的数据模型使用。</li></ul></li><li>ADS层（Application Data Store）<ul><li>个性化维度汇总层，对于不是特别通用的统计维度数据会放在这一层中，这里计算只有自身业务才会关注的维度和指标，眼其他业务线一般没有交集，常用于一些垂直创新业务中。</li></ul></li><li>DIM层（Data Information Record）<ul><li>实时维表层的数据基本上都是从离线维表层导出来的，抽取到在线系统中供实时应用调用。这一层对实时应用来说是静态的，所有的ETL处理工作会在离线系统中完成。</li></ul></li></ul><h6 id="（2）多流关联"><a href="#（2）多流关联" class="headerlink" title="（2）多流关联"></a>（2）多流关联</h6><p>在流式计算中常常需要把两个实时流进行主键关联，以得到对应的实时明细表。在离线系统中两个表关联是非常简单的，因为离线计算在任务启动时已经可以获得两张表的全量数据，只要根据关联键进行分桶关联就可以了。但流式计算不一样，数据的到达是一个增量的过程，并且数据到达的时间是不确定的和无序的，因此在数据处理过程中会涉及中间状态的保存和恢复机制等细节问题。</p><p>实时采集两张表的数据，每到来一条新数据时都在内存中的对方表截至当前的全量数据中查找，如果能查找到，则说明关联成功，直接输出：如果没查找到，则把数据放在内存中的自己表数据集合中等待。另外，不管是否关联成功，内存中的数据都需要备份到外部存储系统中，在任务重启时，可以从外部存储系统中恢复内存数据，这样才能保证数据不丢失。因为在重启时，任务是续跑的，不会重新跑之前的数据。</p><h6 id="（3）维表使用"><a href="#（3）维表使用" class="headerlink" title="（3）维表使用"></a>（3）维表使用</h6><p>在离线系统中，一般是根据业务分区来关联事实表和维表的，因为在关联之前维表的数据就已经就绪了。而在实时计算中，关联维表一般会使用当前的实时数据（T）去关联T-2的维表数据，相当于在T的数据到达之前需要把维表数据准备好，并且一般是一份静态的数据。要基于以下几点的考虑：</p><ul><li>数据无法及时准备好</li><li>无法准确获取全量的最新数据</li><li>数据的无序性</li></ul><h4 id="3、如何进行实时任务优化"><a href="#3、如何进行实时任务优化" class="headerlink" title="3、如何进行实时任务优化"></a>3、如何进行实时任务优化</h4><h6 id="（1）独占资源和共享资源的策略"><a href="#（1）独占资源和共享资源的策略" class="headerlink" title="（1）独占资源和共享资源的策略"></a>（1）独占资源和共享资源的策略</h6><h6 id="（2）合理选择缓存机制，尽量降低读写库次数"><a href="#（2）合理选择缓存机制，尽量降低读写库次数" class="headerlink" title="（2）合理选择缓存机制，尽量降低读写库次数"></a>（2）合理选择缓存机制，尽量降低读写库次数</h6><h6 id="（3）计算单元合并，降低拓扑层次"><a href="#（3）计算单元合并，降低拓扑层次" class="headerlink" title="（3）计算单元合并，降低拓扑层次"></a>（3）计算单元合并，降低拓扑层次</h6><h6 id="（4）内存对象共享，避免字符拷贝"><a href="#（4）内存对象共享，避免字符拷贝" class="headerlink" title="（4）内存对象共享，避免字符拷贝"></a>（4）内存对象共享，避免字符拷贝</h6><h6 id="（5）在高吞吐量和低延时间取平衡"><a href="#（5）在高吞吐量和低延时间取平衡" class="headerlink" title="（5）在高吞吐量和低延时间取平衡"></a>（5）在高吞吐量和低延时间取平衡</h6><hr><h2 id="第六章-数据服务"><a href="#第六章-数据服务" class="headerlink" title="第六章 数据服务"></a>第六章 数据服务</h2><h4 id="1、服务架构演进"><a href="#1、服务架构演进" class="headerlink" title="1、服务架构演进"></a>1、服务架构演进</h4><h6 id="（1）阿里数据服务架构演进过程"><a href="#（1）阿里数据服务架构演进过程" class="headerlink" title="（1）阿里数据服务架构演进过程"></a>（1）阿里数据服务架构演进过程</h6><p><img src="/2023/03/20/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A8%E3%80%8A%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%9A%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E8%B7%B5%E3%80%8B/6.1.png"></p><h6 id="（2）DWSOA"><a href="#（2）DWSOA" class="headerlink" title="（2）DWSOA"></a>（2）DWSOA</h6><p><img src="/2023/03/20/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A8%E3%80%8A%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%9A%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E8%B7%B5%E3%80%8B/6.2.png"></p><p>业务方对数据的需求通过SOA服务的方式暴露出去。由需求驱动，一个需求开发一个或者几个接口，编写接口文档，开放给业务方调用。实现比较简单。缺点明显：</p><ul><li>接口粒度比较粗，灵活性不高，扩展性差，复用率低。</li><li>开发效率不高，无法快速响应业务。</li></ul><h6 id="（3）OpenAPI"><a href="#（3）OpenAPI" class="headerlink" title="（3）OpenAPI"></a>（3）OpenAPI</h6><p><img src="/2023/03/20/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A8%E3%80%8A%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%9A%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E8%B7%B5%E3%80%8B/6.3.png"></p><p>OpenAPI的做法就是将数据按照其统计粒度进行聚合，同样维度的数据，形成一张逻辑表，采用同样的接口描述。结果表明这种方式有效地收敛了接口数量。</p><p>（目测是通过在服务层归类成类似数据库表的模型，减少其他层的编码操作）</p><h6 id="（4）SmartDQ"><a href="#（4）SmartDQ" class="headerlink" title="（4）SmartDQ"></a>（4）SmartDQ</h6><p><img src="/2023/03/20/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A8%E3%80%8A%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%9A%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E8%B7%B5%E3%80%8B/6.4.png"></p><p>着时间的推移，大家对数据的深度使用，分析数据的维度也越来越多，于是，在OpenAPI的基础上，再抽象一层，用DSL(Domain Specific Language，领域专用语言）来描述取数需求。</p><p>采用标准的SQL语法，在此基础上做了一些限制和特殊增强，以降低学习成本。同时也封装了标准DataSource，可以使用ORM(Object Relation Mapping，对象关系映射）框架（目前比较主流的框架有Hibernate、MyBatis等）来解决对象关系映射问题。至此，所有的简单查询服务减少到只有一个接口，这大大降低了数据服务的维护成本。</p><p>（提供接口模板，减少人员维护）</p><h6 id="（5）OneService统一的数据服务层"><a href="#（5）OneService统一的数据服务层" class="headerlink" title="（5）OneService统一的数据服务层"></a>（5）OneService统一的数据服务层</h6><p><img src="/2023/03/20/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A8%E3%80%8A%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%9A%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E8%B7%B5%E3%80%8B/6.5.png"></p><p>SmartDQ其实只满足了简单的查询服务需求，不能满足个性化的取数业务场景，可以使用Lego。OneService主要是提供多种服务类型来满足用户需求，分别是OneService-SmartDQ、OneService-Lego、OneService-iPush、OneService-uTiming。</p><p>（可以使用Lego进行用户画像）</p><h4 id="2、最佳实践"><a href="#2、最佳实践" class="headerlink" title="2、最佳实践"></a>2、最佳实践</h4><h6 id="（1）性能"><a href="#（1）性能" class="headerlink" title="（1）性能"></a>（1）性能</h6><ul><li><p>资源分配</p><ul><li>剥离计算资源：剥离复杂的计算统计逻辑，将其全部交由底层的数据公共层进行处理，只保留核心的业务处理逻辑</li><li>查询资源分配：计了两个独立的线程池：Get线程池和List线程池，分别处理Get请求和List请求，这样就不会因为某些List慢查询，而影响到Get快查询。系统的QPS（Queries-per-second，每秒查询率）比之前提升许多。</li><li>执行计划优化：查询拆分&#x2F;查询优化（List查询转Get查询）</li></ul></li><li><p>缓存优化</p><ul><li>元数据缓存</li><li>模型缓存：将解析后的模型（包括逻辑模型、物理模型）缓存在本地。节省了DSL-&gt;SQL的解析时间。</li><li>结果缓存：对查询结果进行缓存，以提高查询性能。</li></ul></li><li><p>查询能力</p><ul><li>合并查询：离线数据和实时数据的数据源一般不同，调用者的查询方式完全不同。离线数据最准确，需要优先使用离线数据。如果离线数据还未产出，则改用实时数据。</li><li>推送服务：推送服务很好地解决了数据更新的实时性问题，同时也减少了对服务器的请求压力。（减少数据未更新前端不断请求的压力）</li></ul></li></ul><h6 id="（2）稳定性"><a href="#（2）稳定性" class="headerlink" title="（2）稳定性"></a>（2）稳定性</h6><ul><li><p>发布系统</p><ul><li>元数据隔离：为了保障系统的稳定性，根据应用环境设计了三套元数据：日常元数据、预发元数据和线上元数据。<ul><li><img src="/2023/03/20/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A8%E3%80%8A%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%9A%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E8%B7%B5%E3%80%8B/6.6.png"></li></ul></li><li>隔离发布：不同用户的发布不会相互影响。<ul><li>资源划分：定隔离的最小单元。由于调用者的查询请求最终都会转换成对某张逻辑表的查询。</li><li>资源独占：当用户开始修改的时候，系统会锁定其正在修改的逻辑表及其下挂的物理表等资源，禁止其他用户修改。当用户正式发布变更后，就会释放锁定的资源，这时其他用户才可以对相关元数据进行修改。</li><li>增量更新：发布时引擎是不需要重新加载全量元数据的，只需要加载所发布的逻辑表元数据即可。</li></ul></li></ul></li><li><p>隔离：将系统划分为若干个独立模块，当某个模块出现问题时，整体功能仍然能保证可用。另一个作用是可以对系统资源进行有效的管理，从而提高系统的可用性。</p><ul><li>机房隔离</li><li>分组隔离：据某些条件将调用者进行分层，然后将服务端的机器划分为若干个分组，每个分组都有明确的服务对象和保障等级。</li></ul></li><li><p>安全限制</p></li><li><p>监控</p><ul><li>调用日志采集</li><li>调用监控（系统）</li></ul></li><li><p>限流、降级</p></li></ul><hr><h2 id="第七章-数据挖掘"><a href="#第七章-数据挖掘" class="headerlink" title="第七章 数据挖掘"></a>第七章 数据挖掘</h2><p>基于大数据的企业级数据挖掘需要包含两个要素：①面向机器学习算法的并行计算框架与算法平台；②面向企业级数据挖掘的算法资产管理体系。</p><h4 id="1、机器学习算法"><a href="#1、机器学习算法" class="headerlink" title="1、机器学习算法"></a>1、机器学习算法</h4><p><img src="/2023/03/20/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A8%E3%80%8A%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%9A%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E8%B7%B5%E3%80%8B/7.1.png"></p><h4 id="2、数据挖掘中台体系"><a href="#2、数据挖掘中台体系" class="headerlink" title="2、数据挖掘中台体系"></a>2、数据挖掘中台体系</h4><p>在阿里巴巴集团，由于业务场景与商业智能分析需求的多样化，多个部门、多个商业智能及算法团队针对应用问题所提出的算法解决方案往往是独立的，通常一次数据挖掘的过程包括商业理解、数据准备、特征工程、模型训练、模型测试、模型部署、线上应用及效果反馈等环节。</p><p>就数据挖掘的商业场景而言，可以分为两大类应用：个体挖掘应用与关系挖掘应用。个体挖掘应用指对单个实体的行为特征进行预测与分析，如预测某商品的销量、划分某行业的价格区间等；关系挖掘应用指研究多个实体间的关系特征，如商品的相似关系、竞争关系等。</p><p>就数据挖掘技术而言，其包含两大要素：数据和算法。数据是数据挖掘的起源与挖掘结果最终的承载形式，可以说任何数据挖掘的过程都是从数据里来，回数据里去，源于数据而高于数据：算法是数据挖掘的神经中枢，通过算法对原始数据进行加工，得到对业务更有价值的数据。</p><p>因此，对于数据挖掘中台体系的设计也包含两大块：数据中台与算法中台；结合数据挖掘的商业场景，对这两大块的设计又分别从个体挖掘应用和关系挖掘应用两方面进行考虑。</p><h6 id="（1）挖掘数据中台"><a href="#（1）挖掘数据中台" class="headerlink" title="（1）挖掘数据中台"></a>（1）挖掘数据中台</h6><p>对结果数据进行合理的分层，有效隔离通用性强和个性化强的结果，这样可以充分发挥通用性强的算法结果的作用，提升它的复用率，减少不必要的重复建设。基于以上分析，我们把数据中台分为三层：特征层（Featural Data Mining Layer, FDM）、中间层和应用层（Application-orientedData Mining Layer, ADM），其中中间层包括个体中间层（IndividualData Mining Layer, IDM）和关系中间层（RelationalData Mining Layer, RDM）。</p><p><img src="/2023/03/20/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A8%E3%80%8A%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%9A%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E8%B7%B5%E3%80%8B/7.2.png"></p><ul><li><p>FDM层：用于存储在模型训练前常用的特征指标，并进行统一的清洗和去噪处理，提升机器学习特征工程环节的效率。</p></li><li><p>IDM层：个体挖掘指标中间层，面向个体挖掘场景，用于存储通用性强的结果数据，主要包含商品、卖家、买家、行业等维度</p></li><li><p>RDM层：关系挖掘指标中间层，面向关系挖掘场景，用于存储通用性强的结果数据，主要包含商品间的相似关系、竞争关系，店铺间的相似关系、竞争关系等。</p></li><li><p>ADM层：用来沉淀比较个性偏应用的数据挖掘指标，比如用户偏好的类目、品牌等，这些数据已经过深度的加工处理，满足某一特点业务或产品的使用。</p></li></ul><h6 id="（2）挖掘算法中台"><a href="#（2）挖掘算法中台" class="headerlink" title="（2）挖掘算法中台"></a>（2）挖掘算法中台</h6><p>数据挖掘算法中台建设的目的同样在于从各种各样的挖掘场景中抽象出有代表性的几类场景，并形成相应的方法论和实操模板。</p><h4 id="3、数据挖掘案例"><a href="#3、数据挖掘案例" class="headerlink" title="3、数据挖掘案例"></a>3、数据挖掘案例</h4><h6 id="（1）用户画像"><a href="#（1）用户画像" class="headerlink" title="（1）用户画像"></a>（1）用户画像</h6><p>用户画像即是为用户打上各种各样的标签，如年龄、性别、职业、商品品牌偏好、商品类别偏好等。这些标签的数目越丰富，标签越细化，对用户的刻画就越精准。</p><h6 id="（2）互联网反作弊"><a href="#（2）互联网反作弊" class="headerlink" title="（2）互联网反作弊"></a>（2）互联网反作弊</h6><p>业务上看，反作弊工作主要体现在以下几个方面：</p><ul><li>账户／资金安全与网络欺诈防控</li><li>非人行为和账户识别</li><li>虚假订单与信用炒作识别</li><li>广告推广与APP安装反作弊</li><li>UGC恶意信息检测</li></ul><p>算法技术上说，反作弊方法主要包括如下几类：</p><ul><li>基于业务规则的方法：<ul><li>根据实际的业务场景，不断地发现总结作弊和获利手法，通过反作弊规则的不断拓展或产品设计的完善来识别、缓解甚至消除作弊现象。</li><li>优点是精度高、可解释性强，能准确识别老的作弊方式；缺点是人力成本高，而且对新的作弊手法滞后性较强。</li></ul></li><li>基于有监督学习的方法<ul><li>按照有监督分类算法的流程来建模，通过正负样本标记、特征提取、模型训练及预测等过程来识别作弊行为。</li><li>优点是通用性强，人力成本主要集中在样本的标记和特征的处理上；缺点是有些算法结果的可解释性不强，容易造成错判，需要辅以其他指标和方法进行综合判断。</li></ul></li><li>基于无监督学习的方法<ul><li>异常检测算法假设作弊行为极其罕见且在某些特征维度下和正常行为能够明显地区分开来。所以，假设检验、统计分析、聚类分析等手段常被用来做异常检测。</li><li>优点是不需要标记正负样本，而且检测到的异常行为还可以沉淀到规则系统中；缺点是特征设计和提取的工作量大，需要在所有可能的风险维度下刻画行为特征。</li></ul></li></ul><p>算法的实际应用工作主要分为以下两个方面：</p><ul><li>离线反作弊系统</li><li>实时反作弊系统</li></ul><p>未来的挑战：</p><ul><li><p>作弊手段的多样性和多变性</p></li><li><p>算法的及时性和准确性</p></li><li><p>数据及作弊手段的沉淀和逆向反馈</p></li></ul><hr><h2 id="第八章-大数据领域建模综述"><a href="#第八章-大数据领域建模综述" class="headerlink" title="第八章 大数据领域建模综述"></a>第八章 大数据领域建模综述</h2><p>数据模型就是数据组织和存储方法，它强调从业务、数据存取和使用角度合理存储数据。Linux的创始人Torvalds有一段关于“什么才是优秀程序员”的话：“烂程序员关心的是代码，好程序员关心的是数据结构和它们之间的关系”，其阐述了数据模型的重要性。</p><p>有了适合业务和基础数据存储环境的模型，那么大数据就能获得以下好处。</p><ul><li>性能：良好的数据模型能帮助我们快速查询所需要的数据，减少数据的I&#x2F;O吞吐。</li><li>成本：良好的数据模型能极大地减少不必要的数据冗余，也能实现计算结果复用，极大地降低大数据系统中的存储和计算成本。</li><li>效率：良好的数据模型能极大地改善用户使用数据的体验，提高使用数据的效率。</li><li>质量：良好的数据模型能改善数据统计口径的不一致性，减少数据计算错误的可能性。</li></ul><h4 id="1、典型的数据仓库建模方法论"><a href="#1、典型的数据仓库建模方法论" class="headerlink" title="1、典型的数据仓库建模方法论"></a>1、典型的数据仓库建模方法论</h4><h6 id="（1）ER模型"><a href="#（1）ER模型" class="headerlink" title="（1）ER模型"></a>（1）ER模型</h6><p>用实体关系（EntityRelationship, ER）模型描述企业业务，在范式理论上符合3NF。数据仓库中的3NF与OLTP系统中的3NF的区别在于，它是站在企业角度面向主题的抽象，而不是针对某个具体业务流程的实体对象关系的抽象。其具有以下几个特点：</p><ul><li>需要全面了解企业业务和数据。</li><li>实施周期非常长。</li><li>对建模人员的能力要求非常高。</li></ul><p>建模步骤分为三个阶段：</p><ul><li>高层模型：一个高度抽象的模型，描述主要的主题以及主题间的关系，用于描述企业的业务总体概况。</li><li>中层模型：在高层模型的基础上，细化主题的数据项。</li><li>物理模型（也叫底层模型）：在中层模型的基础上，考虑物理存储，同时基于性能和平台特点进行物理属性的设计，也可能做一些表的合并、分区的设计等。</li></ul><h6 id="（2）维度模型"><a href="#（2）维度模型" class="headerlink" title="（2）维度模型"></a>（2）维度模型</h6><p>维度建模从分析决策的需求出发构建模型，为分析需求服务，因此它重点关注用户如何更快速地完成需求分析，同时具有较好的大规模复杂查询的响应性能。其典型的代表是星形模型，以及在一些特殊场景下使用的雪花模型。其设计分为以下几个步骤：</p><ul><li>选择需要进行分析决策的业务过程。业务过程可以是单个业务事件，比如交易的支付、退款等；也可以是某个事件的状态，比如当前的账户余额等；还可以是一系列相关业务事件组成的业务流程，具体需要看我们分析的是某些事件发生情况，还是当前状态，或是事件流转效率。</li><li>选择粒度。在事件分析中，我们要预判所有分析需要细分的程度，从而决定选择的粒度。粒度是维度的一个组合。</li><li>识别维表。选择好粒度之后，就需要基于此粒度设计维表，包括维度属性，用于分析时进行分组和筛选。</li><li>选择事实。确定分析需要衡量的指标。</li></ul><h6 id="（3）Data-Vault模型"><a href="#（3）Data-Vault模型" class="headerlink" title="（3）Data Vault模型"></a>（3）Data Vault模型</h6><p>Data Vault是ER模型的衍生，其设计的出发点也是为了实现数据的整合，但不能直接用于数据分析决策。它强调建立一个可审计的基础数据层，也就是强调数据的历史性、可追溯性和原子性，而不要求对数据进行过度的一致性处理和整合；同时它基于主题概念将企业数据进行结构化组织，并引入了更进一步的范式处理来优化模型，以应对源系统变更的扩展性。DataVault模型由以下几部分组成：</p><ul><li>Hub：是企业的核心业务实体，由实体key、数据仓库序列代理键、装载时间、数据来源组成。（骨架）</li><li>Link：代表Hub之间的关系。这里与ER模型最大的区别是将关系作为一个独立的单元抽象，可以提升模型的扩展性。它可以直接描述1: 1、l:n和n:n的关系，而不需要做任何变更。它由Hub的代理键、装载时间、数据来源组成。（韧带）</li><li>Satellite：是Hub的详细描述内容，一个Hub可以有多个Satellite。它由Hub的代理键、装载时间、来源类型、详细的Hub描述信息组成。（血肉）</li></ul><p>Data Vault模型比ER模型更容易设计和产出，它的ETL加工可实现配置化。</p><h6 id="（4）Anchor模型"><a href="#（4）Anchor模型" class="headerlink" title="（4）Anchor模型"></a>（4）Anchor模型</h6><p>Anchor对DataVault模型做了进一步规范化处理规范到6NF，基本变成了k-v结构化模型。我们看一下Anchor模型的组成：</p><ul><li>Anchors：类似于DataVault的Hub，代表业务实体，且只有主键。</li><li>Attributes：功能类似于DataVault的Satellite，但是它更加规范化，将其全部k-v结构化，一个表只有一个Anchors的属性描述。</li><li>Ties：就是Anchors之间的关系，单独用表来描述，类似于DataVault的Link，可以提升整体模型关系的扩展能力。</li><li>Knots：代表那些可能会在多个Anchors中公用的属性的提炼，比如性别、状态等这种枚举类型且被公用的属性。</li></ul><hr><h2 id="第九章-阿里巴巴数据整合及管理体系"><a href="#第九章-阿里巴巴数据整合及管理体系" class="headerlink" title="第九章 阿里巴巴数据整合及管理体系"></a>第九章 阿里巴巴数据整合及管理体系</h2><p>阿里巴巴集团大数据建设方法论的核心是：从业务架构设计到模型设计，从数据研发到数据服务，做到数据可管理、可追溯、可规避重复建设。</p><h4 id="体系架构"><a href="#体系架构" class="headerlink" title="体系架构"></a>体系架构</h4><p><img src="/2023/03/20/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A8%E3%80%8A%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%9A%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E8%B7%B5%E3%80%8B/9.1.png"></p><h4 id="基本原则"><a href="#基本原则" class="headerlink" title="基本原则"></a>基本原则</h4><ul><li>高内聚和低耦合<ul><li>一个逻辑或者物理模型由哪些记录和字段组成，应该遵循最基本的软件设计方法论的高内聚和低藕合原则</li></ul></li><li>核心模型与扩展模型分离</li><li>公共处理逻辑下沉及单一<ul><li>越是底层公用的处理逻辑越应该在数据调度依赖的底层进行封装与实现，不要让公用的处理逻辑暴露给应用层实现，不要让公共逻辑多处同时存在。</li></ul></li><li>成本与性能平衡</li><li>数据可回滚</li><li>一致性</li><li>命名清晰、可理解</li></ul><h4 id="模型实施"><a href="#模型实施" class="headerlink" title="模型实施"></a>模型实施</h4><h6 id="（1）业界常用模型实施过程"><a href="#（1）业界常用模型实施过程" class="headerlink" title="（1）业界常用模型实施过程"></a>（1）业界常用模型实施过程</h6><ul><li><p>Kimball模型主要探讨需求分析、高层模型、详细模型和模型审查整个过程。</p><ul><li>高层模型：高层模型设计阶段的直接产出目标是创建高层维度模型图，它是对业务过程中的维表和事实表的图形描述。</li><li>详细模型：详细的维度建模过程是为高层模型填补缺失的信息，解决设计问题，并不断测试模型能否满足业务需求，确保模型的完备性。</li><li>模型审查、再设计和验证</li><li>提交ETL设计和开发</li></ul></li><li><p>Inmon对数据模型的定位是：扮演着通往数据仓库其他部分的智能路线图的角色。</p><ul><li>ERD层是数据模型的最高层，该层描述了公司业务中的实体或主题域以及它们之间的关系；</li><li>ERD层是中间层，该层描述了数据模型中的关键字、属性以及细节数据之间的关系；</li><li>物理层是数据建模的最底层，该层描述了数据模型的物理特性。</li></ul></li><li><p>其他模型</p><ul><li>业务建模</li><li>领域建模</li><li>逻辑建模</li><li>物理建模</li></ul></li></ul><h6 id="（2）OneData实施过程"><a href="#（2）OneData实施过程" class="headerlink" title="（2）OneData实施过程"></a>（2）OneData实施过程</h6><p><img src="/2023/03/20/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A8%E3%80%8A%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%9A%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E8%B7%B5%E3%80%8B/9.2.png"></p><p>OneData的实施过程是一个高度迭代和动态的过程，一般采用螺旋式实施方法。在总体架构设计完成之后，开始根据数据域进行迭代式模型设计和评审。在架构设计、规范定义和模型设计等模型实施过程中，都会引人评审机制，以确保模型实施过程的正确性。</p><hr><h2 id="第十章-维度设计"><a href="#第十章-维度设计" class="headerlink" title="第十章 维度设计"></a>第十章 维度设计</h2><h4 id="1、维度设计基础"><a href="#1、维度设计基础" class="headerlink" title="1、维度设计基础"></a>1、维度设计基础</h4><h6 id="（1）基本概念"><a href="#（1）基本概念" class="headerlink" title="（1）基本概念"></a>（1）基本概念</h6><p>维度是维度建模的基础和灵魂。在维度建模中，将度量称为“事实”，将环境描述为“维度”，维度是用于分析事实所需要的多样环境。</p><p>维度所包含的表示维度的列，称为维度属性。维度属性是查询约束条件、分组和报表标签生成的基本来源，是数据易用性的关键。</p><h6 id="（2）基本设计方法"><a href="#（2）基本设计方法" class="headerlink" title="（2）基本设计方法"></a>（2）基本设计方法</h6><ul><li>选择维度或新建维度。作为维度建模的核心，在企业级数据仓库中必须保证维度的唯一性。</li><li>确定主维表。此处的主维表一般是ODS表，直接与业务系统同步。</li><li>确定相关维表。数据仓库是业务源系统的数据整合，不同业务系统或者同一业务系统中的表之间存在关联性。根据对业务的梳理，确定哪些表和主维表存在关联关系，并选择其中的某些表用于生成维度属性。</li><li>确定维度属性。本步骤主要包括两个阶段，其中第一个阶段是从主维表中选择维度属性或生成新的维度属性；第二个阶段是从相关维表中选择维度属性或生成新的维度属性。</li></ul><h6 id="（3）规范化和反规范化"><a href="#（3）规范化和反规范化" class="headerlink" title="（3）规范化和反规范化"></a>（3）规范化和反规范化</h6><p>当属性层次被实例化为一系列维度，而不是单一的维度时，被称为雪花模式。大多数联机事务处理系统（OLTP）的底层数据结构在设计时采用此种规范化技术，通过规范化处理将重复属性移至其自身所属的表中，删除冗余数据。（规范化）</p><p>将维度的属性层次合并到单个维度中的操作称为反规范化。分析系统的主要目的是用于数据分析和统计，如何更方便用户进行统计分析决定了分析系统的优劣。采用雪花模式，用户在统计分析的过程中需要大量的关联操作，使用复杂度高，同时查询性能很差；而采用反规范化处理，则方便、易用且性能好。（反规范化）</p><table><thead><tr><th align="center">规范化</th><th align="center">反规范化</th></tr></thead><tbody><tr><td align="center">可读性不强</td><td align="center">方便、易用（可读性强）</td></tr><tr><td align="center">性能低（需要大量关联）</td><td align="center">性能高</td></tr><tr><td align="center">节约存储</td><td align="center">数据冗余</td></tr><tr><td align="center">复杂性高</td><td align="center">复杂性低</td></tr></tbody></table><h6 id="（4）一致性维度"><a href="#（4）一致性维度" class="headerlink" title="（4）一致性维度"></a>（4）一致性维度</h6><ul><li>共享维表。比如在阿里巴巴的数据仓库中，商品、卖家、买家、类目等维度有且只有一个。所以基于这些公共维度进行的交叉探查不会存在任何问题。</li><li>一致性上卷，其中一个维度的维度属性是另一个维度的维度属性的子集，且两个维度的公共维度属性结构和内容相同。比如在阿里巴巴的商品体系中，有商品维度和类目维度，其中类目维度的维度属性是商品维度的维度属性的子集，且有相同的维度属性和维度属性值。这样基于类目维度进行不同业务过程的交叉探查也不会存在任何问题。</li><li>交叉属性，两个维度具有部分相同的维度属性。比如在商品维度中具有类目属性，在卖家维度中具有主营类目属性，两个维度具有相同的类目属性，则可以在相同的类目属性上进行不同业务过程的交叉探查。</li></ul><h4 id="2、维度设计高级主题"><a href="#2、维度设计高级主题" class="headerlink" title="2、维度设计高级主题"></a>2、维度设计高级主题</h4><h6 id="（1）维度整合"><a href="#（1）维度整合" class="headerlink" title="（1）维度整合"></a>（1）维度整合</h6><ul><li>垂直整合，即不同的来源表包含相同的数据集，只是存储的信息不同。</li><li>水平整合，即不同的来源表包含不同的数据集，不同子集之间无交叉，也可以存在部分交叉。</li></ul><h6 id="（2）数据模型设计过程："><a href="#（2）数据模型设计过程：" class="headerlink" title="（2）数据模型设计过程："></a>（2）数据模型设计过程：</h6><ul><li>扩展性：当源系统、业务逻辑变化时，能通过较少的成本快速扩展模型，保持核心模型的相对稳定性。软件工程中的高内聚、低稠合的思想是重要的指导方针之一。</li><li>效能：在性能和成本方面取得平衡。通过牺牲一定的存储成本，达到性能和逻辑的优化。</li><li>易用性：模型可理解性高、访问复杂度低。用户能够方便地从模型中找到对应的数据表，并能够方便地查询和分析。</li></ul><h6 id="（3）水平拆分"><a href="#（3）水平拆分" class="headerlink" title="（3）水平拆分"></a>（3）水平拆分</h6><ul><li>维度的不同分类的属性差异情况。当维度属性随类型变化较大时，将所有可能的属性建立在一个表中是不切合实际的，也没有必要这样做，此时建议采用将维度的不同分类实例化为不同的维度，同时在主维度中保存公共属性。定义一个主维度用于存放公共属性；同时定义多个子维度，其中除了包含公共属性外，还包含各自的特殊属性。</li><li>业务的关联程度。两个相关性较低的业务，稠合在一起弊大于利，对模型的稳定性和易用性影响较大。此时建议采用维护单一维度。</li></ul><h6 id="（4）垂直拆分"><a href="#（4）垂直拆分" class="headerlink" title="（4）垂直拆分"></a>（4）垂直拆分</h6><p>某些维度属性的来源表产出时间较早，而某些维度属性的来源表产出时间较晚；或者某些维度属性的热度高、使用频繁，而某些维度属性的热度低、较少使用；或者某些维度属性经常变化，而某些维度属性比较稳定</p><p>出于扩展性、产出时间、易用性等方面的考虑，设计主从维度。主维表存放稳定、产出时间早、热度高的属性；从维表存放变化较快、产出时间晚、热度低的属性。</p><p>通过存储的冗余和计算成本的增加，实现了商品主模型的稳定和产出时间的提前，对于整个数据仓库的稳定和下游应用的产出都有较大意义。</p><h4 id="3、维度变化"><a href="#3、维度变化" class="headerlink" title="3、维度变化"></a>3、维度变化</h4><h6 id="（1）缓慢变化堆"><a href="#（1）缓慢变化堆" class="headerlink" title="（1）缓慢变化堆"></a>（1）缓慢变化堆</h6><ul><li><p>重写维度值。采用此种方式，不保留历史数据，始终取最新数据。</p></li><li><p>插人新的维度行。采用此种方式，保留历史数据，维度值变化前的事实和过去的维度值关联，维度值变化后的事实和当前的维度值关联。</p></li><li><p>添加维度列。采用第二种处理方式不能将变化前后记录的事实归一为变化前的维度或者归一为变化后的维度。</p></li></ul><h6 id="（2）快照维表"><a href="#（2）快照维表" class="headerlink" title="（2）快照维表"></a>（2）快照维表</h6><p>优点：</p><ul><li>简单而有效，开发和维护成本低。</li><li>使用方便，理解性好。数据使用方只需要限定日期，即可获取到当天的快照数据。任意一天的事实快照和维度快照通过维度的自然键进行关联即可。</li></ul><p>弊端主要体现在存储的极大浪费上。比如某维度，每天的变化量占总体数据量的比例很低，在极端情况下，每天无变化，使得存储浪费很严重。此方法主要就是实现了牺牲存储获取ETL效率的优化和逻辑上的简化。但是一定要杜绝过度使用这种方法，而且必须要有对应的数据生命周期制度，清除无用的历史数据。</p><h6 id="（3）极限存储"><a href="#（3）极限存储" class="headerlink" title="（3）极限存储"></a>（3）极限存储</h6><ul><li>透明化<ul><li>底层的数据还是历史拉链存储，但是上层做一个视图操作或者在Hive里做一个hook，通过分析语句的语法树，把对极限存储前的表的查询转换成对极限存储表的查询。对于下游用户来说，极限存储表和全量存储方式是一样的。</li></ul></li><li>分月做历史拉链表<ul><li>用极限存储的处理方式，极大地压缩了全量存储的成本，又可以达到对下游用户透明的效果，是一种比较理想的存储方式。但是其本身也有一定的局限性，首先，其产出效率很低，大部分极限存储通常需要t-2；其次，对于变化频率高的数据并不能达到节约成本的效果。因此，在实际生产中，做极限存储需要进行一些额外的处理。</li></ul></li></ul><h6 id="（4）微型维度"><a href="#（4）微型维度" class="headerlink" title="（4）微型维度"></a>（4）微型维度</h6><ul><li>微型维度的局限性。微型维度是事先用所有可能值的组合加载的，需要考虑每个属性的基数，且必须是枚举值。很多属性可能是非枚举型，比如数值类型，如VIP分数、信用分数等；时间类型，如上架时间、下架时间、变更时间等。</li><li>ETL逻辑复杂。对于分布式系统，生成代理键和使用代理键进行ETL加工都非常复杂，ETL开发和维护成本过高。</li><li>破坏了维度的可浏览性。买家维度和微型维度通过事实表建立联系，无法基于VIP等级、信用等级进行浏览和统计。可以通过在买家维度中添加引用微型维度的外键部分来解决此问题，但带来的问题是微型维度未维护历史信息。</li></ul><hr><h2 id="第十一章-事实表设计"><a href="#第十一章-事实表设计" class="headerlink" title="第十一章 事实表设计"></a>第十一章 事实表设计</h2><h4 id="1、事实表基础"><a href="#1、事实表基础" class="headerlink" title="1、事实表基础"></a>1、事实表基础</h4><p>事实表中一条记录所表达的业务细节程度被称为粒度。通常粒度可以通过两种方式来表述：一种是维度属性组合所表示的细节程度：一种是所表示的具体业务含义。</p><p>事实表有三种类型：事务事实表、周期快照事实表和累积快照事实表。事务事实表用来描述业务过程，跟踪空间或时间上某点的度量事件，保存的是最原子的数据，也称为“原子事实表“周期快照事实表以具有规律性的、可预见的时间间隔记录事实，时间间隔如每天、每月、每年等。累积快照事实表用来表述过程开始和结束之间的关键步骤事件，覆盖过程的整个生命周期，通常具有多个日期字段来记录关键时间点，当过程随着生命周期不断变化时，记录也会随着过程的变化而被修改。</p><h6 id="（1）设计原则"><a href="#（1）设计原则" class="headerlink" title="（1）设计原则"></a>（1）设计原则</h6><p>原则1：尽可能包含所有与业务过程相关的事实</p><p>原则2：只选择与业务过程相关的事实</p><p>原则3：分解不可加性事实为可加的组件</p><p>原则4：在选择维度和事实之前必须先声明粒度</p><p>原则5：在同一个事实表中不能有多种不同粒度的事实</p><p>原则6：事实的单位要保持一致</p><p>原则7：对事实的null值要处理</p><p>原则8：使用退化维度提高事实表的易用性</p><h6 id="（2）设计方法"><a href="#（2）设计方法" class="headerlink" title="（2）设计方法"></a>（2）设计方法</h6><p>第一步：选择业务过程及确定事实表类型。</p><p>第二步：声明粒度。</p><p>第三步：确定维度。</p><p>第四步．确定事实。</p><p>第五步．冗余维度。</p><h4 id="2、事务事实表"><a href="#2、事务事实表" class="headerlink" title="2、事务事实表"></a>2、事务事实表</h4><h6 id="（1）单事务事实表"><a href="#（1）单事务事实表" class="headerlink" title="（1）单事务事实表"></a>（1）单事务事实表</h6><p>单事务事实表，顾名思义，即针对每个业务过程设计一个事实表。这样设计的优点不言而喻，可以方便地对每个业务过程进行独立的分析研究。</p><h6 id="（2）多事务事实表"><a href="#（2）多事务事实表" class="headerlink" title="（2）多事务事实表"></a>（2）多事务事实表</h6><p>多事务事实表，将不同的事实放到同一个事实表中，即同一个事实表包含不同的业务过程。多事务事实表在设计时有两种方法进行事实的处理：①不同业务过程的事实使用不同的事实字段进行存放：①不同业务过程的事实使用同一个事实字段进行存放，但增加一个业务过程标签。</p><h6 id="（3）两种事务事实表得选择"><a href="#（3）两种事务事实表得选择" class="headerlink" title="（3）两种事务事实表得选择"></a>（3）两种事务事实表得选择</h6><ul><li>当不同业务过程的度量比较相似、差异不大时，可以采用第二种多事务事实表的设计方式，使用同一个字段来表示度量数据。但这种方式存在一个问题一一在同一个周期内会存在多条记录。</li><li>当不同业务过程的度量差异较大时，可以选择第一种多事务事实表的设计方式，将不同业务过程的度量使用不同字段冗余到表中，非当前业务过程则置零表示。这种方式所存在的问题是度量字段零值较多。</li></ul><h6 id="（4）对比"><a href="#（4）对比" class="headerlink" title="（4）对比"></a>（4）对比</h6><table><thead><tr><th align="center"></th><th align="center">单事务事实表</th><th align="center">多事务事实表</th></tr></thead><tbody><tr><td align="center">业务过程</td><td align="center">一个业务过程建立一个事实表，只反映一个业务过程的事实</td><td align="center">在同一个事实表中反映多个业务过程</td></tr><tr><td align="center">粒度和维度</td><td align="center">粒度不同</td><td align="center">不同业务过程的粒度相同，同时拥有相似的维度</td></tr><tr><td align="center">事实</td><td align="center">过程的事实较多，同时不同业务过程的事实不相同</td><td align="center">导致零值或空值字段较多</td></tr><tr><td align="center">下游业务使用</td><td align="center">关注哪个业务过程就使用相应的事务事实表</td><td align="center">包含多个业务过程</td></tr><tr><td align="center">计算存储成本</td><td align="center"></td><td align="center">加工计算成本较低，同时在存储上也相对节省</td></tr></tbody></table><p>简表：</p><p><img src="/2023/03/20/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A8%E3%80%8A%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%9A%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E8%B7%B5%E3%80%8B/11.1.png"></p><h6 id="（5）设计准则"><a href="#（5）设计准则" class="headerlink" title="（5）设计准则"></a>（5）设计准则</h6><ul><li>事实完整性：事实表包含与其描述的过程有关的所有事实，即尽可能多地获取所有的度量。</li><li>事实一致性：在确定事务事实表的事实时，明确存储每一个事实以确保度量的一致性。</li><li>事实可加性：事实表确定事实时，往往会遇到非可加性度量，比如分摊比例、利润率等，虽然它们也是下游分析的关键点，但往往在事务事实表中关注更多的是可加性事实，下游用户在聚合统计时更加方便。</li></ul><h4 id="3、周期快照事实表"><a href="#3、周期快照事实表" class="headerlink" title="3、周期快照事实表"></a>3、周期快照事实表</h4><p>快照事实表的设计有一些区别于事务事实表设计的性质。事务事实表的粒度能以多种方式表达，但快照事实表的粒度通常以维度形式声明；事务事实表是稀疏的，但快照事实表是稠密的；事务事实表中的事实是完全可加的，但快照模型将至少包含一个用来展示半可加性质的事实。</p><ul><li>用快照采样状态：快照事实表以预定的间隔采样状态度量。这种间隔联合一个或多个维度，将被用来定义快照事实表的粒度，每行都将包含记录所涉及状态的事实。</li><li>快照粒度：事务事实表的粒度可以通过业务过程中所涉及的细节程度来描述，但快照事实表的粒度通常总是被多维声明，可以简单地理解为快照需要采样的周期以及什么将被采样。</li><li>密度与稀疏性：事务事实表是稀疏的，只有当天发生的业务过程，事实表才会记录该业务过程的事实，如下单、支付等；而快照事实表是稠密的，无论当天是否有业务过程发生，都会记录一行，比如针对卖家的历史至今的下单和支付金额，无论当天卖家是否有下单支付事实，都会给该卖家记录一行。</li><li>半可加性：与事务事实表的可加性事实不同，半可加性事实不能根据时间维度获得有意义的汇总结果。</li></ul><h6 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h6><ul><li>事务与快照成对设计：数据仓库维度建模时，对于事务事实表和快照事实表往往都是成对设计的，互相补充，以满足更多的下游统计分析需求，特别是在事务事实表的基础上可以加工快照事实表。</li><li>附加事实：快照事实表在确定状态度量时，一般都是保存采样周期结束时的状态度量。</li><li>周期到日期度量</li></ul><h4 id="4、累计快照事实表"><a href="#4、累计快照事实表" class="headerlink" title="4、累计快照事实表"></a>4、累计快照事实表</h4><h6 id="（1）设计过程"><a href="#（1）设计过程" class="headerlink" title="（1）设计过程"></a>（1）设计过程</h6><ul><li>选择业务过程</li><li>确定粒度</li><li>确定维度</li><li>确定事实</li><li>退化为度</li></ul><h6 id="（2）特点"><a href="#（2）特点" class="headerlink" title="（2）特点"></a>（2）特点</h6><ul><li>数据不断更新：事务事实表记录事务发生时的状态，对于实体的某一实例不再更新z而累积快照事实表则对实体的某一实例定期更新。</li><li>多业务过程日期：累积快照事实表的典型特征是多业务过程日期，用于计算业务过程之间的时间间隔。</li></ul><h4 id="5、三种事实表的比较"><a href="#5、三种事实表的比较" class="headerlink" title="5、三种事实表的比较"></a>5、三种事实表的比较</h4><p><img src="/2023/03/20/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A8%E3%80%8A%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%9A%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E8%B7%B5%E3%80%8B/11.2.png"></p><h4 id="6、无事实的事实表"><a href="#6、无事实的事实表" class="headerlink" title="6、无事实的事实表"></a>6、无事实的事实表</h4><ul><li>事件类的，记录事件的发生。常见的是日志类事实表。</li><li>条件、范围或资格类的，记录维度与维度多对多之间的关系。</li></ul><h4 id="7、聚集型事实表"><a href="#7、聚集型事实表" class="headerlink" title="7、聚集型事实表"></a>7、聚集型事实表</h4><h6 id="（1）基本原则"><a href="#（1）基本原则" class="headerlink" title="（1）基本原则"></a>（1）基本原则</h6><ul><li>一致性：聚集表必须提供与查询明细粒度数据一致的查询结果。</li><li>避免单一表设计：不要在同一个表中存储不同层次的聚集数据；否则将会导致双重计算或出现更糟糕的事情。</li><li>聚集粒度可不同：聚集并不需要保持与原始明细粒度数据一样的粒度，聚集只关心所需要查询的维度。</li></ul><h6 id="（2）基本步骤"><a href="#（2）基本步骤" class="headerlink" title="（2）基本步骤"></a>（2）基本步骤</h6><p>第一步：确定聚集维度。</p><p>第二步：确定一致性上钻。</p><p>第三步：确定聚集事实。</p><h6 id="（3）补充说明"><a href="#（3）补充说明" class="headerlink" title="（3）补充说明"></a>（3）补充说明</h6><ul><li>聚集是不跨越事实的：聚集是针对原始星形模型进行的汇总，为了获取和查询与原始模型一致的结果，聚集的维度和度量必须与原始模型保持一致，因此聚集是不跨越事实的。</li><li>聚集带来的问题：聚集会带来查询性能的提升，但聚集也会增加ETL维护的难度。当子类目对应的一级类目发生变更时，先前存在的、已经被汇总到聚集表中的数据需要被重新调整。</li></ul><hr><h2 id="第十二章-元数据"><a href="#第十二章-元数据" class="headerlink" title="第十二章 元数据"></a>第十二章 元数据</h2><p>按照传统的定义，元数据（Metadata）是关于数据的数据。元数据打通了源数据、数据仓库、数据应用，记录了数据从产生到消费的全过程。元数据主要记录数据仓库中模型的定义、各层级间的映射关系、监控数据仓库的数据状态及ETL的任务运行状态。在数据仓库系统中，元数据可以帮助数据仓库管理员和开发人员非常方便地找到他们所关心的数据，用于指导其进行数据管理和开发工作，提高工作效率。</p><p>将元数据按用途的不同分为两类：技术元数据（Technical Metadata) 和业务元数据（Business Metadata）。</p><p>元数据有重要的应用价值，是数据管理、数据内容、数据应用的基础，在数据管理方面为集团数据提供在计算、存储、成本、质量、安全、模型等治理领域上的数据支持。</p><h4 id="1、统一元数据体系建设思路"><a href="#1、统一元数据体系建设思路" class="headerlink" title="1、统一元数据体系建设思路"></a>1、统一元数据体系建设思路</h4><p><img src="/2023/03/20/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A8%E3%80%8A%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%9A%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E8%B7%B5%E3%80%8B/12.1.png"></p><h4 id="2、元数据应用"><a href="#2、元数据应用" class="headerlink" title="2、元数据应用"></a>2、元数据应用</h4><p>数据的真正价值在于数据驱动决策，通过数据指导运营。通过数据驱动的方法，我们能够判断趋势，从而展开有效行动，帮助自己发现问题，推动创新或解决方案的产生。这就是数据化运营。同样，对于元数据，可以用于指导数据相关人员进行日常工作，实现数据化“运营”。</p><hr><h2 id="第十三章-计算管理"><a href="#第十三章-计算管理" class="headerlink" title="第十三章 计算管理"></a>第十三章 计算管理</h2><h4 id="1、系统优化"><a href="#1、系统优化" class="headerlink" title="1、系统优化"></a>1、系统优化</h4><h6 id="（1）堆优化器HBO（Heap-Based-Optimizer）"><a href="#（1）堆优化器HBO（Heap-Based-Optimizer）" class="headerlink" title="（1）堆优化器HBO（Heap-Based Optimizer）"></a>（1）堆优化器HBO（Heap-Based Optimizer）</h6><p>HBO是根据任务历史执行情况为任务分配更合理的资源，包括内存、CPU以及Instance个数。HBO是对集群资源分配的一种优化，概括起来就是：任务执行历史＋集群状态信息＋优化规则→更优的执行配置。</p><p><strong>原理：</strong></p><ul><li><p>基础资源数量的逻辑：</p><ul><li>对于Map Task，系统需要初始化不同的输入数据量，根据期望的每个Map能处理的数据量，再结合用户提交任务的输入数据量，就可以估算出用户提交的任务所需要的Map数量。</li><li>对于Reduce Task，比较Hive使用Map输入数据量，MaxCompute使用最近7天Reduce对应Map的平均输出数据量作为Reduce的输入数据量，用于计算Instance的数量。对于Reduce个数的估算与Map估算基本相同。</li></ul></li><li><p>加权资源数量的逻辑</p><ul><li>于Map Task，系统需要初始化期望的每个Map能处理的数据量。通过该Map在最近一段时间内的平均处理速度与系统设定的期望值做比较，如果平均处理速度小于期望值，则按照同等比例对基础资源数量进行加权，估算出该Map的加权资源数量。</li><li>对于ReduceTask，方法同上。</li></ul></li><li><p>最终的Instance个数为：基础资源估算值＋加权资源估算值。</p><ul><li>CPU／内存分配逻辑：类似于Instance分配逻辑，也是采用基础资源估算值＋加权资源估算值的方法。</li></ul></li></ul><p><strong>效果：</strong></p><ul><li>提高CPU利用率</li><li>提高内存利用率</li><li>提高Instance并发数</li><li>降低执行时长</li></ul><h6 id="（2）基于代价的优化方式CBO（Cost-Based-Optimization）"><a href="#（2）基于代价的优化方式CBO（Cost-Based-Optimization）" class="headerlink" title="（2）基于代价的优化方式CBO（Cost-Based Optimization）"></a>（2）基于代价的优化方式CBO（Cost-Based Optimization）</h6><p>根据收集的统计信息来计算每种执行方式的代价，进而选择最优的执行方式。</p><p><strong>原理：</strong></p><ul><li><p>Meta Manager</p><ul><li>Meta模块主要提供元数据信息，包括表的元数据、统计信息元数据等。当优化器在选择计划时，需要根据元数据的一些信息进行优化。</li></ul></li><li><p>Statistics</p><ul><li>Statistics主要是帮助优化器选择计划时，提供准确的统计信息。</li><li>优化器提供了UDF来收集统计信息，包括Distinct值、TopN值等，而Count值等统计信息是由底层Meta直接提供的。</li></ul></li><li><p>Rule Set</p><ul><li>优化规则是根据不同情况选择不同的优化点，然后由优化器根据代价模型（CostModel ）来选择启用哪些优化规则。</li></ul></li><li><p>Volcano Planner Core</p><ul><li>Volcano Planner是整个优化器的灵魂，它会将所有信息（Meta信息、统计信息、规则）统一起来处理，然后根据代价模型的计算，获得一个最优计划。</li></ul></li></ul><p><strong>新特性：</strong></p><ul><li>重新排序Join：将Join的所有不同输入进行一个全排列，然后找到代价最小的一个排列。</li><li>自动MapJoin：自动MapJoin充分利用优化器的代价模型进行估算，获得更优的MapJoin方式，而不是通过Hint方式来进行处理。</li></ul><h4 id="2、任务优化"><a href="#2、任务优化" class="headerlink" title="2、任务优化"></a>2、任务优化</h4><h6 id="（1）Map倾斜"><a href="#（1）Map倾斜" class="headerlink" title="（1）Map倾斜"></a>（1）Map倾斜</h6><p>在Map端读数据时，由于读入数据的文件大小分布不均匀，因此会导致有些Map Instance读取并且处理的数据特别多，而有些Map Instance处理的数据特别少，造成Map端长尾。</p><p><strong>常见的倾斜场景：</strong></p><ul><li>上游表文件的大小特别不均匀，并且小文件特别多，导致当前表Map端读取的数据分布不均匀，引起长尾。</li><li>Map端做聚合时，由于某些Map Instance读取文件的某个值特别多而引起长尾，主要是指Count Distinct操作。</li></ul><p><strong>解决方案：</strong></p><p>第一种情况导致的Map端长尾，可通过对上游合并小文件，同时调节本节点的小文件的参数来进行优化，即通过设置“set odps.sql. mapper.merge.limit.size&#x3D;64”和“set odps.sql.mapper.split.size&#x3D;256”两个参数来调节，其中第一个参数用于调节Map任务的Map Instance的个数：第二个参数用于调节单个Map Instance读取的小文件个数，防止由于小文件过多导致Map Instance读取的数据量很不均匀；两个参数配合调整。</p><p>第二种情况通过“distribute by rand()”会将Map端分发后的数据重新按照随机值再进行一次分发。原先不加随机分发函数时，Map阶段需要与使用Map Join的小表进行笛卡儿积操作，Map端完成了大小表的分发和笛卡儿积操作。使用随机分布函数后，Map端只负责数据的分发，不再有复杂的聚合或者笛卡儿积操作，因此不会导致Map端长尾。</p><h6 id="（2）Join倾斜"><a href="#（2）Join倾斜" class="headerlink" title="（2）Join倾斜"></a>（2）Join倾斜</h6><p>如果某个Key上的数据量比较大，则会导致该Instance执行时间较长。其表现为：在执行日志中该Join Task的大部分Instance都已执行完成，但少数几个Instance一直处于执行中（这种现象称之为长尾）。</p><p><strong>常见的倾斜场景：</strong></p><ul><li>Join的某路输入比较小，可以采用Map Join，避免分发引起长尾。</li><li>Join的每路输入都较大，且长尾是空值导致的，可以将空值处理成随机值，避免聚集。</li><li>Join的每路输入都较大，且长尾是热点值导致的，可以对热点值和非热点值分别进行处理，再合并数据。</li></ul><p><strong>解决方案：</strong></p><ul><li><p>MapJoin方案</p><ul><li>Join倾斜时，如果某路输入比较小，则可以采用MapJoin避免倾斜。MapJoin的原理是将Join操作提前到Map端执行，将小表读入内存，顺序扫描大表完成Join。这样可以避免因为分发key不均匀导致数据倾斜。</li></ul></li><li><p>Join因为空值导致长尾</p><ul><li>将空值处理成随机值。因为空值无法关联上，只是分发到一处，因此处理成随机值既不会影响关联结果，也能很好地避免聚焦导致长尾。</li></ul></li><li><p>Join因为热点值导致长尾</p><ul><li>取热点key</li><li>取出非热点数据</li><li>取出热点数据</li><li>将上面取到的非热点数据和热点数据通过“unionall”合并后即得到完整的日志数据，并且关联了商品信息</li></ul></li></ul><h6 id="（3）Reduce倾斜"><a href="#（3）Reduce倾斜" class="headerlink" title="（3）Reduce倾斜"></a>（3）Reduce倾斜</h6><p>Distinct操作，数据无法在Map端的Shuffle阶段根据GroupBy 先做一次聚合操作，以减少传输的数据量，而是将所有的数据都传输到Reduce端，当key的数据分发不均匀时，就会导致Reduce端长尾。</p><p><strong>常见的倾斜场景：</strong></p><ul><li>对同一个表按照维度对不同的列进行Count Distinct操作，造成Map端数据膨胀，从而使得下游的Join和Reduce出现链路上的长尾。</li><li>Map端直接做聚合时出现key值分布不均匀，造成Reduce端长尾。</li><li>动态分区数过多时可能造成小文件过多，从而引起Reduce端长尾。</li><li>多个Distinct同时出现在一段SQL代码中时，数据会被分发多次，不仅会造成数据膨胀N倍，还会把长尾现象放大N倍。</li></ul><p><strong>解决方案：</strong></p><p>第二种情况，可以对热点key进行单独处理，然后通过“UnionAll”合并。（参考“Join倾斜”）</p><p>第三种情况，可以把符合不同条件的数据放到不同的分区，避免通过多次“InsertOverwrite，，写人表中，特别是分区数比较多时，能够很好地简化代码。</p><p>第四种情况，可以先分别进行查询，执行GroupBy原表粒度+ id，然后在子查询外GroupBy原表粒度，最后进行Join操作。（拆分再合并）</p><hr><h2 id="第十四章-存储和成本管理"><a href="#第十四章-存储和成本管理" class="headerlink" title="第十四章 存储和成本管理"></a>第十四章 存储和成本管理</h2><p>在大数据时代，移动互联、社交网络、数据分析、云服务等应用迅速普及，对数据中心提出了革命性的需求，存储管理已经成为IT核心之一。对于数据爆炸式的增长，存储管理也将面临着一系列挑战。如何有效地降低存储资源的消耗，节省存储成本，将是存储管理孜孜追求的目标。</p><h2 id="第十五章-数据质量"><a href="#第十五章-数据质量" class="headerlink" title="第十五章 数据质量"></a>第十五章 数据质量</h2><p>随着IT向DT时代的转变，数据的重要性不言而喻，数据的应用也日趋繁茂，数据正扮演着一个极其重要的角色。数据质量是数据分析结论有效性和准确性的基础，也是这一切的前提。</p><h4 id="1、数据质量保障原则"><a href="#1、数据质量保障原则" class="headerlink" title="1、数据质量保障原则"></a>1、数据质量保障原则</h4><ul><li><p>完整性：完整性是指数据的记录和信息是否完整，是否存在缺失的情况。</p></li><li><p>准确性：准确性是指数据中记录的信息和数据是否准确，是否存在异常或者错误的信息。</p></li><li><p>一致性：一致性一般体现在跨度很大的数据仓库体系中，对于同一份数据，必须保证一致性。</p></li><li><p>及时性：在确保数据的完整性、准确性和一致性后，接下来就要保障数据能够及时产出，这样才能体现数据的价值。</p></li></ul><h4 id="2、数据质量方法"><a href="#2、数据质量方法" class="headerlink" title="2、数据质量方法"></a>2、数据质量方法</h4><p><img src="/2023/03/20/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A8%E3%80%8A%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%9A%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E8%B7%B5%E3%80%8B/15.1.png"></p><h4 id="3、数据资产等级定义"><a href="#3、数据资产等级定义" class="headerlink" title="3、数据资产等级定义"></a>3、数据资产等级定义</h4><ul><li>毁灭性质，即数据一旦出错，将会引起重大资产损失，面临重大收益损失，造成重大公关风险。</li><li>全局性质，即数据直接或者间接用于集团级业务和效果的评估、重要平台的运维、对外数据产品的透露、影响用户在网站的行为等。</li><li>局部性质，即数据直接或间接用于内部一般数据产品或者运营／产品报告，如果出现问题会给事业部或业务线造成影响，或者造成工作效率损失。</li><li>一般性质，即数据主要用于小二的日常数据分析，出现问题几乎不会带来影响或者带来的影响极小。</li><li>未知性质，不能明确说出数据的应用场景，则标注为未知。</li></ul><hr><h2 id="第十六章-数据应用"><a href="#第十六章-数据应用" class="headerlink" title="第十六章 数据应用"></a>第十六章 数据应用</h2><h4 id="1、生意参谋"><a href="#1、生意参谋" class="headerlink" title="1、生意参谋"></a>1、生意参谋</h4><h6 id="（1）看我情"><a href="#（1）看我情" class="headerlink" title="（1）看我情"></a>（1）看我情</h6><p>在生意参谋上，“我情”的数据主要基于店铺经营全链路的各个环节进行设计。以“经营分析”为例，这个板块依次为商家提供流量、商品、交易、服务、物流、营销等不同环节的数据服务，不同服务还能再往下细分，如在“流量分析”下，还会再提供流量地图、访客分析、装修分析等更细粒度的数据。</p><h6 id="（2）看行情"><a href="#（2）看行情" class="headerlink" title="（2）看行情"></a>（2）看行情</h6><p>生意参谋通过市场行情，为商家提供了行业维度的大盘分析，包括行业洞察、搜索词分析、人群画像等。其中，行业洞察可以从品牌、产品、属性、商品、店铺等粒度对本行业数据进行分析：通过搜索词分析可以了解不同关键词的近日表现，从而反推消费者偏好；人群画像能从人群维度人手，直接提供买家人群、卖家人群、搜索人群三大人群的数据洞察信息。</p><h6 id="（3）看敌情"><a href="#（3）看敌情" class="headerlink" title="（3）看敌情"></a>（3）看敌情</h6><p>在保障商家隐私和数据安全的前提下提供竞争分析。</p><h6 id="（4）架构图"><a href="#（4）架构图" class="headerlink" title="（4）架构图"></a>（4）架构图</h6><p><img src="/2023/03/20/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A8%E3%80%8A%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%9A%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E8%B7%B5%E3%80%8B/16.1.png"></p><h6 id="（5）全景图"><a href="#（5）全景图" class="headerlink" title="（5）全景图"></a>（5）全景图</h6><p><img src="/2023/03/20/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A8%E3%80%8A%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%9A%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E8%B7%B5%E3%80%8B/16.2.png"></p><h4 id="2、对内数据产品平台"><a href="#2、对内数据产品平台" class="headerlink" title="2、对内数据产品平台"></a>2、对内数据产品平台</h4><p>通过数据产品将数据转化为用户更优做决策和行动的依据。数据产品有多种形态，包括最简单常见的报表（如静态报表、Dashboard等简单统计分析）、多维分析（OLAP、即席查询分析等工具型数据产品）、专题分析型数据产品（面向某一类业务场景，沉淀分析思路）、智能型数据应用产品（如个性化搜索、推荐、广告定向推送、精准营销等，这类数据应用产品的发展较为成熟，且大都在数据外面穿了一层外衣，使非专业的用户并不能直观地感受到它是数据产品）</p><h6 id="（1）整体架构"><a href="#（1）整体架构" class="headerlink" title="（1）整体架构"></a>（1）整体架构</h6><p><img src="/2023/03/20/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A8%E3%80%8A%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%9A%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E8%B7%B5%E3%80%8B/16.3.png"></p><h6 id="（2）数据监控"><a href="#（2）数据监控" class="headerlink" title="（2）数据监控"></a>（2）数据监控</h6><p>对于所有内部普通运营小二，都有查看或分析业务数据的需求，阿里数据平台提供最基础的报表工具，供用户自助取数、多维分析、DIY个性化数据门户。</p><h6 id="（3）专题分析"><a href="#（3）专题分析" class="headerlink" title="（3）专题分析"></a>（3）专题分析</h6><p>对于专题运营小二，如行业运营小二，对类目有强烈的分析诉求，按照分析师沉淀的成熟分析思路组织数据，实现行业运营小二自助分析行业异动原因，发现行业潜在机会，实现“人人都是分析师”，提高数据化运营的效率和质量。</p><h6 id="（4）应用分析"><a href="#（4）应用分析" class="headerlink" title="（4）应用分析"></a>（4）应用分析</h6><p>对于很多业务系统的流程，数据是其中不可缺少的一环，通过对接前台系统，实现数据的自动化。</p><h6 id="（5）数据决策"><a href="#（5）数据决策" class="headerlink" title="（5）数据决策"></a>（5）数据决策</h6><p>对于高管和决策者，既需要宏观的业务数据，又需要可下沉的数据，还需要丰富的趋势数据来辅助决策，需要通过数据了解业务进展、当前进展是否合理、接下来的业务方向等，针对此类需求提供定制化的数据产品供决策参考，为高管提供宏观决策分析支撑平台，分析历史数据规律，预测未来发展趋势，洞察全行业动态。</p><hr>]]></content>
      
      
      <categories>
          
          <category> TalkingAbout </category>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> 数据仓库 </tag>
            
            <tag> 建模 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SQL小练1</title>
      <link href="/2023/03/16/SQL%E5%B0%8F%E7%BB%831/"/>
      <url>/2023/03/16/SQL%E5%B0%8F%E7%BB%831/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>前言：</strong></p><p>这是一个快失业的大学牲为了在简历上写熟练使用SQL而做的简单练习，越写感觉自己越菜。。。很多常见的语法根本不会，所以借由New Bing进行学习记录。主要采用记录我用的很少&#x2F;没用过的关键词为主，同时记录了我遇到的不错的SQL题。因为篇幅不宜过长，所以SQL小练不会超过10个一文。</p><p>改文记录如下：</p><p>（1）CASE</p><p>（2）UNION</p><p>（3）CONCAT &amp;&amp; CONCAT_WS</p><p>（4）COLLECT &amp;&amp; COLLECT_SET 【Hive SQL】</p><p>（5）CAST</p><p>（6）ROW_NUMBER</p><p>（7）ROUND()</p><p>（8）LAG() &amp;&amp; LEAD()</p><p>（9）LATERAL VIEW</p><p>（10）UDTF简述</p></blockquote><h4 id="1、SQL语法case的具体操作"><a href="#1、SQL语法case的具体操作" class="headerlink" title="1、SQL语法case的具体操作"></a>1、SQL语法case的具体操作</h4><p>SQL语法case的具体操作是一种条件表达式，用于根据条件执行不同的操作。SQL语法case有两种形式：简单的case和搜索的case。</p><p>简单的case是将一个表达式与一组简单表达式进行比较以确定结果。其语法如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CASE</span> 表达式</span><br><span class="line">  <span class="keyword">WHEN</span> 值<span class="number">1</span> <span class="keyword">THEN</span> 结果<span class="number">1</span></span><br><span class="line">  <span class="keyword">WHEN</span> 值<span class="number">2</span> <span class="keyword">THEN</span> 结果<span class="number">2</span></span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">ELSE</span> 结果N</span><br><span class="line"><span class="keyword">END</span></span><br></pre></td></tr></table></figure><p>搜索的case是计算一组布尔表达式以确定结果¹²。其语法如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CASE</span> </span><br><span class="line">  <span class="keyword">WHEN</span> 条件<span class="number">1</span> <span class="keyword">THEN</span> 结果<span class="number">1</span></span><br><span class="line">  <span class="keyword">WHEN</span> 条件<span class="number">2</span> <span class="keyword">THEN</span> 结果<span class="number">2</span></span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">ELSE</span> 结果N</span><br><span class="line"><span class="keyword">END</span></span><br></pre></td></tr></table></figure><p>以下是两个例子：</p><ul><li>在OrderDetails表中，根据Quantity的大小返回不同的文本¹</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> OrderID, Quantity,</span><br><span class="line"><span class="keyword">CASE</span> </span><br><span class="line">  <span class="keyword">WHEN</span> Quantity <span class="operator">&gt;</span> <span class="number">30</span> <span class="keyword">THEN</span> <span class="string">&#x27;The quantity is greater than 30&#x27;</span></span><br><span class="line">  <span class="keyword">WHEN</span> Quantity <span class="operator">=</span> <span class="number">30</span> <span class="keyword">THEN</span> <span class="string">&#x27;The quantity is 30&#x27;</span></span><br><span class="line">  <span class="keyword">ELSE</span> <span class="string">&#x27;The quantity is under 30&#x27;</span></span><br><span class="line"><span class="keyword">END</span> <span class="keyword">AS</span> QuantityText </span><br><span class="line"><span class="keyword">FROM</span> OrderDetails;</span><br></pre></td></tr></table></figure><ul><li>在Customers表中，按照City排序，如果City为空，则按照Country排序¹</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> CustomerName, City, Country </span><br><span class="line"><span class="keyword">FROM</span> Customers </span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> (<span class="keyword">CASE</span> </span><br><span class="line">            <span class="keyword">WHEN</span> City <span class="keyword">IS</span> <span class="keyword">NULL</span> <span class="keyword">THEN</span> Country </span><br><span class="line">            <span class="keyword">ELSE</span> City </span><br><span class="line">          <span class="keyword">END</span>);</span><br></pre></td></tr></table></figure><p>(1) SQL CASE Expression - W3Schools. <a href="https://www.w3schools.com/sql/sql_case.asp">https://www.w3schools.com/sql/sql_case.asp</a></p><p>(2) SQL CASE 语句. <a href="https://www.w3schools.cn/sql/sql_case.asp">https://www.w3schools.cn/sql/sql_case.asp</a></p><p>(3) CASE statement in SQL - SQL Shack. <a href="https://www.sqlshack.com/case-statement-in-sql/">https://www.sqlshack.com/case-statement-in-sql/</a></p><p>(4) SQL CASE - 1Keydata SQL 語法教學. <a href="https://www.1keydata.com/tw/sql/sql-case.html">https://www.1keydata.com/tw/sql/sql-case.html</a></p><hr><h4 id="2、SQL语法UNION的具体操作"><a href="#2、SQL语法UNION的具体操作" class="headerlink" title="2、SQL语法UNION的具体操作"></a>2、SQL语法UNION的具体操作</h4><p>SQL语法Union的具体操作是一种集合运算符，用于合并两个或多个SELECT语句的结果集。SQL语法Union有两种形式：Union和Union All。</p><p>Union是将两个或多个SELECT语句的结果集合并起来，并去除重复的记录。其语法如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> 列名 <span class="keyword">FROM</span> 表名<span class="number">1</span></span><br><span class="line"><span class="keyword">UNION</span></span><br><span class="line"><span class="keyword">SELECT</span> 列名 <span class="keyword">FROM</span> 表名<span class="number">2</span></span><br></pre></td></tr></table></figure><p>请注意，Union内部的每个SELECT语句必须拥有相同数量的列，列也必须拥有相似的数据类型，同时，每条SELECT语句中的列的顺序必须相同。</p><p>Union All是将两个或多个SELECT语句的结果集合并起来，并保留重复的记录¹²。其语法如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> 列名 <span class="keyword">FROM</span> 表名<span class="number">1</span></span><br><span class="line"><span class="keyword">UNION</span> <span class="keyword">ALL</span></span><br><span class="line"><span class="keyword">SELECT</span> 列名 <span class="keyword">FROM</span> 表名<span class="number">2</span></span><br></pre></td></tr></table></figure><p>以下是两个例子：</p><ul><li>在Websites表和apps表中，选取所有不同的country</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> country <span class="keyword">FROM</span> Websites </span><br><span class="line"><span class="keyword">UNION</span> </span><br><span class="line"><span class="keyword">SELECT</span> country <span class="keyword">FROM</span> apps </span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> country;</span><br></pre></td></tr></table></figure><ul><li>在Websites表和apps表中，选取所有中国(CN)的数据，并保留重复值</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> country, name <span class="keyword">FROM</span> Websites </span><br><span class="line"><span class="keyword">WHERE</span> country<span class="operator">=</span><span class="string">&#x27;CN&#x27;</span> </span><br><span class="line"><span class="keyword">UNION</span> <span class="keyword">ALL</span> </span><br><span class="line"><span class="keyword">SELECT</span> country, app_name <span class="keyword">FROM</span> apps </span><br><span class="line"><span class="keyword">WHERE</span> country<span class="operator">=</span><span class="string">&#x27;CN&#x27;</span> </span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> country;</span><br></pre></td></tr></table></figure><p>(1) SQL UNION 操作符 | 菜鸟教程. <a href="https://www.runoob.com/sql/sql-union.html">https://www.runoob.com/sql/sql-union.html</a></p><p>(2) SQL UNION 和 UNION ALL 操作符. <a href="https://www.w3school.com.cn/sql/sql_union.asp">https://www.w3school.com.cn/sql/sql_union.asp</a></p><p>(3) SQL UNION - 1Keydata SQL 語法教學. <a href="https://www.1keydata.com/tw/sql/sqlunion.html">https://www.1keydata.com/tw/sql/sqlunion.html</a></p><hr><h4 id="3、SQL语法concat和concat-ws的区别和具体操作"><a href="#3、SQL语法concat和concat-ws的区别和具体操作" class="headerlink" title="3、SQL语法concat和concat_ws的区别和具体操作"></a>3、SQL语法concat和concat_ws的区别和具体操作</h4><p>SQL语法concat和concat_ws的区别和具体操作是：</p><ul><li>concat函数是将多个字符串连接成一个字符串，如果有任何一个参数为null，则返回值为null。其语法如下：</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CONCAT(string1, string2, ..., stringN)</span><br></pre></td></tr></table></figure><ul><li>concat_ws函数是一种特殊形式的concat函数，也是将多个字符串连接成一个字符串，但是可以一次性指定分隔符（concat_ws就是concat with separator）。其语法如下：</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CONCAT_WS(separator, string1, string2, ..., stringN)</span><br></pre></td></tr></table></figure><p>请注意，concat_ws函数的第一个参数是其它参数间的分隔符，不能为null，如果为null，则返回值为null。</p><p>以下是两个例子：</p><ul><li>在employee_tbl表中，选取id和name列，并用空格连接起来，使用concat函数</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> CONCAT(id,<span class="string">&#x27; &#x27;</span>,name) <span class="keyword">AS</span> id_name <span class="keyword">FROM</span> employee_tbl;</span><br></pre></td></tr></table></figure><ul><li>在employee_tbl表中，选取id和name列，并用空格连接起来，使用concat_ws函数</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> CONCAT_WS(<span class="string">&#x27; &#x27;</span>,id,name) <span class="keyword">AS</span> id_name <span class="keyword">FROM</span> employee_tbl;</span><br></pre></td></tr></table></figure><p>(1) SQL里的concat() 以及concat_ws() 函数的使用_concat_ws函数_一个学习Java的小菜鸟的博客-CSDN博客. <a href="https://blog.csdn.net/weixin_48633655/article/details/106838028">https://blog.csdn.net/weixin_48633655/article/details/106838028</a></p><p>(2) concat和 concat_ws 区别以及踩出来的坑骑白马de图图的博客-CSDN博客. <a href="https://blog.csdn.net/liusuoyin/article/details/108110718">https://blog.csdn.net/liusuoyin/article/details/108110718</a></p><p>(3) MySQL中concat()、concat_ws()、group_concat()函数使用技巧与心得 - 知乎. <a href="https://zhuanlan.zhihu.com/p/257399676">https://zhuanlan.zhihu.com/p/257399676</a></p><hr><h4 id="4、Hive-SQL语法collect和collect-set的区别和具体操作"><a href="#4、Hive-SQL语法collect和collect-set的区别和具体操作" class="headerlink" title="4、Hive SQL语法collect和collect_set的区别和具体操作"></a>4、Hive SQL语法collect和collect_set的区别和具体操作</h4><p>SQL语法collect和collect_set的区别和具体操作是：</p><ul><li>collect函数是一个Hive函数，用于将分组中的某列转为一个数组返回。其语法如下：</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">COLLECT</span>(<span class="keyword">column</span>)</span><br></pre></td></tr></table></figure><ul><li>collect_set函数也是一个Hive函数，用于将分组中的某列转为一个数组返回，但是会去除重复的值。其语法如下：</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">COLLECT_SET(<span class="keyword">column</span>)</span><br></pre></td></tr></table></figure><p>请注意，collect函数和collect_set函数一般搭配group by使用，并且可以和concat_ws函数连用，以指定分隔符。</p><p>以下是两个例子：</p><ul><li>在student表中，按照class分组，将每个班级的name列转为一个数组，并用逗号连接起来，使用collect函数</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> class, CONCAT_WS(<span class="string">&#x27;,&#x27;</span>, <span class="keyword">COLLECT</span>(name)) <span class="keyword">AS</span> names <span class="keyword">FROM</span> student <span class="keyword">GROUP</span> <span class="keyword">BY</span> class;</span><br></pre></td></tr></table></figure><ul><li>在student表中，按照class分组，将每个班级的name列转为一个数组，并用逗号连接起来，使用collect_set函数</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> class, CONCAT_WS(<span class="string">&#x27;,&#x27;</span>, COLLECT_SET(name)) <span class="keyword">AS</span> names <span class="keyword">FROM</span> student <span class="keyword">GROUP</span> <span class="keyword">BY</span> class;</span><br></pre></td></tr></table></figure><p>(1) 数仓工具—Hive语法之collect_set 和 collect_list(17)浊酒南街的博客-CSDN博客. <a href="https://blog.csdn.net/weixin_43597208/article/details/117450304">https://blog.csdn.net/weixin_43597208/article/details/117450304</a></p><p>(2) SQL小知识点系列-3-collect_list&#x2F;collect_set（列转行） - 知乎. <a href="https://zhuanlan.zhihu.com/p/440574505">https://zhuanlan.zhihu.com/p/440574505</a></p><p>(3) Spark SQL里concat_ws和collect_set的作用 - 大葱拌豆腐 - 博客园. <a href="https://www.cnblogs.com/itboys/p/11217815.html">https://www.cnblogs.com/itboys/p/11217815.html</a></p><hr><h4 id="5、SQL语法cast的具体操作"><a href="#5、SQL语法cast的具体操作" class="headerlink" title="5、SQL语法cast的具体操作"></a>5、SQL语法cast的具体操作</h4><p>SQL语法cast的具体操作是：</p><ul><li>cast函数用于将某种数据类型的表达式显式转换为另一种数据类型。其语法如下：</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">CAST</span>(expression <span class="keyword">AS</span> data_type)</span><br></pre></td></tr></table></figure><p>请注意，expression可以是任何有效的SQL表达式，data_type可以是以下类型之一：BINARY，CHAR，DATE，DATETIME，TIME，DECIMAL，SIGNED，UNSIGNED。</p><p>以下是两个例子：</p><ul><li>将文本字符串’12’转换为整型</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">CAST</span>(<span class="string">&#x27;12&#x27;</span> <span class="keyword">AS</span> <span class="type">INT</span>);</span><br></pre></td></tr></table></figure><ul><li>将日期时间2021-01-01 12:34:56转换为日期</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">CAST</span>(<span class="string">&#x27;2021-01-01 12:34:56&#x27;</span> <span class="keyword">AS</span> <span class="type">DATE</span>);</span><br></pre></td></tr></table></figure><p>(1) SQL之CAST函数用法-百度经验. <a href="https://jingyan.baidu.com/article/90808022fab5dbfd91c80f35.html">https://jingyan.baidu.com/article/90808022fab5dbfd91c80f35.html</a></p><p>(2) SQL CAST() - SQL. <a href="https://sql.sh/fonctions/cast">https://sql.sh/fonctions/cast</a></p><p>(3) SQL Server CAST() Function - W3Schools. <a href="https://www.w3schools.com/sql/func_sqlserver_cast.asp">https://www.w3schools.com/sql/func_sqlserver_cast.asp</a></p><p>(4) SQL-cast()函数 - 知乎. <a href="https://zhuanlan.zhihu.com/p/343703794">https://zhuanlan.zhihu.com/p/343703794</a></p><p>(5) MySQL cast()函数 - MySQL教程. <a href="https://www.yiibai.com/mysql/cast.html">https://www.yiibai.com/mysql/cast.html</a></p><p>(6) sql CAST用法 - 水狼一族 - 博客园. <a href="https://www.cnblogs.com/shuilangyizu/p/5952526.html">https://www.cnblogs.com/shuilangyizu/p/5952526.html</a></p><hr><h4 id="6、SQL语法row-number-的具体操作"><a href="#6、SQL语法row-number-的具体操作" class="headerlink" title="6、SQL语法row_number()的具体操作"></a>6、SQL语法row_number()的具体操作</h4><p>row_number()是一个窗口函数，它为查询结果集中的每一行分配一个连续的整数。它的语法如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">row_number</span>() <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> <span class="keyword">column</span> <span class="keyword">order</span> <span class="keyword">by</span> <span class="keyword">column</span>)</span><br></pre></td></tr></table></figure><p>其中，partition by子句用于指定分组依据，order by子句用于指定排序依据。如果没有partition by子句，则对整个结果集进行编号；如果没有order by子句，则按照任意顺序进行编号。</p><p>以下是两个例子：</p><ul><li>例1：从employee表中选择name、salary、department三列，并按照department分组，在每个分组内按照salary降序排序，给每一行添加一个序号rank。</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> name, salary, department, <span class="built_in">row_number</span>() <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> department <span class="keyword">order</span> <span class="keyword">by</span> salary <span class="keyword">desc</span>) <span class="keyword">as</span> rank</span><br><span class="line"><span class="keyword">from</span> employee;</span><br></pre></td></tr></table></figure><p>这样就会得到类似如下的表格：</p><table><thead><tr><th>name</th><th>salary</th><th>department</th><th>rank</th></tr></thead><tbody><tr><td>Alice</td><td>8000</td><td>IT</td><td>1</td></tr><tr><td>Bob</td><td>7000</td><td>IT</td><td>2</td></tr><tr><td>Cathy</td><td>6000</td><td>IT</td><td>3</td></tr><tr><td>David</td><td>9000</td><td>HR</td><td>1</td></tr><tr><td>Eva</td><td>8000</td><td>HR</td><td>2</td></tr><tr><td>Frank</td><td>7000</td><td>HR</td><td>3</td></tr></tbody></table><ul><li>例2：从student表中选择name、score、class三列，并按照class分组，在每个分组内按照score降序排序，给每一行添加一个序号rank。</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> name, score, class, <span class="built_in">row_number</span>() <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> class <span class="keyword">order</span> <span class="keyword">by</span> score <span class="keyword">desc</span>) <span class="keyword">as</span> rank</span><br><span class="line"><span class="keyword">from</span> student;</span><br></pre></td></tr></table></figure><p>这样就会得到类似如下的表格：</p><table><thead><tr><th>name</th><th>score</th><th>class</th><th>rank</th></tr></thead><tbody><tr><td>Amy</td><td>95</td><td>A</td><td>1</td></tr><tr><td>Ben</td><td>90</td><td>A</td><td>2</td></tr><tr><td>Carl</td><td>85</td><td>A</td><td>3</td></tr><tr><td>Dan</td><td>80</td><td>A</td><td>4</td></tr><tr><td>Eve</td><td>75</td><td>A</td><td>5</td></tr><tr><td>Fay</td><td>92</td><td>B</td><td>1</td></tr><tr><td>Glen</td><td>88</td><td>B</td><td>2</td></tr><tr><td>Hank</td><td>84</td><td>B</td><td>3</td></tr><tr><td>Iris</td><td>80</td><td>B</td><td>4</td></tr><tr><td>Jack</td><td>76</td><td>B</td><td>5</td></tr></tbody></table><p>(1) SQL ROW_NUMBER() Function - SQL Tutorial. <a href="https://www.sqltutorial.org/sql-window-functions/sql-row_number/">https://www.sqltutorial.org/sql-window-functions/sql-row_number/</a></p><p>(2) SQL Server Row_number()函数 - SQL Server教程. <a href="https://www.yiibai.com/sqlserver/sql-server-row_number-function.html">https://www.yiibai.com/sqlserver/sql-server-row_number-function.html</a></p><p>(3) 【SQL】連番を振るROW_NUMBER関数を解説！一番よく使う順位付け関数をマスターしよう | ポテパンスタイル. <a href="https://style.potepan.com/articles/23566.html">https://style.potepan.com/articles/23566.html</a></p><p>(4) ROW_NUMBER (Transact-SQL) - SQL Server | Microsoft Learn. <a href="https://learn.microsoft.com/en-us/sql/t-sql/functions/row-number-transact-sql?view=sql-server-ver16">https://learn.microsoft.com/en-us/sql/t-sql/functions/row-number-transact-sql?view=sql-server-ver16</a></p><p>(5) SQL中row_number函数用法_sql的rownumber_sharon@zhang的博客-CSDN博客. <a href="https://blog.csdn.net/baidu_41797613/article/details/120489521">https://blog.csdn.net/baidu_41797613/article/details/120489521</a></p><hr><h4 id="7、SQL语法round-的具体操作"><a href="#7、SQL语法round-的具体操作" class="headerlink" title="7、SQL语法round()的具体操作"></a>7、SQL语法round()的具体操作</h4><p>SQL round()函数用于把数值字段舍入为指定的小数位数。它的语法是：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">round(number, decimals [, operation])</span><br></pre></td></tr></table></figure><p>其中，number是要舍入的数值，decimals是要保留的小数位数，operation是可选的参数，表示是否进行截断而不是四舍五入。如果operation为0或省略，则进行四舍五入；如果operation为非0，则进行截断。</p><p>举两个例子：</p><ul><li>如果要把3.14159舍入为两位小数，可以使用：</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> round(<span class="number">3.14159</span>, <span class="number">2</span>);</span><br></pre></td></tr></table></figure><p>结果是3.14。</p><ul><li>如果要把1234.5678截断为个位数，可以使用：</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> round(<span class="number">1234.5678</span>, <span class="number">0</span>, <span class="number">1</span>);</span><br></pre></td></tr></table></figure><p>结果是1230。</p><p>(1) SQL ROUND() 函数. <a href="https://www.w3school.com.cn/sql/sql_func_round.asp">https://www.w3school.com.cn/sql/sql_func_round.asp</a></p><p>(2) SQL Server ROUND() Function - W3Schools. <a href="https://www.w3schools.com/SQL/func_sqlserver_round.asp">https://www.w3schools.com/SQL/func_sqlserver_round.asp</a></p><p>(3) SQL Server ROUND() Function - TutorialsTeacher. <a href="https://www.tutorialsteacher.com/sqlserver/round-function">https://www.tutorialsteacher.com/sqlserver/round-function</a></p><p>(4) How to Use the ROUND() Function in SQL | LearnSQL.com. <a href="https://learnsql.com/blog/round-function-sql/">https://learnsql.com/blog/round-function-sql/</a></p><p>(5) SQL ROUND() 函數 &#x2F; Function - SQL 語法教學 Tutorial. <a href="https://www.fooish.com/sql/round-function.html">https://www.fooish.com/sql/round-function.html</a></p><p>(6) ROUND (Transact-SQL) - SQL Server | Microsoft Learn. <a href="https://learn.microsoft.com/en-us/sql/t-sql/functions/round-transact-sql?view=sql-server-ver16">https://learn.microsoft.com/en-us/sql/t-sql/functions/round-transact-sql?view=sql-server-ver16</a></p><hr><h4 id="8、SQL语法lag-和lead-的具体操作"><a href="#8、SQL语法lag-和lead-的具体操作" class="headerlink" title="8、SQL语法lag()和lead()的具体操作"></a>8、SQL语法lag()和lead()的具体操作</h4><p>SQL语法中的lag()和lead()函数是两种窗口分析函数，可以在同一次查询中取出同一字段的前N行的数据(Lag)和后N行的数据(Lead)作为独立的列。这两个函数有三个参数，第一个参数是列名，第二个参数是偏移的行数，第三个参数是超出记录窗口时的默认值。</p><p>举两个例子：</p><ol><li>查询每个员工的姓名、部门、工资以及比他工资高的下一个员工的姓名和工资。</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> name, dept, salary,</span><br><span class="line"><span class="built_in">lead</span>(name) <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> dept <span class="keyword">order</span> <span class="keyword">by</span> salary <span class="keyword">desc</span>) <span class="keyword">as</span> next_name,</span><br><span class="line"><span class="built_in">lead</span>(salary) <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> dept <span class="keyword">order</span> <span class="keyword">by</span> salary <span class="keyword">desc</span>) <span class="keyword">as</span> next_salary</span><br><span class="line"><span class="keyword">from</span> employee;</span><br></pre></td></tr></table></figure><ol start="2"><li>查询每个商品的名称、价格以及与上一个商品价格的差异。</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> product, price,</span><br><span class="line">price <span class="operator">-</span> <span class="built_in">lag</span>(price) <span class="keyword">over</span> (<span class="keyword">order</span> <span class="keyword">by</span> price <span class="keyword">asc</span>) <span class="keyword">as</span> diff</span><br><span class="line"><span class="keyword">from</span> goods;</span><br></pre></td></tr></table></figure><p>(1) 关于SQL的LAG()和LEAD()函数_lag sql_一碗烫烫的汤圆的博客-CSDN博客. <a href="https://blog.csdn.net/a5276957/article/details/103808997">https://blog.csdn.net/a5276957/article/details/103808997</a></p><p>(2) Sql窗口分析函数【lead、lag详解】 - 知乎. <a href="https://zhuanlan.zhihu.com/p/466752301">https://zhuanlan.zhihu.com/p/466752301</a></p><p>(3) lag lead分析函数 - 知乎. <a href="https://zhuanlan.zhihu.com/p/347444265">https://zhuanlan.zhihu.com/p/347444265</a></p><p>(4) SQL中lag()和lead()函数使用_lag函数_Schafferyy的博客-CSDN博客. <a href="https://blog.csdn.net/Schaffer_W/article/details/109029630">https://blog.csdn.net/Schaffer_W/article/details/109029630</a></p><hr><h4 id="9、SQL语法lateral-view的具体操作"><a href="#9、SQL语法lateral-view的具体操作" class="headerlink" title="9、SQL语法lateral view的具体操作"></a>9、SQL语法lateral view的具体操作</h4><p>SQL语法中的lateral view子句是用于和split、explode等UDTF（用户自定义表生成函数）一起使用的，它能够将一行数据拆成多行数据，在此基础上可以对拆分后的数据进行聚合。lateral view首先为原始表的每行调用UDTF，UTDF会把一行拆分成一或者多行，lateral view再把结果组合，产生一个支持别名表的虚拟表。</p><p>举两个例子：</p><ol><li>查询每个学生的姓名、年龄以及选修的课程名称。</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> name, age, course</span><br><span class="line"><span class="keyword">from</span> student</span><br><span class="line"><span class="keyword">lateral</span> <span class="keyword">view</span> explode(split(courses, <span class="string">&#x27;,&#x27;</span>)) t <span class="keyword">as</span> course;</span><br></pre></td></tr></table></figure><ol start="2"><li>查询每个订单的编号、金额以及包含的商品名称和数量。</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> order_id, amount, product, quantity</span><br><span class="line"><span class="keyword">from</span> <span class="keyword">order</span></span><br><span class="line"><span class="keyword">lateral</span> <span class="keyword">view</span> explode(items) t <span class="keyword">as</span> item</span><br><span class="line"><span class="keyword">lateral</span> <span class="keyword">view</span> explode(map_keys(item)) k <span class="keyword">as</span> product</span><br><span class="line"><span class="keyword">lateral</span> <span class="keyword">view</span> explode(map_values(item)) v <span class="keyword">as</span> quantity;</span><br></pre></td></tr></table></figure><p>(1) SQL 之 lateral view explode()_hankl1990的博客-CSDN博客. <a href="https://blog.csdn.net/weixin_36630761/article/details/76146842">https://blog.csdn.net/weixin_36630761/article/details/76146842</a></p><p>(2) Lateral View语法 - 简书. <a href="https://www.jianshu.com/p/4804db6a3677">https://www.jianshu.com/p/4804db6a3677</a></p><p>(3) LATERAL VIEW 子句 - Azure Databricks - Databricks SQL. <a href="https://learn.microsoft.com/zh-cn/azure/databricks/sql/language-manual/sql-ref-syntax-qry-select-lateral-view">https://learn.microsoft.com/zh-cn/azure/databricks/sql/language-manual/sql-ref-syntax-qry-select-lateral-view</a></p><p>(4) SQL: lateral view &amp; explode &amp; split (分割&amp;侧视图) - 知乎. <a href="https://zhuanlan.zhihu.com/p/538641683">https://zhuanlan.zhihu.com/p/538641683</a></p><p>(5) LATERAL VIEW clause - Azure Databricks - Databricks SQL. <a href="https://learn.microsoft.com/en-us/azure/databricks/sql/language-manual/sql-ref-syntax-qry-select-lateral-view">https://learn.microsoft.com/en-us/azure/databricks/sql/language-manual/sql-ref-syntax-qry-select-lateral-view</a></p><hr><h4 id="10、SQL-UDTF-常见操作"><a href="#10、SQL-UDTF-常见操作" class="headerlink" title="10、SQL UDTF 常见操作"></a>10、SQL UDTF 常见操作</h4><p>SQL UDTF（用户自定义表值函数）是一种可以返回多行数据的函数，它可以接受0个、1个或多个标量值作为输入参数。UDTF可以在查询的FROM子句中使用，也可以和lateral view子句结合使用。</p><p>举两个例子：</p><ol><li>创建一个UDTF，用于将一个字符串按照指定的分隔符拆分成多行。</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">function</span> split_string(str string, sep string)</span><br><span class="line"><span class="keyword">returns</span> <span class="keyword">table</span> (word string)</span><br><span class="line"><span class="keyword">as</span></span><br><span class="line"><span class="keyword">return</span> <span class="keyword">select</span> <span class="keyword">value</span> <span class="keyword">as</span> word <span class="keyword">from</span> <span class="built_in">unnest</span>(string_to_array(str, sep));</span><br></pre></td></tr></table></figure><ol start="2"><li>创建一个UDTF，用于将一个日期范围转换成每一天的日期。</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">function</span> date_range(start_date <span class="type">date</span>, end_date <span class="type">date</span>)</span><br><span class="line"><span class="keyword">returns</span> <span class="keyword">table</span> (<span class="keyword">day</span> <span class="type">date</span>)</span><br><span class="line"><span class="keyword">as</span></span><br><span class="line"><span class="keyword">return</span> <span class="keyword">select</span> generate_series(start_date, end_date, <span class="type">interval</span> <span class="string">&#x27;1 day&#x27;</span>)::<span class="type">date</span> <span class="keyword">as</span> <span class="keyword">day</span>;</span><br></pre></td></tr></table></figure><p>(1) Flink自定义表值函数UDTF开发、注册和使用流程_实时计算 Flink版-阿里云帮助中心. <a href="https://help.aliyun.com/document_detail/188055.html">https://help.aliyun.com/document_detail/188055.html</a></p><p>(2) Tabular SQL UDFs (UDTFs) | Snowflake Documentation. <a href="https://docs.snowflake.com/en/developer-guide/udf/sql/udf-sql-tabular-functions">https://docs.snowflake.com/en/developer-guide/udf/sql/udf-sql-tabular-functions</a></p><p>(3) mySql的UDF是什么 - 洪福必成 - 博客园. <a href="https://www.cnblogs.com/ghc666/p/8609067.html">https://www.cnblogs.com/ghc666/p/8609067.html</a></p><p>(4) Udf in SQL Server: Create UDF (User Defined Function) in SQL Database. <a href="https://www.webtrainingroom.com/sql/udf">https://www.webtrainingroom.com/sql/udf</a></p><p>(5) User-Defined Functions - SQL Server | Microsoft Learn. <a href="https://learn.microsoft.com/en-us/sql/relational-databases/user-defined-functions/user-defined-functions?view=sql-server-ver16">https://learn.microsoft.com/en-us/sql/relational-databases/user-defined-functions/user-defined-functions?view=sql-server-ver16</a></p><hr><h4 id="课后小练"><a href="#课后小练" class="headerlink" title="课后小练"></a>课后小练</h4><h6 id="（1）常见SQL——行列转换"><a href="#（1）常见SQL——行列转换" class="headerlink" title="（1）常见SQL——行列转换"></a>（1）常见SQL——行列转换</h6><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">描述：表中记录了各年份各部门的平均绩效考核成绩。 </span><br><span class="line">表名：t1 </span><br><span class="line">表结构： a <span class="comment">-- 年份 </span></span><br><span class="line">        b <span class="comment">-- 部门 </span></span><br><span class="line">        c <span class="comment">-- 绩效得分 </span></span><br><span class="line">表内容： a  b  c </span><br><span class="line">      <span class="number">2014</span> B  <span class="number">9</span> </span><br><span class="line">      <span class="number">2015</span> A  <span class="number">8</span> </span><br><span class="line">      <span class="number">2014</span> A  <span class="number">10</span> </span><br><span class="line">      <span class="number">2015</span> B  <span class="number">7</span> </span><br><span class="line">问题一：多行转多列 </span><br><span class="line">问题描述：将上述表内容转为如下输出结果所示： </span><br><span class="line">     a col_A col_B </span><br><span class="line">   <span class="number">2014</span>   <span class="number">10</span>   <span class="number">9</span> </span><br><span class="line">   <span class="number">2015</span>   <span class="number">8</span>    <span class="number">7</span> </span><br><span class="line">   </span><br><span class="line">   </span><br><span class="line">参考答案： </span><br><span class="line"><span class="keyword">select</span> a, </span><br><span class="line">       <span class="built_in">max</span>(<span class="keyword">case</span> <span class="keyword">when</span> b<span class="operator">=</span>&quot;A&quot; <span class="keyword">then</span> c <span class="keyword">end</span>) col_A, </span><br><span class="line">       <span class="built_in">max</span>(<span class="keyword">case</span> <span class="keyword">when</span> b<span class="operator">=</span>&quot;B&quot; <span class="keyword">then</span> c <span class="keyword">end</span>) col_B</span><br><span class="line"><span class="keyword">from</span> t1 </span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> a;</span><br></pre></td></tr></table></figure><h6 id="（2）多行转多列（背景和第一题相同）"><a href="#（2）多行转多列（背景和第一题相同）" class="headerlink" title="（2）多行转多列（背景和第一题相同）"></a>（2）多行转多列（背景和第一题相同）</h6><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">问题描述：<span class="number">2014</span> 年公司组织架构调整，导致部门出现多个绩效，业务及人员不同，</span><br><span class="line">无法合并算绩效，源表内容如下：</span><br><span class="line">    <span class="number">2014</span> B <span class="number">9</span></span><br><span class="line">    <span class="number">2015</span> A <span class="number">8</span></span><br><span class="line">    <span class="number">2014</span> A <span class="number">10</span></span><br><span class="line">    <span class="number">2015</span> B <span class="number">7</span></span><br><span class="line">    <span class="number">2014</span> B <span class="number">6</span></span><br><span class="line">输出结果如下所示：</span><br><span class="line">    a col_A col_B</span><br><span class="line">   <span class="number">2014</span> <span class="number">10</span>  <span class="number">6</span>,<span class="number">9</span></span><br><span class="line">   <span class="number">2015</span>  <span class="number">8</span>   <span class="number">7</span></span><br><span class="line">   </span><br><span class="line">   </span><br><span class="line">参考答案:</span><br><span class="line"><span class="keyword">select</span> a,</span><br><span class="line">       <span class="built_in">max</span>(<span class="keyword">case</span> <span class="keyword">when</span> b<span class="operator">=</span>&quot;A&quot; <span class="keyword">then</span> c <span class="keyword">end</span>) col_A,</span><br><span class="line">       <span class="built_in">max</span>(<span class="keyword">case</span> <span class="keyword">when</span> b<span class="operator">=</span>&quot;B&quot; <span class="keyword">then</span> c <span class="keyword">end</span>) col_B</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">       <span class="keyword">select</span> a, b,</span><br><span class="line">              concat_ws(&quot;,&quot;,collect_set(<span class="built_in">cast</span>(c <span class="keyword">as</span> string))) <span class="keyword">as</span> c       # 将相同部门数字转换为字符串后进行拼接</span><br><span class="line">       <span class="keyword">from</span> t1</span><br><span class="line">       <span class="keyword">group</span> <span class="keyword">by</span> a,b</span><br><span class="line">)tmp</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> a;</span><br></pre></td></tr></table></figure><h6 id="（3）按a分组取b字段排最小时对应的c字段"><a href="#（3）按a分组取b字段排最小时对应的c字段" class="headerlink" title="（3）按a分组取b字段排最小时对应的c字段"></a>（3）按a分组取b字段排最小时对应的c字段</h6><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">表名：t2</span><br><span class="line">表字段及内容：</span><br><span class="line">    a   b  c</span><br><span class="line">  <span class="number">2014</span>  A  <span class="number">3</span></span><br><span class="line">  <span class="number">2014</span>  B  <span class="number">1</span></span><br><span class="line">  <span class="number">2014</span>  C  <span class="number">2</span></span><br><span class="line">  <span class="number">2015</span>  A  <span class="number">4</span></span><br><span class="line">  <span class="number">2015</span>  D  <span class="number">3</span></span><br><span class="line">问题一：按 a 分组取 b 字段最小时对应的 c 字段</span><br><span class="line">输出结果如下所示：</span><br><span class="line">   a   min_c</span><br><span class="line">  <span class="number">2014</span>   <span class="number">3</span></span><br><span class="line">  <span class="number">2015</span>   <span class="number">4</span></span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">参考答案:</span><br><span class="line"><span class="keyword">select</span> a, c <span class="keyword">as</span> min_c</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">(</span><br><span class="line">       <span class="keyword">select</span> a, b, c,</span><br><span class="line">              <span class="built_in">row_number</span>() <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> a <span class="keyword">order</span> <span class="keyword">by</span> b) <span class="keyword">as</span> rn</span><br><span class="line">       <span class="keyword">from</span> t2</span><br><span class="line">) a</span><br><span class="line"><span class="keyword">where</span> rn <span class="operator">=</span> <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SQL</span>解释：</span><br><span class="line">从t2表中选择a、b、c三列，按照a列进行分组，然后在每个分组内按照b列进行排序，给每一行添加一个序号rn。然后从这个结果中选择a、c两列，并将c列重命名为min_c。最后只保留rn等于<span class="number">1</span>的行，也就是每个分组内b列最小的那一行。</span><br></pre></td></tr></table></figure><h6 id="（4）按a分组按b字段排序，对b取累计排名比例"><a href="#（4）按a分组按b字段排序，对b取累计排名比例" class="headerlink" title="（4）按a分组按b字段排序，对b取累计排名比例"></a>（4）按a分组按b字段排序，对b取累计排名比例</h6><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">表名：t3</span><br><span class="line">表字段及内容：</span><br><span class="line">    a   b   c</span><br><span class="line">  <span class="number">2014</span>  A   <span class="number">3</span></span><br><span class="line">  <span class="number">2014</span>  B   <span class="number">1</span></span><br><span class="line">  <span class="number">2014</span>  C   <span class="number">2</span></span><br><span class="line">  <span class="number">2015</span>  A   <span class="number">4</span></span><br><span class="line">  <span class="number">2015</span>  D   <span class="number">7</span></span><br><span class="line">输出结果如下所示：</span><br><span class="line">    a  b  ratio_c</span><br><span class="line">  <span class="number">2014</span> A   <span class="number">0.33</span></span><br><span class="line">  <span class="number">2014</span> B   <span class="number">0.67</span></span><br><span class="line">  <span class="number">2014</span> C   <span class="number">1.00</span></span><br><span class="line">  <span class="number">2015</span> A   <span class="number">0.50</span></span><br><span class="line">  <span class="number">2015</span> D   <span class="number">1.00</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">参考答案：</span><br><span class="line"><span class="keyword">select</span> a, b,</span><br><span class="line">       round(<span class="built_in">row_number</span>() <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> a <span class="keyword">order</span> <span class="keyword">by</span> b) </span><br><span class="line">             <span class="operator">/</span> (<span class="built_in">count</span>(c) <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> a)),<span class="number">2</span>) <span class="keyword">as</span> ratio_c</span><br><span class="line"><span class="keyword">from</span> t3</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> a,b</span><br><span class="line"></span><br><span class="line"><span class="keyword">SQL</span>解释：</span><br><span class="line">从t3表中选择a、b两列，并计算一个新的列ratio_c，它表示每个a分组内的行号与该分组内c列的总数的比值，保留两位小数。然后按照a、b两列进行排序。</span><br></pre></td></tr></table></figure><h6 id="（5）按a分组按b字段排序，对c取平均值"><a href="#（5）按a分组按b字段排序，对c取平均值" class="headerlink" title="（5）按a分组按b字段排序，对c取平均值"></a>（5）按a分组按b字段排序，对c取平均值</h6><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">表名：t4</span><br><span class="line">表字段及内容：</span><br><span class="line">    a   b   c</span><br><span class="line">   <span class="number">2014</span> A   <span class="number">3</span></span><br><span class="line">   <span class="number">2014</span> B   <span class="number">1</span></span><br><span class="line">   <span class="number">2014</span> C   <span class="number">2</span></span><br><span class="line">   <span class="number">2015</span> A   <span class="number">4</span></span><br><span class="line">   <span class="number">2015</span> D   <span class="number">3</span></span><br><span class="line">问题描述：前一行与当前行的均值！</span><br><span class="line">输出结果如下所示：</span><br><span class="line">    a   b avg_c</span><br><span class="line">   <span class="number">2014</span> A   <span class="number">3</span></span><br><span class="line">   <span class="number">2014</span> B   <span class="number">2</span></span><br><span class="line">   <span class="number">2014</span> C  <span class="number">1.5</span></span><br><span class="line">   <span class="number">2015</span> A   <span class="number">4</span></span><br><span class="line">   <span class="number">2015</span> D  <span class="number">3.5</span></span><br><span class="line">   </span><br><span class="line">   </span><br><span class="line">参考答案：</span><br><span class="line"><span class="keyword">select</span> a, b,</span><br><span class="line">       <span class="keyword">case</span> <span class="keyword">when</span> lag_c <span class="keyword">is</span> <span class="keyword">null</span> <span class="keyword">then</span> c</span><br><span class="line">       <span class="keyword">else</span> (c<span class="operator">+</span>lag_c)<span class="operator">/</span><span class="number">2</span> <span class="keyword">end</span> <span class="keyword">as</span> avg_c</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">(</span><br><span class="line">       <span class="keyword">select</span> a, b, c,</span><br><span class="line">              <span class="built_in">lag</span>(c,<span class="number">1</span>) <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> a <span class="keyword">order</span> <span class="keyword">by</span> b) <span class="keyword">as</span> lag_c</span><br><span class="line">       <span class="keyword">from</span> t4</span><br><span class="line">)temp;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Little Tips </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SQL </tag>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java混合Scala</title>
      <link href="/2023/03/05/Java%E6%B7%B7%E5%90%88Scala/"/>
      <url>/2023/03/05/Java%E6%B7%B7%E5%90%88Scala/</url>
      
        <content type="html"><![CDATA[<p>最近这几天把Scala学完了，被他的数据处理能力深深的折服。</p><p>尤其是WordCount功能，之前接过的一个小外包就有这种要求的分词功能，当时是使用的开源依赖Kumo词库，但是别人的东西怎么实现的说实话真不知道。</p><p>后来和同学探讨的过程中了解到Elastic Search是可以实现分词功能的，效果极佳但是资源占用大，对于一个小项目来说可能资源大部分回响ES倾斜，所以虽然有所耳闻但是并没有实际实践。</p><p>再后来学了Hadoop框架，了解到WordCount在上面的实现是拆分成Map和Reduce两个阶段，但是其过程主要面向框架中处理，虽然都是Java但是其实很多过程并不清晰（其实是没能力手撸一个）</p><p>然后学了Scala，刚好Scala最后也是介绍了WordCount功能，本质上Scala对WordCount的处理也是一个Map、Reduce的过程，但是代码简洁（可读性不强），流程也更清晰。于是想着Java和Scala都是基于JVM，那干脆Java中调用Scala，看能否实现。</p><h6 id="Scala代码如下："><a href="#Scala代码如下：" class="headerlink" title="Scala代码如下："></a>Scala代码如下：</h6><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util</span><br><span class="line"><span class="keyword">import</span> scala.collection.<span class="type">JavaConverters</span>._  <span class="comment">// 格式转换依赖包</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">wc</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">WordCount</span></span>(stringList: util.<span class="type">List</span>[<span class="type">String</span>]): util.<span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = &#123;</span><br><span class="line">    <span class="keyword">val</span> s = stringList.asScala.toList  <span class="comment">// 格式转换Java.List --&gt; Scala.List</span></span><br><span class="line">    <span class="comment">// 1) 将句子切分成单词</span></span><br><span class="line">    <span class="keyword">val</span> wordList: <span class="type">List</span>[<span class="type">String</span>] = s.flatMap(str =&gt; str.split(<span class="string">&quot; &quot;</span>))</span><br><span class="line">    <span class="comment">// 2) 将相同的单词放置在一起</span></span><br><span class="line">    <span class="keyword">val</span> wordToWordsMap: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">List</span>[<span class="type">String</span>]] = wordList.groupBy(word =&gt; word)</span><br><span class="line">    <span class="comment">// 3) 对相同的单词进行计数</span></span><br><span class="line">    <span class="comment">// (word, list) =&gt; (word, count)</span></span><br><span class="line">    <span class="keyword">val</span> wordToCountMap: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Int</span>] = wordToWordsMap.map(tuple =&gt; (tuple._1, tuple._2.size))</span><br><span class="line">    <span class="comment">// 4) 对计数完成后的结果进行排序（降序）</span></span><br><span class="line">    <span class="keyword">val</span> sortList: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordToCountMap.toList.sortWith &#123;</span><br><span class="line">      (left, right) =&gt; &#123;</span><br><span class="line">        left._2 &gt; right._2</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    sortList.asJava  <span class="comment">// 以Java.List的格式返回</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="Java端代码如下："><a href="#Java端代码如下：" class="headerlink" title="Java端代码如下："></a>Java端代码如下：</h6><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.Tuple2;</span><br><span class="line"><span class="comment">// 这里引用了Scala元组</span></span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WCImp</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        List&lt;String&gt; sl = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;String&gt;();</span><br><span class="line">        sl.add(<span class="string">&quot;Hello Scala Hbase kafka&quot;</span>);</span><br><span class="line">        sl.add(<span class="string">&quot;Hello Scala Hbase&quot;</span>);</span><br><span class="line">        sl.add(<span class="string">&quot; Hello Scala&quot;</span>);</span><br><span class="line">        sl.add(<span class="string">&quot;Hello&quot;</span>);</span><br><span class="line">        System.out.println(sl);</span><br><span class="line"></span><br><span class="line">        <span class="type">wc</span> <span class="variable">word</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">wc</span>();</span><br><span class="line">        List&lt;Tuple2&lt;String, Object&gt;&gt; s = word.WordCount(sl);</span><br><span class="line">        System.out.println(s);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果：</span></span><br><span class="line"><span class="comment">// [(Hello,4), (Scala,3), (Hbase,2), (,1), (kafka,1)]</span></span><br></pre></td></tr></table></figure><p>关于这个Tuple元组类型，Java中没有原生支持元组，所以还是导入了一个Scala下的依赖包实现Java端数据的传输，这里是为了方便将传回的数据再在Java中进行处理，如果直接作为结果输出可以不需要在Scala那边转Java格式。</p><p>如果还想全部变成Java的话可以尝试在Scala那边将tuple转成map或者其他之后再传，但个人认为这个WordCount的例子中并没有必要。同时，在Java中引入Tuple2后也能实现Scala的元组操作，我觉得挺好玩的（但真不一定很方便）</p><p>关于Scala的数据类型，Java中一切类继承自Object类，所以String自然也是Object的子类；但是Scala中略有不同（参照博客<a href="https://www.cnblogs.com/tt-day/p/16499623.html">scala中的数据类型</a>），Scala的基本数据类型继承自AnyVal，但是String，我们通过源码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> java.lang;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.ObjectStreamField;</span><br><span class="line"><span class="keyword">import</span> java.io.UnsupportedEncodingException;</span><br><span class="line"><span class="keyword">import</span> java.nio.charset.Charset;</span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">class</span> <span class="title class_">String</span></span><br><span class="line">    <span class="keyword">implements</span> <span class="title class_">java</span>.io.Serializable, Comparable&lt;String&gt;, CharSequence</span><br></pre></td></tr></table></figure><p>索引自String.java，所以说Scala中的String和Java中的String基本上是一样的（甚至跳转到的源码也是一样的）。作为参照，可以参考Scala其他数据类型的源码（以Int为例）：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> scala</span><br><span class="line"></span><br><span class="line"><span class="comment">// Int.scala</span></span><br><span class="line"><span class="keyword">final</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Int</span> <span class="title">private</span> <span class="keyword">extends</span> <span class="title">AnyVal</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">toByte</span></span>: <span class="type">Byte</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">toShort</span></span>: <span class="type">Short</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">toChar</span></span>: <span class="type">Char</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">toInt</span></span>: <span class="type">Int</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">toLong</span></span>: <span class="type">Long</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">toFloat</span></span>: <span class="type">Float</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">toDouble</span></span>: <span class="type">Double</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// AnyVal.scala</span></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">AnyVal</span> <span class="keyword">extends</span> <span class="title">Any</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getClass</span></span>(): <span class="type">Class</span>[_ &lt;: <span class="type">AnyVal</span>] = <span class="literal">null</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样就能很好的解释为什么在Scala和Java进行数据类型转换的时候String只能转String，而其他的都是AnyVal转Object了。</p><p>回到Java的Tuple2中，应该对于Tuple包有相应的包处理，但是我只是一时兴起，并没有过多深入，所以只是浅浅的在Java中对Tuple进行一个输出观察，代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (Tuple2 i: s) &#123;</span><br><span class="line">System.out.println(<span class="string">&quot;i =&quot;</span> + i);</span><br><span class="line">    System.out.println(<span class="string">&quot;i.toString =&quot;</span> + i.toString());</span><br><span class="line">    System.out.println(<span class="string">&quot;Normal: &quot;</span> + i._1 + <span class="string">&quot; &quot;</span> +  i._2);</span><br><span class="line">    <span class="type">String</span> <span class="variable">s1</span> <span class="operator">=</span> (String) i._1;</span><br><span class="line">    <span class="type">Integer</span> <span class="variable">s2</span> <span class="operator">=</span> (Integer) i._2;</span><br><span class="line">    System.out.println(<span class="string">&quot;Change: &quot;</span> + s1 + <span class="string">&quot; &quot;</span> + s2);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果：</span></span><br><span class="line"><span class="comment">// i =(Hello,4)</span></span><br><span class="line"><span class="comment">// i.toString =(Hello,4)</span></span><br><span class="line"><span class="comment">// Normal: Hello 4</span></span><br><span class="line"><span class="comment">// Change: Hello 4</span></span><br></pre></td></tr></table></figure><p>可以看出，输出结果在Java能够正常使用，用getClass函数查看：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">System.out.println(<span class="string">&quot;Normal: &quot;</span> + i._1.getClass() + <span class="string">&quot; &quot;</span> +  i._2.getClass());</span><br><span class="line">System.out.println(<span class="string">&quot;Normal: &quot;</span> + i._1.getClass() + <span class="string">&quot; &quot;</span> +  i._2.getClass());</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果：</span></span><br><span class="line"><span class="comment">// Normal: class java.lang.String class java.lang.Integer</span></span><br><span class="line"><span class="comment">// Change: class java.lang.String class java.lang.Integer</span></span><br></pre></td></tr></table></figure><p>但是注意！虽然其类型都是Java.lang.*，但是tuple中的仍然属于Object类型，需要转换。</p><p>本来还想做个Scala、Java转Json和读取Json的测试，但是需要引入其他的依赖，暂时先进行搁置。</p><hr><p>参考资料：</p><p><a href="http://cn.voidcc.com/question/p-vrjwohbl-bad.html">为什么String与Int，Boolean，Byte …在scala中不同？</a></p><p><a href="https://qa.1r1g.com/sf/ask/47229941/">将Java集合转换为Scala集合</a></p><p><a href="https://www.dovov.com/javascala-3.html">将Java集合转换为Scala集合</a></p>]]></content>
      
      
      <categories>
          
          <category> Little Tips </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Scala </tag>
            
            <tag> 大数据 </tag>
            
            <tag> 数据分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如果不由我来做决策，那么错误决策与我无关（《避开错误决策的4个陷阱》）</title>
      <link href="/2023/02/26/%E5%A6%82%E6%9E%9C%E4%B8%8D%E7%94%B1%E6%88%91%E6%9D%A5%E5%81%9A%E5%86%B3%E7%AD%96%EF%BC%8C%E9%82%A3%E4%B9%88%E9%94%99%E8%AF%AF%E5%86%B3%E7%AD%96%E4%B8%8E%E6%88%91%E6%97%A0%E5%85%B3%EF%BC%88%E3%80%8A%E9%81%BF%E5%BC%80%E9%94%99%E8%AF%AF%E5%86%B3%E7%AD%96%E7%9A%844%E4%B8%AA%E9%99%B7%E9%98%B1%E3%80%8B%EF%BC%89/"/>
      <url>/2023/02/26/%E5%A6%82%E6%9E%9C%E4%B8%8D%E7%94%B1%E6%88%91%E6%9D%A5%E5%81%9A%E5%86%B3%E7%AD%96%EF%BC%8C%E9%82%A3%E4%B9%88%E9%94%99%E8%AF%AF%E5%86%B3%E7%AD%96%E4%B8%8E%E6%88%91%E6%97%A0%E5%85%B3%EF%BC%88%E3%80%8A%E9%81%BF%E5%BC%80%E9%94%99%E8%AF%AF%E5%86%B3%E7%AD%96%E7%9A%844%E4%B8%AA%E9%99%B7%E9%98%B1%E3%80%8B%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h2 id="第一部分-大脑是如何做决策的"><a href="#第一部分-大脑是如何做决策的" class="headerlink" title="第一部分 大脑是如何做决策的"></a>第一部分 大脑是如何做决策的</h2><h4 id="大脑处理决策的功能"><a href="#大脑处理决策的功能" class="headerlink" title="大脑处理决策的功能"></a>大脑处理决策的功能</h4><h6 id="模式识别"><a href="#模式识别" class="headerlink" title="模式识别"></a>模式识别</h6><p>模式识别帮助我们对接收的信息进行评估，大脑的每个部位关注一种不同的信息并从过去的记忆信息中寻找匹配项。之后大脑的整合功能会接受已经发现的匹配项信号，并对缺失的信息做出估计。</p><ul><li>意外<ul><li>假如我们面对的是不熟悉得信息输入——尤其是那些表面上看起来似曾相识的信息——我们会以为自己辨认出了什么，而事实并非如此，这叫做误导性经验。我们的大脑可能储藏了过去经验的记忆，而那些记忆又与我们接收到的信息相关联，不幸的是，过去的经验可能和当前的情况不一样，对我们造成了误导。</li><li>我们的思维在我们接受信息之前就早有判断或是决定先入为主，而之前的判断和决定与当前的情况联系起来。如果这些判断不适用于当前情况，它们就会破坏我们既有的识别功能，误判接收到的信息，这是误导性预判。</li></ul></li><li>模式识别依赖于信息对称以及空缺填补，当我们经验丰富时这两个过程可以有效运作，但当我们自以为经验丰富而事实上并非如此时，错误在所难免。</li></ul><h6 id="情感标记"><a href="#情感标记" class="headerlink" title="情感标记"></a>情感标记</h6><p>大脑会给我们的想法和决策打赏情感标记，这些标记被模式识别匹配项触发后会告诉我们应该对其表示关注还是忽略，并且给我们指明行动方向。</p><p>情感标记让我们迅速行动，指引我们警惕关键信息，并瞬间选择某个行动计划。</p><ul><li>战略决策错综复杂，因而要做出至关重要的判断。对这些判断来说，推理和事实通常不足以证明是非对错，还需要本能、第六感和直觉的帮忙，而所有的这些都依赖于我们的情感标记。</li><li>情感交织在做决策的过程中，而且是决策过程必需和重要的组成部分。情感的大多数影响是无意识的，我们只有通过直觉才能意识到它们的存在。我们可以在一定程度上控制情感的影响，比如通过更多的分析，更多对事实的考虑，或者是更清楚地认识到引导我们情感的来源。但是我们无法消除情感的影响。</li><li>没有情感，我们无法做出决策。此外，情感大多数时候对我们的潜意识而不是意识产生影响，好消息是在这一过程中我们的情感被设定为大多数时候帮助我们轻松并且有效的得到正确的答案。</li></ul><h6 id="四个陷阱"><a href="#四个陷阱" class="headerlink" title="四个陷阱"></a>四个陷阱</h6><p>误导性经验、误导性预判、不适当的个人利益和不适当的情感依附是导致错误思维的四种根源，而错误思维会导致错误决策。</p><h6 id="抵御情感的扭曲作用"><a href="#抵御情感的扭曲作用" class="headerlink" title="抵御情感的扭曲作用"></a>抵御情感的扭曲作用</h6><ul><li>强烈的情感经验。我们可能对过去经历的成功、失败、恐惧或喜悦有着深刻的记忆，大多数时候这些情感可以帮助我们。</li><li>预判及先前决策。我们会给以前做出的判断和决策打上强烈的情感标记，如果这些判断无误，那么我们的情感可以帮助我们集中注意力。但是如果这些判断具有误导性，我们的情感就会让我们紧揪着它们不放，就算其他不迷信这些判断的人已经发现了问题的所在，我们依然会沉溺其中。</li><li>个人利益。在做决策时我们的个人利益经常受到威胁，如果这些决策仅仅影响我们自身，我们的情感标记会告诉我们正确答案。但是当我们的个人利益和我们为其他人所负的责任发生冲突时，我们的判断就会失衡。</li><li>情感依附。</li></ul><h4 id="一次一计划"><a href="#一次一计划" class="headerlink" title="一次一计划"></a>一次一计划</h4><p><img src="/2023/02/26/%E5%A6%82%E6%9E%9C%E4%B8%8D%E7%94%B1%E6%88%91%E6%9D%A5%E5%81%9A%E5%86%B3%E7%AD%96%EF%BC%8C%E9%82%A3%E4%B9%88%E9%94%99%E8%AF%AF%E5%86%B3%E7%AD%96%E4%B8%8E%E6%88%91%E6%97%A0%E5%85%B3%EF%BC%88%E3%80%8A%E9%81%BF%E5%BC%80%E9%94%99%E8%AF%AF%E5%86%B3%E7%AD%96%E7%9A%844%E4%B8%AA%E9%99%B7%E9%98%B1%E3%80%8B%EF%BC%89/1.1.png"></p><h6 id="预警过程"><a href="#预警过程" class="headerlink" title="预警过程"></a>预警过程</h6><ul><li>误导性经验最有可能在情况评估阶段干扰我们的思维，不管我们对模式识别错误还是模式的情感标记给我们提供了不合适的行动导向。但是误导性经验同样会导致我们选择不适当的计划或是对结果做出错误判断。</li><li>误导性判断最有可能在我们评估结果时扭曲我们的想法，它们让我们忠于错误的计划。但是它们也会让我们对情况产生误判或者是执着于某一个特定的行动计划——经常是过去有效的计划。</li><li>不适当的个人利益和不适当的情感依附最有可能影响我们对结果的评估方式：它们可以通过给错误的计划打上积极的标签让我们执迷于它。</li></ul><p><img src="/2023/02/26/%E5%A6%82%E6%9E%9C%E4%B8%8D%E7%94%B1%E6%88%91%E6%9D%A5%E5%81%9A%E5%86%B3%E7%AD%96%EF%BC%8C%E9%82%A3%E4%B9%88%E9%94%99%E8%AF%AF%E5%86%B3%E7%AD%96%E4%B8%8E%E6%88%91%E6%97%A0%E5%85%B3%EF%BC%88%E3%80%8A%E9%81%BF%E5%BC%80%E9%94%99%E8%AF%AF%E5%86%B3%E7%AD%96%E7%9A%844%E4%B8%AA%E9%99%B7%E9%98%B1%E3%80%8B%EF%BC%89/1.2.png"></p><hr><h2 id="第二部分-决策错误的原因"><a href="#第二部分-决策错误的原因" class="headerlink" title="第二部分 决策错误的原因"></a>第二部分 决策错误的原因</h2><h4 id="误导性经验"><a href="#误导性经验" class="headerlink" title="误导性经验"></a>误导性经验</h4><p>当我们的记忆包含和当前情况相似又存在重大误差的经验时，我们对当前情况的看法会被误导，对行动方案的选择也会步入歧途。</p><h6 id="两种偏差效应"><a href="#两种偏差效应" class="headerlink" title="两种偏差效应"></a>两种偏差效应</h6><ul><li>可得性启发法<ul><li>我们会根据某一事件在我们记忆中轻易“可得”的次数和概率，对某一件事情的频率、可能性以及可能性的原因做出判断，我们不会评估所有的数据。一份记忆“可得”可能是因为它能激起情感、形象、容易想象、或者具象化。</li><li>新近性和形象性偏差让我们更多的获取最近的形象和形象的信息而不是那些更老的、不那么形象的信息，尽管后者可能相关性更高。</li><li>可回溯性偏差让我们更多地使用容易获取的信息和记忆，甚至在难以获取的信息相关度更高的情况下也是如此。</li><li>假设联系偏差让我们在被问到两件事是否存在联系的时候会寻找存在联系的情况而不会去寻找不存在联系的情况，因此，我们会高估两件事之间的联系。</li></ul></li><li>代表性启发法<ul><li>当我们面对一个决策时，我们倾向于寻找这一决策和自己之前所做决策的相似方面，然后，我们使用过去决策成功时用到的简化算法或是类比法。</li><li>基本比率偏差让人们作决策的时候只考虑一些可获得的信息，而忽略了情况蕴含的未凸显的背景信息。</li><li>回归均值偏差：如果人们被要求估计企业的未来表现，他们倾向于根据过去的表现做出预测。</li></ul></li></ul><h4 id="误导性判断"><a href="#误导性判断" class="headerlink" title="误导性判断"></a>误导性判断</h4><p>预判通过给我们的思想打上情感标记的方式而影响决策。在决策过程中，这些情感标记帮助我们理清对各种情况的多种可能性解读，提供可采取的多种可能行动路线。情感标记加快了我们的模式识别和判断过程。</p><ul><li>过度自信偏差<ul><li>我们在处理陌生问题的时候，经常对自己所做的判断过度自信。</li><li>一旦你做出了预测，你会被该预测锚定，导致该预测两头所限定的范围都过于狭窄。</li></ul></li></ul><h6 id="误导性预判类型"><a href="#误导性预判类型" class="headerlink" title="误导性预判类型"></a>误导性预判类型</h6><ul><li>对情况的判断。这会让管理者们开始对自己棉缎的情况进行界定，界定会影响他们的决策。</li><li>对备选项的判断。</li><li>对目标或者是标准的判断。发展战略经常违背发展至关重要的预判下制定出来。</li><li>对我们能力的判断。我们经常对自己的能力过度自信。</li><li>对可能结果的判断。</li></ul><h6 id="辨别误导性预判"><a href="#辨别误导性预判" class="headerlink" title="辨别误导性预判"></a>辨别误导性预判</h6><ul><li>该决策设计的主要不确定性是什么？</li><li>主要决策人对这些不确定性是否做出了预判？</li><li>预判有客观证据支持吗？如果没有，它们可能具有误导性。</li></ul><h4 id="不适当的情感依附"><a href="#不适当的情感依附" class="headerlink" title="不适当的情感依附"></a>不适当的情感依附</h4><p>个人情感依附环绕在我们周围，并且会对任何一个决策产生关键的影响，有时会给我们造成极大的损害。</p><h6 id="影响决策的情感依附"><a href="#影响决策的情感依附" class="headerlink" title="影响决策的情感依附"></a>影响决策的情感依附</h6><ul><li>情感依附影响惊人的范围。从恋人到商标，情感依附能够形成十分广阔的范围，甚至是一系列十分奇怪的东西。</li><li>情感依附本质上可能是欢快的或险恶的。恐惧、憎恨和遗憾都能够影响到我们的决策，并且同希望、爱情以及幸福的回忆一样具有强烈的效果。</li><li>情感依附具有微妙的力量。</li></ul><h6 id="情感依附的来源"><a href="#情感依附的来源" class="headerlink" title="情感依附的来源"></a>情感依附的来源</h6><ul><li>同决策者一起工作的人们。</li><li>同决策者没有工作附属关系的人们。</li><li>商业元素。决策者对不同的业务单位、工厂、工地、功能发展出依附关系。</li><li>标志性的东西。</li><li>地点。决策者曾经工作过的地方、在关键时期所停留的地方，或者某一特殊经历发生的地方，能够导致明显且强有力的情感依附。</li></ul><h6 id="尝试剔除不适当的情感依附"><a href="#尝试剔除不适当的情感依附" class="headerlink" title="尝试剔除不适当的情感依附"></a>尝试剔除不适当的情感依附</h6><ul><li>决策者是不是对哪些选项如：人、地点或者东西存在情感依附或者地对情感吗？</li><li>是不是有哪些情感依附可能对主要利益主体的相关利益产生冲突呢？</li><li>是否存在哪些具有冲突性的情感依附，能够强烈到显著的扭曲决策者的决策吗？</li></ul><hr><h2 id="第三部分-红旗预警及防御策略"><a href="#第三部分-红旗预警及防御策略" class="headerlink" title="第三部分 红旗预警及防御策略"></a>第三部分 红旗预警及防御策略</h2><p>防御措施涉及的范围广泛，包括干预措施、过程变化、人们的选择、分析技巧以及其他机制。这些方法可以用来减少做出错误决策的风险。然而每个组织都拥有多种用于管理决策的过程，我们将防御措施定义为额外的措施，选择它们是因为它们对某一特定的决策而言是适当的。我们使用这一定义是因为它们能够为抵制错误决策提供安全保障，尽管使用它们也不能保证不犯任何错误。我们不能够消除人们的偏见，但是我们可以抵消它们所能产生的潜在影响。</p><h4 id="防御措施"><a href="#防御措施" class="headerlink" title="防御措施"></a>防御措施</h4><ul><li>经验、数据和分析<ul><li>要为决策者提供新的体验，或新的数据及分析。这么做可以从源头上降低做错决策的风险。</li><li>在商业中，有很多用于收集数据、扩展经验的方式。与关键客户之间的探讨，能够对新产品提供许多有价值的反馈。市场调查能够评估进入新市场的风险。还可以引进顾问，一部分是因为他们的专业技能和现成的人力，再者还因为他们相对而言比较客观。</li></ul></li><li>团队辩论和挑战<ul><li>进行一场挑战偏见的辩论，并不需要设计很复杂的过程。可能就是指针对某一问题。即使对方并不是这一问题的专家，辩论的过程也可以帮助你揭示一些假设和信念。在大型的组织中，精心策划辩论和挑战的典型方式就是组建决策团队。团队规模各不相同，可能从两个人到许多人不等。虽然从通常来讲，参加辩论的人较少才是更佳的做法。</li><li>选择让谁加入团队是至关重要的，这决定着挑战的质量。</li><li>对根深蒂固的观点进行挑战是防御措施的关键来源。强有力的领导需要强有力的挑战。</li></ul></li><li>管理<ul><li>管咯团队是很重要的支撑，用于否决任何决策团队已通过的错误决策。少数大型组织允许由决策提案人审批重要的决策。通常是由独立的非执行董事或者由受托人进行，以此来增加决策过程的客观性。</li></ul></li><li>监控<ul><li>监控过程追踪着决策过程，能够鼓励决策者在提出建议前进行细致的思考。如果决策者知道结果将被记录和宣传，那么这就足够促使他们“三思”了。</li><li>监控对于快速修正错误决策也有帮助，例如，如果早期表现令人失望的话，后期的投入可能会减少。</li><li>额外监控是最终的防弹墙：用于抵抗做出糟糕决策的最后一道防御措施。在没有其他可以替代的措施用来提供保护时，额外监控特别有用。</li></ul></li></ul><h6 id="红旗警示条件"><a href="#红旗警示条件" class="headerlink" title="红旗警示条件"></a>红旗警示条件</h6><ul><li>误导性经历</li><li>误导性预判</li><li>不适当的个人利益</li><li>不适当的感情依附</li></ul><h4 id="四个建议"><a href="#四个建议" class="headerlink" title="四个建议"></a>四个建议</h4><ul><li>保持简单——然后进行迭代<ul><li>首先保持简单，然后在第一个回答的基础上进行迭代。如果开始使用的是一种看似合理的方法，可以稍后在这种方法上进行重构。在一些真实复杂的情景下，修改你对因素的分析。关键是你要从某个地方开始，然后再以此为基础。</li><li>遵循“保持简单”的原则，先做出一个初始的分析，然后去和其他人讨论。事实上，“一次一计划”决策过程的影响是这样的。</li></ul></li><li>从最担心的红旗警示开始<ul><li>一旦选定了一条红旗警示，那么就要考虑一下哪些防御措施最适合用来处理这一红旗警示。然后再回过头去挑选另一条令你担忧的红旗警示。试问一下你自己，你选择的防御措施是否能够提供充分的保护。</li></ul></li><li>如果有疑问，按顺序考虑防御措施<ul><li>首先对新经验和新数据进行考虑。考虑一下怎么样才能利用辩论和挑战来帮助决策者调整她或他的思路，而下一个需要寻求防御措施的领域时管理过程。如果你仍然担心所做的决策是错误的，考虑一下加强监控过程的方式，那样可以鉴定出错误决策的结果，并且尽早有效率的处理。</li></ul></li><li>衡量每个防御措施的好处，抵制其副作用。</li></ul><hr>]]></content>
      
      
      <categories>
          
          <category> TalkingAbout </category>
          
          <category> 运营 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 运营 </tag>
            
            <tag> 决策 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>作为运营的第一本运营书（《从零开始做运营》）</title>
      <link href="/2023/02/12/%E4%BD%9C%E4%B8%BA%E8%BF%90%E8%90%A5%E7%9A%84%E7%AC%AC%E4%B8%80%E6%9C%AC%E8%BF%90%E8%90%A5%E4%B9%A6%EF%BC%88%E3%80%8A%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%81%9A%E8%BF%90%E8%90%A5%E3%80%8B%EF%BC%89/"/>
      <url>/2023/02/12/%E4%BD%9C%E4%B8%BA%E8%BF%90%E8%90%A5%E7%9A%84%E7%AC%AC%E4%B8%80%E6%9C%AC%E8%BF%90%E8%90%A5%E4%B9%A6%EF%BC%88%E3%80%8A%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%81%9A%E8%BF%90%E8%90%A5%E3%80%8B%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>前言：</strong></p><p>我加入工作室的时候职位是策划，在大三转成运营。但说是运营，其实在工作室中和打杂并无太大区别，尤其我还一直想转研发，所以混乱到自己也不知道要干什么。偶然在“打杂”的时候翻到这本《从零开始做运营》，这就是我和这本书的开始。因为是文科类性质的书（至少目前我是这么认为），所以暂且记录下书中我比较认同、感受的观点。也许写到总结时，会有不一样的发现。</p></blockquote><h2 id="互联网的世界，从来没有不需要运营的产品，也没有可以无视产品的运营。"><a href="#互联网的世界，从来没有不需要运营的产品，也没有可以无视产品的运营。" class="headerlink" title="互联网的世界，从来没有不需要运营的产品，也没有可以无视产品的运营。"></a>互联网的世界，从来没有不需要运营的产品，也没有可以无视产品的运营。</h2><h2 id="第一章-实话实说运营"><a href="#第一章-实话实说运营" class="headerlink" title="第一章 实话实说运营"></a>第一章 实话实说运营</h2><ul><li><p>产品经理的工作大部分是需求分析、文档写作以及资源沟通。一个好的产品经理，需要有“跟到底”的精神。</p></li><li><p>一个产品的成功，“三分靠实力，七分靠运气”。产品经理的苦衷在于，做了所有正确的事，实现了所有需求并且完成得非常漂亮，可是如果运气不好，产品就无法形成规模效应。</p></li><li><p>运营人员的成功靠什么呢？可能是“七分靠实力，三分靠运气”。运营人员的苦衷在于，运营需要积累，无论是实力的积累、经验的积累，还是对用户了解程度的积累、对数据敏感程度的积累，这其中的时间、实践、反思、错误，全都是消耗品。创意会随着时间的增⻓而消磨，手段会随着用户的熟悉而失效，最后能够留下来的，是运营人员⻓期磨炼出来的敏锐，是对用户熟知的引导手段的集结。</p></li><li><p>作为一个运营人员，你需要掌握每天流量、数据的变化，洞悉任何一个可能影响运营数据的因素，掌握所有可以提升运营数据的手</p><p>段。</p></li><li><p>产品的需求从用户中产生，在漫⻓的开发、测试、上线之后，产品经理的任务却并没有结束，产品经理还需要通过各种数据和渠道的反馈来了解这个上线的功能或者设计对用户到底有没有用处，用户究竟有没有去使用；如果用户使用了，那么如何让这个功能或者设计变得更好用、更值得用；如果用户没有使用，那么为什么他们不用，需求对应的功能或者设计是否有问题，还是缺乏功能的引导和说明。</p></li><li><p>一个运营指标是为何提出的，运营做的一堆工作究竟对指标有没有帮助，是否还可以持续地提升效果，是否需要将运营手段固化为产品模块，这就是“跟到底”。</p></li><li><p>我们始终应该明白如下两个准则：</p><ul><li>第一，永远不要奢望可以对一无是处的产品进行运营，更别幻想通过运营让这样的产品起死回生甚至走向成功。</li><li>第二，永远不要以为产品的设计完美到无需运营，即便是能够实现自运营的产品，也依然需要持续的运营引导才能达到自运营的状态。</li></ul></li><li><p>在任何一家公司、任何一个岗位，可能都需要坚持两三年，才能明白公司的具体情况、岗位的细节。但是现在，对很多人来说，不要提在一个岗位修炼两三年，让他们在一个公司工作两三年都是奢望。过热的环境、过多的机会让很多人跟着薪资走，哪里薪资高去哪里，哪个行业看起来有机会吸引更多的投资，哪个公司看起来更有机会上市，就往哪里去。很多人面临过多的机会，已经有了选择困难症，但殊不知这样频繁的选择不是你真正需要的，你需要的是让自己变得有责任心和有价值。</p></li><li><p>曾经有人说过，“产品经理是通往CEO（首席执行官）的训练营”。如果这句话是对的，那么运营就是通往COO（首席运营官）或者CMO（市场总监）的训练营。</p></li><li><p>运营入门大多先从非常基础甚至看似毫无价值的事情开始，其中一些工作甚至可以称之为体力活，很多人并不喜欢这样的工作：</p><ul><li>内容运营要做一些内容准备，具体工作很可能是非常基础的上传图片、编辑文本的工作，繁重而且很乏味。</li><li>活动运营要做活动的前期调研。</li><li>产品运营要做产品的前期调研，找各种人要各种数据和表格，打各种电话去研究用户的反馈信息，你会觉得自己像个客服，唠唠叨叨但是无从下手。</li></ul></li></ul><hr><h2 id="第二章-运营是个筐"><a href="#第二章-运营是个筐" class="headerlink" title="第二章 运营是个筐"></a>第二章 运营是个筐</h2><ul><li>运营是个筐，什么都能往里装。</li><li>曾经听人说过：“（互联网）产品是一项贯穿用户整个生命周期的设计行为。它根据用户的需求而变化，最终完成对用户需求的实现与用户体验的完善。”同样的道理，（互联网）运营贯穿了互联网产品整个生命周期，它根据产品的变化而调整，为了实现不同阶段的目标而有所改变，不断适应提高。</li><li>一切能够进行产品推广、促进用户使用、提高用户认知的手段都是运营。根据产品类型的不同，运营的方式也不尽相同，但运营的核心目的只有一个：让产品活得更好、更久。<ul><li>“活得更好”，是通过推广、教育、活动等一系列手段让产品的各项数据获得提升；</li><li>“活得更久”，是通过数据分析和用户行为研究让产品的功能不断完善、易用性不断提升，从而获得更⻓的产品生命周期。</li></ul></li><li>产品的生命周期：<ul><li>具体来说，一个产品，进行产品设计的过程是孕育期；达到上线状态，与用户⻅面，这是初创期；获取用户、持续运营，这是成⻓期；用户稳定，收入持续，这是成熟期；用户衰减、收入减少，这是衰退期；最后完成历史使命，产品终结，这是消亡期。</li><li>孕育期，运营人员应当介入产品设计，预留好运营接口、做好对应的运营准备；初创期，运营人员应该通过各种手段获取初始用户、培养种子用户；成⻓期，运营人员应该借助各种资源进行市场推广、开展各项活动，加速用户与收入的增⻓速度；成熟期，运营人员应当通过各种运营手段，保持用户稳定，保障收入稳定；衰退期，运营人员应当更多地关怀用户，并试图将已有用户导入新的产品；消亡期，运营人员则应当做好后续工作，对用户有个交代。</li></ul></li></ul><p><img src="/2023/02/12/%E4%BD%9C%E4%B8%BA%E8%BF%90%E8%90%A5%E7%9A%84%E7%AC%AC%E4%B8%80%E6%9C%AC%E8%BF%90%E8%90%A5%E4%B9%A6%EF%BC%88%E3%80%8A%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%81%9A%E8%BF%90%E8%90%A5%E3%80%8B%EF%BC%89/2.1.png"></p><ul><li>运营的核心任务归结起来为两点：<ul><li>流量建设：通过各种推广、扩散、营销、活动，提升网站的流量指标，我们通常所说的PV（Page View的英文缩写，意为⻚面浏览量，是评价网站流量最常用的指标之一。）、UV（Unique Visitor的简写，是指不同的、通过互联网访问、浏览这个网⻚的自然人。）、转化率（Take Rates（Conversions Rates），转化率&#x3D;进行了相应的动作的访问量&#x2F;总访问量，用以衡量网站内容对访问者的吸引程度以及网站的宣传效果。）、SEO（Search Engine Optimization的英文缩写，意为“搜索引擎优化”。SEO是指从自然搜索结果获得网站流量的技术和过程。）都在这个环节。</li><li>用户维系：如何持续有效地推动用户的活跃与留存，并从中发现有价值甚至高价值的用户，这些用户会持续地为网站（产品）带来价值、产生收益，让网站（产品）可以存活下去，并且活得有质量。<ul><li>经过多年的发展，“用户”的定义已经发展成“User”（使用者）与“Member”（会员）两种基础定义。</li></ul></li></ul></li></ul><p><img src="/2023/02/12/%E4%BD%9C%E4%B8%BA%E8%BF%90%E8%90%A5%E7%9A%84%E7%AC%AC%E4%B8%80%E6%9C%AC%E8%BF%90%E8%90%A5%E4%B9%A6%EF%BC%88%E3%80%8A%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%81%9A%E8%BF%90%E8%90%A5%E3%80%8B%EF%BC%89/2.2.png"></p><ul><li>运营是一种手段，简单地划分通常分为三类：<ul><li>内容运营<ul><li>网站（产品）中可供用户消费并且延⻓用户停留时间、促进用户转化的展示均可称之为“内容”。内容可能是文字、图片，也可能是音、视频，或者动作。那么，是不是所有的网站（产品）都有内容？我们可以对照下面的问题来找到答案。</li><li>内容运营是指通过创造、编辑、组织、呈现网站或产品的内容，从而提高互联网产品的内容价值，制造出对用户的黏着、活跃产生一定的促进作用的内容。</li><li><img src="/2023/02/12/%E4%BD%9C%E4%B8%BA%E8%BF%90%E8%90%A5%E7%9A%84%E7%AC%AC%E4%B8%80%E6%9C%AC%E8%BF%90%E8%90%A5%E4%B9%A6%EF%BC%88%E3%80%8A%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%81%9A%E8%BF%90%E8%90%A5%E3%80%8B%EF%BC%89/2.3.png"></li><li>内容运营至少包括五个部分：<ul><li>创作内容(采集或者原创，包括各种内容类型）</li><li>编辑审核</li><li>推荐和专题制作</li><li>找到需要这些内容的人，并且想办法呈现给他们</li><li>根据数据和用户反馈，进行内容调整与优化</li></ul></li><li>内容运营的核心：<ul><li>持续制作、编辑及推荐对用户有价值的内容，保证用户可以在产品中获取这些信息</li><li>根据KPI的设计，降低或者提高用户获取内容的成本</li><li>协助网站（产品）获利</li></ul></li><li>内容运营非常倚重文案能力，它对任职人员的思维灵活度、创意水平、逻辑能力都有要求。你既需要想出有趣的新鲜的点子来规划和展示你的内容，又不能过分浮夸以至于用户不知所云为何物。同时，内容运营人员也需要了解用户互动的逻辑，找出有效的方法和手段，刺激用户间产生正向互动，从而获得更多的优质内容。</li></ul></li><li>用户运营<ul><li>什么是用户？所有使用网站及产品的自然人，都是用户。</li><li>用户运营是指：以网站（产品）的用户的活跃、留存、付费为目标，依据用户的需求，制定运营方案甚至是运营机制。目前，用户运营已经发展到针对不同类型的用户采取有针对性的运营策略的阶段。</li><li>不同的网站（产品），用户运营的方式和方法有很大差异，取决于网站（产品）有多依赖用户，内部如何定义用户。将用户定义为User和定义为Member，会带来完全不同的运营策略和运营手段，甚至产生不同的运营工具和运营指标。<ul><li>User指的是使用者，不管是否注册，是否登录，能够使用产品的都是User。</li><li>Member则比使用者要更进一层，可能是完成了注册并登录使用产品的User，也可能是付费使用高级功能的User。总之，Member的定义更精准，需要做的事情也更多。</li></ul></li><li>用户运营首先要做的事情，就是掌握用户结构。另一件事情，就是了解用户的规模以及增⻓或衰退情况，并进行适当的用户分级，了解新用户有多少、老用户有多少、每日增⻓规模有多少、用户都处于怎样的生命周期。</li><li>用户运营的核心：<ul><li>开源（拉动新用户）</li><li>节流（防止用户流失与流失用户挽回）</li><li>维持（已有用户的留存）</li><li>刺激（促进用户活跃甚至向付费用户转化）</li></ul></li></ul></li><li>活动运营<ul><li>活动运营是通过开展独立活动、联合活动，拉动某一个或多个指标的短期提升的运营工作。</li><li>活动运营可以短期拉动运营指标，也可以为产品探路，很多产品的功能可以从活动中总结和提炼出来。</li><li>活动运营人员的日常工作是策划活动。它具体包含如下内容：<ul><li>活动文案撰写：文案用户看得懂，活动可以吸引你的用户。</li><li>活动流程设计：活动流程是自然的、妥帖的、用户乐于去执行的。</li><li>活动规则制定：规则如何设计能让用户最快明白，几步操作是用户的极限。</li><li>活动成本预估：一个活动必然有需要付出的成本，成本高了运营的压力太大，成本低了用户不愿意参与，活动设计得再漂亮也是白搭。</li><li>活动预期收益：你的活动是为了拉动哪个或哪些指标，将为网站（产品）带来怎样的收益，收益不仅仅是收入，还有用户活跃度、留存率，减少流失等指标，这些内容是设计活动的目标。</li><li>活动效果统计：明确地让自己和领导知道：活动效果好不好；如果不好，如何改进，能不能在活动中通过调整文案、入口来改善活动的效果。</li><li>活动改进措施：预备一些可能会在活动中启用的措施，促进活动效果的提升。</li></ul></li></ul></li></ul></li><li>运营虽然看起来包罗万象，但并不意味着运营是起死回生、包治百病的灵丹妙药，甚至有的时候，运营的作用十分微弱。</li><li>运营是一个吃力但未必讨好的活儿，运营的结果好不好，并不仅仅取决于运营人员的个人能力和运营团队的能力，还有一些无法回避的关键要素，比如产品的特色、用户的习惯。</li><li>运营入门的几个要素：<ul><li>心态<ul><li>以运营人员的身份进入互联网行业，请先端正心态，明确几个前提<ul><li>运营不是万能的。</li><li>没有运营是万万不能的。</li><li>运营和产品是无法割裂的。</li><li>运营和很多其他岗位都是亲密无间的好伙伴。</li><li>最高级的运营是自运营。</li></ul></li><li>简单的道理<ul><li>甜一点没有坏处，不管你是否做运营。</li><li>运营思路需要天⻢行空，但是并不代表无迹可寻。</li><li>运营手段需要创造性，但并不代表不可复用。</li><li>生活中的很多细节都可以对运营有所启发。</li></ul></li></ul></li><li>技能<ul><li>自上而下地反思一下你目前有以下哪些技能<ul><li>对数据的敏感度。</li><li>想象力与创造力。</li><li>口头表达能力、文字表达能力。</li><li>沟通能力。</li><li>执行力。</li></ul></li></ul></li><li>思维模式<ul><li>发散性思维：从一个点出发，进行思维的扩展，最终产生多个方案，而不是唯一方案，这就是运营的发散性思维。</li><li>逆向思维：这是一种逆转因果的思维方式，从原因可以推知结果，反过来从结果可以反推原因。</li><li>结构化思维：这是一种系统级别的思维方式，它通常不采用“头痛医头、脚痛医脚”的case by case（具体问题具体分析）解决方案，而是先汇总然后让系统来解决类似的所有问题。</li><li>还需要清楚：<ul><li>进入职场之后，任何职位（除非对口专业）对专业契合度的要求都没有那么高。</li><li>很多时候，会拖我们后腿的，不是所谓的专业是否对口，而是我们的思维方式是否对路。</li><li>跟不上运营节奏的时候，放弃思考，多听多问，然后多想多做。</li></ul></li></ul></li></ul></li></ul><hr><h2 id="第三章-揭开内容运营的面纱"><a href="#第三章-揭开内容运营的面纱" class="headerlink" title="第三章 揭开内容运营的面纱"></a>第三章 揭开内容运营的面纱</h2><ul><li><p>内容运营涉及的事情很多，并且非常细节化，它至少包含了以下内容：</p><ul><li>内容的采集与创造。</li><li>内容的呈现与管理。</li><li>内容的扩散与传导。</li><li>内容的效果与评估。</li></ul></li><li><p>在内容运营的初期，我们对运营工作的排序应当是：</p><ul><li>内容消费者定位（网站定位+受众定位+运营目标）。</li><li>内容来源确认（采集或者寻找内容生产者）。</li><li>内容标准的确立（有哪些内容、如何展现内容、评判内容质量的标准）。</li></ul></li><li><p>内容运营发展到今天，已经不再是简单的内容制造与发送了，内容运营的标准，早已被大大提高了。将你的内容视为你的商品，从初始阶段就定义这个商品的销售对象、选品和展示方式，进而确保上线后的后台内容流转与前台展示效果。</p></li></ul><h4 id="内容初始化——构建网站与产品的价值观"><a href="#内容初始化——构建网站与产品的价值观" class="headerlink" title="内容初始化——构建网站与产品的价值观"></a>内容初始化——构建网站与产品的价值观</h4><p>内容初始化就是在已构建好的内容框架下，在用户进入之前填充一些内容，这些内容是内容运营初期网站或（产品）的核心部分，代表着网站（产品）的价值观。</p><ul><li>依赖项：<ul><li>第一，确立好内容供应链的架构，即通过系统去解决内容从哪里来、到哪里去的流程问题。<ul><li>不管什么样的内容规范，最先解决的其实都不是内容的甄别问题，而是什么样的内容允许被创建。也可以认为，确立了创建内容的标准之后，网站就已经可以初步对垃圾内容的产生进行约束。创建内容标准的确立对甄别内容质量的帮助，是初步减少不良内容出现的概率，及规避对不良内容的清洗带来的用户投诉和用户意⻅的反弹。</li><li>即便是有了系统和规则的约束，内容质量的甄别也依然会有部分内容依赖人工，而且内容质量的甄别，本身就是所有有内容的网站和产品始终都在寻找解决方案的重要事项。</li></ul></li><li>第二，确立好内容面对的初始用户群（关于初始用户或者称为“种子用户”，我们会在后面具体讨论）。<ul><li>通过各种方式将好的内容呈现给用户。呈现的方法，无非是用户主动发现，以及运营人员对用户主动推送与引导两种方式。</li><li><img src="/2023/02/12/%E4%BD%9C%E4%B8%BA%E8%BF%90%E8%90%A5%E7%9A%84%E7%AC%AC%E4%B8%80%E6%9C%AC%E8%BF%90%E8%90%A5%E4%B9%A6%EF%BC%88%E3%80%8A%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%81%9A%E8%BF%90%E8%90%A5%E3%80%8B%EF%BC%89/3.1.png"></li></ul></li><li>第三，明确第一阶段用内容解决的问题，并进行内容准备。</li><li>第四，关键路径的梳理与初始内容的准备。</li></ul></li><li>一个网站（产品）进入正式运营阶段，就需要建立一些标准，具体包括：<ul><li>内容质量的甄别。</li><li>好内容的露出与呈现方式。</li><li>持续的推送与推荐机制的建立。</li><li>实现“自运营”的路径与机制选择。</li></ul></li></ul><h4 id="把好的内容呈现给用户"><a href="#把好的内容呈现给用户" class="headerlink" title="把好的内容呈现给用户"></a>把好的内容呈现给用户</h4><p>渠道选择的原则自不待言，就是要使用用户最常接触、且最易使用的那部分渠道。</p><ul><li>推送渠道的选择<ul><li>第一，优先考虑渠道是否覆盖推送对象。</li><li>第二，推送内容的时效性。</li><li>依据：<ul><li>历史推送数据。它主要包括使用过什么样的渠道，各个渠道的到达率与转化率如何。</li><li>竞品选择的渠道。如果没有历史数据，就需要预估，此时比较具有参考价值的，是竞品的渠道选择。</li><li>用户兴趣点所涉及的渠道。如果没有历史数据，也没有掌握竞品的情况甚至没有竞品，那么可能就需要根据用户的行为去猜测用户可能会在哪些渠道上接受信息。</li></ul></li></ul></li><li>文案的撰写<ul><li>贴近受众的心理。</li><li>选一个好位置。</li><li>简单有趣，朗朗上口。</li><li>符合场景。</li></ul></li></ul><p>好文案的特征：<strong>称呼亲切、内容简单、落款严肃、充满诱惑</strong>。</p><h4 id="公共平台内容运营的步骤"><a href="#公共平台内容运营的步骤" class="headerlink" title="公共平台内容运营的步骤"></a>公共平台内容运营的步骤</h4><ul><li><p>先定位</p><p>根据品牌自身的特点、受众、调性来定义公共平台所要进行运营的内容的特色、受众和调性。</p><p>这个定位，实际上包含两层意思：第一层意思是面向受众群的定位。你要清楚哪些受众群体会喜欢你的内容。第二层意思是面向内容的定位。对于这样的受众群体，你应该通过什么类型的内容进行⻓期的运营。</p></li><li><p>快速测试，获取反馈</p><p>要进行快速测试，看之前定位的受众是否接受发布的内容，如果发现反馈平平，那就多试几次加以调整。</p></li><li><p>培养用户的习惯</p><p>不管是早晨通勤时间发布，中午休息时间发布，还是晚上休闲时间发布，这个时间点都不重要。<strong>重要的是，要在固定的时间发布内容。</strong>如果内容发布的时间固定，⻓期关注内容的用户会养成定时查看的习惯。</p><p>习惯是建立在用户对内容感兴趣的基础上，如果前两步没有做好，这一步就没有价值了。</p></li><li><p>坚持⻓期的内容运营方针</p></li><li><p>与内容消费者保持互动</p><p><strong>公共平台上的内容消费者，或许也是内容生产者</strong>，和他们进行沟通，很有可能带来有益的提醒，帮助运营者找到用户关心的问题并予以解决。这并不难，只要你肯提供消费者需要的内容，你就解决了他们关心的问题。</p></li><li><p>坚持原创</p><p>原创的符合品牌特点及受众口味的内容，最容易引爆热点。所以，对于希望在公共平台开展内容运营的企业和运营人员来说，就要先明白这些道理，然后摆正心态，坚持做正确的事。</p></li></ul><h4 id="内容运营的核心"><a href="#内容运营的核心" class="headerlink" title="内容运营的核心"></a>内容运营的核心</h4><p>一个网站（产品），只要有内容，就涉及内容供应链的建立，而内容供应链的建立必然涉及三方：网站（产品）、内容生产者及内容消费者。这三方关系着内容运营的核心。</p><ul><li><p>内容消费者</p><p>内容消费者是消费内容的人（阅读、采纳、运用），他们与网站（产品）的定位息息相关，他们决定了网站（产品）的内容给谁看，谁会对这些内容感兴趣从而提供可转化的流量。</p></li><li><p>内容生产者</p><p>内容生产者是生产内容的人，他们是网站（产品）内容的发动机，他们决定了网站（产品）会提供怎样的内容。内容生产者所提供的内容与内容消费者兴趣的匹配，是保证内容流转效率和网站（产品）转化能力的动力。</p></li><li><p>网站与产品</p><p>网站与产品是联系内容生产者和内容消费者的渠道或平台，它需要维系内容生产者，满足内容消费者，通过各种方式保证网站（产品）的运转。</p></li></ul><h6 id="内容运营的反馈机制和跟进策略"><a href="#内容运营的反馈机制和跟进策略" class="headerlink" title="内容运营的反馈机制和跟进策略"></a>内容运营的反馈机制和跟进策略</h6><ul><li>在内容的采集与管理工作中，必须考虑用户反馈和对应的跟进策略。</li><li>反馈机制和跟进策略可以根据平台的不同选择合适的展现方式。</li><li>数据挖掘机制非常重要，但更重要的是对数据挖掘之后的反馈与跟进。</li><li>内容不是一成不变的，而是需要调整与提高。·内容运营必须要有KPI，但不管是曝光度的指标还是其他指标，指标的意义都不仅仅是“达成”，而是要反过来指导下一阶段的内容运营工作。</li></ul><hr><h2 id="第四章-做一个有趣的活动"><a href="#第四章-做一个有趣的活动" class="headerlink" title="第四章 做一个有趣的活动"></a>第四章 做一个有趣的活动</h2><p>做运营，离不开活动。活动运营，顾名思义是通过组织活动在短期内快速提升相关指标的运营手段。我们拆分一下这句话中的关键字：</p><p>短期：在一个较短的时间内开展活动。</p><p>快速：用简单直接的方式在较短时间内达成结果。</p><p>提升指标：目的明确，提升活动对应指标，达成KPI。</p><p>具体来说，一个完整的活动运营流程可能会涉及如下步骤：</p><p><img src="/2023/02/12/%E4%BD%9C%E4%B8%BA%E8%BF%90%E8%90%A5%E7%9A%84%E7%AC%AC%E4%B8%80%E6%9C%AC%E8%BF%90%E8%90%A5%E4%B9%A6%EF%BC%88%E3%80%8A%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%81%9A%E8%BF%90%E8%90%A5%E3%80%8B%EF%BC%89/4.1.png"></p><p>策划：活动的设计阶段，会定义明确的活动时间、对象、方式、目标、预算等。</p><p>开发：活动需要由设计人员设计界面，请开发人员开发实现功能。</p><p>测试：一个活动开发完成后，需要测试以确认功能是否可用与易用。</p><p>宣传：找到可以触达用户的渠道，协调资源来做活动露出。这个阶段几乎是和开发、测试同时进行的，而且为了活动效果，在上线之前就会做一些预热。</p><p>上线：终于到了上线时间，活动就会在线上进行展示，让用户参与活动。</p><p>指标监控：活动上线后，需要监测相应的指标，根据指标反映的问题进行适当的调整。</p><p>奖励发放：活动结束后（当然，也可以是活动进行中），对符合奖励条件的用户发放奖励。</p><p>效果评估：活动结束后，评估活动效果，总结经验教训，以备下次活动参考借鉴。</p><p>在整个活动运营过程中，有四件事情非常重要，可以称之为“核心”，它们分别是：</p><ul><li>活动设计与成本预算。</li><li>活动⻛险管控与应急预案。</li><li>活动数据监测与应对策略。</li><li>活动效果判定与总结。</li></ul><h6 id="请铭记：一个运营者，如果心中永远只有当前的目标，而忽略了行动的目的，那么他终将一无所获。"><a href="#请铭记：一个运营者，如果心中永远只有当前的目标，而忽略了行动的目的，那么他终将一无所获。" class="headerlink" title="请铭记：一个运营者，如果心中永远只有当前的目标，而忽略了行动的目的，那么他终将一无所获。"></a>请铭记：一个运营者，如果心中永远只有当前的目标，而忽略了行动的目的，那么他终将一无所获。</h6><h4 id="活动设计与成本预算"><a href="#活动设计与成本预算" class="headerlink" title="活动设计与成本预算"></a>活动设计与成本预算</h4><p>针对活动运营的成本预算管控，我们在活动设计上可以做什么呢？</p><ul><li>先看能不能借势，再看能不能借力。可以借势的活动用抽奖的方式进行，可以借力的活动用合作分摊成本。</li><li>如果势、力皆无，那么就要拿出数据说服老板，要么降低活动预期，要么增加活动预算。</li><li>如果说服不了老板，那么，尽你的最大努力，来设计一个吸引人的活动吧。</li></ul><h6 id="活动规则的设计准则"><a href="#活动规则的设计准则" class="headerlink" title="活动规则的设计准则"></a>活动规则的设计准则</h6><p>活动规则的设计准则就一句话：流程简单少思考，文案清晰无歧义。</p><p>但是，在这个准则之上，还有一个很高的帽子：活动设计与活动理由的无缝衔接。</p><p>即使一个活动设计得再无聊，如果有足够多的人看到它，它也可能会起到很好的宣传效果；而不管一个活动设计得多么精致，如果人们并不知晓，那它也不太可能有效果。所以，活动策划的另一个关键是，宣传渠道投放。</p><h4 id="活动策划"><a href="#活动策划" class="headerlink" title="活动策划"></a>活动策划</h4><ol><li><p>活动主题：活动文案的一部分，让用户看得懂，明白活动是什么主题，是否对他有吸引力。</p></li><li><p>活动对象：明确活动针对的群体，让用户看得懂，让自己抓得住，让领导认可。</p></li><li><p>活动时间：活动的开始时间、结束时间，奖励的发放时间、领取时间。</p></li><li><p>活动描述：活动文案的一部分，让用户看过之后明白要不要参与，怎么参与。</p></li><li><p>规则详情：活动文案的一部分，让用户看得懂，让开发人员看得懂，一部分内容是在前端展示给用户看的，另一部分内容是让开发人员知道活动如何实现。</p></li><li><p>投放渠道：让市场人员或者你自己看得懂，要有投放时间、投放渠道的选择、预算。</p></li><li><p>⻛险控制：让开发人员看得懂你的⻛险环节是什么，有无对应的措施来解决。</p></li><li><p>监测指标：涵盖大多数相关指标，包括投放渠道的监控、用户参与情况的监控、奖励发放的监控等。监测这些指标可以帮助你在查看数据的时候找到问题，并且启发你去解决这些问题。</p></li><li><p>成本预估：一个活动需要多少钱，单人成本是多少。成本预估不一定非常准确，但是必须要树立这个意识。有一些活动是不花钱的，但是如果要花钱，你要明白一个活动的容量有多大，对指标的帮助是什么，为了这些利益，你需要多少成本支持。</p></li><li><p>效果评估：有成本就有收益，你的活动目的对网站（产品）的哪些指标是有帮助的，以及如何体现，你需要考虑，并让领导认可。</p></li><li><p>FAQ（常⻅问题解答）：可以另外准备一个文档，提供给客服或者相关人员，帮助解决用户在参与活动中遇到的问题。FAQ要详细、标准。如果活动规模大，仅有FAQ还不够，你需要提前准备客服的培训文件，并积极与客服人员沟通。</p></li></ol><p><strong>活动策划文档的目的，是为了让活动做得有理有据。做活动的理由、耗费运营成本的代价、上线后可能带来的预期收益都是必须体现在活动策划中的。</strong></p><h4 id="活动风险管控与应急预案"><a href="#活动风险管控与应急预案" class="headerlink" title="活动风险管控与应急预案"></a>活动风险管控与应急预案</h4><p>运营最累的部分，其实是如何控制运营⻛险，把用户体验做到最好。而活动运营最累的环节不是如何设计一个有趣的活动，而是如何保证活动开展过程中的用户体验，减少活动的⻛险。</p><p>换而言之，哪怕是最普通的活动内容，用户看了完全提不起参与的兴趣，都不是最可怕的，最应该引起运营人员关注的是，<strong>不能让有兴趣参与的用户在整个活动流程中感到不快</strong>，不管是活动开发有Bug（错误）导致的体验不佳，还是活动设计有漏洞导致的不公平，这些都是需要考虑和严格把关的内容。</p><p><img src="/2023/02/12/%E4%BD%9C%E4%B8%BA%E8%BF%90%E8%90%A5%E7%9A%84%E7%AC%AC%E4%B8%80%E6%9C%AC%E8%BF%90%E8%90%A5%E4%B9%A6%EF%BC%88%E3%80%8A%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%81%9A%E8%BF%90%E8%90%A5%E3%80%8B%EF%BC%89/4.2.png"></p><p><img src="/2023/02/12/%E4%BD%9C%E4%B8%BA%E8%BF%90%E8%90%A5%E7%9A%84%E7%AC%AC%E4%B8%80%E6%9C%AC%E8%BF%90%E8%90%A5%E4%B9%A6%EF%BC%88%E3%80%8A%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%81%9A%E8%BF%90%E8%90%A5%E3%80%8B%EF%BC%89/4.3.png"></p><p>活动⻛控的严格程度是有一些窍门的。</p><ul><li>产品发展初期，为了吸引用户进入，⻛控可以较为宽松，甚至直接不做⻛控。</li><li>产品发展期，为了促进用户留存及活跃，对部分提升用户留存和活跃的活动可以使用较为宽松的⻛控，但涉及到付费行为，就需要较为严格的⻛控。</li><li>产品成熟期，需要较为严格的⻛控，这个时期最怕的就是数据的大起大落，严格⻛控可以帮助你将数据变化控制在比较平稳的范围内，也可以对有实际价值的客户提供更多奖励。</li><li>产品衰退期，可以采用较为宽松的⻛控以延⻓产品的生命周期。</li></ul><h6 id="活动运营人员首先要明白，活动是一种短期刺激运营指标的手段。"><a href="#活动运营人员首先要明白，活动是一种短期刺激运营指标的手段。" class="headerlink" title="活动运营人员首先要明白，活动是一种短期刺激运营指标的手段。"></a>活动运营人员首先要明白，活动是一种短期刺激运营指标的手段。</h6><p><img src="/2023/02/12/%E4%BD%9C%E4%B8%BA%E8%BF%90%E8%90%A5%E7%9A%84%E7%AC%AC%E4%B8%80%E6%9C%AC%E8%BF%90%E8%90%A5%E4%B9%A6%EF%BC%88%E3%80%8A%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%81%9A%E8%BF%90%E8%90%A5%E3%80%8B%EF%BC%89/4.5.png"></p><hr><h2 id="第五章-用户运营比想象得更难"><a href="#第五章-用户运营比想象得更难" class="headerlink" title="第五章 用户运营比想象得更难"></a>第五章 用户运营比想象得更难</h2><p>所有的用户运营工作，都建立在一个相同的基础上，即对用户的充分了解。如何证明我们了解用户呢？举一个很简单的例子。假设要做一个User Referral（用户推荐）活动，运营人员应当知道，用户喜欢用哪些渠道进行分享和邀请，同时也应当知道，这个活动在哪些外部平台推广宣传，或者和哪些外部平台做联合推广，会达到最优效果。</p><p>所有的工作，都围绕一个内容——人。既然用户是人，就绕不开需求理论。</p><h4 id="通过数据窥探用户"><a href="#通过数据窥探用户" class="headerlink" title="通过数据窥探用户"></a>通过数据窥探用户</h4><h6 id="转化率"><a href="#转化率" class="headerlink" title="转化率"></a>转化率</h6><ul><li>列表⻚转化率&#x3D;最终下单用户数&#x2F;商品列表⻚到达用户数</li><li>详情⻚转化率&#x3D;最终下单用户数&#x2F;商品详情⻚到达用户数</li><li>支付转化率（支付成功率）&#x3D;支付成功的用户&#x2F;最终下单用户数</li></ul><p>数据需要归类，不同类别的数据需要分门别类地存放和使用，然后找到数据之间的关联与逻辑关系，分析需要归因，对数据产生的现象背后的原因要加以分析和查找。</p><p>不管是归类还是归因，最后都需要验证推论的正确性，这就产生了持续运营的总结和归纳，表现到行为上，就是重现与试错。能够确认的归因就重现，不能确认的就试错。通过这两种方式，用户运营人员就能以较高的高度和较宏观的视角，去看待和了解用户。</p><h4 id="直面用户"><a href="#直面用户" class="headerlink" title="直面用户"></a>直面用户</h4><p>数据为我们提供预测用户的依据，帮助我们验证猜测和推论是否成立。但是，数据绝不是唯一一个了解用户的途径，事实上，有一种方法被广泛使用，产品经理称之为“用户研究”。</p><p>当然，从运营角度来看，直面用户的方法可能未必需要那么多，但是其原理是一致的。需要注意的是，运营与用户面对面地做深度访谈之类的行为是比较困难的。</p><h6 id="客服时间反馈"><a href="#客服时间反馈" class="headerlink" title="客服时间反馈"></a>客服时间反馈</h6><p>客服是直面用户的第一道闸门，这个闸门既可以为运营和产品人员指出已有的问题和潜在的⻛险，也可以隔绝所有问题的反馈并阻挡改进的步伐。</p><p>通常是先记录所有的客服事件并挖掘其背后的问题，再归纳其共性。从运营端找到用户最关注的点，立即予以解决或排定优先级着手解决。</p><h6 id="电话回访"><a href="#电话回访" class="headerlink" title="电话回访"></a>电话回访</h6><p>回访的关键在于明确问题，尝试让用户重现问题以帮助自己明晰症结所在。</p><h6 id="问卷调查"><a href="#问卷调查" class="headerlink" title="问卷调查"></a>问卷调查</h6><p>尽量客观地描述选项；尽量避免预设立场之后进行问卷设计与分析；尽量让问卷的设计可以覆盖大多数用户，提供大样本基础；尽量回收足够多的有效问卷。</p><p>起来都很简单，但做起来很难。</p><h6 id="聚类调研"><a href="#聚类调研" class="headerlink" title="聚类调研"></a>聚类调研</h6><p>直面的是类似用户，推论的是选型用户。所谓选型用户，就是预设立场选出来的典型用户。</p><h4 id="工作内容"><a href="#工作内容" class="headerlink" title="工作内容"></a>工作内容</h4><p><img src="/2023/02/12/%E4%BD%9C%E4%B8%BA%E8%BF%90%E8%90%A5%E7%9A%84%E7%AC%AC%E4%B8%80%E6%9C%AC%E8%BF%90%E8%90%A5%E4%B9%A6%EF%BC%88%E3%80%8A%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%81%9A%E8%BF%90%E8%90%A5%E3%80%8B%EF%BC%89/5.1.png"></p><h6 id="开源"><a href="#开源" class="headerlink" title="开源"></a>开源</h6><ul><li>注册渠道的挑选和打开</li><li>提升注册转化率</li></ul><h6 id="节流"><a href="#节流" class="headerlink" title="节流"></a>节流</h6><ul><li>定义用户沉默或流失的标准</li><li>建立流失预警机制</li><li>对已流失的用户进行挽回</li></ul><h6 id="促活跃"><a href="#促活跃" class="headerlink" title="促活跃"></a>促活跃</h6><ul><li>定义用户留存与用户活跃的标准</li><li>提升用户留存率</li><li>提升用户活跃度（用户行为、产品使用频次等）</li></ul><h6 id="转付费"><a href="#转付费" class="headerlink" title="转付费"></a>转付费</h6><ul><li>通过一系列行为让未付费的活跃用户付费</li><li>通过机制让已付费的用户持续付费</li></ul><h6 id="注册转化"><a href="#注册转化" class="headerlink" title="注册转化"></a>注册转化</h6><p>对于网站（产品）来说，运营和产品人员应该通过引导流程告诉用户：产品是什么、核心价值在哪里、提供怎样的服务等等。作为运营者，必须清醒地认识到，对于一个新用户，只有他&#x2F;她通过注册引导流程，到达产品使用界面，甚至完成第一次使用，才算得上是一个真正的用户。在这里有几个原则需要把握：</p><ul><li><p>把用户当成傻子。应当简单明了、图文并茂地告诉用户，这是什么，用户能做什么，用户从哪里开始体验。</p></li><li><p>最大程度地展现核心功能、核心价值、核心玩法。</p></li><li><p>分阶段展示次要功能、次要价值、次要玩法，不要试图全部塞给用户。</p></li><li><p>根据数据统计调整文案，改进引导顺序等细节。</p></li><li><p>引导要有趣，不要让用户觉得枯躁；步骤要简单、流程要短，很少有人在进行数次点击还没看明白你要表达什么之后，依然有耐心。</p></li><li><p>引导要捆绑用户行为，用户的每一个反馈都可以告诉你，他究竟是否明白你在说什么。每一个反馈都可以提供一些激励，促使他继续下去，完成流程。</p></li></ul><h4 id="节流到底节什么流"><a href="#节流到底节什么流" class="headerlink" title="节流到底节什么流"></a>节流到底节什么流</h4><ul><li>定义流失用户的衡量标准</li><li>建立流失预警机制</li><li>预防用户流失<ul><li>给用户想要的一切。</li><li>持续给他们想要的一切。</li><li>尝试给他们可能喜欢的一切。</li><li>避免让他们失去兴趣。</li></ul></li></ul><hr><h2 id="第六章-关于数据的一二三"><a href="#第六章-关于数据的一二三" class="headerlink" title="第六章 关于数据的一二三"></a>第六章 关于数据的一二三</h2><h4 id="数据的定义"><a href="#数据的定义" class="headerlink" title="数据的定义"></a>数据的定义</h4><p>数据，其实就是与产品和运营相关的一些数值。这些数值，可以通过第三方工具或通过自行开发进行统计，这些数值是研究和分析的基础素材。不管什么样的产品，都有一些核心数据，它们是进行分析，得出结论的基础。</p><p><img src="/2023/02/12/%E4%BD%9C%E4%B8%BA%E8%BF%90%E8%90%A5%E7%9A%84%E7%AC%AC%E4%B8%80%E6%9C%AC%E8%BF%90%E8%90%A5%E4%B9%A6%EF%BC%88%E3%80%8A%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%81%9A%E8%BF%90%E8%90%A5%E3%80%8B%EF%BC%89/6.1.png"></p><h4 id="数据分析的方法"><a href="#数据分析的方法" class="headerlink" title="数据分析的方法"></a>数据分析的方法</h4><ul><li>确定数据的准确性</li><li>明确影响数据的因素</li><li>重视⻓期的数据监测</li><li>持客观的视角</li><li>注意剔除干扰项</li></ul><h4 id="数据分析的方法、误区与数据说谎的手法"><a href="#数据分析的方法、误区与数据说谎的手法" class="headerlink" title="数据分析的方法、误区与数据说谎的手法"></a>数据分析的方法、误区与数据说谎的手法</h4><p><strong>核心观点：</strong>运营数据分析的关键不在于数据，而在于分析。或者说，所有数据分析的关键都在于分析，而不在于数据本身。</p><p><strong>前提：</strong>数据分析的能力是渐进的，对数据的敏感度是需要培养的。</p><p><strong>事实：</strong>数据表达出的信息与多种因素相关，运营人员尝试学习运营数据分析之前，要尽量抛开预设立场，并且明白不同类别的数据在不同的阶段其重要性也是不同的。</p><h6 id="UV（Unique-Visitors）：独立访客数"><a href="#UV（Unique-Visitors）：独立访客数" class="headerlink" title="UV（Unique Visitors）：独立访客数"></a>UV（Unique Visitors）：独立访客数</h6><p>独立访客数和独立IP是两个概念。独立IP要求访问者的IP地址各不相同，而独立访客数则未必。</p><h6 id="PV（Page-Views）：⻚面访问量"><a href="#PV（Page-Views）：⻚面访问量" class="headerlink" title="PV（Page Views）：⻚面访问量"></a>PV（Page Views）：⻚面访问量</h6><p>每一个用户，每打开一个⻚面，就是一个PV。</p><h6 id="RV（Repeat-Visitors）：重复访客"><a href="#RV（Repeat-Visitors）：重复访客" class="headerlink" title="RV（Repeat Visitors）：重复访客"></a>RV（Repeat Visitors）：重复访客</h6><p>比如，昨天小明浏览了我的微信公众号，今天他又来了。小明就是一个RV。</p><h6 id="TP（Time-On-Page）：⻚面停留时间"><a href="#TP（Time-On-Page）：⻚面停留时间" class="headerlink" title="TP（Time On Page）：⻚面停留时间"></a>TP（Time On Page）：⻚面停留时间</h6><h6 id="Traffic-Sources：流量来源渠道"><a href="#Traffic-Sources：流量来源渠道" class="headerlink" title="Traffic Sources：流量来源渠道"></a>Traffic Sources：流量来源渠道</h6><p>比如，百度每天为你的网站贡献了100个UV；用户直接输入网址为你的网站贡献了10000个UV；微信每天为你的网站带来1000个UV。这些都是流量来源渠道。</p><h6 id="数据使用的方法"><a href="#数据使用的方法" class="headerlink" title="数据使用的方法"></a>数据使用的方法</h6><ul><li>掌握历史数据。</li><li>从历史数据中归纳规律。</li><li>通过规律反向进行数据预测。</li><li>学会对数据进行拆解。</li></ul><h6 id="运营数据分析的误区"><a href="#运营数据分析的误区" class="headerlink" title="运营数据分析的误区"></a>运营数据分析的误区</h6><ul><li>不要用单一类型的数据去评价全局。</li><li>不要夸大偶然事件，认为带来必然结果。</li><li>避免用结论推导原因。</li><li>避免唯数据论。</li></ul><h6 id="运营数据说谎的手法"><a href="#运营数据说谎的手法" class="headerlink" title="运营数据说谎的手法"></a>运营数据说谎的手法</h6><ul><li>拉伸图表</li><li>修改坐标轴数据</li><li>故意选择有利的样本</li><li>样本规模差异</li></ul><h6 id="读懂数据背后的人"><a href="#读懂数据背后的人" class="headerlink" title="读懂数据背后的人"></a>读懂数据背后的人</h6><ul><li>抛弃预设立场<ul><li>研究数据的波动和波动的节点，通过这一步去确立要研究哪些相关事件，研究用户行为还是系统事件。</li><li>这一步是定位，但不要定性。</li></ul></li><li>深挖用户行为与系统事件<ul><li>挖掘对应时间节点的相关事件，包括系统事件和用户行为，通过这一步找出可能造成影响的动作和事件。</li></ul></li><li>尝试换位思考<ul><li>把用户的真实反馈模拟出来，而不是夸大或削弱用户的反馈。必要的时候，可以找一些用户进行调研。</li></ul></li><li>整合关键数据<ul><li>整合可能有用的核心数据，譬如历史数据、关联数据、竞品数据等，最后得出结论：<ul><li>造成数据变化的原因究竟是什么？</li><li>有什么办法可以改善或者促进数据的变化？</li><li>总结经验，类似情况再次发生时，应该进行何种处置与预案。</li></ul></li></ul></li></ul><hr><h2 id="第七章-当运营遇到产品"><a href="#第七章-当运营遇到产品" class="headerlink" title="第七章 当运营遇到产品"></a>第七章 当运营遇到产品</h2><p>最早是没有“运营”与“产品”岗位划分的，大家都被叫作“策划”。后来，开始出现了单独的“产品经理”岗位与“运营专员”岗位的招聘，于是，产品和运营开始拥有各自的发展道路。</p><p>运营需要产品，产品也需要运营。运营需要产品提供场景、工具、环境等；产品需要运营提供用户、内容、活动等。所以，这是一对兄弟，也是一对对手，他们之间会出现优先级的争取、资源的争抢，更会出现双方的协同合作，共同实现目标。</p><p><strong>一切能够帮助产品进行推广、促进用户使用、提高用户认知的手段都是运营。</strong>运营切入产品最好的节点是：<strong>产品设计之前</strong>：根据产品设计的发展目标（含目标用户、目标市场、阶段规划），进行早期的运营工具设计、运营目标分解、运营切入点选择、运营路线图制作、运营策略规划。</p><h6 id="运营指标"><a href="#运营指标" class="headerlink" title="运营指标"></a>运营指标</h6><ul><li><p>产品定位。包括运营切入点是什么，切入点面对的是哪些用户，他们的消费水平如何，兴趣点在哪里。</p></li><li><p>产品质量。包括功能指标、性能指标。</p></li><li><p>产品对运营的支持。要留住用户，既需要好的产品功能、产品体验，也需要得力的运营工具、活动设计。</p></li><li><p>市场推广。包括对哪些人开放，在哪些市场投放。</p></li><li><p>商务合作。包括联合运营是否可以事半功倍，商务合作是否要排他等。</p></li><li><p>财务预算。无论用户数还是流水、收入或者营收，都涉及单人用户的维护成本。财务预算要明确，能否支撑运营目标的达成。</p></li><li><p>商业模式。预算即成本。现有的商业模式能否支撑成本，是否需要引入投资，在什么节点引入。运营目标拆解之后，这些都会变得清晰。</p></li></ul><hr><h2 id="第八章-用户习惯的养成"><a href="#第八章-用户习惯的养成" class="headerlink" title="第八章 用户习惯的养成"></a>第八章 用户习惯的养成</h2><p>“用户习惯”这个词，更多地出现在产品经理进行用户研究、交互设计的过程中。所谓的用户习惯，更多的是心理学层面上的研究，主要讨论在产品的交互设计中，怎样能够让用户不假思索的使用产品。</p><p><strong>运营层面的“用户习惯”，是帮助用户适应运营节奏并形成习惯、对运营活动形成期望。</strong></p><p>用户习惯养成的第一个要点是持续，持续并不等于一个活动做一年，而是每到这个节点，你都有对应的运营策略。第二个要点是固化，固化不等于每到这个节点你都做同样的事情，而是每到这个节点你会让用户有相似的感知。</p><h6 id="运营人员应该做什么？"><a href="#运营人员应该做什么？" class="headerlink" title="运营人员应该做什么？"></a>运营人员应该做什么？</h6><ul><li>将自己的运营计划从1天、1周，提高到1月、1年的周期。</li><li>对关键节点进行⻓期运营策略设计。</li><li>保持与产品人员、开发人员的沟通，善用资源。</li><li>养成观测数据的习惯。·保持对竞品的关注，做差异化的运营准备。</li></ul><h6 id="用户真的需要被教育吗"><a href="#用户真的需要被教育吗" class="headerlink" title="用户真的需要被教育吗"></a>用户真的需要被教育吗</h6><ul><li>如果你的设计（无论是产品功能还是运营机制）符合用户的预期，那么用户是不需要被教育的。</li><li>如果你的设计不符合用户的预期，并且你打算通过这些设计差异与竞争对手保留竞争优势，那么用户是需要被教育的。</li></ul><p>从这一点上说，用户是否需要教育，取决于你的设计。</p><hr><h2 id="第九章-移动端的运营"><a href="#第九章-移动端的运营" class="headerlink" title="第九章 移动端的运营"></a>第九章 移动端的运营</h2><p>如果说Web时代是聚合流量然后分发，App时代就是将零散流量聚合，看起来似乎差不多，只是入口变为出口，但实际操作手法却大相径庭。做Web，只要你能和入口保持良好的关系，拿得到推荐位、广告位，买得起关键词，合作起来⻛生水起，流量哗哗地进，当然，是否留得住用户又是另外一个话题。而做App，你除了要和入口（商店）保持良好的关系，拿到首发、推荐之外，还要有切实有效的办法从各个分散的入口导流。而且，这直接考验你留住流量的能力，因为App的流量一旦流失，挽回难度比Web要大得多，原因很简单，因为Web用户关闭的是浏览器，只要入口还在，就能想办法挽回用户，可App用户流失，删除的是应用，应用一旦不再出现在用户的手机屏幕上，想要挽回用户，那付出的代价就太高了。</p><ul><li>从运营的角度来说，虽然渠道变了，介质变了，但是内容运营的基本方法并没有变。</li><li>移动端的内容要更专注、质量更高，同时不能局限于内容方面的运营。</li><li>由于社交功能的引入，好的内容被传播的可能性更高，传播后获客成本可能更低</li><li>坚持做原创内容。这个微信公众号的内容定位是互联网运营，并且坚持发布原创内容。</li><li>保持高频率更新。这个微信公众号的内容供应频率是每天更新一次。</li><li>读者留言必回并开放评论。鼓励用户留言，并对用户留言中有价值的问题进行总结并转化成内容；在获得了原创保护功能下的评论功能后，不阻拦用户的评论，并依然保证每条评论必回。</li></ul><h4 id="移动端运营的特点"><a href="#移动端运营的特点" class="headerlink" title="移动端运营的特点"></a>移动端运营的特点</h4><ul><li><p>第一，从分享的角度来说，移动端的分享更容易，通常只需三步操作</p><ul><li><img src="/2023/02/12/%E4%BD%9C%E4%B8%BA%E8%BF%90%E8%90%A5%E7%9A%84%E7%AC%AC%E4%B8%80%E6%9C%AC%E8%BF%90%E8%90%A5%E4%B9%A6%EF%BC%88%E3%80%8A%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%81%9A%E8%BF%90%E8%90%A5%E3%80%8B%EF%BC%89/9.1.png"></li></ul></li><li><p>第二，从互动的角度来说，移动端的互动更简单，往往只有一两个动作，但是用户点赞的成本不低。</p></li><li><p>第三，从信任的角度来说，移动端由于增加了社交功能，用户建立信任的时间缩短，但对种子用户的忠诚度要求更高。</p></li><li><p>第四，从忠诚的角度来说，只有用心的服务才能换来客户的忠诚，这一点并没有因为移动端的特点而有所不同。</p></li><li><p>第五，从营销的角度来说，如果不用心做内容，营销效果也会打折扣。</p></li></ul><hr><h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>一开始看这本书，主要是冲着”作为工作室的运营，但是连基本的运营体系都不甚了解，说出去难免让人笑话“这个目的看的。本来说是简单的做个文摘，因为距离书本出版已经过了好多年了，众所周知互联网时代是巨变的。可是看了几章之后发现技术的革新并不意味着思想的革新，很多现有的运营模式都和以前的一般相似。如果按第二章说的：运营是个筐，那么到我这就认为：运营是个圈——技术的发展只会变更最大化效益的运营手段，但是主流的运营模式和场景都一直在兜兜转转没有太大改变。</p><p>还有一点是最近大家都在找实习了，焦虑无形中就传播了出来，我看到第六章关于数据的描述才猛然发现——我一个学大数据的，居然不知道大数据中的数据究竟包含些什么？同时因为最近在实践数仓的项目，我都难以想象PB级的数据到底来源于哪里？又有些什么内容？反而是这本书给了我答案。</p><p>没必要为了未来就什么业而慌乱，Java后端也好、大数据也罢、哪怕是运营或者产品，开卷有益。这是我对这本书的高度肯定！</p><p>——Alexie-Z-Yevich 2023.2.12</p>]]></content>
      
      
      <categories>
          
          <category> TalkingAbout </category>
          
          <category> 运营 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据分析 </tag>
            
            <tag> 运营 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>软件工程</title>
      <link href="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/"/>
      <url>/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>前言：</strong></p><p>开始打算按照这第九版教材的课后习题做一个个人解答文档，然后发现——课后题内容太宽泛了，鄙人水平不足，误导大家就不好了；然后决定把书的章节精简整理，看书看到第三章越看越不对劲——老师上课完全没讲书，万一写多了最后不考岂不是害了大家？所以最后取了个折中的办法——对书本的前11章节内容进行精简学习，然后着重研究下软件工程中常见的九种图。</p><p>希望对正在看该文档的你有所帮助。</p><p>更新：后期老师专门画了下重点，所以会在文档种我认为比较重要的地方打上<strong>【重点】</strong>标记，可以从目录进行索引。Github不支持目录就算了。</p></blockquote><h2 id="第一章"><a href="#第一章" class="headerlink" title="第一章"></a>第一章</h2><h4 id="【重点】定义"><a href="#【重点】定义" class="headerlink" title="【重点】定义"></a>【重点】定义</h4><p>软件工程包括过程、一系列方法（实践）和大量的工具，专业人员借由这些来构建高质量的计算机软件。</p><p>软件具有产品和产品交付载体的双重作用。</p><p>软件是：</p><ul><li>指令的集合（计算机程序），通过执行这些指令可以满足预期的特性、功能和性能需求；</li><li>数据结构，使得程序可以合理利用信息；</li><li>软件描述信息，它以硬拷贝和虚拟形式存在，用来描述程序的操作和使用。</li></ul><h4 id="软件应用领域"><a href="#软件应用领域" class="headerlink" title="软件应用领域"></a>软件应用领域</h4><p>计算机软件分为七大类：</p><ul><li>系统软件。一整套服务于其他程序的程序。</li><li>应用程序。解决特定业务需要的独立应用程序。处理商务或技术数据，以协助业务操作或协助做出管理&#x2F;技术决策。</li><li>工程&#x2F;科学软件。“数值计算”类程序。</li><li>嵌入式软件。存在于某个产品或者系统中，可实现和控制面向最终用户和系统本身的特性和功能。</li><li>产品线软件。包括可复用的构件，并为多个不同用户的使用提供特定功能。</li><li>Web&#x2F;移动App。以网络为中心，其概念涵盖了宽泛的应用软件产品，包括基于浏览器的App、云计算、基于服务的计算和安装在移动设备上的软件。</li><li>人工智能软件。利用启发式方法解决常规计算和分析无法解决的复杂问题。</li></ul><h4 id="软件过程"><a href="#软件过程" class="headerlink" title="软件过程"></a>软件过程</h4><h6 id="过程框架"><a href="#过程框架" class="headerlink" title="过程框架"></a>过程框架</h6><p>沟通——策划——建模——构建——部署</p><h6 id="普适性活动"><a href="#普适性活动" class="headerlink" title="普适性活动"></a>普适性活动</h6><ul><li>软件项目跟踪和控制</li><li>软件质量保障</li><li>技术评审</li><li>测量</li><li>软件配置管理</li><li>可复用性管理</li><li>工作产品的准备和生产</li></ul><h4 id="软件工程实践"><a href="#软件工程实践" class="headerlink" title="软件工程实践"></a>软件工程实践</h4><h6 id="实践的精髓"><a href="#实践的精髓" class="headerlink" title="实践的精髓"></a>实践的精髓</h6><ul><li>理解问题（沟通和分析）</li><li>策划解决问题（建模和软件设计）</li><li>实施计划（代码生成）</li><li>检查结果（测试和质量保证）</li></ul><h6 id="通用原则"><a href="#通用原则" class="headerlink" title="通用原则"></a>通用原则</h6><ul><li>存在价值。一个软件系统因为为用户提供价值而具有存在价值，所有决策应该都基于这个思想。</li><li>保持简洁。所有的设计都应该尽可能简洁，但不是过于简化。</li><li>保持愿景。清晰的愿景是软件项目成功的基础。</li><li>关注使用者。在需求说明、设计、编写文档和实现过程中，牢记要让别人理解你所做的事情。</li><li>面向未来。永远不要把自己的设计局限于一隅，构建可以解决通用问题的系统，为各种可能的方案做好准备，而不是仅仅针对某一个具体问题。</li><li>提前计划复用。提前做好复用计划将降低开发费用，并增加可复用构件以及构件化系统的价值。</li><li>认真思考。在行动之前清晰定位、完整思考通常能产生更好的结果。</li></ul><hr><h2 id="第二章-过程模型"><a href="#第二章-过程模型" class="headerlink" title="第二章 过程模型"></a>第二章 过程模型</h2><p>在开发产品或构建系统时，遵循一系列可预测的步骤（即路线图）是非常重要的，它有助于及时交付高质量的产品。软件开发中所遵循的路线图就成为“软件过程”。软件过程提高了软件工程活动的稳定性、可控性和有组织性，如果不进行控制，软件活动将变得混乱。</p><p>软件过程定义为一个为创建高质量软件所需要完成的活动、动作和任务的框架。</p><p>线性过程流（linear process flow）从沟通到部署顺序执行五个框架活动；</p><ul><li><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/2.1.png"></li></ul><p>迭代过程流（iterative process flow）在执行下一个活动前重复执行之前的一个或多个活动；</p><ul><li><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/2.2.png"></li></ul><p>演化过程流（evolutionary process flow）采用循环的方式执行各个活动，每次循环都能产生更为完善的软件版本；</p><ul><li><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/2.3.png"></li></ul><p>并行过程流（parallel process flow）将一个或多个活动与其他活动并行执行。</p><ul><li><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/2.4.png"></li></ul><h4 id="【重点】过程模型的对比"><a href="#【重点】过程模型的对比" class="headerlink" title="【重点】过程模型的对比"></a>【重点】过程模型的对比</h4><table><thead><tr><th align="center">模型</th><th>概述</th><th align="center">图像</th><th align="center">优点</th><th align="center">缺点</th></tr></thead><tbody><tr><td align="center">瀑布模型</td><td>瀑布模型（waterfall model）又称为线性顺序模型（linear sequential model），提出了一个系统的、顺序的软件开发方法。<br>从用户需求规格说明开始，通过策划、建模、构建和部署过程，最终提供完整的技术支持。</td><td align="center"><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/2.5.png"></td><td align="center">容易理解和计划；<br>适用于充分理解的小型项目；<br>分析和测试是顺序线性的</td><td align="center">不能很好的适应变化；<br>测试在过程的后期进行；<br>客户确认在最后阶段</td></tr><tr><td align="center">原型模型</td><td>原型开发范型开始于沟通。<br>软件开发人员和其他利益相关者进行会晤，定义软件的整体目标，明确已知需求，并大致勾画出以后再进一步定义的东西。<br>然后迅速策划一个原型开发迭代并进行建模（以“快速设计”的方式）。</td><td align="center"><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/2.6.png"></td><td align="center">变更需求对后续设计影响较小；<br>客户很早并频繁的参与其中；<br>对小型项目来说效果好；<br>产品失败的可能性降低</td><td align="center">客户的参与可能会造成进度延误；<br>“提交”一个原型，可能会造成初步完成的假象；<br>原型被抛弃导致工作白干了；<br>很难计划和管理</td></tr><tr><td align="center">螺旋模型</td><td>螺旋模型是一种演进式软件过程模型。它结合了原型的迭代性质和瀑布模型的可控性和系统性的特点。它具有快速开发越来越完善的软件版本的潜力。<br>螺旋模型将软件开发为一系列演进版本。在早期的迭代中，软件可能是一个理论模型或者原型。在后来的迭代中，会产生逐渐一系列逐渐完整的系统版本。</td><td align="center"><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/2.7.png"></td><td align="center">有持续不断的客户参与；<br>开发风险得到控制；<br>适用于大型复杂项目；<br>适用于可扩展产品</td><td align="center">风险分析失效可能导致项目失败；<br>项目可能难于管理；<br>需要一个专家开发团队</td></tr><tr><td align="center">统一过程模型</td><td>统一过程（Unified Process，UP）尝试着从传统软件过程中挖掘最好的特征和性质，但是以敏捷开发中许多最好的原则来实现。<br>它建立了迭代的、增量的过程流，提供了演进的特征，对现代软件开发非常重要。</td><td align="center"><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/2.8.png"></td><td align="center">重视文档质量；<br>有持续不断的客户参与；<br>适合需求变更的情况；<br>对维护项目非常有效</td><td align="center">用例并不总是精确的；<br>具有复杂的软件增量集成；<br>阶段的重叠可能会带来问题；<br>需要一个专家开发团队</td></tr></tbody></table><hr><h2 id="第三章-敏捷和敏捷过程【重点】"><a href="#第三章-敏捷和敏捷过程【重点】" class="headerlink" title="第三章 敏捷和敏捷过程【重点】"></a>第三章 敏捷和敏捷过程【重点】</h2><p>敏捷方法是为了克服传统软件工程中认识和实践的弱点而形成的。</p><p>不确定意味着变更，而变更意味着付出昂贵的成本，特别是对变更失去控制或疏于管理的情况下。而敏捷开发最令人信服的特点之一就是它能够通过软件过程来降低由变更所带来的成本。</p><p>敏捷是有效的响应变更，它鼓励采用能够使沟通更便利的团队结构和协作态度。它强调可运行软件的快速交付而不那么看重中间产品；它将客户作为开发团队的一部分开展工作，以消除持续、普遍存在于多数软件项目中的“区分我们和他们”的态度；它承认在不确定的世界里，计划是有局限性的，项目计划必须是可以灵活调整的。</p><p>强调这样一个增量交付策略：根据具体的产品类型和运行环境，尽快将可工作的软件交付给客户。</p><table><thead><tr><th align="center">敏捷技术</th><th align="left">概述</th><th>图像</th><th align="center">优点</th><th align="center">缺点</th></tr></thead><tbody><tr><td align="center">Scrum</td><td align="left">应用Scrum原则指导过程中的开发活动，过程由“需求、分析、设计、演化和交付”等框架性活动组成。<br>        每一个框架活动中，工作任务在相对较短的时间盒的期限内完成称为一个冲刺（sprint）。冲刺包括：冲刺规划会议、每日Scrum会议、冲刺评审会议、冲刺回顾。<br>        冲刺中举行的工作适应于当前的问题，由Scrum团队规定并进行实施修改。</td><td><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/3.1.png"></td><td align="center">产品负责人设置优先级；<br>团队拥有决策权；<br>文档是轻量级的；<br>支持频繁更新</td><td align="center">很难控制变更成本；<br>可能不适合大型团队；<br>需要专家团队成员</td></tr><tr><td align="center">XP</td><td align="left">极限编程（XP）包括策划、设计、编码和测试四个框架活动的规则和时间。<br>策划：策划活动从倾听开始，这是一个需求收集活动。<br>设计：XP设计严格遵守KIS（Keep It Simple，保持简洁）原则。不鼓励额外的功能性设计。<br>编码：XP建议，在故事开发和初步设计完成后，团队不要直接开始编码，而是开发系列单元测试用于校验本次（软件增量）发布的所有故事。<br>测试：所建立的单元测试应当使用一个可以自动实施的框架。</td><td><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/3.2.png"></td><td align="center">强调客户参与；<br>建立合理的计划和时间表；<br>开发人员对项目高度投入；<br>产品失败的可能性低</td><td align="center">会受到“交付”原型的诱惑；<br>需要经常开会，导致成本增加；<br>可能允许过多的变更；<br>对高度熟练的团队成员有依赖性</td></tr><tr><td align="center">看板法</td><td align="left">看板法是一种精益方法学，提供了改进过程或工作流的方法。看板专注于变更管理和服务交付。<br>变更管理定义了将请求的变更集成到基于软件的系统的过程。<br>服务交付则专注于了解客户需求和期望。<br>团队成员管理其工作，并对于自组织完成工作给予充分的自由度。可根据需要逐步演化策略以改进结果。</td><td><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/3.3.png"></td><td align="center">预算和时间要求较低；<br>允许更早交付产品；<br>过程策略记录在案；<br>有持续的过程改进</td><td align="center">成功与否取决于团队合作技巧；<br>糟糕的业务分析可能会毁了项目；<br>灵活性可能导致开发人员失去焦点；<br>开发人员不愿意使用测量</td></tr><tr><td align="center">DevOps</td><td align="left">DevOps旨在将开发和运维相结合，尝试在整个软件供应链中应用敏捷开发和精益开发原则。设计一下几个阶段：<br>- 持续开发。将软件可交付成果分解到多次冲刺中开发，增量由开发团队的质量保证成员进行测试。<br>- 持续测试。自动化测试工具用于帮助团队成员同时测试多个代码增量，以确保在集成之前它们没有缺陷。<br>- 持续集成。在此阶段，将集成代码部署（安装）到生产环境，其中包括准备接收新功能的分布在全球的多个站点。<br>- 持续监控。开发团队成员的运维人员通过监控软件在生产环境中的性能，并在用户发现问题之前主动查找问题，以提高软件的质量。</td><td><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/3.4.png"></td><td align="center">代码部署的时间缩短了；<br>团队包括开发人员和运维人员；<br>团队拥有端到端的项目所有权；<br>主动监控已部署的产品</td><td align="center">存在处理新旧代码的压力；<br>成效严重依赖自动化工具；<br>部署可能会影响生产环境；<br>需要一个专家开发团队</td></tr></tbody></table><hr><h2 id="第四章-推荐的过程模型"><a href="#第四章-推荐的过程模型" class="headerlink" title="第四章 推荐的过程模型"></a>第四章 推荐的过程模型</h2><p>项目各不相同，团队也各不相同。没有哪种软件工程框架适合所有的软件产品。</p><h4 id="软件开发项目时应考虑的一些建议"><a href="#软件开发项目时应考虑的一些建议" class="headerlink" title="软件开发项目时应考虑的一些建议"></a>软件开发项目时应考虑的一些建议</h4><p>1、在没有足够反馈的情况下，使用线性过程模型是有风险的。</p><p>2、计划前期获取大量的需求既无可能也无必要。</p><p>3、前期需求获取可能不会降低成本或者防止超时。</p><p>4、软件开发中需要适当的项目管理。</p><p>5、文档与软件应该同步推进，而不应当拖延到构建开始时。</p><p>6、应尽早并且频繁地让利益相关者参与到软件开发过程中。</p><p>7、测试人员应在软件构建前就参与其中。</p><h4 id="敏捷过程模型和螺旋模型对比"><a href="#敏捷过程模型和螺旋模型对比" class="headerlink" title="敏捷过程模型和螺旋模型对比"></a>敏捷过程模型和螺旋模型对比</h4><table><thead><tr><th align="center">敏捷过程模型</th><th align="center">螺旋模型</th></tr></thead><tbody><tr><td align="center">不适合大型高风险或任务关键型任务</td><td align="center">不适用于小型、低风险的项目</td></tr><tr><td align="center">最少化规则、最少化文档</td><td align="center">需要多个步骤，以及前期完成的文档</td></tr><tr><td align="center">测试人员需要持续参与</td><td align="center">测试人员的早期参与（可由外部团队完成）</td></tr><tr><td align="center">易于适应产品变化</td><td align="center">在原型完成前难以进行产品更改</td></tr><tr><td align="center">非常依赖利益相关者的交互</td><td align="center">需要利益相关者持续参与计划和风险评估</td></tr><tr><td align="center">易于管理</td><td align="center">需要正式的项目管理和协调</td></tr><tr><td align="center">尽早交付部分解决方案</td><td align="center">难以判断项目结束时间</td></tr><tr><td align="center">非正式的风险管理</td><td align="center">良好的风险管理</td></tr><tr><td align="center">内建的持续过程改进</td><td align="center">项目结束时进行过程改进</td></tr></tbody></table><h4 id="一些敏捷需求定义的最佳实践"><a href="#一些敏捷需求定义的最佳实践" class="headerlink" title="一些敏捷需求定义的最佳实践"></a>一些敏捷需求定义的最佳实践</h4><p>1、通过匹配利益相关者的可用性以及评价他们的投入来鼓励其积极参与。</p><p>2、使用简单的模型（例如便利贴，快速草稿，用户故事）减少参与的障碍。</p><p>3、在使用需求表示技术之前，花一些时间来解释他们。</p><p>4、采用利益相关者的术语，并尽可能避免使用技术术语。</p><p>5、使用广度优先的方法来全面了解项目，然后再深入细节。</p><p>6、在计划实施用户故事时，允许开发团队及时完善（在利益相关者的参与下）需求详细信息。</p><p>7、将要实现的功能列出一个优先级列表，并首先实施最重要的用户故事。</p><p>8、与你的利益相关者密切合作，仅在创建下一个原型时记录对所有人有用的需求。</p><p>9、质疑是否需要维护未来可能用不到的模型和文档。</p><p>10、确保你具有管理的支持，以保证需求定义期间利益相关者和资源的可用性。</p><p>两个现实：</p><ul><li>利益相关者不可能在看到可工作软件之前先描述出整个系统；</li><li>利益相关者很难在看到实际软件之前先描述出软件所应具有的质量需求。</li></ul><h4 id="敏捷体系结构设计的四个关键要素"><a href="#敏捷体系结构设计的四个关键要素" class="headerlink" title="敏捷体系结构设计的四个关键要素"></a>敏捷体系结构设计的四个关键要素</h4><p><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/4.1.png"></p><p>1、关注关键的质量属性，并在构建它们时将其合并到原型中。</p><p>2、在规划原型时，成功的软件产品会将客户可见的功能和基础体系结构结合在一起。</p><p>3、如果对体系结构决策和相关质量问题给予足够的重视，那么敏捷体系结构就可以实现代码的可维护性和可扩展性。</p><p>4、持续管理并同步功能需求和体系结构需求间的依赖关系，以确保不断演化的体系结构基础能及时适应未来的增量。</p><h4 id="第一个功能原型的过程"><a href="#第一个功能原型的过程" class="headerlink" title="第一个功能原型的过程"></a>第一个功能原型的过程</h4><h6 id="1、从纸质原型过渡到软件设计"><a href="#1、从纸质原型过渡到软件设计" class="headerlink" title="1、从纸质原型过渡到软件设计"></a>1、从纸质原型过渡到软件设计</h6><p>为系统创建纸质原型很划算，并且可以在开发过程的早期完成，可以避免浪费时间构建错误的原型。</p><h6 id="2、设计用户界面原型"><a href="#2、设计用户界面原型" class="headerlink" title="2、设计用户界面原型"></a>2、设计用户界面原型</h6><p>创建用户界面原型作为第一个功能原型的一部分是一个明智的想法，客户发现软件产品易于学习和使用，他们更有可能使用它。</p><h6 id="3、创建一个虚拟原型"><a href="#3、创建一个虚拟原型" class="headerlink" title="3、创建一个虚拟原型"></a>3、创建一个虚拟原型</h6><p>与在已完成的原型上添加新的用户界面相比，放弃早期用户界面设计的代价要小得多。</p><h6 id="4、将输入和输出功能添加到原型"><a href="#4、将输入和输出功能添加到原型" class="headerlink" title="4、将输入和输出功能添加到原型"></a>4、将输入和输出功能添加到原型</h6><p>添加输入和输出功能到用户界面原型，能提供一种可以测试演化中原型的简便方法。</p><h6 id="5、实现算法"><a href="#5、实现算法" class="headerlink" title="5、实现算法"></a>5、实现算法</h6><p>实现算法涉及将你的想法和草图转换为程序源代码的过程。</p><h6 id="6、测试原型"><a href="#6、测试原型" class="headerlink" title="6、测试原型"></a>6、测试原型</h6><p>测试原型以演示客户要求的功能，这样可以在像客户展示之前发现一些尚未发现的缺陷。</p><h6 id="7、考虑原型的部署"><a href="#7、考虑原型的部署" class="headerlink" title="7、考虑原型的部署"></a>7、考虑原型的部署</h6><p>可以帮助你避免采用一些捷径，这些捷径会导致创建出的软件将来很难维护。</p><h4 id="获取原型反馈的最佳实践技巧"><a href="#获取原型反馈的最佳实践技巧" class="headerlink" title="获取原型反馈的最佳实践技巧"></a>获取原型反馈的最佳实践技巧</h4><h6 id="1、在要求原型反馈时提供框架素材"><a href="#1、在要求原型反馈时提供框架素材" class="headerlink" title="1、在要求原型反馈时提供框架素材"></a>1、在要求原型反馈时提供框架素材</h6><p>允许用户主动提供反馈的机制，而不是对抗性的。</p><h6 id="2、选择适当的人，测试你的模型"><a href="#2、选择适当的人，测试你的模型" class="headerlink" title="2、选择适当的人，测试你的模型"></a>2、选择适当的人，测试你的模型</h6><p>对原型进行评价是降低产品开发出错风险的关键。</p><h6 id="3、提出合适的问题"><a href="#3、提出合适的问题" class="headerlink" title="3、提出合适的问题"></a>3、提出合适的问题</h6><p>所有利益相关者都同意原型的目标。</p><h6 id="4、像用户提供备选方案时保持中立"><a href="#4、像用户提供备选方案时保持中立" class="headerlink" title="4、像用户提供备选方案时保持中立"></a>4、像用户提供备选方案时保持中立</h6><p>避免让用户感觉他们在以一种被“出卖”的方式做事。</p><h6 id="5、测试时进行调整"><a href="#5、测试时进行调整" class="headerlink" title="5、测试时进行调整"></a>5、测试时进行调整</h6><p>用户使用原型时，你需要具有灵活的思维方式。</p><h6 id="6、欢迎用户提出自己的想法"><a href="#6、欢迎用户提出自己的想法" class="headerlink" title="6、欢迎用户提出自己的想法"></a>6、欢迎用户提出自己的想法</h6><p>关注用户说了什么。</p><h4 id="维护发布软件"><a href="#维护发布软件" class="headerlink" title="维护发布软件"></a>维护发布软件</h4><p>维护指的是在最终用户环境中接受和交付（发布）软件之后，保持软件运行所需要的活动。</p><h6 id="改正性维护（corective-maintenance）"><a href="#改正性维护（corective-maintenance）" class="headerlink" title="改正性维护（corective maintenance）"></a>改正性维护（corective maintenance）</h6><p>软件交付给最终用户后，对软件进行反应性修改，以修复发现的问题。</p><h6 id="适应性维护（adaptive-maintenance）"><a href="#适应性维护（adaptive-maintenance）" class="headerlink" title="适应性维护（adaptive maintenance）"></a>适应性维护（adaptive maintenance）</h6><p>软件交付后的反应性修改，以保证软件在不断变化的最终用户环境中可用。</p><h6 id="完善性维护（perfective-maintenance）"><a href="#完善性维护（perfective-maintenance）" class="headerlink" title="完善性维护（perfective maintenance）"></a>完善性维护（perfective maintenance）</h6><p>软件交付后的主动修改，以提供新的用户特征、更好的程序代码结构或改进的文档。</p><h6 id="预防性维护（preventive-maintenance）"><a href="#预防性维护（preventive-maintenance）" class="headerlink" title="预防性维护（preventive maintenance）"></a>预防性维护（preventive maintenance）</h6><p>软件交付后对其进行主动修改，以便在用户发现产品故障之前进行检测和纠正。</p><p>主动的维护可以被安排和计划；反应性维护通常被描述为救火，因为它不能被计划，而且对于最终用户活动的成功至关重要的软件系统，必须立即处理。</p><p><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/4.2.png"></p><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/4.3.png"></p><hr><h2 id="第五章-软件工程的人员方面"><a href="#第五章-软件工程的人员方面" class="headerlink" title="第五章 软件工程的人员方面"></a>第五章 软件工程的人员方面</h2><h4 id="团队结构"><a href="#团队结构" class="headerlink" title="团队结构"></a>团队结构</h4><p>“最佳”团队结构取决于组织的管理风格、团队组成人员的数量以及他们的技术水平，还有整体的问题难度。</p><p>策划软件工程团队结构时应该考虑的项目因素：</p><ul><li>需解决问题的难度</li><li>基于代码行或功能点的结果程序的“规模”</li><li>团队成员合作的时间（团队寿命）</li><li>问题可模块化的程度</li><li>所建系统的质量和可靠性</li><li>交付日期要求的严格程度</li><li>项目所需的社会化（交流）程度</li></ul><h4 id="软件工程心理学"><a href="#软件工程心理学" class="headerlink" title="软件工程心理学"></a>软件工程心理学</h4><p>包括个人认知和激励，软件团队的群体动力及公司的组织行为。一个成功的（“有凝聚力的”）软件团队比普通团队更多产、更有动力。为实现高效，软件团队必须有目标意识、参与意识、信任意识以及进步意识。此外，必须避免“毒性”——混乱和消极的工作环境、不适合的软件过程、软件团队中模糊的角色定义以及不断暴露的故障。</p><hr><h2 id="第六章-理解需求"><a href="#第六章-理解需求" class="headerlink" title="第六章 理解需求"></a>第六章 理解需求</h2><p>理解问题的需求是软件工程师面对的最困难的任务之一。</p><h4 id="需求工程"><a href="#需求工程" class="headerlink" title="需求工程"></a>需求工程</h4><p>需求工程（Requirement Engineering，RE）是指致力于不断理解需求的大量任务和技术。从软件过程的角度来看，需求工程是一个软件工程动作，开始于沟通并持续到建模活动。需求工程为设计和构建奠定了坚实的基础。</p><p>需求工程在设计和构件之间建立起联系的桥梁。允许软件团队检查将要进行的软件工作的内容；必须提交的设计和构建的特定要求；完成指导工作顺序的优先级定义，以及将深切地影响随后设计的信息、功能和行为。</p><p>需求工程包括七项任务：</p><h6 id="1、起始"><a href="#1、起始" class="headerlink" title="1、起始"></a>1、起始</h6><p>在项目起始阶段，要建立基本的理解，包括存在的问题、谁需要解决方案、期望的解决方案的性质。在完成一项任务的区间，需要在所有利益相关者与软件团队之间建立沟通，以便开始有效的协作。</p><h6 id="2、获取"><a href="#2、获取" class="headerlink" title="2、获取"></a>2、获取</h6><p>询问客户、用户和其他人以下问题：系统或产品的目标是什么，想要实现什么，系统和产品如何满足业务的要求，最终系统和产品如何用与日常工作。在软件产品开发迭代过程中，很可能不断出现新的需求。</p><h6 id="3、细化"><a href="#3、细化" class="headerlink" title="3、细化"></a>3、细化</h6><p>细化任务的核心是开发一个精确的需求模型，用以说明软件的功能、特征和信息的各个方面。</p><h6 id="4、协商"><a href="#4、协商" class="headerlink" title="4、协商"></a>4、协商</h6><p>应该让客户、用户和其他利益相关者对各自的需求排序，然后按优先级讨论冲突。有效的协商不存在赢家也不存在输家。结果应该是双赢的，因为双方都可以接受的“交易”得到了巩固。</p><h6 id="5、规格说明"><a href="#5、规格说明" class="headerlink" title="5、规格说明"></a>5、规格说明</h6><p>术语规格说明对不同的人有不同的含义。规格说明可以是一份写好的文档、一套图形化的模型、一个形式化的数学模型、一组使用场景、一个原型或上述各项的任意组合。</p><h6 id="6、确认"><a href="#6、确认" class="headerlink" title="6、确认"></a>6、确认</h6><p>再确认阶段将对需求工程的工作产品进行质量评估。这个阶段最关心的是各个产品的一致性。</p><h6 id="7、需求管理"><a href="#7、需求管理" class="headerlink" title="7、需求管理"></a>7、需求管理</h6><p>需求管理是帮助项目组在项目进程中标识、控制和追踪需求以及需求变更的一组活动。</p><h4 id="利益相关者"><a href="#利益相关者" class="headerlink" title="利益相关者"></a>利益相关者</h4><p>定义为“直接或简介从正在开发的系统中获益的人”。每个利益相关者对系统都有不同的考虑，当系统成功开发后能获得的收益也不相同，同样，在系统开发失败时面临的风险也是不同的。</p><h4 id="需求监控"><a href="#需求监控" class="headerlink" title="需求监控"></a>需求监控</h4><p>在实现增量开发时，需求监控显得尤为有益。包括5项任务：</p><ul><li>分布式调试，用于发现错误并找到出错的原因；</li><li>运行验证，确认软件与规格说明是否匹配；</li><li>运行确定，评估逐步扩展的软件是否满足用户目标；</li><li>商业活动监控，评估系统是否满足商业目标；</li><li>演化与协同设计，为系统演化过程中的利益相关者提供信息。</li></ul><h4 id="确认需求"><a href="#确认需求" class="headerlink" title="确认需求"></a>确认需求</h4><p>需求模型的评审将解决如下问题：</p><ul><li>每项需求都与系统或产品的整体目标一致吗？</li><li>所有的需求都已经在相应的抽象层上说明了吗？换句话说，是否一些需求是在技术细节过多的层次上提出的，并不适合当前阶段？</li><li>需求是真正必需的，还是另外加上去的？有可能不是系统目标必需的特性吗？</li><li>每项需求都有界定且无歧义吗？</li><li>每项需求都有归属吗？换句话说，是否每项需求都标记了来源（通常是明确的个人）？</li><li>是否有一些需求和其他需求相冲突？</li><li>在系统或产品所处的技术环境下，每个需求都能够实现吗？</li><li>一旦实现后，每个需求是可测试的吗？</li><li>需求模型恰当的反映了将要构建系统的信息、功能和行为吗？</li><li>需求模型是否已经使用合适的方式“分割”，能够逐步揭示详细的系统信息？</li><li>已经使用需求模式简化需求模型了吗？已经恰当的确认了所有的模式吗？所有模式都与用户的需求一致吗？</li></ul><hr><h2 id="第七章-需求建模——一种推荐的方法"><a href="#第七章-需求建模——一种推荐的方法" class="headerlink" title="第七章 需求建模——一种推荐的方法"></a>第七章 需求建模——一种推荐的方法</h2><h4 id="【重点】需求分析"><a href="#【重点】需求分析" class="headerlink" title="【重点】需求分析"></a>【重点】需求分析</h4><p>需求分析产生软件操作特征的规格说明，指明软件和其他系统元素的接口，规定软件必须满足的约束。需求建模动作为以下一种或多种模型类型：</p><ul><li>场景模型：出自各种系统“参与者”观点的需求。</li><li>面向类的模型：表示面向对象类（属性和操作）的模型和如何通过类的协作获得系统需求。</li><li>行为模型：表示软件如何对内部或外部“事件”作出反应。</li><li>数据模型：描述问题信息域的模型。</li><li>面向流的模型：表示系统的功能元素并且描述当功能元素在系统中运行时怎样进行数据变换。</li></ul><p>这些模型为软件设计者提供信息，这些信息可以被转化为结构、接口和构件级的设计。最终，在软件开发完成后，需求模型（和需求规格说明）就为开发人员和客户提供了评估软件质量的手段。</p><h6 id="需求模型实现的主要目标"><a href="#需求模型实现的主要目标" class="headerlink" title="需求模型实现的主要目标"></a>需求模型实现的主要目标</h6><ul><li>描述客户需要什么</li><li>为软件设计奠定基础</li><li>定义在软件完成后可以被确认的一组需求。</li></ul><p>分析模型在系统级描述和软件设计之间建立了桥梁，需求模型的所有元素都可以直接追踪到设计模型。</p><h4 id="需求建模原则"><a href="#需求建模原则" class="headerlink" title="需求建模原则"></a>需求建模原则</h4><h6 id="1、问题的信息域必须得到表达和理解。"><a href="#1、问题的信息域必须得到表达和理解。" class="headerlink" title="1、问题的信息域必须得到表达和理解。"></a>1、问题的信息域必须得到表达和理解。</h6><p>信息域包含流入系统的数据、流出系统的数据以及数据存储区中手机和整理的永久保存的数据。</p><h6 id="2、必须定义软件执行的功能"><a href="#2、必须定义软件执行的功能" class="headerlink" title="2、必须定义软件执行的功能"></a>2、必须定义软件执行的功能</h6><p>软件功能可以为终端用户带来直接好处，而那些为用户可见的功能提供内部支持的功能也可以直接受益。</p><h6 id="3、必须表示软件的行为（作为外部事件的结果）"><a href="#3、必须表示软件的行为（作为外部事件的结果）" class="headerlink" title="3、必须表示软件的行为（作为外部事件的结果）"></a>3、必须表示软件的行为（作为外部事件的结果）</h6><p>计算机软件的行为受到其与外部环境的交互作用驱动。</p><h6 id="4、描述信息、功能和行为的模型必须以分层（或分级）的方式进行分割以揭示细节"><a href="#4、描述信息、功能和行为的模型必须以分层（或分级）的方式进行分割以揭示细节" class="headerlink" title="4、描述信息、功能和行为的模型必须以分层（或分级）的方式进行分割以揭示细节"></a>4、描述信息、功能和行为的模型必须以分层（或分级）的方式进行分割以揭示细节</h6><h6 id="5、分析任务应从基本信息转向实现细节"><a href="#5、分析任务应从基本信息转向实现细节" class="headerlink" title="5、分析任务应从基本信息转向实现细节"></a>5、分析任务应从基本信息转向实现细节</h6><h4 id="基于类建模"><a href="#基于类建模" class="headerlink" title="基于类建模"></a>基于类建模</h4><h6 id="分析类"><a href="#分析类" class="headerlink" title="分析类"></a>分析类</h6><ul><li>外部实体（例如其它系统、设备、人员）：产生或使用信息以供基于计算机的系统使用。</li><li>事务（例如报告、显示、字母、信号）：问题信息域的一部分。</li><li>偶发事件或事件（例如所有权转移或完成机器人的一组移动动作）：在系统操作环境内发生。</li><li>角色（例如经理、工程师、销售人员）：由和系统交互的人员办理。</li><li>组织单元（例如部门、组、团队）：和某个应用系统相关。</li><li>场地（例如制造车间或码头）：建立问题的环境和系统的整体功能。</li><li>结构（例如传感器、四轮交通工具、见算计）：定义了对象的类或与对象相关的类。</li></ul><h6 id="定义属性和操作"><a href="#定义属性和操作" class="headerlink" title="定义属性和操作"></a>定义属性和操作</h6><p>属性描述已经选择包含在需求模型中的类。属性定义类，以澄清类在问题空间的环境下意味着什么。</p><p>软件工程师应该研究用例并选择那些合理的“属于”类的“事物”。每个类都应该回答如下问题：什么数据项（组合项或基本项）能够在当前问题环境内完整地定义这个类？</p><p>操作定义了某个对象的行为。通常可以粗略的划分为4种类型：</p><ul><li>以某种方式操作数据（例如添加、删除、重新格式化、选择）</li><li>执行计算的操作</li><li>请求某个对象的状态的操作</li><li>监视某个对象发生某个控制事件的操作。</li></ul><h6 id="类-职责-协作者建模（Class-Responsibility-Collaborator，CRC）"><a href="#类-职责-协作者建模（Class-Responsibility-Collaborator，CRC）" class="headerlink" title="类-职责-协作者建模（Class-Responsibility-Collaborator，CRC）"></a>类-职责-协作者建模（Class-Responsibility-Collaborator，CRC）</h6><p>可以识别和组织与系统或产品需求相关的类。CRC模型可以看作是索引卡的集合。每个索引卡的左侧都有一个职责列表，而右侧是可以履行这些职责的相应的协作者。职责是和类相关的属性和操作。协作者是提供完成某个指责所需要信息和动作类。</p><p><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/7.1.png"></p><h4 id="功能建模"><a href="#功能建模" class="headerlink" title="功能建模"></a>功能建模</h4><p>功能模型处理两个应用程序处理元素，每个元素代表不同层次的过程抽象：</p><ul><li>用户可观察到的功能是由应用程序提供给最终用户的；</li><li>分析类中的操作实现与类相关的行为。</li></ul><h6 id="过程视图"><a href="#过程视图" class="headerlink" title="过程视图"></a>过程视图</h6><p>UML活动图通过提供特定场景内交互流的图形化标识来补充用例，类似于流程图。使用圆角矩阵表示特定的系统功能，箭头表示通过系统的流，菱形标识决策分支（标记菱形发出的每个箭头），实水平线表示并行发生的活动。</p><p><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/7.2.png"></p><h6 id="UML顺序图"><a href="#UML顺序图" class="headerlink" title="UML顺序图"></a>UML顺序图</h6><p>UML顺序图可用于行为建模。顺序图还可用于显示事件如何引发从一个对象到另一个对象的转移。一旦通过检查用例确认了事件，建模人员就创建了一个顺序图，即用时间函数表示事件是如何引发从一个对象流到另一个对象。顺序图是用例的简化版本，他表示导致行为从一个类流到另一个类的关键类和事件。</p><p><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/7.3.png"></p><h4 id="行为建模"><a href="#行为建模" class="headerlink" title="行为建模"></a>行为建模</h4><p>行为模型显示了软件如何对内部&#x2F;外部事件或激励做出响应。对于将要构建的系统而言，这些信息对于创建系统的有效设计很有用。UML活动图可用于对系统元素如何响应内部时间进行建模。</p><p>分析师必须按如下步骤进行：</p><ul><li>评估所有的用例，以保证完全理解系统内的交互顺序</li><li>识别驱动交互顺序的事件，并理解这些事件如何与特定的对象相互关联</li><li>为每个用例生成序列</li><li>创建系统状态图</li><li>评审行为模型以验证准确性和一致性</li></ul><h6 id="UML状态图"><a href="#UML状态图" class="headerlink" title="UML状态图"></a>UML状态图</h6><p>分析类的状态图。UML状态图是行为模型的一个组成部分，为每个类呈现了主动状态和导致这些主动状态发生变化的事件（触发器）。</p><p><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/7.4.png"></p><h6 id="UML活动图"><a href="#UML活动图" class="headerlink" title="UML活动图"></a>UML活动图</h6><p>UML活动图在特定的场景内通过迭代流的图形化表示来补充用例。（详见上文内容）</p><p>UML泳道图是活动图的一种有用的变形，允许建模人员表示用例所描述的活动流，同时指出哪个参与者或分析类负责由活动矩阵所描述的活动。职责由纵向分割图中的并行条表示，就像游泳池中的泳道。</p><p><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/7.5.png"></p><hr><h2 id="第八章-设计概念"><a href="#第八章-设计概念" class="headerlink" title="第八章 设计概念"></a>第八章 设计概念</h2><p>软件设计包括一系列原理、概念和实践，可以指导开发高质量的系统或产品。设计原理建立了指导设计工作的最重要原则。在运用设计实践的技术和方法之前，必须先理解设计概念，设计实践本身会产生软件的各种表示，以指导随后的构建活动。</p><p>设计是软件工程是否成功的关键。技术债务是软件开发中的一个概念，它涉及与返工相关的成本，这些成本是由于现在选择“快速而粗糙的”解决方案而导致的，而不是使用会花费更多时间的更好方法。增量的构建软件产品时，不可避免地会产生技术债务。优秀的开发团队必须设法通过定期重构软件来减少技术债务。</p><p>控制技术债务而不推迟编码的一种策略是利用多样化和聚合的设计实践。多样化是指识别需求模型元素所建议的可能的备选设计方案的实践。聚合是评估和拒绝不符合软件解决方案定义的非功能性需求所要求约束的备选设计方案的过程。多样化和聚合融合了：</p><ul><li>来自建立类似实体经验的直觉和判断力</li><li>一系列指导模型演化方式的原则和启发式方法</li><li>一系列评价质量的标准</li><li>得出最终设计表示的迭代过程</li></ul><p>一旦以这种方式确定了可行的备选方案，开发人员便可以很好的创建不太可能被抛弃式原型的软件增量。</p><h4 id="软件工程中的设计"><a href="#软件工程中的设计" class="headerlink" title="软件工程中的设计"></a>软件工程中的设计</h4><p>软件设计是建模活动的最后一个软件工程活动，接着便要进入构建阶段（编码和测试）。</p><p><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/8.1.png"></p><ul><li>数据设计或类设计将类模型转化为设计类的实现以及软件实现所要求的数据结构</li><li>体系结构设计定义了软件的主要结构化元素之间的关系、可满足系统需求的体系结构风格和模式以及影响体系结构实现方式的约束。</li><li>接口设计描述了软件和协作系统之间、软件和使用人员之间是如何通信的。</li><li>构件级设计将软件体系结构的结构化元素变换为对软件构件的过程性描述。</li></ul><p>设计师质量形成的地方，设计提供了可以用于质量评估的软件表示，设计是将利益相关者的需求准确的转化为最终软件产品或系统的唯一方法。软件设计是所有软件工程活动和随后的软件支持活动的基础。</p><h4 id="设计过程"><a href="#设计过程" class="headerlink" title="设计过程"></a>设计过程</h4><h6 id="指导良好设计演化的三个特征"><a href="#指导良好设计演化的三个特征" class="headerlink" title="指导良好设计演化的三个特征"></a>指导良好设计演化的三个特征</h6><ul><li>设计应当实现所有包含在需求模型中的显式需求，而且必须满足利益相关者期望的所有的隐式需求。</li><li>对于那些编码这和测试者以及随后的软件维护者而言，设计应当是可读的、可理解的指南。</li><li>设计应当提供软件的全貌，从实现的角度对数据域、功能域和行为域进行处理。</li></ul><h6 id="质量指导原则"><a href="#质量指导原则" class="headerlink" title="质量指导原则"></a>质量指导原则</h6><p>1、设计应展现出这样一种体系结构：</p><ul><li>已经使用可识别的体系结构风格或模式创建；</li><li>由能够展现出良好的设计特征的构建构成；</li><li>能够以演化的方式实现，，从而便于实施和测试。</li></ul><p>2、设计应该模块化，也就是说，应将软件逻辑的划分为元素或子系统。</p><p>3、设计应该包含数据、体系结构、接口和构件的清晰表示。</p><p>4、设计应导出数据结构，这些数据结构适用于要实现的类，并从可识别的数据模式提取。</p><p>5、设计应到处显示独立功能特征的构件。</p><p>6、设计应导出接口，这些接口降低了构件之间以及构件与外部环境之间连接的复杂性。</p><p>7、设计的导出应采用可重复的方法进行，这些方法由软件需求分析过程中获取的信息而产生。</p><p>8、应使用能够有效传达其意义的表示法来表达设计。</p><p><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/8.2.png"></p><h4 id="设计概念"><a href="#设计概念" class="headerlink" title="设计概念"></a>设计概念</h4><h6 id="1、抽象"><a href="#1、抽象" class="headerlink" title="1、抽象"></a>1、抽象</h6><p>在最高的抽象级上，使用问题所处环境的语言以概括性的术语描述解决方案。在较低的抽象级上，将提供更详细的解决方案说明。</p><p>在开发不同层次的抽象时，软件设计师力图创建过程抽象和数据抽象。过程抽象是指具有明确和有限功能的指令序列。数据抽象是描述数据对象的命名数据集合。</p><h6 id="2、体系结构"><a href="#2、体系结构" class="headerlink" title="2、体系结构"></a>2、体系结构</h6><p>软件体系结构意指“软件的整体结构和这种结构为系统提供概念完整性的方式”。</p><p>软件设计的目标之一是导出系统体系结构示意图，该示意图作为一个框架，将指导更详细的设计活动。一系列的体系结构模式使软件工程师能够重用设计层概念。</p><p>结构特性定义了“系统的构件、构件被封装的方式以及构件之间相互作用的方式”。外部功能特性指出“设计体系结构如何满足需求，这些需求包括性能需求、能力需求、可靠性需求、安全性需求、可适应性需求以及其他的系统特征需求”。相关系统族“抽取出相似系统设计中常遇到的重复性模式”。</p><p>结构模型将体系结构表示为程序构建的有组织的集合。框架模型可以通过确定相似应用中遇到的可复用体系结构设计框架（模式）来提高设计抽象的级别。动态模型强调程序体系结构的行为方面指明结构或系统配置如何随着外部事件的变化而产生变化。过程模型强调系统必须提供的业务或技术流程的设计。功能模型可用于表示系统的功能层次结构。</p><h6 id="3、模式"><a href="#3、模式" class="headerlink" title="3、模式"></a>3、模式</h6><p>设计模式描述了解决某个明确定义的设计问题的设计结构，该设计问题处在一个特定环境中，该环境会影响到模式的应用和使用方式。</p><p>每种设计模式的目的都是提供一种描述，以使设计人员可以决定：</p><ul><li>模式是否适用于当前工作</li><li>模式是否可以复用（因此节约设计时间）</li><li>模式是否能够用于知道开发一个相似的但功能或结构不同的模式</li></ul><h6 id="4、关注点分离"><a href="#4、关注点分离" class="headerlink" title="4、关注点分离"></a>4、关注点分离</h6><p>关注点分离是一个设计概念，它表明任何复杂问题如果被分解为可以独立解决或优化的若干块，该复杂问题便能够更容易的得到处理。关注点是一个特征或一个行为，被指定为软件需求模型的一部分。将关注点分割为更小的关注点，便可用更小的工作量和时间解决一个问题。</p><h6 id="5、模块化"><a href="#5、模块化" class="headerlink" title="5、模块化"></a>5、模块化</h6><p>模块化使关注点分离最常见的表现。软件被划分为独立命名的、可处理的构件，有时被称为模块，把这些构件集成到一起可以满足问题的需求。</p><p>模块化设计使开发工作更易于规划，可以定义和交付软件增量，更容易实施变更，能够有效的开展测试和调试，可以进行长期维护而没有严重的副作用。</p><h6 id="6、信息屏蔽"><a href="#6、信息屏蔽" class="headerlink" title="6、信息屏蔽"></a>6、信息屏蔽</h6><p>信息屏蔽原则提出模块应该“具有的特征是：每个模块对其他模块都隐蔽自己的设计决策”。换句话说，模块应该被特别说明并设计，使信息（算法和数据）都包含在模块内，其他模块无需对这些信息进行访问。</p><p>隐蔽的含义是，通过定义一系列的模块得到有效的模块化，独立模块之间只交流实现软件功能所必需的信息。抽象有助于定义构成软件的过程（或信息）实体。隐蔽定义并加强了对模块内过程细节的访问约束以及对模块所使用的任何局部数据结构的访问约束。</p><h6 id="7、功能独立"><a href="#7、功能独立" class="headerlink" title="7、功能独立"></a>7、功能独立</h6><p>功能独立的概念是关注点分离、模块化、抽象和信息隐蔽概念的直接产物。</p><p>通过开发具有“专一”功能和“避免”与其他模块过多交互的模块，可以实现功能独立。换句话说，软件设计时应使每个模块仅涉及需求的某个特定子集，并且当从程序结构的其他部分观察时，每个模块只有一个简单的接口。</p><p>独立性可以通过两条定性的标准进行评估：内聚性和耦合性。内聚性显示了某个模块相关功能的强度；耦合性显示了模块间的相互依赖性。</p><h6 id="8、逐步求精"><a href="#8、逐步求精" class="headerlink" title="8、逐步求精"></a>8、逐步求精</h6><p>逐步求精是一种自顶向下的设计策略，通过逐步分解功能的宏观陈述（过程抽象）进行层次开发，直到最终到达程序设计语言的语句这一级。</p><p>求精是一个细化的过程。抽象和细化是互补的概念。抽象能够明确说明内部过程和数据，但对“外部使用者”隐藏了底层细节；细化有助于设计过程中揭示底层细节。这两个概念有助于设计人员在设计演化中构建完整的设计模型。</p><h6 id="9、重构"><a href="#9、重构" class="headerlink" title="9、重构"></a>9、重构</h6><p>重构是一种重新组织的技术，可以简化构件的设计（或代码）而无需改变其功能或行为。</p><h6 id="10、设计类"><a href="#10、设计类" class="headerlink" title="10、设计类"></a>10、设计类</h6><p>当设计模型发生演化时，必须定义一组设计类，它们可以通过提供设计细节来对分析类进行求精，这些设计细节将这些类得以实现并创建支持业务解决方案的软件基础设施。</p><p>随着体系结构的形成，每个分析类转化为设计表示，抽象级就降低了。也就是说，分析类表示数据对象和应用于它们的关联服务。设计类更多的表现技术细节，用于指导实现。</p><p>设计类定义了四个特征：</p><ul><li>完整性与充分性。设计类应该完整的封装所有可以合理预见的存在于类中的属性和方法。</li><li>原始性。和一个设计类相关的方法应该关注于实现类的某一个服务。</li><li>高内聚性。一个内聚的设计类具有小的、集中的职责集合，并且专注于使用属性和方法来实现那些职责。</li><li>低耦合性。在设计模型中，设计类之间相互协作时必然的。但是，协作应该保持在一个可以接受的最小范围内。</li></ul><p><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/8.3.png"></p><h4 id="设计模型"><a href="#设计模型" class="headerlink" title="设计模型"></a>设计模型</h4><p><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/8.4.png"></p><p>在某些情况下，分析模型和设计模型之间可能存在明显的差异；而有些情况下，分析模型慢慢地融入设计模型而没有明显的差异。</p><h6 id="1、设计建模原则"><a href="#1、设计建模原则" class="headerlink" title="1、设计建模原则"></a>1、设计建模原则</h6><p>一组可以应用的设计原则：</p><ul><li>原则1：设计应可追溯到需求模型。</li><li>原则2：始终考虑要构建系统的体系结构。</li><li>原则3：数据设计与处理功能设计同等重要。</li><li>原则4：接口（内部和外部）的设计必须谨慎。</li><li>原则5：用户界面设计应适应最终用户的需求。</li><li>原则6：构件级设计应在功能上独立。</li><li>原则7：构件应彼此松耦合，并应与外部环境松耦合。</li><li>原则8：设计表示（模型）应易于理解。</li><li>原则9：设计应迭代式开发。</li><li>原则10：设计模型的创建并不排除采用敏捷方法的可能性。</li></ul><h6 id="2、接口设计元素"><a href="#2、接口设计元素" class="headerlink" title="2、接口设计元素"></a>2、接口设计元素</h6><p>接口设计有三个重要的元素：</p><ul><li>用户界面（User Interface，UI）<ul><li>UI设计（越来越多称为UX或者用户体验设计）是一项主要的软件工程活动。</li><li>通常，UI是整个应用程序体系结构中唯一的子系统，旨在为最终用户提供令人满意的用户体验。</li></ul></li><li>和其它系统、设备、网络、信息生成者或使用者的外部接口<ul><li>外部接口设计需要发送和接收信息实体的确定信息。</li></ul></li><li>各种设计构件之间的内部接口<ul><li>内部接口设计和构件级设计紧密相关。</li></ul></li></ul><p>这些接口设计元素能够使软件进行外部通信，还能使软件体系结构中的构件进行内部通信和协作。</p><h6 id="3、构件级设计元素"><a href="#3、构件级设计元素" class="headerlink" title="3、构件级设计元素"></a>3、构件级设计元素</h6><p>软件的构件级设计完整的描述了每个软件构件的内部细节。为此，构件级设计为所有局部数据对象定义数据结构，为所有在构件内发生的处理定义算法细节，并定义允许访问所有构件操作（行为）的接口。</p><p><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/8.5.png">此为UML构件图</p><p>构件的设计细节可以在许多不同的抽象级别上建模。UML活动图可以用来表示处理逻辑。构件的算法细节可以使用伪代码或某种其他图形来表示。数据结构细节通常使用伪代码或用于实现的编程语言来建模。</p><h6 id="4、部署级设计元素"><a href="#4、部署级设计元素" class="headerlink" title="4、部署级设计元素"></a>4、部署级设计元素</h6><p>在设计过程中，开发UML部署图以及随后的细化使用了描述符形式，这意味着部署图表明了计算环境，但并没有明确的说明配置细节。</p><p><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/8.6.png"></p><hr><h2 id="第九章-体系结构设计——一种推荐的方法"><a href="#第九章-体系结构设计——一种推荐的方法" class="headerlink" title="第九章 体系结构设计——一种推荐的方法"></a>第九章 体系结构设计——一种推荐的方法</h2><h4 id="体系结构"><a href="#体系结构" class="headerlink" title="体系结构"></a>体系结构</h4><p>软件的体系结构可以帮助：</p><ul><li>分析设计在满足既定需求方面的有效性</li><li>在设计变更相对容易的阶段，考虑体系结构可能的选择方案</li><li>降低与软件构件相关风险的方式</li></ul><p>体系结构的定义方式强调了体系结构表示中“软件构件”的作用。</p><h6 id="重要性"><a href="#重要性" class="headerlink" title="重要性"></a>重要性</h6><ul><li>软件体系结构提供了一种有助于促进所有利益相关者之间交流的表示形式。</li><li>软件体系结构突出了可能会对后续所有软件工程产生重要影响的早期设计决策。</li><li>软件体系结构提供了一个相对较小的描述软件不同构件之间如何组织和交互的模型。</li></ul><p>体系结构设计模型和其中包含的体系结构模式是可传递的。也就是说，体系结构的类型、风格和模式可以应用于其他系统的设计，并且表示了一组抽象，这使得软件工程师能以可预见的方式描述体系结构。</p><p>在定义软件体系结构时做出好的决策是一个软件产品是否成功的关键。软件体系结构确定了系统的结构并决定了系统的质量。</p><p><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/9.1.png"></p><h4 id="体系结构风格"><a href="#体系结构风格" class="headerlink" title="体系结构风格"></a>体系结构风格</h4><p>每个体系结构风格都描述了一种系统类别，包括：</p><ul><li>一组执行系统所需要的功能的构件</li><li>一组实现构件间“通信、合作和协调”的连接件</li><li>定义构件如何集成为系统的约束</li><li>能够使设计者通过分析系统组成元素的已知属性来理解系统整体性质的语义模型</li></ul><p>体系结构风格就是施加在整个系统设计上的一种变换，目的是为系统中所有构件建立一个结构。</p><p>体系结构模式（architectural pattern）和体系结构风格一样，也对体系结构设计施加一种变换。两者存在不同：</p><ul><li>体系结构模式设计的范围更窄一些，它更多地关注体系结构的一个方面而不是体系结构的整体</li><li>体系结构模式为体系结构定义规则，描述了软件是如何在基础功能层次上处理某些功能性方面的问题</li><li>体系结构模式倾向于解决体系结构环境中特定的行为问题。</li></ul><p>体系结构模式可以与体系结构风格相结合来更好地确定系统的整体结构。</p><h6 id="体系结构风格的简单分类"><a href="#体系结构风格的简单分类" class="headerlink" title="体系结构风格的简单分类"></a>体系结构风格的简单分类</h6><ul><li><p>以数据为中心的体系结构。数据存储区位于该体系结构的中心，其他构建频繁访问该存储区并更新，添加或修改存储区中的数据。以数据为中心的体系结构促进了可集成性（integrability）。</p><ul><li><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/9.2.png"></li></ul></li><li><p>数据流体系结构。该体系结构应用于输入数据需要经过一系列计算或操作构件以转换为输出数据的情况。</p><ul><li><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/9.3.png"></li></ul></li><li><p>调用和返回体系结构。该体系结构可以实现一个相对易于修改和扩展的程序结构。</p><ul><li>主程序&#x2F;子程序体系结构。这种经典的程序结构将功能划分为控制层次结构，其中一个“主”程序调用其他程序构件，而这些构件又可以调用其他的构件。<ul><li><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/9.4.png"></li></ul></li><li>远程过程调用体系结构。主程序&#x2F;子程序体系结构中的构件分布在网络中的多台计算机上。</li></ul></li><li><p>面向对象的体系结构。系统的构件封装了数据和必须用于该数据的操作。构件之间的通信和合作是通过信息传递实现的。</p><ul><li><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/9.5.png"></li></ul></li><li><p>层次体系结构。许多不同的层次被定义，每层完成的操作逐渐接近机器指令集。</p><ul><li><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/9.6.png"></li></ul></li><li><p>模型-视图-控制器（Model-View-Controller，MVC）体系结构是Web应用开发中经常使用的众多推荐移动基础设施模型之一。模型包含所有应用特定内容和处理逻辑。试图包含所有接口特定功能并能够显示终端用户所需的内容和操作逻辑。控制器管理对模型和视图的访问并协调它们之间的数据流。</p><ul><li><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/9.7.png"></li></ul></li></ul><h4 id="体系结构考虑要素"><a href="#体系结构考虑要素" class="headerlink" title="体系结构考虑要素"></a>体系结构考虑要素</h4><ul><li>经济性——好的软件通常是整洁的，依靠抽象来减少不必要的细节。同时，避免由不必要的功能和特征带来的复杂性。</li><li>易见性——设计模型创建后，对于那些随后审查该模型的软件工程师而言，体系结构决策和其相应的原因应当是显而易见的。重要的设计和领域概念必须被有效的传达。</li><li>隔离性——在设计时分割不同的关注点有时被称为隔离性。适当的隔离性可以使得模块化设计易于实现，然而过分的隔离性将导致碎片化和可用性的损失。</li><li>对称性——体系结构对称性是指系统在其属性上是一致且平衡的。对称的设计更易于理解，领悟和沟通。</li><li>应急性——紧急的，自组织的行为和控制是创建可扩展，高效且经济的软件体系结构的关键。</li></ul><h4 id="评估候选的体系结构设计"><a href="#评估候选的体系结构设计" class="headerlink" title="评估候选的体系结构设计"></a>评估候选的体系结构设计</h4><p>设计分析活动是迭代执行的：</p><ul><li>收集场景</li><li>给出需求，约束和环境描述</li><li>描述用于解决相应场景和需求体系结构风格和模式。体系结构风格必须使用以下体系结构视图描述：<ul><li>模型视图用于分析构件的任务分配和信息隐藏的程度</li><li>过程视图用于分析系统性能</li><li>数据流视图用于分析体系结构满足功能需求的程度</li></ul></li><li>通过独立考虑各属性来评估质量属性</li><li>对于特定的体系结构风格，确定质量属性对各种体系结构属性的敏感度</li><li>使用第五步中的敏感度分析对候选体系结构（第三步开始）进行评论</li></ul><p>一旦确定体系结构的敏感点，就可以通过识别对多个属性敏感的体系结构元素来寻找权衡点。</p><hr><h2 id="第十章-构件级设计"><a href="#第十章-构件级设计" class="headerlink" title="第十章 构件级设计"></a>第十章 构件级设计</h2><p>体系结构第一次迭代完成以后，就应该开始构件级设计。在这个阶段，全部数据和软件的程序结构都已经建立起来。其目的是把设计模型转换为可运行软件。但是现有的设计模型的抽象层次相对较高，而可运行程序的抽象层次较低。构件级设计在体系结构设计和编码之间架起桥梁，可以减少在编码阶段引入的错误数量。</p><h4 id="【重点】什么是构件？"><a href="#【重点】什么是构件？" class="headerlink" title="【重点】什么是构件？"></a>【重点】什么是构件？</h4><p>通常来讲，构件是计算机软件中的一个模块化的构造块。系统中模块化的、可部署的和可替换的部件，该部件封装了实现并对外提供一组接口。</p><h6 id="面向对象的观点"><a href="#面向对象的观点" class="headerlink" title="面向对象的观点"></a>面向对象的观点</h6><p>在面向对象软件工程环境中，一个构件包括一个协作类集合。构件中的每个类都得到详细阐述，以包括所有属性与其实现相关的操作。</p><h6 id="传统的观点"><a href="#传统的观点" class="headerlink" title="传统的观点"></a>传统的观点</h6><p>在传统软件工程环境中，一个构件就是程序的一个功能要素，程序由处理逻辑、实现处理逻辑所需的内部数据结构以及能够保证构建被调用和实现数据传递的接口构成。</p><p>传统构件也称为模块，主要有三种：</p><ul><li>控制构件，协调问题域中所有其他构件的调用</li><li>问题域构件，完成客户需要的全部功能或部分功能</li><li>基础设施构件，负责完成问题域中所需的支持处理的功能</li></ul><h4 id="【重点】基本设计原则"><a href="#【重点】基本设计原则" class="headerlink" title="【重点】基本设计原则"></a>【重点】基本设计原则</h4><h6 id="开闭原则（Open-Closed-Principle，OCP）"><a href="#开闭原则（Open-Closed-Principle，OCP）" class="headerlink" title="开闭原则（Open-Closed Principle，OCP）"></a>开闭原则（Open-Closed Principle，OCP）</h6><p>“模块（构件）应该对外延具有开放性，对修改具有封闭性”</p><p>简单地说，设计者应该采用一种无须对构件自身内部做修改就可以进行扩展的方式来说明构件。为了达到这个目的，设计者需要进行抽象，让那些可能需要扩展的功能与设计类本身之间起到缓冲区的作用。</p><h6 id="Liskov替换原则（Liskov-Substitution-Principle，LSP）"><a href="#Liskov替换原则（Liskov-Substitution-Principle，LSP）" class="headerlink" title="Liskov替换原则（Liskov Substitution Principle，LSP）"></a>Liskov替换原则（Liskov Substitution Principle，LSP）</h6><p>“子类可以替换它们的基类”</p><p>LSP原则要求源自基类的任何子类必须遵守基类与使用该基类的构件之间的隐含约定。在这里的讨论中，“约定”既是前置条件——构件使用基类前必须为真，又是后置条件——构件使用基类后必须为真。当设计者创建了导出类，这些子类必须遵守前置条件和后置条件。</p><h6 id="依赖倒置原则（Dependency-Inversion-Principle，DIP）"><a href="#依赖倒置原则（Dependency-Inversion-Principle，DIP）" class="headerlink" title="依赖倒置原则（Dependency Inversion Principle，DIP）"></a>依赖倒置原则（Dependency Inversion Principle，DIP）</h6><p>“依赖抽象，而非具体实现”</p><p>构件依赖的是其他具体构件（不是依赖像接口这样的抽象类）越多，扩展起来就越困难。</p><h6 id="接口分离原则（Interface-Segregation-Principle，ISP）"><a href="#接口分离原则（Interface-Segregation-Principle，ISP）" class="headerlink" title="接口分离原则（Interface Segregation Principle，ISP）"></a>接口分离原则（Interface Segregation Principle，ISP）</h6><p>“多个客户专用接口比一个通用接口好”</p><p>ISP原则建议设计者应该为每个主要的客户类型都设计一个专用的接口。</p><p>其他的一些打包原则：</p><h6 id="发布-x2F-复用等价性原则（Reuse-x2F-Release-Equivalency-Principe，REP）"><a href="#发布-x2F-复用等价性原则（Reuse-x2F-Release-Equivalency-Principe，REP）" class="headerlink" title="发布&#x2F;复用等价性原则（Reuse&#x2F;Release Equivalency Principe，REP）"></a>发布&#x2F;复用等价性原则（Reuse&#x2F;Release Equivalency Principe，REP）</h6><p>“复用的粒度就是发布的粒度”</p><p>当类或构件被设计为可复用时，在可复用实体的开发者和使用者之间就建立了一种隐含的约定关系。</p><h6 id="共同封装原则（Common-Closure-Principle，CCP）"><a href="#共同封装原则（Common-Closure-Principle，CCP）" class="headerlink" title="共同封装原则（Common Closure Principle，CCP）"></a>共同封装原则（Common Closure Principle，CCP）</h6><p>“一同变更的类应该合在一起”</p><p>类应该根据其内聚性进行打包。也就是说，当类被打包成设计的一部分时，他们应该处理相同的功能或者行为域。</p><h6 id="共同复用原则（Common-Reuse-Principle，CRP）"><a href="#共同复用原则（Common-Reuse-Principle，CRP）" class="headerlink" title="共同复用原则（Common Reuse Principle，CRP）"></a>共同复用原则（Common Reuse Principle，CRP）</h6><p>“不能一起复用的类不能被分到一组”</p><p>只有那些一起被复用的类才应该包含在一个包中。</p><h4 id="构件级设计指导方针"><a href="#构件级设计指导方针" class="headerlink" title="构件级设计指导方针"></a>构件级设计指导方针</h4><ul><li>构件。对那些已经被确定为体系结构模型一部分的构件应该建立命名约定，并对其做进一步的精细化处理，使其称为构件级模型的一部分。</li><li>接口。接口提供关于通信和协作的重要信息。</li><li>依赖和继承。为了提高可读性，依赖关系自左向右，继承关系自底（导出类）向上（基类）。</li></ul><h4 id="【重点】内聚性"><a href="#【重点】内聚性" class="headerlink" title="【重点】内聚性"></a>【重点】内聚性</h4><p>内聚性描述为构件的“专一性”。意味着构建或者类只封装那些相互关联密切，以及构件或类自身有密切关系的属性和操作。</p><ul><li>功能内聚。主要通过操作来体现。当一个模块完成一组且只有一组操作并返回结果时，就称此模块是功能内聚的。</li><li>分层内聚。由包、构件和类来体现。高层能够访问底层的服务，但底层不能访问高层的服务。</li><li>通信内聚。访问相同数据的所有操作被定义在一个类中。一般来说，这些类只着眼于数据的查询、访问和存储。</li></ul><h4 id="【重点】耦合"><a href="#【重点】耦合" class="headerlink" title="【重点】耦合"></a>【重点】耦合</h4><p>耦合是类之间彼此联系程度的一种定性度量。随着类（构件）之间的依赖越来越多，类之间的耦合程度亦会增加。在构件级设计中，一个重要的目标就是尽可能地保持低耦合。</p><ul><li>内容耦合发生在当一个控件“暗中修改其他控件的内部数据”时。这违反了基本设计概念中的信息隐蔽原则。</li><li>控制耦合发生在当操作A调用操作B，并且向B传递了一个控制标记时。接着，控制标记将会指引B中的逻辑流程。这种耦合形式的主要问题在于，B中的一个不相关变更往往能导致A所传递控制标记的意义也必须发生变更。如果忽略这个问题，就会引起错误。</li><li>外部耦合发生在当一个构件和基础设施构件进行通信或协作时。尽管这种类型的耦合是必要的，但是在一个系统中应该尽量将这种耦合限制在少量的构件或者类范围内。</li></ul><p>耦合是必然存在的。然而，设计者应该尽可能降低耦合，并且在不可避免出现高耦合的情况下，要充分理解高耦合的后果。</p><h4 id="实施构件级设计"><a href="#实施构件级设计" class="headerlink" title="实施构件级设计"></a>实施构件级设计</h4><p>典型的任务集：</p><h6 id="步骤1：标识出所有与问题域相对应的设计类"><a href="#步骤1：标识出所有与问题域相对应的设计类" class="headerlink" title="步骤1：标识出所有与问题域相对应的设计类"></a>步骤1：标识出所有与问题域相对应的设计类</h6><h6 id="步骤2：确定所有与基础设施域相对应的设计类"><a href="#步骤2：确定所有与基础设施域相对应的设计类" class="headerlink" title="步骤2：确定所有与基础设施域相对应的设计类"></a>步骤2：确定所有与基础设施域相对应的设计类</h6><h6 id="步骤3：细化所有未作为可复用构件获取的设计类"><a href="#步骤3：细化所有未作为可复用构件获取的设计类" class="headerlink" title="步骤3：细化所有未作为可复用构件获取的设计类"></a>步骤3：细化所有未作为可复用构件获取的设计类</h6><p>a：在类或构件协作时说明消息的细节</p><p>b：为每个构件确定适当的接口</p><p>c：细化属性，并且定义实现属性所需要的数据类型和数据结构</p><p>d：详细描述每个操作中的数据流</p><h6 id="步骤4：描述持久数据源（数据库和文件）并确定管理数据源所需要的类"><a href="#步骤4：描述持久数据源（数据库和文件）并确定管理数据源所需要的类" class="headerlink" title="步骤4：描述持久数据源（数据库和文件）并确定管理数据源所需要的类"></a>步骤4：描述持久数据源（数据库和文件）并确定管理数据源所需要的类</h6><h6 id="步骤5：开发并且细化类或构件的行为表示"><a href="#步骤5：开发并且细化类或构件的行为表示" class="headerlink" title="步骤5：开发并且细化类或构件的行为表示"></a>步骤5：开发并且细化类或构件的行为表示</h6><h6 id="步骤6：细化部署图以提供额外的实现细节"><a href="#步骤6：细化部署图以提供额外的实现细节" class="headerlink" title="步骤6：细化部署图以提供额外的实现细节"></a>步骤6：细化部署图以提供额外的实现细节</h6><h6 id="步骤7：重构每个构件级设计表示，并且总是考虑其他可选方案"><a href="#步骤7：重构每个构件级设计表示，并且总是考虑其他可选方案" class="headerlink" title="步骤7：重构每个构件级设计表示，并且总是考虑其他可选方案"></a>步骤7：重构每个构件级设计表示，并且总是考虑其他可选方案</h6><h4 id="基于构件的开发"><a href="#基于构件的开发" class="headerlink" title="基于构件的开发"></a>基于构件的开发</h4><table><thead><tr><th>优势</th><th>风险</th></tr></thead><tbody><tr><td>缩短交付周期：用现成的构件库构建完整的应用要快得多</td><td>构件选择的风险：对于黑盒构件，开发者很难预测构件的行为，或者开发者可能会将需求映射到错误的构件</td></tr><tr><td>更好的投资回报率（ROI）：购买现成的构件而不是重新开发相同功能的构件有时会节省资源</td><td>构件集成的风险：构件之间缺乏互操作性标准，这就经常需要开发者为构件编写“包装代码”以提供适合的接口</td></tr><tr><td>分摊开发构件的成本：在不同的应用中复用构件可以让多个项目分摊开发成本</td><td>质量风险：未知的设计假设使得部分构件更难测试，这会影响系统的安全性、性能以及可靠性</td></tr><tr><td>提高软件质量：构件在不同的应用中被测试且复用</td><td>安全风险：以非预期的方式使用系统，以及以未经测试的组合方式集成构件而造成系统脆弱</td></tr><tr><td>基于构件的应用有较好的可维护性：经过精心的工程实践，使用新的或者增强过的构件替换废弃构件是相对容易的。</td><td>系统演进风险：更新之后的构件可能和用户的需求不兼容或者包含其他未文档化的特性</td></tr></tbody></table><hr><h2 id="第十一章-用户体验设计"><a href="#第十一章-用户体验设计" class="headerlink" title="第十一章 用户体验设计"></a>第十一章 用户体验设计</h2><p>用户体验设计是一组渐进的过程，可帮助开发团队和项目利益相关者专注于为软件产品的用户提供良好的体验。UX设计比用户界面设计和可用性或可访问性工程要广泛。若要使其有效，则它必须在项目生命周期的早期开始。等到项目结束时才添加用户界面功能的开发人员不太可能为用户提供良好的体验。</p><h4 id="用户体验设计元素"><a href="#用户体验设计元素" class="headerlink" title="用户体验设计元素"></a>用户体验设计元素</h4><p><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/11.1.png"></p><ul><li>策略：确认所有构成用户体验设计基础工作的用户需求和客户业务目标</li><li>范围：包括实现与项目策略一致的一系列特性所需的功能和内容要求</li><li>结构：包括交互设计和信息体系结构</li><li>框架：由三部分组成。信息设计、界面设计、导航设计</li><li>界面：向用户呈现视觉设计或已完成项目的</li></ul><h4 id="黄金规则"><a href="#黄金规则" class="headerlink" title="黄金规则"></a>黄金规则</h4><h6 id="1、把控制权交给用户"><a href="#1、把控制权交给用户" class="headerlink" title="1、把控制权交给用户"></a>1、把控制权交给用户</h6><ul><li>以不强迫用户进入不必要的或不希望的动作方式来定义交互模式</li><li>提供灵活的交互</li><li>允许用户交互被中断和撤销</li><li>当技能水平高时可以使交互流线化并允许定制交互</li><li>使用户与内部技术细节隔离开来</li><li>设计应允许用户与出现在屏幕上的对象直接交互</li></ul><h6 id="2、减轻用户的记忆负担"><a href="#2、减轻用户的记忆负担" class="headerlink" title="2、减轻用户的记忆负担"></a>2、减轻用户的记忆负担</h6><ul><li>减少对短期记忆的要求</li><li>建立有意义的默认设置</li><li>定义直观的快捷方式</li><li>界面的视觉布局应该基于真实世界的象征</li><li>以一种渐进的方式揭示信息</li></ul><h6 id="3、保持界面一致"><a href="#3、保持界面一致" class="headerlink" title="3、保持界面一致"></a>3、保持界面一致</h6><ul><li>允许用户将当前任务放入有意义的环境中</li><li>在完整的产品线内保持一致</li><li>如果过去的交互模型已经建立起了用户期望，除非有不得已的理由，否则不要改变它</li></ul><h6 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h6><p>用户界面的分析和设计过程是迭代的，开始于螺旋模型的内部，且包括四个不同的框架活动。</p><p><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/11.2.png"></p><ul><li>界面分析活动的重点在于那些与系统交互的用户的轮廓</li><li>界面设计的目标是定义一组界面对象和动作，使用户能够以满足系统所定义的每个使用目标的方式完成所有的定义的任务</li><li>界面构建通常开始于创建可评估使用场景的原型</li><li>界面确认着重于：<ul><li>界面正确的实现每个用户定义的任务，以及达到所有一般用户需求的能力</li><li>界面容易使用和学习的程度</li><li>作为工作中的得力工具，用户对界面的接受程度</li></ul></li></ul><h4 id="用户体验分析"><a href="#用户体验分析" class="headerlink" title="用户体验分析"></a>用户体验分析</h4><p>软件工程过程模型的一个重要原则是：在试图设计一个解决方案之前，最好对问题有所理解。</p><p>在用户体验的设计中，理解问题就意味着了解：</p><ul><li>通过界面和系统交互的人（最终用户）</li><li>最终用户为完成工作要执行的任务</li><li>作为界面的一部分而显示的内容</li><li>任务处理的环境</li></ul><h4 id="用户体验设计"><a href="#用户体验设计" class="headerlink" title="用户体验设计"></a>用户体验设计</h4><p><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/11.3.png"></p><ul><li>理解。围绕用户研究进行，在该活动中，团队收集有关软件产品要解决的问题的信息。</li><li>草图。为各个团队成员（包括利益相关者）提供了讨论并解决在理解阶段发现的问腿所需的空间和时间。</li><li>决策。每个利益相关者展示其解决方案草图，然后团队投票决定在随后的原型设计活动中有用的解决方案。</li><li>原型。在这一阶段创建的原型可能使基于草图阶段选择方案的最小可行产品，又或是基于希望在验证阶段与潜在用户一起评估的客户旅程图或情节故事的一部分。</li><li>验证。观察用户试用设计模型是发现其UX设计中主要问题的最佳方法，这可以让你立刻开始迭代设计。</li></ul><hr><h2 id="常见的九种UML图"><a href="#常见的九种UML图" class="headerlink" title="常见的九种UML图"></a>常见的九种UML图</h2><p>（以下内容引用自<a href="https://www.lifengdi.com/archives/article/352">九种常用的UML图总结 - 李锋镝的博客</a>）</p><p>UML（Unified Modeling Language）<strong>统一建模语言</strong>，又称<strong>标准建模语言</strong>。是用来对软件密集系统进行可视化<strong>建模</strong>的一种语言。UML的定义包括UML语义和UML表示法两个元素。</p><p>UML是在开发阶段，说明、可视化、构建和书写一个<strong>面向对象</strong>软件密集系统的制品的开放方法。最佳的应用是工程实践，对大规模，复杂系统进行建模方面，特别是在<strong>软件架构</strong>层次，已经被验证有效。统一建模语言（UML）是一种模型化语言。模型大多以图表的方式表现出来。一份典型的建模图表通常包含几个块或框，连接线和作为模型附加信息之用的文本。这些虽简单却非常重要，在UML规则中相互联系和扩展。</p><p><strong>UML图的作用：</strong></p><p>UML的目标是以面向对象图的方式来描述任何类型的系统，具有很宽的应用领域。其中最常用的是建立软件系统的模型，但它同样可以用于描述非软件领域的系统，如机械系统、企业机构或业务过程，以及处理复杂数据的信息系统、具有实时要求的工业系统或工业过程等。总之，UML是一个通用的标准建模语言，可以对任何具有静态结构和动态行为的系统进行建模，而且适用于系统开发的不同阶段，从需求规格描述直至系统完成后的测试和维护。</p><p><strong>特点：</strong></p><p>（1）UML统一了各种方法对不同类型的系统、不同开发阶段以及不同内部概念的不同观点，从而有效的消除了各种建模语言之间不必要的差异。它实际上是一种通用的建模语言，可以为许多面向对象建模方法的用户广泛使用。</p><p>（2）UML建模能力比其它面向对象建模方法更强。它不仅适合于一般系统的开发，而且对并行、分布式系统的建模尤为适宜。</p><p>（3）UML是一种建模语言，而不是一个开发过程。</p><h3 id="下面是九种常用的UML图："><a href="#下面是九种常用的UML图：" class="headerlink" title="下面是九种常用的UML图："></a>下面是九种常用的UML图：</h3><p><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/12.1.png" alt="软件工程备考"></p><h3 id="1-用例图（UseCase-Diagrams）"><a href="#1-用例图（UseCase-Diagrams）" class="headerlink" title="1.用例图（UseCase Diagrams）"></a>1.用例图（UseCase Diagrams）</h3><p>用例图是从用户（角色）的角度出发，描述角色和用例之间的关系。即：谁要使用系统，一级他们使用系统可以做什么。简单来说就是：谁，可以用此系统做什么。</p><p><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/12.2.jpg" alt="软件工程备考"></p><h3 id="2-类图（Class-Diagram）"><a href="#2-类图（Class-Diagram）" class="headerlink" title="2.类图（Class Diagram）"></a>2.类图（Class Diagram）</h3><p>类图是描述系统中的类，以及各个类之间的关系的静态视图。是面向对象系统建模中最常用和最重要的图，是定义其他图的基础。</p><p>在UML类图中，常见的有以下几种关系: 泛化（Generalization）, 实现（Realization），关联（Association），聚合（Aggregation），组合（Composition），依赖（Dependency）。</p><p>各种关系的强弱顺序： 泛化 &#x3D; 实现 &gt; 组合 &gt; 聚合 &gt; 关联 &gt; 依赖</p><p>2.1.泛化（Generalization）</p><p>泛化是一种继承关系，表示一般与特殊的关系，它指定了子类如何继承父类的所有特征和行为。</p><p><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/12.4.jpg" alt="软件工程备考"></p><p>2.2.实现（Realization）</p><p>实现是一种类与接口的关系，表示类是接口所有特征和行为的实现。</p><p><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/12.5.jpg" alt="软件工程备考"></p><p>2.3.关联（Association）</p><p>关联是一种拥有的关系，它使一个类知道另一个类的属性和方法；关联可以是双向的，也可以是单向的。双向的关联可以有两个箭头或者没有箭头，单向的关联有一个箭头。</p><p><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/12.3.jpg" alt="软件工程备考"></p><p>2.4.聚合（Aggregation）</p><p>聚合是整体与部分的关系，且部分可以离开整体而单独存在。如车和轮胎是整体和部分的关系，轮胎离开车仍然可以存在。</p><p>​    　　聚合关系是关联关系的一种，是强的关联关系；关联和聚合在语法上无法区分，必须考察具体的逻辑关系。</p><p><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/12.6.jpg" alt="软件工程备考"></p><p>2.5.组合（Composition）</p><p>组合是整体与部分的关系，但部分不能离开整体而单独存在。如公司和部门是整体和部分的关系，没有公司就不存在部门。</p><p>​    　组合关系是关联关系的一种，是比聚合关系还要强的关系，它要求普通的聚合关系中代表整体的对象负责代表部分的对象的生命周期。</p><p><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/12.7.jpg" alt="软件工程备考"></p><p>2.6.依赖（Dependency）</p><p>依赖是一种使用的关系，即一个类的实现需要另一个类的协助，所以要尽量不使用双向的互相依赖.</p><p><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/12.8.jpg" alt="软件工程备考"></p><h3 id="3-对象图（Object-Diagrams）"><a href="#3-对象图（Object-Diagrams）" class="headerlink" title="3.对象图（Object Diagrams）"></a>3.对象图（Object Diagrams）</h3><p>对象图和类图一样反映系统的静态过程，但它是从实际的或原型化的情景来表达的。对象图显示某时刻对象和对象之间的关系。一个UML对象图可看成一个类图的特殊用例，实例和类可在其中显示。</p><p><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/12.9.jpg" alt="软件工程备考"></p><h3 id="4-状态图（Statechart-Diagrams）"><a href="#4-状态图（Statechart-Diagrams）" class="headerlink" title="4.状态图（Statechart Diagrams）"></a>4.状态图（Statechart Diagrams）</h3><p>状态图描述类的对象所有可能的状态，以及事件发生时状态的转移条件。他们可以告知一个对象可以拥有的状态，并且事件会怎么随着时间的推移来影响这些状态。</p><p>状态图是对类图的补充。</p><p><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/12.10.jpg" alt="软件工程备考"></p><h3 id="5-活动图（Activity-Diagrams）"><a href="#5-活动图（Activity-Diagrams）" class="headerlink" title="5.活动图（Activity Diagrams）"></a>5.活动图（Activity Diagrams）</h3><p>活动图描述用例要求所要进行的活动，以及活动间的约束关系，有利于识别并行活动。能够演示出系统中哪些地方存在功能，以及这些功能和系统中其他组件的功能如何共同满足前面使用用例图的业务需求。</p><p>活动图是状态图的一种特殊情况，这些状态大都处于活动状态。本质是一种流程图，它描述了活动到活动的控制流。</p><p><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/12.11.jpg" alt="软件工程备考"></p><h3 id="6-序列图-时序图（Sequence-Diagrams）"><a href="#6-序列图-时序图（Sequence-Diagrams）" class="headerlink" title="6.序列图-时序图（Sequence Diagrams）"></a>6.序列图-时序图（Sequence Diagrams）</h3><p>序列图是用来显示你的参与者如何以一系列顺序的步骤与系统的对象交互的模型。顺序图可以用来展示对象之间是如何进行交互的。序列图将显示的重点放在消息序列上，即强调消息是如何在对象之间被发送和接收的。</p><p>序列图展示的是多个系统或者对象之间的交互的顺序，强调时间顺序。</p><p><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/12.12.jpeg" alt="软件工程备考"></p><h3 id="7-协作图（Collaboration-Diagrams）"><a href="#7-协作图（Collaboration-Diagrams）" class="headerlink" title="7.协作图（Collaboration Diagrams）"></a>7.协作图（Collaboration Diagrams）</h3><p>协作图和序列图相似，显示对象间的动态合作关系。可以看成是类图和顺序图的交集，协作图建模对象或者角色，以及它们彼此之间是如何通信的。</p><p><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/12.13.png" alt="软件工程备考"></p><h3 id="8-构件图（Component-Diagrams）"><a href="#8-构件图（Component-Diagrams）" class="headerlink" title="8.构件图（Component Diagrams）"></a>8.构件图（Component Diagrams）</h3><p>构件图是用来表示系统中构件与构件之间，类或接口与构件之间的关系图。其中，构建图之间的关系表现为依赖关系，定义的类或接口与类之间的关系表现为依赖关系或实现关系。</p><p>构件图也叫组件图，由组件、接口和组件之间联系构成，描述的是在软件系统中遵从并实现一组接口的物理的、可替换的软件模块。</p><p>组件图 &#x3D; 构件（Component）+接口（Interface）+关系（Relationship）+端口（Port）+连接器（Connector）</p><p><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/12.14.jpg" alt="软件工程备考"></p><h3 id="9-部署图（Deployment-Diagrams）"><a href="#9-部署图（Deployment-Diagrams）" class="headerlink" title="9.部署图（Deployment Diagrams）"></a>9.部署图（Deployment Diagrams）</h3><p>部署图又叫配置图，是用来建模系统的物理部署。</p><p>部署图由节点以及节点之间的关系组成。</p><p>部署图描述的是系统运行时的结构，展示了硬件的配置及其软件如何部署到网络结构中。</p><p>部署图通常用来帮助理解分布式系统，一个系统模型只有一个部署图。</p><p>部署图用于可视化的软件组件部署的系统中的物理组件的拓扑结构。</p><p><img src="/2023/02/05/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%A4%87%E8%80%83/12.15.jpg" alt="软件工程备考"></p>]]></content>
      
      
      <categories>
          
          <category> 我的大学 </category>
          
          <category> 大三上学期 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计算机网络</title>
      <link href="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/"/>
      <url>/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/</url>
      
        <content type="html"><![CDATA[<p>因为本专业不学习《通信原理》，故一些涉及到通信原理的知识点，如果老师上课并没有过分强调，以下大概率不会特别做笔记。</p><h2 id="第一章-概述"><a href="#第一章-概述" class="headerlink" title="第一章 概述"></a>第一章 概述</h2><hr><h2 id="第二章-物理层"><a href="#第二章-物理层" class="headerlink" title="第二章 物理层"></a>第二章 物理层</h2><h4 id="1、传输媒体"><a href="#1、传输媒体" class="headerlink" title="1、传输媒体"></a>1、传输媒体</h4><p>传输媒体可分为导引型传输媒体（双绞线、同轴电缆、光纤）和非导引型传输媒体（微波通信）。【并不属于计算机网络的一部分，但是可以归纳在物理层】</p><ul><li>同轴电缆：早期局域网中的使用&#x2F;有线电视的使用</li><li>双绞线：8跟绝缘彩线绞合。绞合能抵御部分来自外界的电磁波干扰、减少相邻导线的电磁干扰。（现在的网线）</li><li>光纤：通信容量大；传输损耗小，远距离传输更加经济；抗雷电和电磁干扰性能好；无串音干扰，保密性好；体积小，重量轻。单数需要专用设备进行切割，且接口价格昂贵。</li></ul><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/2.1.png"></p><ul><li>无线电波：低频（LF）和中频（MF）使用地面波（基站）进行传输；高频（HF）和甚高频（VHF）使用地球上方100~500千米的带电离子层反射传播</li><li>微波：采用轨道同步卫星进行传播（无线网络、GPS）；低轨道卫星通信系统用于构成空间高速链路。</li><li>红外线：点对点无线传播；直线；传输速率低。</li></ul><h4 id="2、物理层协议的主要任务"><a href="#2、物理层协议的主要任务" class="headerlink" title="2、物理层协议的主要任务"></a>2、物理层协议的主要任务</h4><ul><li>机械特性：指明接口所引用接线器的形状和尺寸、引脚数目和排列、固定和锁定的装置。</li><li>电气特性：指明在接口电缆的各条线上出现的电压的范围。</li><li>功能特性：指明某条线上出现的某一电平的电压表示何种意义。</li><li>过程特性：指明对于不同功能的各种可能事件的出现顺序。</li></ul><h4 id="3、物理层的基本概念"><a href="#3、物理层的基本概念" class="headerlink" title="3、物理层的基本概念"></a>3、物理层的基本概念</h4><ul><li>物理层考虑的是怎样才能在连接各种计算机的传输媒体上传输数据比特流。</li><li>物理层为数据链路层屏蔽了各种传输媒体的差异，使数据链路层只需要考虑如何完成本层的协议和服务，而不必考虑网络具体的传输媒体是什么。</li></ul><h4 id="4、传输方式"><a href="#4、传输方式" class="headerlink" title="4、传输方式"></a>4、传输方式</h4><ul><li>串行传输：一次只发送一个比特，只有一条线路。</li><li>并行传输：一次发送n个比特，有多条线路。（传输速度是串行传播的n倍，但是成本高）<ul><li>计算机内部通信采用并行传输（CPU多核多进程），外部传输&#x2F;通信采用串行传播。</li></ul></li><li>同步传输：进行时钟同步<ul><li>外同步：在收发双方之间添加一条单独的时钟信号线</li><li>内同步：发送端将时钟同步信号编码到发送数据中一起传输。</li></ul></li><li>异步传输：在传输字节前后加上起始标识和结束标识。<ul><li>字节之间异步（字节之间的时间间隔不固定）</li><li>字节之间的每个比特仍然需要同步（各比特的持续时间相同）</li></ul></li><li>单向通信（单工）：只有一个数据传输方向（广播）【一条信道】</li><li>双向交替通信（半双工）：数据双向传播，但是不能同时。（异步，对讲机）【两条信道】</li><li>双向同时通信（全双工）：双向同时通信（电话）【两条信道】</li></ul><h4 id="5、常用编码（物理层主要解决传0还是传1的问题）"><a href="#5、常用编码（物理层主要解决传0还是传1的问题）" class="headerlink" title="5、常用编码（物理层主要解决传0还是传1的问题）"></a>5、常用编码（物理层主要解决传0还是传1的问题）</h4><p>码元：一段调制好的基本波形，可以表示比特信息。</p><ul><li>不归零编码（NRZ）：码元在任一时刻都不为0，接收端为了对码元计数需要额外一根传输线来传输时钟信号才能保持发送方和接收方同步（同步问题）， 浪费资源故计算机网络不采用这种编码。</li><li>归零编码（RZ）：每个码元传输结束后信号都要“归零”。相当于将时钟信号用“归零”方式编码在了数据内（自同步）。带宽浪费在“归零”上，编码效率低。</li><li>曼彻斯特编码：在每个码元的中间时刻进行跳变（0变1、1变0），跳变既表示时钟又表示数据。</li><li>差分曼彻斯特编码：跳变仅表示时钟，用码元开始处电平是否变化表示数据。（同1异0）</li><li>反向不归零编码（NRZI）：在码元时间内不会出现零电平。若后一个码元时间内所持续的电平与前一个码元时间内所持续的电平不同（也称为电平反转）则表示0，若电平保持不变则表示1。</li></ul><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/2.2.png"></p><h4 id="6、信道常用准则-x2F-公式"><a href="#6、信道常用准则-x2F-公式" class="headerlink" title="6、信道常用准则&#x2F;公式"></a>6、信道常用准则&#x2F;公式</h4><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/2.3.png"></p><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/2.4.png"></p><p>在信道带宽一定的情况下，根据奈氏准则和香农公式，要想提高信息中的传输速率就必须采用多元制（更好的调制方法）和努力提高信道中的信噪比。</p><hr><h2 id="第三章-数据链路层"><a href="#第三章-数据链路层" class="headerlink" title="第三章 数据链路层"></a>第三章 数据链路层</h2><h4 id="1、数据链路层概述"><a href="#1、数据链路层概述" class="headerlink" title="1、数据链路层概述"></a>1、数据链路层概述</h4><ul><li>链路（Link）：就是从一个结点到相邻结点的一段物理线路，而中间没有任何其他的交换节点。</li><li>数据链路（Data Link）：是指把实现通信协议的邮件和软件加到链路上，就构成了数据链路。</li><li>数据链路层以帧为单位传输数据。</li></ul><h4 id="2、封装成帧"><a href="#2、封装成帧" class="headerlink" title="2、封装成帧"></a>2、封装成帧</h4><ul><li>封装成帧是指数据链路层给上层交付的协议数据单元添加帧头和帧尾使之成为帧。<ul><li>帧头和帧尾中包含有重要的控制信息。</li><li>帧头和帧尾的作用之一就是帧定界。</li></ul></li><li>透明传输是指数据链路对上层交付的传输数据没有任何限制，就好像数据链路层不存在一样。<ul><li>面向字节的物理链路使用字节填充（或称字符填充）的方法实现透明传输。</li><li>面向比特的物理链路使用比特填充的方法实现透明传输。</li></ul></li><li>为了提高帧的传输效率，应当使帧的数据部分的长度尽可能大些。</li><li>考虑到差错控制等多种因素，每一种数据链路层协议都规定了帧的数据部分的长度上限，即最大传送单元MTU（Maximum Transfer Unit）。</li></ul><h4 id="3、差错检测"><a href="#3、差错检测" class="headerlink" title="3、差错检测"></a>3、差错检测</h4><ul><li><p>比特差错：实际的通信链路都不是理想的，比特在传输过程中可能会产生差错：1可能变成0，0也可能变成1。</p></li><li><p>误码率BER（Bit Error Rate）：在一段时间内，传输错误的比特占所传输比特总数的比率。</p></li><li><p>使用差错检测码来检测数据在传输过程中是否产生了比特差错，是数据链路层所要解决的重要问题之一。</p></li><li><p>奇偶校验：在待发送的数据后面添加1位奇偶校验位，使整个数据（包括所添加的校验位在内）中“1”的个数位技术（奇检验）或偶数（偶校验）。</p><ul><li>如果有奇数个位发生误码，则奇偶性发生变化，可以检查出误码；</li><li>如果有偶数个位发生误码，则奇偶性不发生变化，不能检查出误码。</li></ul></li><li><p>循环冗余校验CRC（Cyclic Redundancy Check）：收发双方约定好一个生成多项式G(x)；发送方基于待发送的数据和生成多项式计算出差错检测码（冗余码），将其添加到待传输数据的后面一起传输；接收方通过生成多项式来计算收到的数据是否产生了误码。</p><ul><li>检错码只能检测出帧在传输过程中出现了差错，但并不能定位错误，因此无法纠正错误。</li><li>CRC有很好的检错能力（漏检率非常低），虽然计算比较复杂，但非常易于用硬件实现，因此广泛应用于数据链路层。</li></ul></li><li><p>要想纠正传输中的差错，可以使用冗余信息更多的纠错码进行前向纠错。但纠错码的开销比较大，在计算机网络中较少使用。</p></li><li><p>在计算机网络中通常采用检错重传方式来纠正传输中的差错（可靠传输服务【不局限于数据链路层】），或者仅仅是丢弃检测到差错的帧（不可靠传输服务）。</p></li><li><p>比特差错只是传输差错中的一种，传输差错还包括分组丢失、分组失序以及分组重复（其他传输差错一般不出现在数据链路层，而在其上层）。</p></li></ul><h4 id="4、可靠传输协议的实现："><a href="#4、可靠传输协议的实现：" class="headerlink" title="4、可靠传输协议的实现："></a>4、可靠传输协议的实现：</h4><p>（1）停止等待协议SW（Stop-and-Wait）：</p><ul><li>接收端检测到数据分组有误码时，将其丢弃并等待发送方的超时重传。（对于误码率较高的点对点链路，为使发送方尽早重传，也可给发送方发送NAK分组。）</li><li>为了让接收方能后判断所收到的数据分组是否重复，需要给数据分组编号。（由于停等协议的停等特性，只需一个编号表示0&#x2F;1）</li><li>为了让发送方能够判断所收到的ACK分组是否时重复的，需要给ACK分组编号，所用比特数量与数据分组所用比特数量一样。（数据链路层一般不会出现ACK分组迟到的情况，因此在数据链路层使用停等协议可以不用给ACK分组编号。）</li><li>超时计时器设置的重传时间应仔细选择。一般可将重传时间选为略大于“从发送方到接收方的平均往返时间”。<ul><li>数据链路层点对点的往返时间比较确定，重传时间比较好设定。</li><li>运输层由于端到端的往返世纪那非常不确定，设置合适的重传时间有时并不容易。</li></ul></li></ul><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/3.1.png"></p><ul><li>停等协议信道利用率低。<ul><li>当往返时延RTT远大于数据帧发送时延T<del>D</del>时（例如使用卫星链路），信道利用率非常低；</li><li>若出现重传，则对于传送有用的数据信息来说，信道利用率还要降低。</li></ul></li></ul><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/3.2.png"></p><p>（2）回退N帧协议GBN（Go-Back_N）：</p><ul><li>累计确认：接收方不一定要对收到的数据分组逐个发送确认，而是可以在收到几个数据分组后，对按序到达的最后一个数据分组发送确认。ACKn表示序号为n及以前的所有数据分组都已正确接收。</li><li>发送窗口的尺寸不能超过其上线，否则接收方无法分辨新、旧数据分组，导致重复接收。</li></ul><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/3.3.png"></p><ul><li>回退N帧协议在流水线传输的基础上利用发送窗口来限制发送方连续发送数据分组的数量，是一种连续ARQ协议。</li><li>在协议工作过程中发送窗口和接收窗口不断向前滑动，因此这类协议又称为滑动窗口协议。</li><li>当通信线路质量不好时，信道利用率并不比停止-等待协议高。</li></ul><p>（3）选择重传协议SR（Selective Request）</p><p>回退N帧协议的接收窗口尺寸W<del>R</del>只能等于1，因此接受方只能按序接收正确到达的数据分组。一个数据分组的误码就会导致其后续多个数据分组不能被接收方按序接收而丢弃（尽管无乱序和误码），这造成发送方对这些数据分组的超时重传是对通信资源的极大浪费。</p><p>选择重传协议：接收窗口尺寸W<del>R</del>不再等于1（而应大于1），接收方先收下失序到达但无误码并且序号落在接收窗口内的那些数据分组，等到所缺分组收齐后再一并送交上层。</p><ul><li>为了使发送方仅重传出现差错的分组，接收方不能再采用累计确认，而需要对每个正确接收到的数据分组进行逐一确认。</li></ul><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/3.4.png"></p><h4 id="5、点对点协议PPP（Point-to-Point-Protocol）"><a href="#5、点对点协议PPP（Point-to-Point-Protocol）" class="headerlink" title="5、点对点协议PPP（Point-to-Point Protocol）"></a>5、点对点协议PPP（Point-to-Point Protocol）</h4><ul><li>PPP协议是目前使用最广泛的点对点数据链路层协议。</li><li>PPP协议为在点对点链路传输各种协议数据报提供了一个标准方法。<ul><li>对各种协议数据报的封装方法（封装成帧）</li><li>链路控制LCP（用于建立、配置以及测试数据链路的连接）</li><li>一套网络控制协议NCPs（每一个协议支持不同的网络层协议）</li></ul></li><li>帧格式（目前阶段不要求掌握）：</li></ul><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/3.5.png"></p><ul><li>工作状态：</li></ul><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/3.6.png"></p><h4 id="6、媒体接入控制"><a href="#6、媒体接入控制" class="headerlink" title="6、媒体接入控制"></a>6、媒体接入控制</h4><ul><li>媒体接入控制MAC（Medium Access Control）：共享信道要着重考虑如何协调多个发送和接收站点对一个共享传输媒体的占用。</li></ul><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/3.7.png"></p><p>随着技术的发展，交换技术的成熟和成本的降低，具有更高性能的使用点对点链路和链路层交换机的交换式局域网在有线领域已完全取代了共享式局域网，但由于无线信道的广播天性，无线局域网任然使用共享媒体技术。</p><h6 id="（1）静态划分信道——信道复用"><a href="#（1）静态划分信道——信道复用" class="headerlink" title="（1）静态划分信道——信道复用"></a>（1）静态划分信道——信道复用</h6><ul><li>复用（Multiplexing）是通信技术中的一个重要概念。服用就是通过一条物理线路同时传输多路用户的信号。</li><li>当网络中传输媒体的传输容量大于多条单一信道传输的总通信量时，可利用复用技术在一条物理线路上建立多条通信信道来充分利用传输媒体的带宽。</li><li>常见的复用技术：<ul><li>频分复用FDM：所有用户同时占用不同的频带资源进行通信。</li><li>时分复用TDM：所有用户在不同的时间占用同样的频带宽度。</li><li>波分复用WDM</li><li>码分复用CDM：另一种共享信道的方法。更常用的名词是码分多址CDMA（Code Division Multiple Access）；每一个用户可以在同样的时间使用同样的频带进行通信；使用经过特殊挑选的不同码型，抗干扰能力强（早期多用于军事通信，现在价格便宜，已广泛应用 ）</li></ul></li><li>复用与多址：<ul><li>复用是将单一媒体上的频带资源划分成很多子信道，这些子信道之间相互独立，互不干扰。从媒体的整体频带资源上看，每个子信道只占用该媒体频带资源的一部分。</li><li>多址（多点接入）处理的是动态分配信道给用户。用户仅暂时性占用信道，移动通信系统基本属于这种情况。（无线广播&#x2F;电视广播是信道永久分配，不需要多址）</li><li>这里并不严格区分复用和多址的概念（目前：复用 &#x3D;&#x3D; 多址）</li></ul></li></ul><h6 id="（2）动态接入控制——随机接入——CSMA-x2F-CD协议"><a href="#（2）动态接入控制——随机接入——CSMA-x2F-CD协议" class="headerlink" title="（2）动态接入控制——随机接入——CSMA&#x2F;CD协议"></a>（2）动态接入控制——随机接入——CSMA&#x2F;CD协议</h6><ul><li>工作原理：<ul><li>多址接入MA：多个主机连接在一条总线上，竞争使用总线。</li><li>载波监听CS：发送帧前先检测总线，若总线空闲96比特时间，则立即发送；若总线忙，则持续检测总线空闲96比特时间后再重新发送。</li><li>碰撞检测CD：边发送边检测碰撞。若检测到碰撞，则立即停止发送，退避一段时间后再重新发送。</li></ul></li></ul><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/3.8.png"></p><h6 id="（3）动态接入控制——随机接入——CSMA-x2F-CA协议"><a href="#（3）动态接入控制——随机接入——CSMA-x2F-CA协议" class="headerlink" title="（3）动态接入控制——随机接入——CSMA&#x2F;CA协议"></a>（3）动态接入控制——随机接入——CSMA&#x2F;CA协议</h6><p>载波监听多址接入&#x2F;碰撞避免 Carrier Sense Multiple Access&#x2F;Collision Avoidance</p><ul><li><strong>在无线局域网中，任然可以使用载波监听多址接入CSMA</strong>，在发送帧之前先对传输媒体进行载波监听。若发现有其他站在发送帧，就推迟发送以免发生碰撞。</li><li><strong>在无线局域网中，不能使用碰撞检测CD。</strong><ul><li>由于无线信道的传输条件特殊，其信号强度的动态范围非常大，无线网卡上接收到的信号强度往往会远小于发送信号的强度（可能相差百万倍）。如果<strong>在无线网卡上实现碰撞检测CD，对硬件的要求非常高</strong>。</li><li>即使能够在邮件上实现无线局域网的碰撞检测功能，但由于无线电波传播的特殊性<strong>（存在隐蔽站问题），进行碰撞检测的意义也不大</strong>。</li></ul></li><li>802.11无线局域网使用CSMA&#x2F;CA协议，在CSMA的基础上增加了一个碰撞避免CA功能，而不再实现碰撞检测功能。</li><li>由于不可能避免所有碰撞，并且无线信道误码率较高，802.11标准害<strong>使用了数据链路层确认机制（停止-等待协议）</strong>来保证数据被正确接收。</li><li>802.11的MAC层标准定义了两种不同的媒体接入控制方式：<ul><li><strong>分布式协调功能DCF（Distributed Coordination Function）</strong>：在DCF方式下，没有中心控制站点，每个站点使用CSMA&#x2F;CA协议通过争用信道来获取发送权，这是802.11定义的默认方式。</li><li><strong>点协调功能PCF（Point Coordination Function）</strong>：PCF方式使用集中控制的接入算法（一般在接入点AP实现集中控制），是802.11定义的可选方式，在实际中较少使用。</li></ul></li></ul><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/3.9.png"></p><h4 id="7、MAC地址（Media-Access-Control）"><a href="#7、MAC地址（Media-Access-Control）" class="headerlink" title="7、MAC地址（Media Access Control）"></a>7、MAC地址（Media Access Control）</h4><h6 id="（1）简述"><a href="#（1）简述" class="headerlink" title="（1）简述"></a>（1）简述</h6><ul><li>当多个主机连接在同一个广播信道上，要想实现两个主机之间的通信，则每个主机都必须有一个唯一的标识，即一个数据链路层地址；</li><li>在每个主机发送的<strong>帧中必须携带标识发送主机和接受主机的地址</strong>。由于这类地址是用于媒体接入控制MAC，因此这类地址被称为<strong>MAC地址</strong>。<ul><li>MAC地址一般被固化在网卡（网络适配器）的电可擦可编程只读存储器EEPROM中，因此MAC地址也被成为<strong>硬件地址</strong>；</li><li>MAC地址有时也被称为<strong>物理地址。（这并不意味着MAC地址属于网络体系结构中的物理层）</strong></li></ul></li><li>一般情况下，用户主机会包含两个网络适配器：有线局域网适配器（有线网卡）和无线局域网（无线网卡）。每个网络适配器都有一个全球唯一的MAC地址。而交换机和路由器往往拥有更多的网络接口，所以会拥有更多的MAC地址。综上所述，<strong>严格来说，MAC地址是对网络上各接口的唯一标识，而不是对网络上各设备的唯一标识。</strong></li></ul><h6 id="（2）IEEE-802局域网的MAC地址格式"><a href="#（2）IEEE-802局域网的MAC地址格式" class="headerlink" title="（2）IEEE 802局域网的MAC地址格式"></a>（2）IEEE 802局域网的MAC地址格式</h6><p>扩展的唯一标识符EUI（EUI-48）</p><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/3.10.png"></p><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/3.11.png"></p><h6 id="（3）发送顺序"><a href="#（3）发送顺序" class="headerlink" title="（3）发送顺序"></a>（3）发送顺序</h6><ul><li>字节发送顺序：第一字节——》第六字节</li><li>字节内比特发送顺序：b<del>0</del>——b<del>7</del></li></ul><h4 id="8、IP地址（属于网络层）"><a href="#8、IP地址（属于网络层）" class="headerlink" title="8、IP地址（属于网络层）"></a>8、IP地址（属于网络层）</h4><h6 id="（1）简述-1"><a href="#（1）简述-1" class="headerlink" title="（1）简述"></a>（1）简述</h6><p>IP地址是因特网（Internet）上主机和路由器所使用的地址，用于标识两部分信息：</p><ul><li>网络编号：标识因特网上数以百万计的网络</li><li>主机编号：标识同一网络上不同主机（或路由器各接口）</li></ul><p>MAC地址不具备区分不同网络的功能。</p><ul><li>如果只是一个单独的网络，不接入因特网，可以只使用MAC地址</li><li>如果主机所在的网络要接入因特网，则IP地址和MAC地址都需要使用</li></ul><h6 id="（2）数据包转发过程中IP地址与MAC地址的变化情况"><a href="#（2）数据包转发过程中IP地址与MAC地址的变化情况" class="headerlink" title="（2）数据包转发过程中IP地址与MAC地址的变化情况"></a>（2）数据包转发过程中IP地址与MAC地址的变化情况</h6><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/3.12.png"></p><ul><li>数据包转发过程中<strong>源IP地址和目的IP地址保持不变</strong></li><li>数据包转发过程中<strong>源MAC地址和目的MAC地址逐个链路（或逐个网络）改变</strong></li></ul><h4 id="9、地址解析协议ARP协议"><a href="#9、地址解析协议ARP协议" class="headerlink" title="9、地址解析协议ARP协议"></a>9、地址解析协议ARP协议</h4><ul><li>源主机在自己的<strong>ARP高速缓存表</strong>中查找目的主机的IP地址所对应的MAC地址，若找到了，则可以封装MAC帧进行发送；若找不到，则发送<strong>ARP请求（封装在广播MAC帧中）</strong></li><li>目的主机收到ARP请求后，将源主机的IP地址与MAC地址记录到自己的ARP高速缓存表中，然后给源主机发送<strong>ARP响应（封装在单播MAC帧中）</strong>，ARP响应中包含有目的主机的IP地址和MAC地址</li><li>源主机收到ARP响应后，将目的主机的IP地址与MAC地址记录到自己的ARP高速缓存表中，然后就可以封装之前想发送的MAC帧并发送给目的主机</li><li><strong>ARP的作用范围：逐段链路或逐个网络使用</strong></li><li><strong>除ARP请求和响应外，ARP还有其它类型的报文</strong>（例如用于检查IP地址冲突的“无故ARP、免费ARP（Gratuitous ARP）”）</li><li>ARP没有安全验证机制，<strong>存在ARP欺骗（攻击）问题</strong></li></ul><h4 id="10、集线器与交换机的区别"><a href="#10、集线器与交换机的区别" class="headerlink" title="10、集线器与交换机的区别"></a>10、集线器与交换机的区别</h4><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/3.13.png"></p><h6 id="（1）以太网交换机"><a href="#（1）以太网交换机" class="headerlink" title="（1）以太网交换机"></a>（1）以太网交换机</h6><ul><li><p>以太网交换机通常都有<strong>多个接口</strong>。每个接口都可以直接与一台主机或另一个以太网交换机相连。一般都工作在<strong>全双工方式</strong></p></li><li><p>以太网交换机具有并行性，能<strong>同时连通多对接口</strong>，使多对主机能同时通信，<strong>无碰撞（不使用CSMA&#x2F;CD协议）</strong></p></li><li><p>以太网交换机一般都具有多种速率的接口，例如：10Mb&#x2F;s、100Mb&#x2F;s、1Gb&#x2F;s、10Gb&#x2F;s接口的多种组合。</p></li><li><p>以太网交换机<strong>工作在数据链路层（也包括物理层</strong>），它收到帧后，在帧交换表中查找<strong>帧的目的MAC地址所对应的接口号</strong>，然后通过该接口转发帧。</p></li><li><p>以太网交换机是一种即插即用设备，其内部的<strong>帧交换表是通过子学习算法自动地逐渐建立起来的</strong>。</p></li><li><p>帧的两种转发方式</p><ul><li><strong>存储转发</strong></li><li><strong>直通交换</strong>：采用基于硬件的交叉矩阵（交换时延非常小，但不检查帧是否有差错）</li></ul></li></ul><h6 id="（2）对比集线器和交换机"><a href="#（2）对比集线器和交换机" class="headerlink" title="（2）对比集线器和交换机"></a>（2）对比集线器和交换机</h6><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/3.14.png"></p><p><strong>（集线器已逐步被市场淘汰）</strong></p><h6 id="（3）以太网交换机自学习和转发帧的流程"><a href="#（3）以太网交换机自学习和转发帧的流程" class="headerlink" title="（3）以太网交换机自学习和转发帧的流程"></a>（3）以太网交换机自学习和转发帧的流程</h6><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/3.15.png"></p><h6 id="（4）以太网交换机的生成树协议STP（Spanning-Tree-Protocol）"><a href="#（4）以太网交换机的生成树协议STP（Spanning-Tree-Protocol）" class="headerlink" title="（4）以太网交换机的生成树协议STP（Spanning Tree Protocol）"></a>（4）以太网交换机的生成树协议STP（Spanning Tree Protocol）</h6><ul><li><p>如何提高以太网的可靠性？</p><ul><li>添加<strong>冗余链路</strong>可以提高以太网的可靠性，但是，冗余链路也会带来负面效应——形成<strong>网络环路</strong>。</li><li>网络环路将带来以下问题：<ul><li><strong>广播风暴</strong>：大量消耗网络资源，使得网络无法正常转发其他数据帧</li><li><strong>主机收到重复的广播帧</strong>：大量消耗主机资源</li><li><strong>交换机的帧交换表震荡（漂移）</strong></li></ul></li></ul></li><li><p>以太网交换机使用<strong>生成树协议STP</strong>，可以在增加冗余链路来提高网络可靠性的同时又<strong>避免网络环路带来的各种问题</strong>。</p><ul><li>无论交换机之间采用怎样的物理连接，交换机都能够<strong>自动计算并构建一个逻辑上没有环路的网络</strong>，其逻辑拓扑结构必须是树型的（无逻辑环路）</li><li>最终生成的树型逻辑拓扑要<strong>确保联通整个网络</strong></li><li>当首次连接交换机或网络<strong>物理拓扑发生变化</strong>时（有可能是人为改变或故障），交换机都将进行<strong>生成树的重新计算</strong></li></ul></li></ul><h4 id="11、虚拟局域网VLAN"><a href="#11、虚拟局域网VLAN" class="headerlink" title="11、虚拟局域网VLAN"></a>11、虚拟局域网VLAN</h4><h6 id="（1）概述"><a href="#（1）概述" class="headerlink" title="（1）概述"></a>（1）概述</h6><ul><li><p>使用一个或多个以太网交换机互连起来的交换式以太网，其所有站点都属于<strong>同一个广播域</strong></p></li><li><p>随着交换式以太网规模的扩大，广播域相应扩大</p></li><li><p>巨大的广播域会带来很多<strong>弊端</strong>：</p><ul><li>广播风暴</li><li>难以管理和维护</li><li>潜在的安全问题</li></ul></li><li><p>分割广播域的方法</p><ul><li>使用路由器可以隔离广播域（成本较高）</li><li>虚拟局域网VLAN（Virtual Local Area Network）是一种将局域网内的<strong>设备划分成与物理位置无关的逻辑组的技术，这些逻辑组具有共同的需求</strong>。</li></ul></li></ul><h6 id="（2）虚拟局域网VLAN的实现机制（考研用）"><a href="#（2）虚拟局域网VLAN的实现机制（考研用）" class="headerlink" title="（2）虚拟局域网VLAN的实现机制（考研用）"></a>（2）虚拟局域网VLAN的实现机制（考研用）</h6><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/3.16.png"></p><hr><h2 id="第四章-网络层"><a href="#第四章-网络层" class="headerlink" title="第四章 网络层"></a>第四章 网络层</h2><h4 id="1、概述"><a href="#1、概述" class="headerlink" title="1、概述"></a>1、概述</h4><p>网络层的主要任务是<strong>实现网络互连，进而实现数据包在各网络之间的传输。</strong></p><p>要实现网络层的任务，需要解决以下问题：</p><ul><li><p>网络层向运输层提供怎样的服务（“可靠传输”还是“不可靠传输”）</p></li><li><p>网络寻址问题</p></li><li><p>路由选择问题</p></li></ul><p>因特网（Internet）是目前全世界用户数量最多的互联网，它<strong>使用TCP&#x2F;IP协议栈</strong>。</p><p>由于TCP&#x2F;IP协议栈的网络层使用<strong>网际协议IP</strong>，它是整个协议栈的核心协议，因此在TCP&#x2F;IP协议栈中网络层常称为<strong>网际层</strong>。</p><h4 id="2、网络层提供的两种服务"><a href="#2、网络层提供的两种服务" class="headerlink" title="2、网络层提供的两种服务"></a>2、网络层提供的两种服务</h4><h6 id="（1）面向连接的虚电路服务"><a href="#（1）面向连接的虚电路服务" class="headerlink" title="（1）面向连接的虚电路服务"></a>（1）面向连接的虚电路服务</h6><ul><li><strong>可靠通信由网络来保证</strong></li><li>必须建立<strong>网络层的连接——虚电路VC</strong>（Virtual Circuit）</li><li>通信双方<strong>沿着已建立的虚电路发送分组</strong></li><li>目的主机的地址仅在连接建立阶段使用，之后每个<strong>分组的首部只需携带一条虚电路的编号</strong>（构成虚电路的每一段链路都有一个虚电路编号）。这种通信方式如果再使用可靠传输的网络协议，就可使所发送的分组最终正确到达接收方（无差错按序到达、不丢失、不重复）</li><li><strong>通信结束后，需要释放之前所建立的虚电路</strong></li></ul><h6 id="（2）无连接的数据包服务"><a href="#（2）无连接的数据包服务" class="headerlink" title="（2）无连接的数据包服务"></a>（2）无连接的数据包服务</h6><ul><li><strong>可靠通信应当由用户主机来保证</strong></li><li><strong>不需要建立网络层连接</strong></li><li><strong>每个分组可走不同的路径</strong></li><li>每个分组的<strong>首部必须携带目的主机的完整地址</strong></li><li>这种通信方式所传送的<strong>分组可能误码、丢失、重复和失序</strong></li><li>由于<strong>网络本身不提供端到端的可靠传输服务</strong>，这使得网络中的路由器可以做得比较简单，而且价格低廉（与电信网的交换机相比较）</li><li>因特网采用了这种设计思想，也就是将<strong>复杂的网络处理功能置于因特网的边缘（用户主机和其内部的运输层）</strong>，而将相对简单的尽最大女里的分组交付功能置于因特网核心</li></ul><h6 id="（2）两种服务的比较"><a href="#（2）两种服务的比较" class="headerlink" title="（2）两种服务的比较"></a>（2）两种服务的比较</h6><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/4.1.png"></p><h4 id="3、IPv4"><a href="#3、IPv4" class="headerlink" title="3、IPv4"></a>3、IPv4</h4><h6 id="（1）概述-1"><a href="#（1）概述-1" class="headerlink" title="（1）概述"></a>（1）概述</h6><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/4.2.png"></p><p>IPv4地址采用<strong>点分十进制表示方法</strong>以方便用户使用。</p><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/4.3.png"></p><h6 id="（2）分类编址的IPv4地址"><a href="#（2）分类编址的IPv4地址" class="headerlink" title="（2）分类编址的IPv4地址"></a>（2）分类编址的IPv4地址</h6><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/4.4.png"></p><h6 id="（3）划分子网的IPv4地址"><a href="#（3）划分子网的IPv4地址" class="headerlink" title="（3）划分子网的IPv4地址"></a>（3）划分子网的IPv4地址</h6><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/4.5.png"></p><h6 id="（4）无分类编址的IPv4地址"><a href="#（4）无分类编址的IPv4地址" class="headerlink" title="（4）无分类编址的IPv4地址"></a>（4）无分类编址的IPv4地址</h6><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/4.6.png"></p><h6 id="（5）IPv4地址的应用规划"><a href="#（5）IPv4地址的应用规划" class="headerlink" title="（5）IPv4地址的应用规划"></a>（5）IPv4地址的应用规划</h6><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/4.7.png"></p><h4 id="4、IP数据报的发送和转发过程"><a href="#4、IP数据报的发送和转发过程" class="headerlink" title="4、IP数据报的发送和转发过程"></a>4、IP数据报的发送和转发过程</h4><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/4.8.png"></p><h4 id="5、静态路由配置及其可能产生的路由环路问题"><a href="#5、静态路由配置及其可能产生的路由环路问题" class="headerlink" title="5、静态路由配置及其可能产生的路由环路问题"></a>5、静态路由配置及其可能产生的路由环路问题</h4><h6 id="（1）静态路由配置是指用户或网络管理员使用路由器的相关命令给路由器人工配置路由表"><a href="#（1）静态路由配置是指用户或网络管理员使用路由器的相关命令给路由器人工配置路由表" class="headerlink" title="（1）静态路由配置是指用户或网络管理员使用路由器的相关命令给路由器人工配置路由表"></a>（1）静态路由配置是指用户或网络管理员使用路由器的相关命令给路由器<strong>人工配置路由表</strong></h6><ul><li>这种人工配置方式简单、开销小。但<strong>不能及时适应网络状态（流量、拓扑等）的变化</strong>。</li><li>一般只在小规模网络中采用。</li></ul><h6 id="（2）使用静态路由配置可能出现以下导致产生路由环路的错误"><a href="#（2）使用静态路由配置可能出现以下导致产生路由环路的错误" class="headerlink" title="（2）使用静态路由配置可能出现以下导致产生路由环路的错误"></a>（2）使用静态路由配置可能出现以下导致产生路由环路的错误</h6><ul><li>配置错误</li><li>聚合了不存在的网络</li><li>网络故障</li></ul><h6 id="（3）路由条目类型"><a href="#（3）路由条目类型" class="headerlink" title="（3）路由条目类型"></a>（3）路由条目类型</h6><ul><li>直连网络</li><li>静态路由（人工配置）</li><li>动态路由（路由选择协议）</li></ul><h6 id="（4）特殊的静态路由条目"><a href="#（4）特殊的静态路由条目" class="headerlink" title="（4）特殊的静态路由条目"></a>（4）特殊的静态路由条目</h6><ul><li>默认路由（目的网络为0.0.0.0，地址掩码为0.0.0.0）</li><li>特定主机路由（目的网络为特定主机的IP地址，地址掩码为255.255.255.255）</li><li>黑洞路由（下一跳为null0）</li></ul><h4 id="6、路由选择协议"><a href="#6、路由选择协议" class="headerlink" title="6、路由选择协议"></a>6、路由选择协议</h4><h6 id="（1）概述-2"><a href="#（1）概述-2" class="headerlink" title="（1）概述"></a>（1）概述</h6><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/4.9.png"></p><h6 id="（2）路由信息协议RIP（Routing-Information-Protocol）基本工作原理"><a href="#（2）路由信息协议RIP（Routing-Information-Protocol）基本工作原理" class="headerlink" title="（2）路由信息协议RIP（Routing Information Protocol）基本工作原理"></a>（2）路由信息协议RIP（Routing Information Protocol）基本工作原理</h6><ul><li>路由信息协议RIP是内部网关协议IGP中最先得到广泛使用的协议之一，其相关标准文档为RFC 1058</li><li>RIP要求自治系统AS内的每一个路由器都要维护从它自己到AS内其他每一个网络的距离记录。这是一组距离，称为“<strong>距离向量D-V（Distance-Vector）</strong>”</li><li>RIP使用<strong>跳数</strong>（Hop Count）作为度量（Metric）来<strong>衡量到达目的网络的距离</strong><ul><li>路由器到直连网络的距离定义为1</li><li>路由器到非直连网络的距离定义为所经过的路由器数加1</li><li>允许一条路径最多只能包含15个路由器。<strong>“距离”等于16时相当于不可达。因此，RIP只适用于小型互联网</strong>。</li></ul></li><li>RIP认为<strong>好的路由</strong>就是“距离短”的路由，也就是<strong>所通过路由器数量最少的路由</strong></li><li>当到达同意目的网络有多条“距离相等”的路由时，可以进行<strong>等价负载均衡</strong></li><li>RIP包含以下要点：<ul><li>和谁交换信息仅和相邻路由器交换信息</li><li>交换什么信息        自己的路由表</li><li>何时交换信息        周期性交换</li></ul></li><li>RIP存在“<strong>坏消息传播得慢</strong>”的问题（又称为路由环路或距离无穷计数问题，这是距离向量算法的一个故有问题。可以采取多种措施减少出现该问题的概率或减小该问题带来的危害）<ul><li><strong>限制最大路径距离</strong>为15（16表示不可达）</li><li>当路由表发生变化时就立即发送更新报文（即“<strong>触发更新</strong>”），而不仅是周期性发送</li><li>让路由器记录收到某特定路由信息的接口，而不让同一路由信息再通过此接口向反方向传送（即“<strong>水平分割</strong>”）</li></ul></li></ul><h6 id="（3）开放最短路径优先OSPF（Open-Shortest-Path-First）基本工作原理"><a href="#（3）开放最短路径优先OSPF（Open-Shortest-Path-First）基本工作原理" class="headerlink" title="（3）开放最短路径优先OSPF（Open Shortest Path First）基本工作原理"></a>（3）开放最短路径优先OSPF（Open Shortest Path First）基本工作原理</h6><p>开放最短路径优先OSPF是为了克服RIP的缺点在1989年开发出来的。“开放”表明OSPF协议不是受某一家厂商控制，而是<strong>公开发表</strong>的；“最短路径优先”是因为使用了Dijikstra提出的<strong>最短路径算法</strong>SPF。</p><p>OSPF是<strong>基于链路状态</strong>的，不像RIP那样是基于距离向量的；采用SPF算法去计算路由，从算法上保证了<strong>不会产生路由环路</strong>。OSPF<strong>不限制网络规模，更新效率高，收敛速度快</strong>。</p><p>链路状态是指本路由器都和那些路由器相邻，以及相应链路的“代价”（cost）【“代价”用来表示费用、距离、时延、带宽，等等。这些是由网络管理人员来决定】</p><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/4.10.png"></p><h6 id="（4）边界网关协议BGP的基本工作原理"><a href="#（4）边界网关协议BGP的基本工作原理" class="headerlink" title="（4）边界网关协议BGP的基本工作原理"></a>（4）边界网关协议BGP的基本工作原理</h6><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/4.11.png"></p><h4 id="7、IPv4数据报的首部格式"><a href="#7、IPv4数据报的首部格式" class="headerlink" title="7、IPv4数据报的首部格式"></a>7、IPv4数据报的首部格式</h4><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/4.12.png"></p><h4 id="8、网际控制报文ICMP"><a href="#8、网际控制报文ICMP" class="headerlink" title="8、网际控制报文ICMP"></a>8、网际控制报文ICMP</h4><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/4.13.png"></p><h4 id="9、虚拟专用网VPN与网络地址转换NAT"><a href="#9、虚拟专用网VPN与网络地址转换NAT" class="headerlink" title="9、虚拟专用网VPN与网络地址转换NAT"></a>9、虚拟专用网VPN与网络地址转换NAT</h4><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/4.14.png"></p><hr><h2 id="第五章-运输层"><a href="#第五章-运输层" class="headerlink" title="第五章 运输层"></a>第五章 运输层</h2><p>物理层、数据链路层和网络层共同解决了将主机通过异构网络互联所面临的问题，实现了主机与主机之间的通信。但实际上在计算机网络中<strong>进行通信的真正实体是位于通信两端主机中的进程</strong>。</p><p>为<strong>运行在不同主机上的应用进程提供直接的通信服务</strong>是运输层的任务，运输层协议又被称为端到端协议。</p><h4 id="1、概述-1"><a href="#1、概述-1" class="headerlink" title="1、概述"></a>1、概述</h4><p>运输层向高层用户屏蔽了下面网络核心的细节（如网络拓扑、所采用的路由选择协议等），它使应用进程看见的就好像是在<strong>两个运输层实体之间有一条端到端的逻辑通信信道</strong>。</p><p>根据应用需求的不同，因特网的运输层为应用层提供了两种不同的运输协议，即<strong>面向连接的TCP和无连接的UDP</strong>。</p><h4 id="2、运输层端口号、复用与分用的概念"><a href="#2、运输层端口号、复用与分用的概念" class="headerlink" title="2、运输层端口号、复用与分用的概念"></a>2、运输层端口号、复用与分用的概念</h4><h6 id="（1）进程端口号"><a href="#（1）进程端口号" class="headerlink" title="（1）进程端口号"></a>（1）进程端口号</h6><p>运行在计算机上的进程使用进程标识符PID来标志。因特网上的计算机并不是使用统一的操作系统，不同操作系统使用不同格式的进程标识符。</p><p>为了使不同操作系统的计算机的应用进程之间能够进行网络通信，就必须<strong>使用统一的方法对TCP&#x2F;IP体系的应用进程进行标识</strong>。</p><p>TCP&#x2F;IP体系的运输层使用端口号来区分应用层的不同应用进程。</p><ul><li>端口号使用16比特表示，取值范围0~65535<ul><li>熟知端口号：0~1023，IANA把这些端口指派给了TCP&#x2F;IP体系中最重要的一些应用协议，例如：FTP|21&#x2F;20、HTTP|80、DNS|53</li><li>登记端口号：1024~49151，为没有熟知端口号的应用程序使用。使用这类端口号必须在IANA按照规定的手续登记，以防止重复。例如：Microsoft RDP微软远程桌面|3389</li><li>短暂端口号：49152~65535，留给客户进程选择暂时使用。当服务器进程收到用户进程的报文时，就知道用户进程所使用的动态端口号。通信结束后，这个端口号可供其他客户进程以后使用。</li></ul></li><li><strong>端口号只具有本地意义，即端口号只是为了表示本计算机应用层中的各进程，在因特网中，不同计算机的相同端口号是没有联系的。</strong></li></ul><h6 id="（2）复用与分用"><a href="#（2）复用与分用" class="headerlink" title="（2）复用与分用"></a>（2）复用与分用</h6><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/5.1.png"></p><h4 id="3、UDP和TCP的对比"><a href="#3、UDP和TCP的对比" class="headerlink" title="3、UDP和TCP的对比"></a>3、UDP和TCP的对比</h4><h6 id="（1）用户数据报协议UDP（User-Datagram-Protocol）"><a href="#（1）用户数据报协议UDP（User-Datagram-Protocol）" class="headerlink" title="（1）用户数据报协议UDP（User Datagram Protocol）"></a>（1）用户数据报协议UDP（User Datagram Protocol）</h6><ul><li>无连接</li><li>支持一对一，一对多，多对一和多对多交互通信</li><li>对应用层交付的报文直接打包</li><li>尽最大努力交付，也就是不可靠；不使用流量控制和拥塞控制</li><li>首部开销小，仅8字节</li></ul><h6 id="（2）传输控制协议TCP（Transmission-Control-Protocol）"><a href="#（2）传输控制协议TCP（Transmission-Control-Protocol）" class="headerlink" title="（2）传输控制协议TCP（Transmission Control Protocol）"></a>（2）传输控制协议TCP（Transmission Control Protocol）</h6><ul><li>面向连接</li><li>每一条TCP连接只能有两个端点EP，只能一对一通信</li><li>面向字节流</li><li>可靠传输，使用流量控制和拥塞控制</li><li>首部最小20字节，最大60字节</li></ul><h4 id="4、TCP的流量控制"><a href="#4、TCP的流量控制" class="headerlink" title="4、TCP的流量控制"></a>4、TCP的流量控制</h4><p>一般来说，我们总是希望数据传输得更快一些。但如果发送方把数据发送的过快，接收方就可能来不及接收，这就会造成数据的丢失。</p><p>所谓流量控制（flow control）就是<strong>让发送方的发送速率不要太快，要让接收方来得及接收</strong>。</p><p>利用<strong>滑动窗口</strong>机制可以很方便地在TCP连接上实现对发送方得流量控制。TCP接收方利用自己的<strong>接收窗口的大小来限制发送方发送窗口的大小</strong>。TCP发送方收到接收方的零窗口通知后，应启动持续计时器。持续<strong>计时器超时后，向接收方发送零窗口探测报文</strong>。</p><h4 id="5、TCP的拥塞控制"><a href="#5、TCP的拥塞控制" class="headerlink" title="5、TCP的拥塞控制"></a>5、TCP的拥塞控制</h4><p>在某段时间，若<strong>对网络中的某一资源的需求超过了该资源所能提供的可用部分，网络性能就要变坏。这种情况就叫拥塞</strong>（congesting）。计算机中的链路容量（带宽）、交换节点中的缓存和处理机等，都属于网络资源。</p><p>若<strong>出现拥塞而不进行控制，整个网络的吞吐量将随输入负荷的增大而下降。</strong></p><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/5.2.png"></p><hr><h6 id="（1）拥塞控制算法"><a href="#（1）拥塞控制算法" class="headerlink" title="（1）拥塞控制算法"></a>（1）拥塞控制算法</h6><p>假定如下条件：</p><ul><li>数据时单方向传送，而另一个方向只传送确认。</li><li>接收方总是有足够大的缓存空间，因而发送方发送窗口的大小由网络的拥塞程度来决定。</li><li>以最大报文段MSS的个数为讨论问题的单位，而不是以字节为单位。</li></ul><p>发送方维护一个叫做<strong>拥塞窗口cwnd</strong>的状态变量，其值<strong>取决于网络的拥塞程度，并且动态变化</strong>。</p><ul><li>拥塞窗口<strong>维护原则</strong>：只要网络没有出现拥塞，拥塞窗口就再增大一些；但只要网络出现拥塞，拥塞窗口就减少一些。</li><li>判断出现<strong>网络拥塞的依据</strong>：没有按时收到应当到达的确认报文（即<strong>发生超时重传</strong>）</li></ul><p>发送方将拥塞窗口作为<strong>发送窗口swnd</strong>，即swnd&#x3D;cwnd。维护一个慢开始门限<strong>ssthresh</strong>状态变量：</p><ul><li>当cwnd &lt; ssthresh时，使用慢开始算法；</li><li>当cwnd &gt; ssthresh时，停止使用慢开始算法而改用拥塞避免算法；</li><li>当cwnd &#x3D; ssthresh时，既可使用慢开始算法，也可使用拥塞避免算法。</li></ul><h6 id="（2）慢开始（slow-start）与拥塞避免（congestion-avoidance）"><a href="#（2）慢开始（slow-start）与拥塞避免（congestion-avoidance）" class="headerlink" title="（2）慢开始（slow-start）与拥塞避免（congestion avoidance）"></a>（2）慢开始（slow-start）与拥塞避免（congestion avoidance）</h6><ul><li>重传计时器超时，判断网络可能出现了拥塞，进行以下工作：<ul><li>将ssthresh值更新为发生拥塞时cwnd值的一半</li><li>将cwnd值减少为1，并重新开始执行慢开始算法</li></ul></li><li>“慢开始”是指一开始向网络注入的报文段少，并不是指拥塞窗口cwnd增长速度慢；</li><li>“拥塞避免”并非完全能够避免拥塞，而是指在拥塞避免阶段将拥塞窗口控制位按线性规律增长，使网络比较不容易出现拥塞。</li></ul><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/5.3.png"></p><h6 id="（3）快重传（fast-retransmit）与快恢复（fast-recovery）"><a href="#（3）快重传（fast-retransmit）与快恢复（fast-recovery）" class="headerlink" title="（3）快重传（fast retransmit）与快恢复（fast recovery）"></a>（3）快重传（fast retransmit）与快恢复（fast recovery）</h6><ul><li>快重传就是使发送方尽快进行重传，而不是等超时计时器超时再重传。<ul><li>要求接收方不要等待自己发送数据时才捎带确认，而是立即发送确认；</li><li>及时收到了失序的报文段也要立即发出对已收到的报文段的重复确认。</li><li>发送方一旦收到3个连续的重复确认，就将相应的报文段立即重传，而不是等该报文段的超时重传计时器超时再重传。</li><li>对于个别丢失的报文段，发送方不会出现超时重传，也就不会误认为出现了拥塞（进而降低拥塞窗口cwnd为1）。使用快重传可以使整个网络的吞吐量提高约20%。</li></ul></li><li>发送方一旦收到3个重复确认，就知道现在只是丢失了个别的报文段。于是不启动慢开始算法，而执行快恢复算法<ul><li>发送方将慢开始门限ssthresh值和拥塞窗口cwnd值调整为当前窗口的一般；开始执行拥塞避免算法。</li><li>也有的快恢复实现是是把快恢复开始时的拥塞控制cwnd值在增大一些，即等于新的ssthresh+3.<ul><li>既然发送方收到3个重复的确认，就表明3个数据报文段已经离开了网络；</li><li>这3个报文段不再消耗网络资源而是停留在接收方的接收缓存中；</li><li>现在网络中不是堆积了报文段而是减少了3个报文段。因此可以适当把拥塞窗口扩大些。</li></ul></li></ul></li></ul><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/5.4.png"></p><h4 id="6、TCP超时重传时间的选择"><a href="#6、TCP超时重传时间的选择" class="headerlink" title="6、TCP超时重传时间的选择"></a>6、TCP超时重传时间的选择</h4><h6 id="（1）超时重传时间的选择"><a href="#（1）超时重传时间的选择" class="headerlink" title="（1）超时重传时间的选择"></a>（1）超时重传时间的选择</h6><ul><li>不能直接使用某次测量得到的RTT样本来计算超时重传时间RTO。</li><li>利用每次测量得到的RTT样本，计算加权**平均往返时间RTT<del>s</del>**（又称为平滑的往返时间）</li></ul><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/5.5.png"></p><ul><li>用这种方法得出的加权平均往返时间RTT<del>s</del>就比测量出的RTT值更加平滑。显然，**超时重传时间RTO应略大于加权平均往返时间RTT<del>s</del>**。</li></ul><h6 id="（2）解决超时重传时无法测准往返时间RTT"><a href="#（2）解决超时重传时无法测准往返时间RTT" class="headerlink" title="（2）解决超时重传时无法测准往返时间RTT"></a>（2）解决超时重传时无法测准往返时间RTT</h6><p>Karn提出了一个算法：<strong>在计算加权平均往返时间RTT<del>s</del>时，只要报文段重传了，就不采用其往返时间RTT样本</strong>。也就是出现重传时，不重新计算RTT<del>s</del>，进而超时重传时间RTO也不会重新计算。</p><ul><li>这又引起了新的问题。如果报文段的实验突然增大了很多，并且之后很长一段时间都会保持这种时延。因此在原来得出的重传时间内，不会收到确认报文段。于是就重传报文段。但根据Karn算法，不考虑重传的报文段的往返时间样本。这样，超时重传时间就无法更新。这会导致报文段反复被重传。</li></ul><p>因此，需要对Karn算法进行修正。<strong>报文段每重传一次，就把超时重传时间RTO增大一些</strong>。典型的做法是将新的RTO的值渠伟旧RTO值得2被。</p><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/5.6.png"></p><h4 id="7、TCP可靠传输的实现"><a href="#7、TCP可靠传输的实现" class="headerlink" title="7、TCP可靠传输的实现"></a>7、TCP可靠传输的实现</h4><p>TCP基于<strong>以字节为单位的滑动窗口</strong>来实现可靠传输。</p><h6 id="（1）"><a href="#（1）" class="headerlink" title="（1）"></a>（1）</h6><p>虽然发送方的发送窗口是根据接收方的接收窗口设置的，但在同一时刻，<strong>发送方的发送窗口并不是和接收方的接收窗口一样大</strong>。</p><ul><li>网络传送窗口值需要经历一定的时间滞后，并且这个时间还是不确定的。</li><li>发送方还可能根据网络当时的拥塞情况适当减小自己的发送窗口尺寸。</li></ul><h6 id="（2）"><a href="#（2）" class="headerlink" title="（2）"></a>（2）</h6><p>对于不按序到达的数据应如何处理，TCP并无明确规定。</p><ul><li>如果接收方把不按序到达的数据一律丢弃，那么接收窗口的管理将会比较简单，但这样做对网络资源的利用不利，因为发送方会重复传送较多的数据。</li><li>TCP通常对不按序到达的数据是先临时存放在接收窗口中，等到字节流中所缺少的字节收到后，再<strong>按序交付上层的应用进程</strong>。</li></ul><h6 id="（3）"><a href="#（3）" class="headerlink" title="（3）"></a>（3）</h6><p>TCP要求接收方必须有<strong>累计确认和捎带确认机制</strong>，这样可以减小传输开销。接收方可以在合适的时候发送确认，也可以在自己有数据要发送时把确认信息顺便捎带上。</p><ul><li><strong>接收方不应过分推迟发送确认</strong>，否则会导致发送方不必要的超时重传，这反而浪费了网络的资源。</li><li>捎带确认实际上并不经常发生，因为大多数应用程序很少同时在两个方向上发送数据。</li></ul><h6 id="（3）-1"><a href="#（3）-1" class="headerlink" title="（3）"></a>（3）</h6><p><strong>TCP的通信是全双工通信</strong>。通信中的每一方都是再发送和接收报文段。因此，每一方都有自己的发送窗口和接收窗口。</p><h4 id="8、TCP的运输连接管理"><a href="#8、TCP的运输连接管理" class="headerlink" title="8、TCP的运输连接管理"></a>8、TCP的运输连接管理</h4><p>TCP是面向连接的协议，它基于运输链接来传送TCP报文段；TCP运输链接的建立和释放是每一次面向连接的通信中必不可少的过程；主要有以下三个阶段：</p><ul><li>建立TCP连接</li><li>数据传送</li><li>释放TCP连接</li></ul><p>TCP的运输连接管理就是使运输连接的建立和释放都能正常地进行。</p><h6 id="（1）TCP的连接建立"><a href="#（1）TCP的连接建立" class="headerlink" title="（1）TCP的连接建立"></a>（1）TCP的连接建立</h6><p>TCP连接建立需要解决一下问题：</p><ul><li>使TCP双方能够确知对方的存在</li><li>使TCP双方能够协商一些参数（如最大窗口值、是否使用窗口扩大选项和时间戳选项以及服务质量等）</li><li>使TCP双方能够对运输实体资源（如缓存大小、连接表中的项目等）进行分配</li></ul><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/5.7.png"></p><h6 id="（2）TCP的连接释放"><a href="#（2）TCP的连接释放" class="headerlink" title="（2）TCP的连接释放"></a>（2）TCP的连接释放</h6><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/5.8.png"></p><h4 id="9、TCP报文段的首部格式"><a href="#9、TCP报文段的首部格式" class="headerlink" title="9、TCP报文段的首部格式"></a>9、TCP报文段的首部格式</h4><p>为了实现可靠传输，TCP采用了<strong>面向字节流</strong>的方式。但TCP在发送数据时，是从发送缓存去除一部分或全部字节并给其添加一个首部使之称为TCP报文段后进行发送。</p><ul><li>一个TCP报文段由<strong>首部和数据载荷</strong>两部分构成</li><li>TCP的全部功能都体现在它首部中各字段的作用</li></ul><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/5.10.png"></p><hr><h2 id="第六章-应用层"><a href="#第六章-应用层" class="headerlink" title="第六章 应用层"></a>第六章 应用层</h2><p>应用层是计算网络体系的最顶层，是设计和建立计算机网络的最终目的，也是计算机网络中发展最快的部分。</p><ul><li>早期基于文本的应用（电子邮件、远程登录、文件传输、新闻组）</li><li>20世纪90年代万维网WWW</li><li>当今流行的即时通信、P2P文件共享及各种音视频应用</li></ul><h4 id="（1）客户-x2F-服务器（Client-x2F-Server，C-x2F-S）"><a href="#（1）客户-x2F-服务器（Client-x2F-Server，C-x2F-S）" class="headerlink" title="（1）客户&#x2F;服务器（Client&#x2F;Server，C&#x2F;S）"></a>（1）客户&#x2F;服务器（Client&#x2F;Server，C&#x2F;S）</h4><h6 id="1、C-x2F-S方式"><a href="#1、C-x2F-S方式" class="headerlink" title="1、C&#x2F;S方式"></a>1、C&#x2F;S方式</h6><ul><li><p>客户和服务器是指通信中所涉及的两个应用进程。</p></li><li><p>客户&#x2F;服务器方式所描述的是进程之间服务和被服务的关系。</p></li><li><p>客户是服务请求方，服务器是服务提供方。</p></li><li><p>服务器总是处于运行状态，并等待客户的服务请求。服务器具有固定端口号（例如HTTP服务器的默认端口号为80），而运行服务器的主机也具有固定的IP地址。</p></li></ul><h6 id="2、C-x2F-S方式是因特网上传统的、同时也是最成熟的方式。"><a href="#2、C-x2F-S方式是因特网上传统的、同时也是最成熟的方式。" class="headerlink" title="2、C&#x2F;S方式是因特网上传统的、同时也是最成熟的方式。"></a>2、C&#x2F;S方式是因特网上传统的、同时也是最成熟的方式。</h6><h6 id="3、基于C-x2F-S方式的应用服务通常是服务集中型的，即应用服务集中在网络中中比客户计算机少得多的服务器计算机上。"><a href="#3、基于C-x2F-S方式的应用服务通常是服务集中型的，即应用服务集中在网络中中比客户计算机少得多的服务器计算机上。" class="headerlink" title="3、基于C&#x2F;S方式的应用服务通常是服务集中型的，即应用服务集中在网络中中比客户计算机少得多的服务器计算机上。"></a>3、基于C&#x2F;S方式的应用服务通常是服务集中型的，即应用服务集中在网络中中比客户计算机少得多的服务器计算机上。</h6><ul><li>由于一台服务器计算机要为多个客户机提供服务，在C&#x2F;S应用中，<strong>常会出现服务器计算机跟不上众多客户机请求的情况</strong>。</li><li>为此，在C&#x2F;S应用中，常用<strong>计算机集群</strong>（或服务器场）构建一个强大的虚拟服务器。</li></ul><h4 id="（2）对等（Peer-to-Peer，P2P）"><a href="#（2）对等（Peer-to-Peer，P2P）" class="headerlink" title="（2）对等（Peer-to-Peer，P2P）"></a>（2）对等（Peer-to-Peer，P2P）</h4><h6 id="1、对等方式"><a href="#1、对等方式" class="headerlink" title="1、对等方式"></a>1、对等方式</h6><p>在P2P方式中，<strong>没有固定的服务请求者和服务提供者</strong>，分布在网络边缘各端系统中的应用进程是对等的，被称为<strong>对等方。对等方相互之间直接通信</strong>，每个对等方既是服务的请求者，优势服务的提供者。</p><p>目前，在因特网上流行的P2P应用主要包括P2P文件共享、即时通信、P2P流媒体、分布式存储等。</p><p>基于P2P的应用是<strong>服务分散型</strong>的，因为服务不是集中在少数几个服务器计算机中，而是分散在大量对等计算机中，这些计算机并不为服务提供商所有，而是为个人控制的桌面计算机和笔记本电脑，它们通常位于住宅、校园和办公室中。</p><p>P2P方式最突出的特性之一就是它的<strong>可扩展性</strong>。因为系统每增加一个对等方，不仅增加的是服务的请求者，同时增加了服务的提供者，<strong>系统性能不会因规模的增大而降低</strong>。</p><p>P2P方式<strong>具有成本上的优势</strong>，因为它通常不需要庞大的服务器设施和服务器带宽。为了降低成本，服务提供商对于将P2P方式用于应用的兴趣越来越大。</p><h4 id="（3）动态主机配置协议DHCP"><a href="#（3）动态主机配置协议DHCP" class="headerlink" title="（3）动态主机配置协议DHCP"></a>（3）动态主机配置协议DHCP</h4><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/6.1.png"></p><h4 id="（4）域名系统DNS（Domain-Name-System）"><a href="#（4）域名系统DNS（Domain-Name-System）" class="headerlink" title="（4）域名系统DNS（Domain Name System）"></a>（4）域名系统DNS（Domain Name System）</h4><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/6.2.png"></p><h4 id="（5）文件传送协议FTP（File-Transfer-Protocol）"><a href="#（5）文件传送协议FTP（File-Transfer-Protocol）" class="headerlink" title="（5）文件传送协议FTP（File Transfer Protocol）"></a>（5）文件传送协议FTP（File Transfer Protocol）</h4><p>文件传送协议FTP是因特网上使用得最广泛得文件传送协议，文件传送：将某台计算机中的文件通过网络传送到可能相距很远的另一台计算机中，是一项基本的网络应用。</p><ul><li>FTP提供交互式的访问，允许客户指明文件的类型与格式（如指明是否使用ASCII码），并允许文件具有存取权限。</li><li>FTP屏蔽了各计算机系统的细节，因而适合于在异构网络中任意计算机之间传送文件。</li></ul><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/6.3.png"></p><h4 id="（6）电子邮件（E-mail）"><a href="#（6）电子邮件（E-mail）" class="headerlink" title="（6）电子邮件（E-mail）"></a>（6）电子邮件（E-mail）</h4><p>电子邮件系统采用客户&#x2F;服务器方式。</p><p>电子邮件系统的三个主要组成构件：用户代理，邮件服务器，电子邮件所需的协议。</p><ul><li><p>用户代理是用户与电子邮件系统的接口，又称为电子邮件客户端软件。</p></li><li><p>邮件服务器是电子邮件系统的基础设施。因特网上所有的ISP都有邮件服务器，其功能是发送和接收邮件，同时还要负责维护用户的邮箱。</p></li><li><p>协议包括邮件发送协议（SMTP等）和邮件读取协议（POP3，IMAP等）</p></li></ul><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/6.4.png"></p><h4 id="（7）万维网WWW"><a href="#（7）万维网WWW" class="headerlink" title="（7）万维网WWW"></a>（7）万维网WWW</h4><p><img src="/2023/02/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%A4%87%E8%80%83/6.5.png"></p>]]></content>
      
      
      <categories>
          
          <category> 我的大学 </category>
          
          <category> 大三上学期 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>我的网络安全入门（《白帽子讲Web安全》）</title>
      <link href="/2023/01/06/%E6%88%91%E7%9A%84%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E5%85%A5%E9%97%A8%EF%BC%88%E3%80%8A%E7%99%BD%E5%B8%BD%E5%AD%90%E8%AE%B2Web%E5%AE%89%E5%85%A8%E3%80%8B%EF%BC%89/"/>
      <url>/2023/01/06/%E6%88%91%E7%9A%84%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E5%85%A5%E9%97%A8%EF%BC%88%E3%80%8A%E7%99%BD%E5%B8%BD%E5%AD%90%E8%AE%B2Web%E5%AE%89%E5%85%A8%E3%80%8B%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h2 id="一些浅显的起步"><a href="#一些浅显的起步" class="headerlink" title="一些浅显的起步"></a>一些浅显的起步</h2><p>在我开始读这本书之前，对于网络安全的感受就是两个：DDOS和SQL注入。DDOS是因为我喜欢玩一些偏门的新游戏，比如说猫灵相册、四叶草剧场都有过被DDOS攻击的经历，当时稍微从UP主epcdiy了解了下DDOS操作“肉鸡”攻击的方式【<a href="https://www.bilibili.com/video/BV1cY411x7k8/?is_story_h5=false&p=1&share_from=ugc&share_medium=android&share_plat=android&share_session_id=386178ae-bb4d-477e-b817-3da6c775ef42&share_source=QQ&share_tag=s_i&timestamp=1671463997&unique_k=UrQmcxP&vd_source=a81ef8427e696b92de364d833142bd10">网络霸凌者只会DDoS欺负小网站？我让高防服务器教你做人！</a>】，感叹了下服务器还是选阿里云啥的好。。。咳咳，扯远了；SQL注入主要是在工作室一次技术沙龙听学长分享的时候偶然之间听到的，觉得有意思也想自己试试，但是用来攻击自己的网站都不能成功，不过在读完这本书后我也明白了为什么（不过是因为现在的框架已经将大部分常见的攻击已经过滤掉了）。</p><p>说起读这本书的契机，实际上是因为工作室的老师在20大之前召开了一次关于网络安全的会议，告诉我们写系统要注意网络安全。当时我完全没考虑过网络安全的事情，浅显的认为网络安全就是所谓系统中的Spring Security以及使用的Jwt，当然这些的确是网络安全的一部分，但是只是实现的工具罢了。对于网络安全我并没有一个完整的理念&#x2F;体系，当时真的天真的认为一个系统配了个Authorization&#x2F;Token就差不多安全了，现在再回过头来看确实是挺肤浅的。</p><p>总而言之，就这样我就开始了这本书的阅读。也愈发关注起了网络安全，经常有意识的在B站看看有意思的网安视频，催使我更新文档的就是其中之一：<a href="https://www.bilibili.com/video/BV1i14y157YV/?spm_id_from=333.337.search-card.all.click&vd_source=a81ef8427e696b92de364d833142bd10">电子监听、全国断网，棱镜门背后，中国如何从末路狂奔到世界之巅</a>，未来没准从大数据转到网安了呢？（笑）</p><p>因为不是很会做总结归纳，所以我就从本书的总结开始，对每一章的总结进行一个排疑，借此也巩固我自己的一个理解。我并没有很深入的阅读，相反，我阅读得相当简单，这里面设计的代码面太广，我也无法对书中的每一段代码进行推敲，因此文档里面肯定有很多问题，毕竟这本书也是有一定年限&#x2F;自己的技术也不是很硬&#x2F;读的内容还是过浅，加上我总是喜欢加上个人的理解。如果你找到了任何文档的错误，欢迎在issue上留言，我会及时修改哒！</p><h2 id="第一章-安全世界观"><a href="#第一章-安全世界观" class="headerlink" title="第一章 安全世界观"></a>第一章 安全世界观</h2><p><strong>互联网本来是安全的，自从有了研究安全的人之后，互联网就变得不安全了。</strong></p><h4 id="1、为什么是Web安全？"><a href="#1、为什么是Web安全？" class="headerlink" title="1、为什么是Web安全？"></a>1、为什么是Web安全？</h4><p>在早期互联网中，Web并非互联网的主流应用，相对来说，基于SMTP、POP3、FTP、IRC等协议的服务拥有着绝大多数的用户。因此黑客们主要的攻击目标是网络、操作系统以及软件等领域，Web安全领域的攻击与防御技术均处于非常原始的阶段。</p><p>时代在发展，防火墙技术的兴起改变了互联网安全的格局。尤其是以Cisco、华为等为代表的网络设备厂商，开始在网络产品中更加重视网络安全，最终改变了互联网安全的走向。防火墙、ACL技术的兴起，使得直接暴露在互联网上的系统得到了保护。</p><p>运营商、防火墙对于网络的封锁，使得暴露在互联网上的非Web服务越来越少，且Web技术的成熟使得Web应用的功能越来越强大，最终成为了互联网的主流。黑客们的目光，也渐渐转移到了Web这块大蛋糕上。</p><h4 id="2、Web攻击技术的发展"><a href="#2、Web攻击技术的发展" class="headerlink" title="2、Web攻击技术的发展"></a>2、Web攻击技术的发展</h4><p>Web 1.0时代，人们更多的是关注服务器端动态脚本的安全问题，比如将一个可执行脚本（俗称webshell）上传到服务器上，从而获得权限。动态脚本语言的普及，以及Web技术发展初期对安全问题认知的不足导致很多“血案”的发生，同时也遗留下很多历史问题。</p><p>SQL注入的出现是Web安全史上的一个里程碑，它最早出现大概是在1999年，并很快就成为Web安全的头号大敌。黑客们发现通过SQL注入攻击，可以获取很多重要的、敏感的数据，甚至能够通过数据库获取系统访问权限，这种效果并不比直接攻击系统软件差，Web攻击一下子就流行起来。SQL注入漏洞至今仍然是Web安全领域中的一个重要组成部分。</p><p>XSS（跨站脚本攻击）的出现则是Web安全史上的另一个里程碑。</p><p>Web 2.0的兴起，XSS、CSRF等攻击已经变得更为强大。Web攻击的思路也从服务器端转向了客户端，转向了浏览器和用户。</p><p>Web技术发展到今天，构建出了丰富多彩的互联网。互联网业务的蓬勃发展，也催生出了许多新兴的脚本语言，比如Python、Ruby、NodeJS等，敏捷开发成为互联网的主旋律。而手机技术、移动互联网的兴起，也给HTML 5带来了新的机遇和挑战。与此同时，Web安全技术，也将紧跟着互联网发展的脚步，不断地演化出新的变化。</p><h4 id="3、安全问题的本质"><a href="#3、安全问题的本质" class="headerlink" title="3、安全问题的本质"></a>3、安全问题的本质</h4><p><strong>安全是什么？什么样的情况下会产生安全问题？我们要如何看待安全问题？</strong></p><h6 id="（1）一个安全问题是如何产生的？"><a href="#（1）一个安全问题是如何产生的？" class="headerlink" title="（1）一个安全问题是如何产生的？"></a>（1）一个安全问题是如何产生的？</h6><p>我们不妨先从现实世界入手。火车站、机场里，在乘客们开始正式旅程之前，都有一个必要的程序：安全检查。</p><p>安全检查的过程按照需要进行过滤。通过一个安全检查（过滤、净化）的过程，可以梳理未知的人或物，使其变得可信任。被划分出来的具有不同信任级别的区域，我们称为信任域，划分两个不同信任域之间的边界，我们称为信任边界。</p><p><strong>数据从高等级的信任域流向低等级的信任域，是不需要经过安全检查的；数据从低等级的信任域流向高等级的信任域，则需要经过信任边界的安全检查。</strong></p><p>因此，<strong>安全问题的本质是信任的问题</strong>。</p><p>一切的安全方案设计的基础，都是建立在信任关系上的。我们必须相信一些东西，必须有一些最基本的假设，安全方案才能得以建立；如果我们否定一切，安全方案就会如无源之水，无根之木，无法设计，也无法完成。</p><p>从另一个角度来说，一旦我们作为决策依据的条件被打破、被绕过，那么就会导致安全假设的前提条件不再可靠，变成一个伪命题。因此，把握住信任条件的度，使其恰到好处，正是设计安全方案的难点所在，也是安全这门学问的艺术魅力所在。</p><h6 id="（2）安全问题没有一劳永逸"><a href="#（2）安全问题没有一劳永逸" class="headerlink" title="（2）安全问题没有一劳永逸"></a>（2）安全问题没有一劳永逸</h6><p><strong>安全是一个持续的过程。</strong></p><p>自从互联网有了安全问题以来，攻击和防御技术就在不断碰撞和对抗的过程中得到发展。从微观上来说，在某一时期可能某一方占了上风；但是从宏观上来看，某一时期的攻击或防御技术，都不可能永远有效，永远用下去。这是因为防御技术在发展的同时，攻击技术也在不断发展，两者是互相促进的辩证关系。以不变的防御手段对抗不断发展的攻击技术，就犯了刻舟求剑的错误。</p><p>安全产品本身也需要不断地升级，也需要有人来运营。产品本身也需要一个新陈代谢的过程，否则就会被淘汰。在现代的互联网产品中，自动升级功能已经成为一个标准配置，一个有活力的产品总是会不断地改进自身。</p><h4 id="4、安全三要素"><a href="#4、安全三要素" class="headerlink" title="4、安全三要素"></a>4、安全三要素</h4><p>设计安全方案之前，要正确、全面地看待安全问题，首先要理解安全问题的组成属性。前人通过无数实践，最后将安全的属性总结为安全三要素，简称CIA。后来还有人想扩充这些要素，增加了诸如可审计性、不可抵赖性等，但最最重要的还是以上三个要素。在设计安全方案时，也要以这三个要素为基本的出发点，去全面地思考所面对的问题。</p><h6 id="（1）机密性（Confidentiality）"><a href="#（1）机密性（Confidentiality）" class="headerlink" title="（1）机密性（Confidentiality）"></a>（1）机密性（Confidentiality）</h6><p>机密性要求保护数据内容不能泄露，加密是实现机密性要求的常见手段。</p><h6 id="（2）完整性（Integrity）"><a href="#（2）完整性（Integrity）" class="headerlink" title="（2）完整性（Integrity）"></a>（2）完整性（Integrity）</h6><p>完整性要求保护数据内容是完整、没有被篡改的。常见的保证一致性的技术手段是数字签名。</p><h6 id="（3）可用性（Availability）"><a href="#（3）可用性（Availability）" class="headerlink" title="（3）可用性（Availability）"></a>（3）可用性（Availability）</h6><p>可用性要求保护资源是“随需而得”。（不能盲目响应请求，这样会造成DDOS攻击[拒绝服务]，但又要保证正常的请求不能被过滤掉）</p><h4 id="5、安全评估"><a href="#5、安全评估" class="headerlink" title="5、安全评估"></a>5、安全评估</h4><p>安全评估的过程，可以简单地分为4个阶段：资产等级划分、威胁分析、风险分析、确认解决方案。</p><h6 id="（1）资产等级划分"><a href="#（1）资产等级划分" class="headerlink" title="（1）资产等级划分"></a>（1）资产等级划分</h6><p>资产等级划分是所有工作的基础，这项工作能够帮助我们明确目标是什么，要保护什么。</p><p><strong>互联网安全的核心问题，是数据安全的问题。</strong>完成资产等级划分后，对要保护的目标已经有了一个大概的了解，接下来就是要划分信任域和信任边界了。通常我们用一种最简单的划分方式，就是从网络逻辑上来划分。比如最重要的数据放在数据库里，那么把数据库的服务器圈起来；Web应用可以从数据库中读&#x2F;写数据，并对外提供服务，那再把Web服务器圈起来；最外面是不可信任的Internet。</p><h6 id="（2）威胁分析"><a href="#（2）威胁分析" class="headerlink" title="（2）威胁分析"></a>（2）威胁分析</h6><p>在安全领域里，我们把可能造成危害的来源称为<strong>威胁（Threat）</strong>，而把可能会出现的损失称为<strong>风险（Risk）</strong>。风险一定是和损失联系在一起的。</p><ul><li>STRIDE模型：STRIDE是6个单词的首字母缩写，我们在分析威胁时，可以从以下6个方面去考虑。</li></ul><p><img src="/2023/01/06/%E6%88%91%E7%9A%84%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E5%85%A5%E9%97%A8%EF%BC%88%E3%80%8A%E7%99%BD%E5%B8%BD%E5%AD%90%E8%AE%B2Web%E5%AE%89%E5%85%A8%E3%80%8B%EF%BC%89/1.1.png"></p><p>威胁分析是非常重要的一件事情，很多时候还需要经常回顾和更新现有的模型。可能存在很多威胁，但并非每个威胁都会造成难以承受的损失。一个威胁到底能够造成多大的危害，如何去衡量它？这就要考虑到风险了。我们判断风险高低的过程，就是风险分析的过程。</p><h6 id="（3）风险分析"><a href="#（3）风险分析" class="headerlink" title="（3）风险分析"></a>（3）风险分析</h6><p>风险由以下因素组成：<strong>Risk &#x3D; Probability * Damage Potential</strong></p><p>影响风险高低的因素，除了造成损失的大小外，还需要考虑到发生的可能性。我们在考虑安全问题时，要结合具体情况，权衡事件发生的可能性，才能正确地判断出风险。</p><ul><li>DREAD模型：由微软提出。DREAD也是几个单词的首字母缩写，它指导我们应该从哪些方面去判断一个威胁的风险程度。</li></ul><p><img src="/2023/01/06/%E6%88%91%E7%9A%84%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E5%85%A5%E9%97%A8%EF%BC%88%E3%80%8A%E7%99%BD%E5%B8%BD%E5%AD%90%E8%AE%B2Web%E5%AE%89%E5%85%A8%E3%80%8B%EF%BC%89/1.2.png"></p><p>在DREAD模型里，每一个因素都可以分为高、中、低三个等级。在上表中，高、中、低三个等级分别以3、2、1的分数代表其权重值，因此，我们可以具体计算出某一个威胁的风险值。</p><p>任何时候都应该记住——<strong>模型是死的，人是活的，再好的模型也是需要人来使用的</strong>，在确定攻击面，以及判断风险高低时，都需要有一定的经验，这也是安全工程师的价值所在。类似STRIDE和DREAD的模型可能还有很多，不同的标准会对应不同的模型，只要我们觉得这些模型是科学的，能够帮到我们，就可以使用。但模型只能起到一个辅助的作用，最终做出决策的还是人。</p><h6 id="（4）确认解决方案"><a href="#（4）确认解决方案" class="headerlink" title="（4）确认解决方案"></a>（4）确认解决方案</h6><p>安全评估的产出物，就是安全解决方案。解决方案一定要有针对性，这种针对性是由资产等级划分、威胁分析、风险分析等阶段的结果给出的。</p><p>设计解决方案不难，难的是如何设计一个好的解决方案。设计一个好的解决方案，是真正考验安全工程师水平的时候。</p><p>对于互联网来说，<strong>安全是要为产品的发展与成长保驾护航的</strong>。我们不能使用“粗暴”的安全方案去阻碍产品的正常发展，所以应该形成这样一种观点：<strong>没有不安全的业务，只有不安全的实现方式。好的安全方案对用户应该是透明的，尽可能地不要改变用户的使用习惯。</strong></p><p>好的安全产品或模块除了要兼顾用户体验外，还要易于持续改进。一个好的安全模块，同时也应该是一个优秀的程序，从设计上也需要做到<strong>高聚合、低耦合、易于扩展</strong>。</p><ul><li>一个优秀安全方案的特点：能够有效解决问题；用户体验好；高性能；低耦合；易于扩展和升级。</li></ul><h4 id="6、具体设计安全方案的技巧"><a href="#6、具体设计安全方案的技巧" class="headerlink" title="6、具体设计安全方案的技巧"></a>6、具体设计安全方案的技巧</h4><h6 id="（1）Secure-By-Default原则"><a href="#（1）Secure-By-Default原则" class="headerlink" title="（1）Secure By Default原则"></a>（1）Secure By Default原则</h6><ul><li>黑名单、白名单</li></ul><p>按照白名单的思想，应该根据业务需求，列出一个允许使用的软件以及软件版本的清单，在此清单外的软件则禁止使用。选择白名单的思想，基于白名单来设计安全方案，其实就是信任白名单是好的，是安全的。但是一旦这个信任基础不存在了，那么安全就荡然无存。</p><ul><li>最小权限原则</li></ul><p>最小权限原则要求系统只授予主体必要的权限，而不要过度授权，这样能有效地减少系统、网络、应用、数据库出错的机会。</p><p>（在使用最小权限原则时，需要认真梳理业务所需要的权限，在很多时候，开发者并不会意识到业务授予用户的权限过高。在通过访谈了解业务时，可以多设置一些反问句，比如：您确定您的程序一定需要访问Internet吗？通过此类问题，来确定业务所需的最小权限。）</p><h6 id="（2）纵深防御原则（Defense-inDepth）"><a href="#（2）纵深防御原则（Defense-inDepth）" class="headerlink" title="（2）纵深防御原则（Defense inDepth）"></a>（2）纵深防御原则（Defense inDepth）</h6><p>纵深防御包含两层含义：首先，要在各个不同层面、不同方面实施安全方案，避免出现疏漏，不同安全方案之间需要相互配合，构成一个整体；其次，要在正确的地方做正确的事情，即：<strong>在解决根本问题的地方实施针对性的安全方案。</strong></p><p>纵深防御并不是同一个安全方案要做两遍或多遍，而是要从不同的层面、不同的角度对系统做出整体的解决方案。它要求我们深入理解威胁的本质，从而做出正确的应对措施。</p><ul><li>“统一威胁管理”（Uni-fied Threat Management）：UTM几乎集成了所有主流安全产品的功能，比如防火墙、VPN、反垃圾邮件、IDS、反病毒等。UTM的定位是当中小企业没有精力自己做安全方案时，可以在一定程度上提高安全门槛。但是UTM并不是万能药，很多问题并不应该在网络层、网关处解决，所以实际使用时效果未必好，它更多的是给用户买个安心。</li></ul><h6 id="（3）数据与代码分离原则"><a href="#（3）数据与代码分离原则" class="headerlink" title="（3）数据与代码分离原则"></a>（3）数据与代码分离原则</h6><p>在Web安全中，由“注入”引起的问题比比皆是，如XSS、SQL Injection、CRLF Injection、X-Path Injection等。此类问题均可以根据“数据与代码分离原则”设计出真正安全的解决方案，因为这个原则抓住了漏洞形成的本质原因。</p><h6 id="（4）不可预测性原则（Unpredictable）"><a href="#（4）不可预测性原则（Unpredictable）" class="headerlink" title="（4）不可预测性原则（Unpredictable）"></a>（4）不可预测性原则（Unpredictable）</h6><p>从克服攻击方法的角度看问题，能有效地对抗基于篡改、伪造的攻击。</p><p>不可预测性的实现往往需要用到加密算法、随机数算法、哈希算法，好好使用这条原则，在设计安全方案时往往会事半功倍。</p><hr><h2 id="第二章-浏览器安全"><a href="#第二章-浏览器安全" class="headerlink" title="第二章 浏览器安全"></a>第二章 浏览器安全</h2><p>浏览器是互联网最大的入口，绝大多数用户使用互联网的工具是浏览器。一方面，浏览器天生就是一个客户端，如果具备了安全功能，就可以像安全软件一样对用户上网起到很好的保护作用；另一方面，浏览器安全也成为浏览器厂商之间竞争的一张底牌，浏览器厂商希望能够针对安全建立起技术门槛，以获得竞争优势。因此近年来随着浏览器版本的不断更新，浏览器安全功能变得越来越强大。</p><h4 id="1、同源策略（Same-Origin-Policy）"><a href="#1、同源策略（Same-Origin-Policy）" class="headerlink" title="1、同源策略（Same Origin Policy）"></a>1、同源策略（Same Origin Policy）</h4><p>同源策略（Same Origin Policy）是一种约定，它是浏览器最核心也最基本的安全功能，如果缺少了同源策略，则浏览器的正常功能可能都会受到影响。可以说<strong>Web是构建在同源策略的基础之上的，浏览器只是针对同源策略的一种实现</strong>。浏览器的同源策略，限制了来自不同源的“document”或脚本，对当前“document”读取或设置某些属性。</p><ul><li><strong>XMLHttpRequest受到同源策略的约束，不能跨域访问资源</strong>（这就是常见的开发中需要配置跨域的原因）。如果XMLHttpRequest能够跨域访问资源，则可能会导致一些敏感数据泄露，比如CSRF的token，从而导致发生安全问题。</li></ul><h4 id="2、浏览器沙箱"><a href="#2、浏览器沙箱" class="headerlink" title="2、浏览器沙箱"></a>2、浏览器沙箱</h4><p>在网页中插入一段恶意代码，利用浏览器漏洞执行任意代码的攻击方式，在黑客圈子里被形象地称为“挂马”。“挂马”是浏览器需要面对的一个主要威胁。浏览器的多进程架构，将浏览器的各个功能模块分开，各个浏览器实例分开，当一个进程崩溃时，也不会影响到其他的进程。</p><p>Sandbox即沙箱，计算机技术发展到今天，Sandbox已经成为泛指“<strong>资源隔离类模块</strong>”的代名词。Sandbox的设计目的一般是为了让不可信任的代码运行在一定的环境中，限制不可信任的代码访问隔离区之外的资源。如果一定要跨越Sandbox边界产生数据交换，则只能通过指定的数据通道，比如经过封装的API来完成，在这些API中会严格检查请求的合法性。</p><p>Sandbox的应用范围非常广泛。采用Sandbox技术，无疑可以让不受信任的网页代码、JavaScript代码运行在一个受到限制的环境中，从而保护本地桌面系统的安全。</p><h4 id="3、恶意网址拦截"><a href="#3、恶意网址拦截" class="headerlink" title="3、恶意网址拦截"></a>3、恶意网址拦截</h4><p>恶意网址拦截的工作原理很简单，一般都是浏览器周期性地从服务器端获取一份最新的恶意网址黑名单，如果用户上网时访问的网址存在于此黑名单中，浏览器就会弹出一个警告页面。</p><p>常见的恶意网址分为两类：一类是挂马网站，这些网站通常包含有恶意的脚本如JavaScript或Flash，通过利用浏览器的漏洞（包括一些插件、控件漏洞）执行shellcode，在用户电脑中植入木马；另一类是钓鱼网站，通过模仿知名网站的相似页面来欺骗用户。</p><hr><h2 id="第三章-跨站脚本攻击（XSS）"><a href="#第三章-跨站脚本攻击（XSS）" class="headerlink" title="第三章 跨站脚本攻击（XSS）"></a>第三章 跨站脚本攻击（XSS）</h2><p>跨站脚本攻击（XSS）是客户端脚本安全中的头号大敌。</p><h4 id="1、简介"><a href="#1、简介" class="headerlink" title="1、简介"></a>1、简介</h4><p>跨站脚本攻击，英文全称是Cross Site Script，本来缩写是CSS，但是为了和层叠样式表（Cas-cading Style Sheet，CSS）有所区别，所以在安全领域叫做“XSS”。</p><p>XSS攻击，通常指黑客通过“<strong>HTML注入</strong>”篡改了网页，插入了恶意的脚本，从而在用户浏览网页时，控制用户浏览器的一种攻击。在一开始，这种攻击的演示案例是跨域的，所以叫做“跨站脚本”。但是发展到今天，由于JavaScript的强大功能以及网站前端应用的复杂化，是否跨域已经不再重要。但是由于历史原因，XSS这个名字却一直保留下来。</p><p>XSS长期以来被列为客户端Web安全中的头号大敌。因为XSS破坏力强大，且产生的场景复杂，难以一次性解决。现在业内达成的共识是：针对各种不同场景产生的XSS，需要区分情景对待。即便如此，复杂的应用环境仍然是XSS滋生的温床。</p><ul><li>反射型XSS：简单地把用户输入的数据“反射”给浏览器。也就是说，黑客往往需要诱使用户“点击”一个恶意链接，才能攻击成功。反射型XSS也叫做“非持久型XSS”（Non-persistent XSS）。<strong>（诱使进入钓鱼网站的过程）</strong></li><li>存储型XSS：存储型XSS会把用户输入的数据“存储”在服务器端。这种XSS具有很强的稳定性。存储型XSS通常也叫做“持久型XSS”(Persistent XSS)，因为从效果上来说，它存在的时间是比较长的。<strong>（钓鱼网站内操作的过程）</strong></li><li>DOM Based XSS：从效果上来说也是反射型XSS。单独划分出来，是因为DOM Based XSS的形成原因比较特别，是通过修改页面的DOM节点形成的XSS。<strong>（利用组件执行的函数将攻击代码植入执行）</strong></li></ul><h4 id="2、XSS攻击"><a href="#2、XSS攻击" class="headerlink" title="2、XSS攻击"></a>2、XSS攻击</h4><h6 id="（1）XSS-Payload"><a href="#（1）XSS-Payload" class="headerlink" title="（1）XSS Payload"></a>（1）XSS Payload</h6><p>XSS攻击成功后，攻击者能够对用户当前浏览的页面植入恶意脚本，通过恶意脚本，控制用户的浏览器。这些用以完成各种具体功能的恶意脚本，被称为“XSS Payload”。实际上就是JavaScript脚本（还可以是Flash或其他富客户端的脚本），所以任何JavaScript脚本能实现的功能，XSS Payload都能做到。</p><p>一个最常见的XSS Payload，就是通过读取浏览器的Cookie对象，从而发起“Cookie劫持”攻击。（Cookie的“HttpOnly”标识可以防止“Cookie劫持”）下面是几个常见的XSS Payload方式：</p><ul><li><strong>构造GET与POST请求</strong></li><li><strong>XSS钓鱼</strong>（对于验证码，XSS Payload可以通过读取页面内容，将验证码的图片URL发送到远程服务器上来实施——攻击者可以在远程XSS后台接收当前验证码，并将验证码的值返回给当前的XSS Payload，从而绕过验证码。 || 对于修改密码，可以利用JavaScript在当前页面上“画出”一个伪造的登录框，当用户在登录框中输入用户名与密码后，其密码将被发送至黑客的服务器上。）</li><li><strong>识别用户浏览器</strong>（通过XSS读取浏览器的UserAgent对象）</li><li><strong>标识用户安装的软件</strong>（知道了用户使用的浏览器、操作系统后，进一步可以识别用户安装的软件。黑客通过判断用户安装的软件，选择对应的浏览器漏洞，最终达到植入木马的目的。）</li><li><strong>CSS History Hack</strong>（利用style的visited属性——如果用户曾经访问过某个链接，那么这个链接的颜色会变得与众不同）</li><li><strong>获取用户真实IP地址</strong>（JavaScript本身并没有提供获取本地IP地址的能力，一般来说，XSS攻击需要借助第三方软件来完成。比如，客户端安装了Java环境（JRE），那么XSS就可以通过调用JavaApplet的接口获取客户端的本地IP地址。）<strong>【这一条告诉我们，不要觉得代理翻墙就安全了，黑客能做到的，要相信网安也能做到，小心网警来敲门】</strong></li></ul><h6 id="（2）XSS攻击平台"><a href="#（2）XSS攻击平台" class="headerlink" title="（2）XSS攻击平台"></a>（2）XSS攻击平台</h6><p>XSS Payload如此强大，为了使用方便，有安全研究者将许多功能封装起来，成为XSS攻击平台。这些攻击平台的主要目的是为了演示XSS的危害，以及方便渗透测试使用。下面就介绍几个常见的XSS攻击平台。</p><ul><li>Attack API是安全研究者pdp所主导的一个项目，它总结了很多能够直接使用XSS Payload，归纳为API的方式。（<a href="https://github.com/Cyb3rWard0g/Invoke-ATTACKAPI">Cyb3rWard0g&#x2F;Invoke-ATTACKAPI: A PowerShell script to interact with the MITRE ATT&amp;CK Framework via its own API (github.com)</a>）</li><li>BeEF曾经是最好的XSS演示平台。不同于Attack API，BeEF所演示的是一个完整的XSS攻击过程。BeEF有一个控制后台，攻击者可以在后台控制前端的一切。（<a href="https://github.com/beefproject/beef">beefproject&#x2F;beef: The Browser Exploitation Framework Project (github.com)</a>）</li><li>XSS-Proxy是一个轻量级的XSS攻击平台，通过嵌套iframe的方式可以实时地远程控制被XSS攻击的浏览器。（<a href="https://xss-proxy.sourceforge.net/">XSS-Proxy: A tool for realtime XSS hijacking and control (sourceforge.net)</a>）</li></ul><p>这些XSS攻击平台有助于<strong>深入理解XSS的原理和危害</strong>。（可以直接在Github上找到开源项目【大部分已经作为时代历程而落幕了】，CSDN也有新手教程，不过XSS主要是面对前端和PHP的【个人感觉】，要求先有比较高的水准才能自己写脚本，我不会所以就没下着玩玩）</p><h6 id="（3）终极武器XSS-Worm"><a href="#（3）终极武器XSS-Worm" class="headerlink" title="（3）终极武器XSS Worm"></a>（3）终极武器XSS Worm</h6><p>XSS Worm是XSS的一种终极利用方式，它的破坏力和影响力是巨大的。但是发起XSS Worm攻击也有一定的条件。一般来说，用户之间发生交互行为的页面，如果存在存储型XSS，则比较容易发起XSS Worm攻击。</p><p>比如，发送站内信、用户留言等页面，都是XSS Worm的高发区，需要重点关注。而相对的，如果一个页面只能由用户个人查看，比如“用户个人资料设置”页面，因为缺乏用户之间互动的功能，所以即使存在XSS，也不能被用于XSS Worm的传播。攻击者想要通过XSS做坏事是很容易的，而XSS Worm则能够把这种<strong>破坏无限扩大</strong>。</p><h6 id="（4）调试JavaScript"><a href="#（4）调试JavaScript" class="headerlink" title="（4）调试JavaScript"></a>（4）调试JavaScript</h6><p>要想写好XSS Payload，需要有很好的JavaScript功底，调试JavaScript是必不可少的技能。</p><ul><li><strong>Firebug：这是最常用的脚本调试工具</strong>，前端工程师与Web Hacking必备，被喻为“居家旅行的瑞士军刀”。（可以查看页面DOM节点）（<a href="https://github.com/firebug/firebug">firebug&#x2F;firebug: Web Development Evolved - The Firebug you have known and loved (github.com)</a>）</li><li><strong>Fiddler：是一个本地代理服务器</strong>，需要将浏览器设置为使用本地代理服务器上网才可使用。Fiddler会监控所有的浏览器请求，并有能力在浏览器请求中插入数据。（支持脚本编程）（<a href="https://www.telerik.com/">Telerik &amp; Kendo UI - .NET Components Suites &amp; JavaScript UI Libraries</a>【现在已经是比较成熟的商业化开发产品了】）</li><li><strong>HttpWatch</strong>：是一个商业软件，它以插件的形式内嵌在浏览器中。（<a href="https://www.httpwatch.com/">HttpWatch: An Advanced Network Debugger and HTTP Sniffer for Chrome, Edge and IE</a>）</li></ul><h6 id="（5）XSS构造技巧"><a href="#（5）XSS构造技巧" class="headerlink" title="（5）XSS构造技巧"></a>（5）XSS构造技巧</h6><ul><li><strong>利用字符编码</strong>（转义字符&#x2F;浏览器不同）</li><li><strong>绕过长度限制</strong></li><li><strong>使用&lt;base&gt;标签</strong></li><li><strong>windows.name</strong>（对当前窗口的window.name对象赋值，没有特殊字符的限制。因为window对象是浏览器的窗体，而并非document对象，因此很多时候window对象不受同源策略的限制。攻击者利用这个对象，可以实现跨域、跨页面传递数据。在某些环境下，这种特性将变得非常有用。）</li></ul><h6 id="（6）Flash-XSS"><a href="#（6）Flash-XSS" class="headerlink" title="（6）Flash XSS"></a>（6）Flash XSS</h6><p>Flash的时代已经落幕了，所以感兴趣的同学可以自己去看看书（狗头）。</p><h4 id="3、XSS防御"><a href="#3、XSS防御" class="headerlink" title="3、XSS防御"></a>3、XSS防御</h4><p>XSS的防御是复杂的。</p><h6 id="（1）HttpOnly"><a href="#（1）HttpOnly" class="headerlink" title="（1）HttpOnly"></a>（1）HttpOnly</h6><p>浏览器将禁止页面的JavaScript访问带有HttpOnly属性的Cookie。严格地说，HttpOnly并非为了对抗XSS——HttpOnly解决的是XSS后的Cookie劫持攻击。需要注意的是，服务器可能会设置多个Cookie（多个key-value对），而HttpOnly可以有选择性地加在任何一个Cookie值上。</p><p>使用HttpOnly有助于缓解XSS攻击，但仍然需要其他能够解决XSS漏洞的方案。</p><h6 id="（2）输入检查"><a href="#（2）输入检查" class="headerlink" title="（2）输入检查"></a>（2）输入检查</h6><p>输入检查，在很多时候也被用于格式检查。例如，用户在网站注册时填写的用户名，会被要求只能为字母、数字的组合。这些格式检查，有点像一种“白名单”，也可以让一些基于特殊字符的攻击失效。</p><p><strong>输入检查的逻辑，必须放在服务器端代码中实现</strong>。如果只是在客户端使用JavaScript进行输入检查，是很容易被攻击者绕过的。目前Web开发的普遍做法，是同时在客户端JavaScript中和服务器端代码中实现相同的输入检查。客户端JavaScript的输入检查，可以阻挡大部分误操作的正常用户，从而节约服务器资源。</p><p>在XSS的防御上，输入检查一般是检查用户输入的数据中是否包含一些特殊字符，如&lt;、&gt;、’、”等。如果发现存在特殊字符，则将这些字符过滤或者编码。比较智能的“输入检查”，可能还会匹配XSS的特征。比如查找用户数据中是否包含了“&lt;script&gt;”、“javascript”等敏感字符。这种输入检查的方式，可以称为“XSS Filter”。互联网上有很多开源的“XSS Filter”的实现。</p><h6 id="（3）输出检查"><a href="#（3）输出检查" class="headerlink" title="（3）输出检查"></a>（3）输出检查</h6><ul><li><strong>安全的编码函数</strong>：编码分为很多种，针对HTML代码的编码方式是HtmlEncode。HtmlEncode并非专用名词，它只是一种函数实现。它的作用是将字符转换成HTMLEntities，对应的标准是ISO-8859-1。在PHP中，有htmlentities()和htmlspe-cialchars()两个函数可以满足安全要求。JavaScript的编码方式可以使用JavascriptEncode。</li><li><strong>在正确的地方使用正确的编码</strong></li></ul><h6 id="（4）XSS产生的本质原因"><a href="#（4）XSS产生的本质原因" class="headerlink" title="（4）XSS产生的本质原因"></a>（4）XSS产生的本质原因</h6><p>XSS的本质是一种<strong>“HTML注入”</strong>，用户的数据被当成了HTML代码一部分来执行，从而混淆了原本的语义，产生了新的语义。</p><h6 id="（5）处理富文本"><a href="#（5）处理富文本" class="headerlink" title="（5）处理富文本"></a>（5）处理富文本</h6><p>HTML是一种结构化的语言，比较好分析。通过htmlparser可以解析出HTML代码的标签、标签属性和事件。在过滤富文本时，<strong>“事件”应该被严格禁止</strong>，因为“富文本”的展示需求里不应该包括“事件”这种动态效果。而一些危险的标签，比如&lt;iframe&gt;、&lt;script&gt;、&lt;base&gt;、&lt;form&gt;等，也是应该严格禁止的。</p><p>在标签的选择上，应该<strong>使用白名单，避免使用黑名单</strong>。比如，只允许&lt;a&gt;、&lt;我的网络安全入门（《白帽子讲Web安全》）&gt;、&lt;div&gt;等比较“安全”的标签存在。“白名单原则”不仅仅用于标签的选择，同样应该用于属性与事件的选择。</p><p><strong>尽可能地禁止用户自定义CSS与style。</strong></p><h6 id="（6）防御DOM-Based-XSS"><a href="#（6）防御DOM-Based-XSS" class="headerlink" title="（6）防御DOM Based XSS"></a>（6）防御DOM Based XSS</h6><p>DOM Based XSS是一种比较特别的XSS漏洞，前文提到的几种防御方法都不太适用，需要特别对待。DOM Based XSS是从<strong>JavaScript中输出数据到HTML页面里</strong>。之前提到的方法都是针对“从服务器应用直接输出到HTML页面”的XSS漏洞，因此并不适用于DOM Based XSS。</p><p>会触发DOM Based XSS的地方有很多，以下几个地方是JavaScript输出到HTML页面的必经之路。</p><ul><li>document.write()</li><li>document.writeln()</li><li>xxx.innerHTML&#x3D;</li><li>xxx.outerHTML&#x3D;</li><li>innerHTML.replace</li><li>document.attachEvent()</li><li>window.attachEvent()</li><li>document.location.replace()</li><li>document.location.assign()</li><li>……</li></ul><p>除了服务器端直接输出变量到JavaScript外，还有以下几个地方可能会成为DOM Based XSS的输入点，也需要重点关注。</p><ul><li>页面中所有的inputs框</li><li>window.location(href、hash等)</li><li>window.name ?document.referrer</li><li>document.cookie ?localstorage</li><li>XMLHttpRequest返回的数据</li><li>……</li></ul><h4 id="4、业务风险角度看XSS攻击"><a href="#4、业务风险角度看XSS攻击" class="headerlink" title="4、业务风险角度看XSS攻击"></a>4、业务风险角度看XSS攻击</h4><p>从风险的角度看，用户之间有互动的页面，是可能发起XSS Worm攻击的地方。而根据不同页面的PageView高低，也可以分析出哪些页面受XSS攻击后的影响会更大。比如在网站首页发生的XSS攻击，肯定比网站合作伙伴页面的XSS攻击要严重得多。</p><p>在修补XSS漏洞时遇到的最大挑战之一是漏洞数量太多，因此开发者可能来不及，也不愿意修补这些漏洞。从业务风险的角度来重新定位每个XSS漏洞，就具有了重要的意义。</p><hr><h2 id="第四章-跨站点请求伪造（CSRF）"><a href="#第四章-跨站点请求伪造（CSRF）" class="headerlink" title="第四章 跨站点请求伪造（CSRF）"></a>第四章 跨站点请求伪造（CSRF）</h2><p>CSRF的全名是Cross Site RequestForgery，翻译成中文就是跨站点请求伪造。它是一种常见的Web攻击，也是Web安全中最容易被忽略的一种攻击方式，在某些时候能够产生强大的破坏性。</p><h4 id="1、浏览器的Cookie策略"><a href="#1、浏览器的Cookie策略" class="headerlink" title="1、浏览器的Cookie策略"></a>1、浏览器的Cookie策略</h4><p>浏览器所持有的Cookie分为两种：<strong>一种是“Session Cookie”，又称“临时Cookie”；另一种是“Third-party Cookie”，也称为“本地Cookie”</strong>。</p><p>两者的区别在于，Third-party Cookie是服务器在Set-Cookie时指定了Expire时间，只有到了Expire时间后Cookie才会失效，所以这种Cookie会保存在本地；而Session Cookie则没有指定Expire时间，所以浏览器关闭后，Session Cookie就失效了。在浏览网站的过程中，若是一个网站设置了Session Cookie，那么在浏览器进程的生命周期内，即使浏览器新打开了Tab页，Session Cookie也都是有效的。Session Cookie保存在浏览器进程的内存空间中；而Third-party Cookie则保存在本地。</p><p>常见的CSRF攻击在于利用浏览器策略发送了第三方Cookie用于认证。</p><h4 id="2、P3P头"><a href="#2、P3P头" class="headerlink" title="2、P3P头"></a>2、P3P头</h4><p>P3P Header是W3C制定的一项关于隐私的标准，全称是The Platform for Privacy Preferences。</p><p>在网站的业务中，P3P头主要用于类似广告等需要跨域访问的页面。P3P头设置后，对于Cookie的影响将扩大到整个域中的所有页面，因为Cookie是以域和path为单位的，这并不符合“最小权限”原则。</p><p>P3P头的介入改变了a.com的隐私策略，从而使得&lt;iframe&gt;、&lt;script&gt;等标签在浏览器中不再拦截第三方Cookie的发送。P3P头只需要由网站设置一次即可，之后每次请求都会遵循此策略，而不需要再重复设置。</p><h4 id="3、GET-amp-POST"><a href="#3、GET-amp-POST" class="headerlink" title="3、GET &amp; POST"></a>3、GET &amp; POST</h4><p>大多数CSRF攻击发起时，使用的HTML标签都是&lt;我的网络安全入门（《白帽子讲Web安全》）&gt;、&lt;iframe&gt;、&lt;script&gt;等带“src”属性的标签，这类标签只能够发起一次GET请求，而不能发起POST请求。</p><p>但是实际上，<strong>CSRF攻击不只是GET请求</strong>，对于攻击者来说，有若干种方法可以构造出一个POST请求。攻击者甚至可以将这个页面隐藏在一个不可见的iframe窗口中，那么整个自动提交表单的过程，对于用户来说也是不可见的。</p><h4 id="4、CSRF的防御"><a href="#4、CSRF的防御" class="headerlink" title="4、CSRF的防御"></a>4、CSRF的防御</h4><h6 id="（1）验证码"><a href="#（1）验证码" class="headerlink" title="（1）验证码"></a>（1）验证码</h6><p><strong>验证码被认为是对抗CSRF攻击最简洁而有效的防御方法。</strong>CSRF攻击的过程，往往是在用户不知情的情况下构造了网络请求。而验证码，则强制用户必须与应用进行交互，才能完成最终请求。因此在通常情况下，验证码能够很好地遏制CSRF攻击。</p><p>但是验证码并非万能。很多时候，出于用户体验考虑，网站不能给所有的操作都加上验证码。因此，验证码只能作为防御CSRF的一种<strong>辅助手段，而不能作为最主要的解决方案</strong>。</p><h6 id="（2）Referer-Check"><a href="#（2）Referer-Check" class="headerlink" title="（2）Referer Check"></a>（2）Referer Check</h6><p>Referer Check在互联网中最常见的应用就是<strong>“防止图片盗链”</strong>。同理，Referer Check也可以被用于检查请求是否来自合法的“源”。</p><p>Referer Check的缺陷在于，服务器并非什么时候都能取到Referer。很多用户出于隐私保护的考虑，限制了Referer的发送。在某些情况下，浏览器也不会发送Referer，比如从HTTPS跳转到HTTP，出于安全的考虑，浏览器也不会发送Referer。</p><h6 id="（3）Anti-CSRF-Token"><a href="#（3）Anti-CSRF-Token" class="headerlink" title="（3）Anti CSRF Token"></a>（3）Anti CSRF Token</h6><ul><li><strong>CSRF的本质：重要操作的所有参数都是可以被攻击者猜测到的。</strong>出于这个原因，可以想到一个解决方案：把参数加密，或者使用一些随机数，从而让攻击者无法猜测到参数值。这是“不可预测性原则”的一种应用。（加密过程可以详见第十一章）<strong>但是！！！</strong>加密或混淆后的URL将变得非常难读，对用户非常不友好。其次，如果加密的参数每次都改变，则某些URL将无法再被用户收藏。最后，普通的参数如果也被加密或哈希，将会给数据分析工作带来很大的困扰，因为数据分析工作常常需要用到参数的明文。</li><li><strong>Token的使用原则</strong>：防御CSRF的Token，是根据“不可预测性原则”设计的方案，所以<strong>Token的生成一定要足够随机，需要使用安全的随机数生成器生成Token</strong>。此外，这个Token的目的不是为了防止重复提交。所以为了使用方便，<strong>可以允许在一个用户的有效生命周期内，在Token消耗掉前都使用同一个Token</strong>。但是如果用户已经提交了表单，则这个Token已经消耗掉，应该再次重新生成一个新的To-ken。如果Token保存在Cookie中，而不是服务器端的Session中，则会带来一个新的问题。如果一个用户打开几个相同的页面同时操作，当某个页面消耗掉Token后，其他页面的表单内保存的还是被消耗掉的那个Token，因此其他页面的表单再次提交时，会出现Token错误。在这种情况下，可以考虑<strong>生成多个有效的Token，以解决多页面共存的场景</strong>。最后，使用Token时应该<strong>注意Token的保密性</strong>。Token如果出现在某个页面的URL中，则可能会通过Referer的方式泄露。</li></ul><hr><h2 id="第五章-点击劫持（ClickJacking）"><a href="#第五章-点击劫持（ClickJacking）" class="headerlink" title="第五章 点击劫持（ClickJacking）"></a>第五章 点击劫持（ClickJacking）</h2><p>点击劫持是一种视觉上的欺骗手段。攻击者使用一个透明的、不可见的iframe，覆盖在一个网页上，然后诱使用户在该网页上进行操作，此时用户将在不知情的情况下点击透明的iframe页面。通过调整iframe页面的位置，可以诱使用户恰好点击在iframe页面的一些功能性按钮上。<strong>（现在是2023年1月，最大的“点击劫持”其实就在我们的日常生活中，那些找不到关闭按钮的小广告，正是点击劫持的典型代表）</strong></p><h4 id="1、图片覆盖攻击"><a href="#1、图片覆盖攻击" class="headerlink" title="1、图片覆盖攻击"></a>1、图片覆盖攻击</h4><p>点击劫持的本质是一种视觉欺骗。顺着这个思路，还有一些攻击方法也可以起到类似的作用，比如图片覆盖。Cross Site Image Overlaying攻击，简称XSIO，通过调整图片的style使得图片能够覆盖在所指定的任意位置。</p><p>XSIO不同于XSS，它利用的是图片的style，或者能够控制CSS。如果应用没有限制style的po-sition为absolute的话，图片就可以覆盖到页面上的任意位置，形成点击劫持。图片还可以伪装得像一个正常的链接、按钮；或者在图片中构造一些文字，覆盖在关键的位置，就有可能完全改变页面中想表达的意思，在这种情况下，不需要用户点击，也能达到欺骗的目的。</p><h4 id="2、拖拽劫持与数据窃取"><a href="#2、拖拽劫持与数据窃取" class="headerlink" title="2、拖拽劫持与数据窃取"></a>2、拖拽劫持与数据窃取</h4><p>很多浏览器都开始支持Drag &amp; Drop 的API。对于用户来说，拖拽使他们的操作更加简单。浏览器中的拖拽对象可以是一个链接，也可以是一段文字，还可以从一个窗口拖拽到另外一个窗口，因此拖拽是不受同源策略限制的。“拖拽劫持”的思路是<strong>诱使用户从隐藏的不可见iframe中“拖拽”出攻击者希望得到的数据，然后放到攻击者能控制的另外一个页面中，从而窃取数据</strong>。在JavaScript或者Java API的支持下，这个攻击过程会变得非常隐蔽。因为它突破了传统Click-Jacking一些先天的局限，所以这种新型的“拖拽劫持”能够造成更大的破坏。</p><h4 id="3、ClickJacking-3-0：触屏劫持"><a href="#3、ClickJacking-3-0：触屏劫持" class="headerlink" title="3、ClickJacking 3.0：触屏劫持"></a>3、ClickJacking 3.0：触屏劫持</h4><p>触屏操作通常对应一下几个事件：</p><ul><li>touchstart，手指触摸屏幕时发生；</li><li>touchend，手指离开屏幕时发生；</li><li>touchmove，手指滑动时发生；</li><li>touchcancel，系统可取消touch事件。</li></ul><p>手机上的屏幕范围有限，手机浏览器为了节约空间，甚至隐藏了地址栏，因此手机上的视觉欺骗可能会变得更加容易实施。</p><h4 id="4、防御ClickJacking"><a href="#4、防御ClickJacking" class="headerlink" title="4、防御ClickJacking"></a>4、防御ClickJacking</h4><h6 id="（1）frame-busting"><a href="#（1）frame-busting" class="headerlink" title="（1）frame busting"></a>（1）frame busting</h6><p>写一段JavaScript代码，以禁止iframe的嵌套。这种方法叫frame busting。</p><h6 id="（2）X-Frame-Options"><a href="#（2）X-Frame-Options" class="headerlink" title="（2）X-Frame-Options"></a>（2）X-Frame-Options</h6><p>frame busting存在被绕过的可能，所以我们需要寻找其他更好的解决方案。一个比较好的方案是使用一个HTTP头——X-Frame-Options。它有三个可选的值：</p><ul><li>DENY</li><li>SAMEORIGIN</li><li>ALLOW-FROM origin</li></ul><p>当值为DENY时，浏览器会拒绝当前页面加载任何frame页面；若值为SAMEORIGIN，则frame页面的地址只能为同源域名下的页面；若值为AL-LOW-FROM，则可以定义允许frame加载的页面地址。</p><hr><h2 id="第六章-HTML-5安全"><a href="#第六章-HTML-5安全" class="headerlink" title="第六章 HTML 5安全"></a>第六章 HTML 5安全</h2><p>HTML 5是W3C制定的新一代HTML语言的标准。（也就是现在常说的H5）</p><h4 id="1、HTML-5新标签"><a href="#1、HTML-5新标签" class="headerlink" title="1、HTML 5新标签"></a>1、HTML 5新标签</h4><h6 id="（1）新标签的XSS"><a href="#（1）新标签的XSS" class="headerlink" title="（1）新标签的XSS"></a>（1）新标签的XSS</h6><p>一些XSS Filter如果建立了一个黑名单的话，则可能就不会覆盖到HTML 5新增的标签和功能，从而避免发生XSS。</p><p>HTML 5中新增的一些标签和属性，使得XSS等Web攻击产生了新的变化，为了总结这些变化，有安全研究者建立了一个HTML5 Security Cheat-sheet项目。（虽然并没有找到该项目，但是都23年了，不少备忘录已经趋于成熟，例举一个我找到的：<a href="https://cheatsheetseries.owasp.org/cheatsheets/HTML5_Security_Cheat_Sheet.html">HTML5 安全 - OWASP 备忘单系列</a>）</p><h6 id="（2）iframe的sandbox"><a href="#（2）iframe的sandbox" class="headerlink" title="（2）iframe的sandbox"></a>（2）iframe的sandbox</h6><p>在HTML 5中，专门为iframe定义了一个新的属性，叫sandbox。使用sandbox这一个属性后，&lt;iframe&gt;标签加载的内容将被视为一个独立的“源”，其中的脚本将被禁止执行，表单被禁止提交，插件被禁止加载，指向其他浏览对象的链接也会被禁止。sandbox属性可以通过参数来支持更精确的控制。有以下几个值可以选择：</p><ul><li>allow-same-origin：允许同源访问；</li><li>allow-top-navigation：允许访问顶层窗口；</li><li>allow-forms：允许提交表单；</li><li>allow-scripts：允许执行脚本。</li></ul><h6 id="（3）Link-Types：noreferrer"><a href="#（3）Link-Types：noreferrer" class="headerlink" title="（3）Link Types：noreferrer"></a>（3）Link Types：noreferrer</h6><p>在HTML 5中为&lt;a&gt;标签和&lt;area&gt;标签定义了一个新的Link Types：noreferrer。顾名思义，标签指定了noreferrer后，浏览器在请求该标签指定的地址时将不再发送Referer。</p><p>这种设计是出于保护敏感信息和隐私的考虑。因为通过Referer，可能会泄露一些敏感信息。这个标签需要开发者手动添加到页面的标签中，对于有需求的标签可以选择使用noreferrer。代码如下：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;xxx&quot;</span> <span class="attr">rel</span>=<span class="string">&quot;noreferrer&quot;</span> &gt;</span>test<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br></pre></td></tr></table></figure><h6 id="（4）Canvas"><a href="#（4）Canvas" class="headerlink" title="（4）Canvas"></a>（4）Canvas</h6><p>不同于&lt;我的网络安全入门（《白帽子讲Web安全》）&gt;标签只是远程加载一个图片，&lt;canvas&gt;标签让JavaScript可以在页面中直接操作图片对象，也可以直接操作像素，构造出图片区域。Canvas的出现极大地挑战了传统富客户端插件的地位，开发者甚至可以用Canvas在浏览器上写一个小游戏。</p><p>通过Canvas自动破解验证码，最大的好处是可以在浏览器环境中实现在线破解，大大降低了攻击的门槛。HTML 5使得过去难以做到的事情，变为可能。</p><h4 id="2、其他安全问题"><a href="#2、其他安全问题" class="headerlink" title="2、其他安全问题"></a>2、其他安全问题</h4><h6 id="（1）Cross-Origin-Resource-Sharing"><a href="#（1）Cross-Origin-Resource-Sharing" class="headerlink" title="（1）Cross-Origin Resource Sharing"></a>（1）Cross-Origin Resource Sharing</h6><p>浏览器实现的同源策略（Same Origin Policy）限制了脚本的跨域请求。但互联网的发展趋势是越来越开放的，因此跨域访问的需求也变得越来越迫切。同源策略给Web开发者带来了很多困扰，他们不得不想方设法地实现一些“合法”的跨域技术，由此诞生了jsonp、iframe跨域等技巧。</p><h6 id="（2）postMessage跨窗口传递"><a href="#（2）postMessage跨窗口传递" class="headerlink" title="（2）postMessage跨窗口传递"></a>（2）postMessage跨窗口传递</h6><p>window这个对象几乎是不受同源策略限制的，很多脚本攻击都巧妙地利用了window对象的这一特点。在HTML 5中，为了丰富Web开发者的能力，制定了一个新的API：postMessage。postMessage允许每一个window（包括当前窗口、弹出窗口、iframes等）对象往其他的窗口发送文本消息，从而实现跨窗口的消息传递。这个功能是不受同源策略限制的。</p><p>在使用postMessage()时，有两个安全问题需要注意：</p><ul><li>在必要时，可以在接收窗口验证 Domain，甚至验证URL，以防止来自非法页面的消息。这实际上是在代码中实现一次同源策略的验证过程。</li><li>实际应用中，如果将消息写入innerHTML，甚至直接写入script中，则可能会导致DOMbased XSS的产生。根据“Secure By Default”原则，在接收窗口不应该信任接收到的消息，而需要对消息进行安全检查。</li></ul><p>使用postMessage，会使XSS Payload变得更加的灵活。</p><h6 id="（3）Web-Storage"><a href="#（3）Web-Storage" class="headerlink" title="（3）Web Storage"></a>（3）Web Storage</h6><p>Web Storage分为Session Storage 和 LocalStorage。Session Storage关闭浏览器就会失效，而Local Storage则会一直存在。<strong>Web Storage就像一个非关系型数据库，由Key-Value对组成，可以通过JavaScript对其进行操作</strong>。</p><p>Web Storage也受到同源策略的约束，每个域所拥有的信息只会保存在自己的域下，跨域时无法读取localStorage。Web Storage让Web开发更加的灵活多变，它的强大功能也为XSS Payload大开方便之门。攻击者有可能将恶意代码保存在Web Storage中，从而实现跨页面攻击。当Web Storage中保存有敏感信息时，也可能会成为攻击的目标，而XSS攻击可以完成这一过程。</p><hr><h2 id="第七章-注入攻击"><a href="#第七章-注入攻击" class="headerlink" title="第七章 注入攻击"></a>第七章 注入攻击</h2><p>注入攻击是Web安全领域中一种最为常见的攻击方式。<strong>注入攻击的本质，是把用户输入的数据当做代码执行。</strong>这里有两个关键条件，第一个是用户能够控制输入；第二个是原本程序要执行的代码，拼接了用户输入的数据。</p><h4 id="1、SQL注入"><a href="#1、SQL注入" class="headerlink" title="1、SQL注入"></a>1、SQL注入</h4><p>在SQL注入的过程中，如果网站的Web服务器开启了错误回显，则会为攻击者提供极大的便利，比如攻击者在参数中输入一个单引号“’”，引起执行查询语句的语法错误，服务器直接返回了错误信息。错误回显披露了敏感信息，对于攻击者来说，构造SQL注入的语句就可以更加得心应手了。</p><h6 id="（1）盲注（Blind-Injection）"><a href="#（1）盲注（Blind-Injection）" class="headerlink" title="（1）盲注（Blind Injection）"></a>（1）盲注（Blind Injection）</h6><p>“盲注”就是在服务器没有错误回显时完成的注入攻击。服务器没有错误回显，对于攻击者来说缺少了非常重要的“调试信息”，所以攻击者必须找到一个方法来验证注入的SQL语句是否得到执行。<strong>最常见的盲注验证方法是，构造简单的条件语句，根据返回页面是否发生变化，来判断SQL语句是否得到执行。</strong></p><h6 id="（2）Timing-Attack"><a href="#（2）Timing-Attack" class="headerlink" title="（2）Timing Attack"></a>（2）Timing Attack</h6><p>利用BENCHMARK()函数，可以让同一个函数执行若干次，使得结果返回的时间比平时要长；通过时间长短的变化，可以判断出注入语句是否执行成功。这是一种边信道攻击，这个技巧在盲注中被称为Timing Attack。</p><p>Timing Attack是盲注的一种高级技巧。在不同的数据库中，都有着类似于BENCHMARK()的函数，可以被Timing Attack所利用。</p><h4 id="2、数据库攻击技巧"><a href="#2、数据库攻击技巧" class="headerlink" title="2、数据库攻击技巧"></a>2、数据库攻击技巧</h4><h6 id="（1）常见的攻击技巧"><a href="#（1）常见的攻击技巧" class="headerlink" title="（1）常见的攻击技巧"></a>（1）常见的攻击技巧</h6><p>在注入攻击的过程中，常常会用到一些读写文件的技巧。比如在MySQL中，就可以通过LOAD_FILE()读取系统文件，并通过INTODUMPFILE写入本地文件。当然这要求当前数据库用户有读写系统相应文件或目录的权限。</p><p>如果当前数据库用户有创建表的权限：首先通过LOAD_FILE()将系统文件读出，再通过INTODUMPFILE将该文件写入系统中，然后通过LOAD DATA INFILE将文件导入创建的表中，最后就可以通过一般的注入技巧直接操作表数据了。</p><p>除了可以使用INTO DUMPFILE外，还可以使用INTO OUTFILE，两者的区别是DUMPFILE适用于二进制文件，它会将目标文件写入同一行内；而OUTFILE则更适用于文本文件。写入文件的技巧，经常被用于导出一个Web-shell，为攻击者的进一步攻击做铺垫。因此在设计数据库安全方案时，可以<strong>禁止普通数据库用户具备操作文件的权限</strong>。</p><h6 id="（2）命令执行"><a href="#（2）命令执行" class="headerlink" title="（2）命令执行"></a>（2）命令执行</h6><p>通过lib_mysqludf_sys提供的几个函数执行系统命令，其中最主要的函数是sys_eval()和sys_exec()。在攻击过程中，将lib_mysqludf_sys.so上传到数据库能访问到的路径下。在创建UDF（User-Defined Functions）之后，就可以使用sys_eval()等函数执行系统命令了。 ?sys_eval，执行任意命令，并将输出返回。</p><ul><li>sys_exec，执行任意命令，并将退出码返回。 ?sys_get，获取一个环境变量。</li><li>sys_set，创建或修改一个环境变量。</li></ul><p><strong>在建立数据库账户时应该遵循“最小权限原则”，尽量避免给Web应用使用数据库的管理员权限。</strong></p><h6 id="（3）攻击存储过程"><a href="#（3）攻击存储过程" class="headerlink" title="（3）攻击存储过程"></a>（3）攻击存储过程</h6><p>存储过程为数据库提供了强大的功能，它与UDF很像，但存储过程必须使用CALL或者EXE-CUTE来执行。除了利用存储过程直接攻击外，存储过程本身也可能会存在注入漏洞。</p><h6 id="（4）编码问题"><a href="#（4）编码问题" class="headerlink" title="（4）编码问题"></a>（4）编码问题</h6><p>在有些时候，不同的字符编码也可能会导致一些安全问题。注入攻击中常常会用到单引号“’”、双引号“””等特殊字符。在应用中，开发者为了安全，经常会使用转义字符“\”来转义这些特殊字符。但当数据库使用了“宽字符集”时，可能会产生一些意想不到的漏洞。比如，当MySQL使用了GBK编码时，0xbf27 和 0xbf5c都会被认为是一个字符（双字节字符）。</p><p>要解决这种问题，需要<strong>统一数据库、操作系统、Web应用所使用的字符集，以避免各层对字符的理解存在差异</strong>。统一设置为UTF-8是一个很好的方法。如果因为种种原因无法统一字符编码，则需要<strong>单独实现一个用于过滤或转义的安全函数，在其中需要考虑到字符的可能范围</strong>。</p><h6 id="（5）SQL-Column-Truncation"><a href="#（5）SQL-Column-Truncation" class="headerlink" title="（5）SQL Column Truncation"></a>（5）SQL Column Truncation</h6><p>在MySQL的配置选项中，有一个sql_mode选项。当MySQL的sql-mode设置为default时，即没有开启STRICT_ALL_TABLES选项时，MySQL对于用户插入的超长值只会提示warning，而不是error（如果是error则插入不成功），这可能会导致发生一些“截断”问题。</p><p>简单来说就是当插入的数据超过设置长度时，只把限制内的长度存入。比如说：如果用户名只允许存8位，管理员名称为admin，那么创建名字的时候这是为admin___x（其中_代表空格），那么将存入的是admin___，经过一些处理（比如说过滤空格）可以实现和admin一样的效果。</p><h4 id="3、防御SQL注入"><a href="#3、防御SQL注入" class="headerlink" title="3、防御SQL注入"></a>3、防御SQL注入</h4><p>SQL注入的防御并不是一件简单的事情，开发者常常会走入一些误区。比如只对用户输入做一些escape处理，这是不够的。</p><h6 id="（1）使用预编译语句"><a href="#（1）使用预编译语句" class="headerlink" title="（1）使用预编译语句"></a>（1）使用预编译语句</h6><p>防御SQL注入的最佳方式，就是使用预编译语句，<strong>绑定变量</strong>。使用预编译的SQL语句，SQL语句的语义不会发生改变。在SQL语句中，变量用?表示，攻击者无法改变SQL的结构，即使攻击者插入类似于tom’ or ‘1’&#x3D;’1的字符串，也只会将此字符串当做username来查询。</p><h6 id="（2）使用存储过程"><a href="#（2）使用存储过程" class="headerlink" title="（2）使用存储过程"></a>（2）使用存储过程</h6><p>使用安全的存储过程对抗SQL注入。使用存储过程的效果和使用预编语句译类似，其区别就是存储过程需要先将SQL语句定义在数据库中。但需要注意的是，存储过程中也可能会存在注入问题，因此应该尽量避免在存储过程内使用动态的SQL语句。如果无法避免，则应该使用严格的输入过滤或者是编码函数来处理用户的输入数据。</p><h6 id="（3）检查数据类型"><a href="#（3）检查数据类型" class="headerlink" title="（3）检查数据类型"></a>（3）检查数据类型</h6><p>检查输入数据的数据类型，在很大程度上可以对抗SQL注入。但数据类型检查并非万能，如果需求就是需要用户提交字符串，比如一段短文，则需要依赖其他的方法防范SQL注入。</p><h6 id="（4）使用安全函数"><a href="#（4）使用安全函数" class="headerlink" title="（4）使用安全函数"></a>（4）使用安全函数</h6><h4 id="4、其他注入攻击"><a href="#4、其他注入攻击" class="headerlink" title="4、其他注入攻击"></a>4、其他注入攻击</h4><p>除了SQL注入外，在Web安全领域还有其他的注入攻击，这些注入攻击都有相同的特点，就是应用违背了<strong>“数据与代码分离”原则</strong>。</p><h6 id="（1）XML注入"><a href="#（1）XML注入" class="headerlink" title="（1）XML注入"></a>（1）XML注入</h6><p>XML是一种常用的标记语言，通过标签对数据进行结构化表示。XML与HTML都是SGML（Standard Generalized Markup Language，标准通用标记语言）。</p><p>XML注入，也需要满足注入攻击的两大条件：用户能控制数据的输入；程序拼凑了数据。在修补方案上，与HTML注入的修补方案也是类似的，对用户输入数据中包含的“语言本身的保留字符”进行转义即可。</p><h6 id="（2）代码注入"><a href="#（2）代码注入" class="headerlink" title="（2）代码注入"></a>（2）代码注入</h6><p>代码注入与命令注入往往都是由一些不安全的函数或者方法引起的，其中的典型代表就是eval()。<strong>存在代码注入漏洞的地方，与“后门”没有区别。</strong>Java的脚本引擎、PHP、JSP的动态include（文件包含漏洞）导致的代码执行，都可以算是一种代码注入。代码注入多见于脚本语言，有时候代码注入可以造成命令注入（Command Injection）。</p><p>对抗代码注入、命令注入时，需要<strong>禁用eval()、system()等可以执行命令的函数。如果一定要使用这些函数，则需要对用户的输入数据进行处理</strong>。此外，在PHP&#x2F;JSP中避免动态include远程文件，或者安全地处理它。</p><h6 id="（3）CRLF注入"><a href="#（3）CRLF注入" class="headerlink" title="（3）CRLF注入"></a>（3）CRLF注入</h6><p>CRLF实际上是两个字符：CR是Carriage Re-turn(ASCII 13, \r)，LF是Line Feed(ASCII 10,\n)。\r\n这两个字符是用于表示换行的，其十六进制编码分别为0x0d、0x0a。<strong>CRLF常被用做不同语义之间的分隔符。因此通过“注入CRLF字符”，就有可能改变原有的语义。</strong></p><p>对抗CRLF的方法非常简单，只需要处理好“\r”、“\n”这两个保留字符即可，尤其是那些使用“换行符”作为分隔符的应用。</p><hr><h2 id="第八章-文件上传漏洞"><a href="#第八章-文件上传漏洞" class="headerlink" title="第八章 文件上传漏洞"></a>第八章 文件上传漏洞</h2><h4 id="1、概述"><a href="#1、概述" class="headerlink" title="1、概述"></a>1、概述</h4><p>文件上传漏洞是指用户上传了一个可执行的脚本文件，并通过此脚本文件获得了执行服务器端命令的能力。这种攻击方式是最为直接和有效的，有时候几乎没有什么技术门槛。文件上传后导致的常见安全问题一般有：</p><ul><li>上传文件是Web脚本语言，服务器的Web容器解释并执行了用户上传的脚本，导致代码执行；</li><li>上传文件是Flash的策略文件crossdomain.xml，黑客用以控制Flash在该域下的行为（其他通过类似方式控制策略文件的情况类似）；</li><li>上传文件是病毒、木马文件，黑客用以诱骗用户或者管理员下载执行；</li><li>上传文件是钓鱼图片或为包含了脚本的图片，在某些版本的浏览器中会被作为脚本执行，被用于钓鱼和欺诈。</li></ul><p>除此之外，还有一些不常见的利用方法，比如将上传文件作为一个入口，溢出服务器的后台处理程序，如图片解析模块；或者上传一个合法的文本文件，其内容包含了PHP脚本，再通过“本地文件包含漏洞（Local File Include）”执行此脚本；等等。在大多数情况下，文件上传漏洞一般都是指“上传Web脚本能够被服务器解析”的问题，也就是通常所说的webshell的问题。要完成这个攻击，要满足如下几个条件：</p><ul><li>首先，上传的文件能够被Web容器解释执行。所以文件上传后所在的目录要是Web容器所覆盖到的路径。</li><li>其次，用户能够从Web上访问这个文件。如果文件上传了，但用户无法通过Web访问，或者无法使得Web容器解释这个脚本，那么也不能称之为漏洞。</li><li>最后，用户上传的文件若被安全检查、格式化、图片压缩等功能改变了内容，则也可能导致攻击不成功。</li></ul><h4 id="2、功能导致的漏洞"><a href="#2、功能导致的漏洞" class="headerlink" title="2、功能导致的漏洞"></a>2、功能导致的漏洞</h4><p>在文件上传漏洞的利用过程中，攻击者发现一些和Web Server本身特性相关的功能，如果加以利用，就会变成威力巨大的武器。</p><h6 id="（1）Apache文件解析问题"><a href="#（1）Apache文件解析问题" class="headerlink" title="（1）Apache文件解析问题"></a>（1）Apache文件解析问题</h6><p>在Apache 1.x、2.x中，对文件名的解析就存在这种特性：Apache对于文件名的解析是从后往前解析的，直到遇见一个Apache认识的文件类型为止。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Phpshell.php.rar.rar.rar.rar.rar</span><br></pre></td></tr></table></figure><p>Apache不认识.rar这个文件类型，所以会一直遍历后缀到.php，然后认为这是一个PHP类型的文件。</p><h6 id="（2）IIS文件解析问题"><a href="#（2）IIS文件解析问题" class="headerlink" title="（2）IIS文件解析问题"></a>（2）IIS文件解析问题</h6><p>IIS 6在处理文件解析时，也出过一些漏洞。前面提到的0x00字符截断文件名，在IIS和Windows环境下曾经出过非常类似的漏洞，不过截断字符变成了分号“;”。当文件名为abc.asp;xx.jpg时，IIS 6会将此文件解析为abc.asp，文件名被截断了，从而导致脚本被执行。</p><h6 id="（3）PHP-CGI路径解析问题-amp-amp-利用上传文件钓鱼"><a href="#（3）PHP-CGI路径解析问题-amp-amp-利用上传文件钓鱼" class="headerlink" title="（3）PHP CGI路径解析问题 &amp;&amp; 利用上传文件钓鱼"></a>（3）PHP CGI路径解析问题 &amp;&amp; 利用上传文件钓鱼</h6><p>自己看书吧这个就。</p><h4 id="3、安全的文件上传功能"><a href="#3、安全的文件上传功能" class="headerlink" title="3、安全的文件上传功能"></a>3、安全的文件上传功能</h4><h6 id="（1）文件上传的目录设置为不可执行"><a href="#（1）文件上传的目录设置为不可执行" class="headerlink" title="（1）文件上传的目录设置为不可执行"></a>（1）文件上传的目录设置为不可执行</h6><p>只要Web容器无法解析该目录下的文件，即使攻击者上传了脚本文件，服务器本身也不会受到影响，因此此点至关重要。在实际应用中，很多大型网站的上传应用，文件上传后会放到独立的存储上，做静态文件处理，一方面方便使用缓存加速，降低性能损耗；另一方面也杜绝了脚本执行的可能。</p><h6 id="（2）判断文件类型"><a href="#（2）判断文件类型" class="headerlink" title="（2）判断文件类型"></a>（2）判断文件类型</h6><p>在判断文件类型时，可以结合使用MIMEType、后缀检查等方式。在文件类型检查中，强烈推荐白名单的方式，黑名单的方式已经无数次被证明是不可靠的。此外，对于图片的处理，可以使用压缩函数或者resize函数，在处理图片的同时破坏图片中可能包含的HTML代码。（前端过滤文件类型）</p><h6 id="（3）使用随机数改写文件名和文件路径"><a href="#（3）使用随机数改写文件名和文件路径" class="headerlink" title="（3）使用随机数改写文件名和文件路径"></a>（3）使用随机数改写文件名和文件路径</h6><p>文件上传如果要执行代码，则需要用户能够访问到这个文件。在某些环境中，用户能上传，但不能访问。如果应用使用随机数改写了文件名和路径，将极大地增加攻击的成本。与此同时，像shell.php.rar.rar这种文件，或者是crossdo-main.xml这种文件，都将因为文件名被改写而无法成功实施攻击。（这也是为什么现在主流的后端保存图片的时候文件会在后端规格化命名）</p><h6 id="（4）单独设置文件服务器的域名"><a href="#（4）单独设置文件服务器的域名" class="headerlink" title="（4）单独设置文件服务器的域名"></a>（4）单独设置文件服务器的域名</h6><p>由于浏览器同源策略的关系，一系列客户端攻击将失效，比如上传crossdomain.xml、上传包含JavaScript的XSS利用等问题将得到解决。但能否如此设置，还需要看具体的业务环境。（也可以使用一些云端存储设备【收费但是更安全】，比如说七牛云、阿里云OSS）</p><hr><h2 id="第九章-认证和会话管理"><a href="#第九章-认证和会话管理" class="headerlink" title="第九章 认证和会话管理"></a>第九章 认证和会话管理</h2><p>“认证”是最容易理解的一种安全。如果一个系统缺乏认证手段，明眼人都能看出来这是“不安全”的。最常见的认证方式就是用户名与密码，但认证的手段却远远不止于此。</p><h4 id="1、“认证”与“授权”"><a href="#1、“认证”与“授权”" class="headerlink" title="1、“认证”与“授权”"></a>1、“认证”与“授权”</h4><p>“认证”和“授权”是两件事情，认证的英文是Authentication，授权则是Authorization。分清楚这两个概念其实很简单，只需要记住下面这个事实：<strong>认证的目的是为了认出用户是谁，而授权的目的是为了决定用户能够做什么。</strong></p><p>证的手段是多样化的，其目的就是为了能够识别出正确的人。如何才能准确地判断一个人是谁呢？这是一个哲学问题，在被哲学家们搞清楚之前，我们只能够依据人的不同“凭证”来确定一个人的身份。钥匙仅仅是一个很脆弱的凭证，其他诸如指纹、虹膜、人脸、声音等生物特征也能够作为识别一个人的凭证。认证实际上就是一个验证凭证的过程。</p><p>如果只有一个凭证被用于认证，则称为“单因素认证”；如果有两个或多个凭证被用于认证，则称为“双因素（Two Factors）认证”或“多因素认证”。一般来说，多因素认证的强度要高于单因素认证，但是在<strong>用户体验上，多因素认证或多或少都会带来一些不方便的地方</strong>。</p><h4 id="2、密码"><a href="#2、密码" class="headerlink" title="2、密码"></a>2、密码</h4><p>密码是最常见的一种认证手段，持有正确密码的人被认为是可信的。长期以来，桌面软件、互联网都普遍以密码作为最基础的认证手段。</p><p>密码的<strong>优点是使用成本低，认证过程实现起来很简单；缺点是密码认证是一种比较弱的安全方案</strong>，可能会被猜解，要实现一个足够安全的密码认证方案，也不是一件轻松的事情。“密码强度”是设计密码认证方案时第一个需要考虑的问题。在用户密码强度的选择上，每个网站都有自己的策略。</p><h4 id="3、多因素认证"><a href="#3、多因素认证" class="headerlink" title="3、多因素认证"></a>3、多因素认证</h4><p>除了支付密码外，手机动态口令、数字证书、宝令、支付盾、第三方证书等都可用于用户认证。这些不同的认证手段可以互相结合，使得认证的过程更加安全。密码不再是唯一的认证手段，在用户密码丢失的情况下，也有可能有效地保护用户账户的安全。<strong>多因素认证提高了攻击的门槛。</strong></p><h4 id="4、Session与认证"><a href="#4、Session与认证" class="headerlink" title="4、Session与认证"></a>4、Session与认证</h4><p>密码与证书等认证手段，一般仅仅用于登录（Login）的过程。当登录完成后，用户访问网站的页面，不可能每次浏览器请求页面时都再使用密码认证一次。因此，当认证成功后，就需要替换一个对用户透明的凭证。这个凭证，就是SessionID。最常见的做法就是把SessionID加密后保存在Cookie中，因为Cookie会随着HTTP请求头发送，且受到浏览器同源策略的保护。</p><p><strong>SessionID一旦在生命周期内被窃取，就等同于账户失窃。</strong>同时由于SessionID是用户登录之后才持有的认证凭证，因此黑客不需要再攻击登录过程（比如密码），在设计安全方案时需要意识到这一点。</p><p>在生成SessionID时，需要<strong>保证足够的随机性，比如采用足够强的伪随机数生成算法</strong>。现在的网站开发中，都有很多成熟的开发框架可以使用。这些成熟的开发框架一般都会提供Cookie管理、Session管理的函数，可以善用这些函数和功能。</p><h4 id="5、Session-Fixation攻击"><a href="#5、Session-Fixation攻击" class="headerlink" title="5、Session Fixation攻击"></a>5、Session Fixation攻击</h4><p>在用户登录网站的过程中，如果登录前后用户的SessionID没有发生变化，则会存在Session Fixation问题。具体攻击的过程是，用户X（攻击者）先获取到一个未经认证的SessionID，然后将这个SessionID交给用户Y去认证，Y完成认证后，服务器并未更新此SessionID的值（注意是未改变SessionID，而不是未改变Session），所以X可以直接凭借此SessionID登录进Y的账户。</p><h4 id="6、Session保持攻击"><a href="#6、Session保持攻击" class="headerlink" title="6、Session保持攻击"></a>6、Session保持攻击</h4><p>一般的应用都会给session设置一个失效时间，当到达失效时间后，Session将被销毁。但有一些系统，出于用户体验的考虑，只要这个用户还“活着”，就不会让这个用户的Session失效。从而攻击者可以通过不停地发起访问请求，让Session一直“活”下去。</p><p>对抗这种攻击，常见的做法是在一定时间后，强制销毁Session。这个时间可以是从用户登录的时间算起，设定一个阈值，比如3天后就强制Session过期。但强制销毁Session可能会影响到一些正常的用户，还可以选择的方法是当用户客户端发生变化时，要求用户重新登录。比如用户的IP、UserA-gent等信息发生了变化，就可以强制销毁当前的Session，并要求用户重新登录。</p><p>最后，还需要考虑的是同一用户可以同时拥有几个有效Session。若每个用户只允许拥有一个Session，则攻击者想要一直保持一个Session也是不太可能的。当用户再次登录时，攻击者所保持的Session将被“踢出”。</p><h4 id="7、单点登录（Single-Sign-On）"><a href="#7、单点登录（Single-Sign-On）" class="headerlink" title="7、单点登录（Single Sign On）"></a>7、单点登录（Single Sign On）</h4><p>用户只需要登录一次，就可以访问所有的系统。从用户体验的角度看，SSO无疑让用户的使用更加的方便；从安全的角度看，SSO把风险集中在单点上，这样做是有利有弊的。</p><p><strong>SSO的优点在于风险集中化，就只需要保护好这一个点。</strong>如果让每个系统各自实现登录功能，由于各系统的产品需求、应用环境、开发工程师的水平都存在差异，登录功能的安全标准难以统一。而SSO解决了这个问题，它把用户登录的过程集中在一个地方。在单点处设计安全方案，甚至可以考虑使用一些较“重”的方法，比如双因素认证。此外对于一些中小网站来说，维护一份用户名、密码也是没有太大必要的开销，所以如果能将这个工作委托给一个可以信任的第三方，就可以将精力集中在业务上。</p><p><strong>SSO的缺点同样也很明显，因为风险集中了，所以单点一旦被攻破的话，后果会非常严重，影响的范围将涉及所有使用单点登录的系统。</strong>降低这种风险的办法是在一些敏感的系统里，再单独实现一些额外的认证机制。比如网上支付平台，在付款前要求用户再输入一次密码，或者通过手机短信验证用户身份等。</p><hr><h2 id="第十章-访问控制"><a href="#第十章-访问控制" class="headerlink" title="第十章 访问控制"></a>第十章 访问控制</h2><p>“权限”一词在安全领域出现的频率很高。“权限”实际上是一种“能力”。对于权限的合理分配，一直是安全设计中的核心问题。但“权限”一词的中文含义过于广泛，因此本章中将使用“访问控制”代替。在互联网安全领域，尤其是Web安全领域中，“权限控制”的问题都可以归结为“访问控制”的问题，这种描述也更精确一些。</p><p>权限控制，或者说访问控制，广泛应用于各个系统中。抽象地说，都是某个主体（subject）对某个客体（object）需要实施某种操作（operation），而系统对这种操作的限制就是权限控制。</p><p>在网络中，为了保护网络资源的安全，一般是通过路由设备或者防火墙建立基于IP的访问控制。这种访问控制的“主体”是网络请求的发起方（比如一台PC），“客体”是网络请求的接收方（比如一台服务器），主体对客体的“操作”是对客体的某个端口发起网络请求。这个操作能否执行成功，是受到防火墙ACL策略限制的。</p><p>在操作系统中，对文件的访问也有访问控制。此时“主体”是系统的用户，“客体”是被访问的文件，能否访问成功，将由操作系统给文件设置的ACL（访问控制列表）决定。比如在Linux系统中，一个文件可以执行的操作分为“读”、“写”、“执行”三种，分别由r、w、x表示。这三种操作同时对应着三种主体：文件拥有者、文件拥有者所在的用户组、其他用户。主体、客体、操作这三者之间的对应关系，构成了访问控制列表。</p><h4 id="1、垂直管理权限"><a href="#1、垂直管理权限" class="headerlink" title="1、垂直管理权限"></a>1、垂直管理权限</h4><p><strong>访问控制实际上是建立用户与权限之间的对应关系</strong>，现在应用广泛的一种方法，就是“基于角色的访问控制（Role-Based Access Control）”，简称RBAC。</p><p>RBAC事先会在系统中定义出不同的角色，不同的角色拥有不同的权限，一个角色实际上就是一个权限的集合。而系统的所有用户都会被分配到不同的角色中，一个用户可能拥有多个角色，角色之间有高低之分（权限高低）。在系统验证权限时，只需要验证用户所属的角色，然后就可以根据该角色所拥有的权限进行授权了。</p><p><strong>Spring Security中的权限管理，就是RBAC模型的一个实现</strong>。Spring Security基于SpringMVC框架，它的前身是Acegi，是一套较为全面的Web安全解决方案。在Spring Security中提供了认证、授权等功能。在这里我们只关注Spring Security的授权功能。</p><ul><li>Spring Security提供了一系列的“FilterChain”，每个安全检查的功能都会插入在这个链条中。在与Web系统集成时，开发者只需要将所有用户请求的URL都引入到Filter Chain即可。</li><li>Spring Security提供两种权限管理方式，一种是“基于URL的访问控制”，一种是“基于method的访问控制”。这两种访问控制都是RBAC模型的实现，换言之，在Spring Security中都是验证该用户所属的角色，以决定是否授权。</li></ul><p>权限管理其实是业务需求上的一个问题，需要根据业务的不同需求来实现不同的权限管理。因此很多时候，系统都需要自己定制权限管理。这种<strong>基于角色的权限管理（RBAC模型）</strong>，我们可以称之为“垂直权限管理”。</p><p>不同角色的权限有高低之分。高权限角色访问低权限角色的资源往往是被允许的，而低权限角色访问高权限角色的资源往往则被禁止。如果一个本属于低权限角色的用户通过一些方法能够获得高权限角色的能力，则发生了“越权访问”。</p><h4 id="2、水平权限管理"><a href="#2、水平权限管理" class="headerlink" title="2、水平权限管理"></a>2、水平权限管理</h4><p>RBAC这种“基于角色的访问控制”模型下，系统只会验证用户A是否属于角色RoleX，而不会判断用户A是否能访问只属于用户B的数据DataB，因此，发生了越权访问。这种问题，我们就称之为“水平权限管理问题”。</p><p>相对于垂直权限管理来说，水平权限问题出在同一个角色上。系统只验证了能访问数据的角色，既没有对角色内的用户做细分，也没有对数据的子集做细分，因此缺乏一个用户到数据之间的对应关系。由于水平权限管理是系统缺乏一个数据级的访问控制所造成的，因此<strong>水平权限管理又可以称之为“基于数据的访问控制”</strong>。</p><h4 id="3、OAuth"><a href="#3、OAuth" class="headerlink" title="3、OAuth"></a>3、OAuth</h4><p>OAuth是一个在不提供用户名和密码的情况下，授权第三方应用访问Web资源的安全协议。OAuth 与 OpenID都致力于让互联网变得更加的开放。OpenID解决的是认证问题，OAuth则更注重授权。认证与授权的关系其实是一脉相承的，后来人们发现，其实更多的时候真正需要的是<strong>对资源的授权</strong>。</p><hr><h2 id="第十一章-加密算法与随机数"><a href="#第十一章-加密算法与随机数" class="headerlink" title="第十一章 加密算法与随机数"></a>第十一章 加密算法与随机数</h2><p>加密算法与伪随机数算法是开发中经常会用到的东西，但加密算法的专业性非常强，在Web开发中，如果对加密算法和伪随机数算法缺乏一定的了解，则很可能会错误地使用它们，最终导致应用出现安全问题。</p><h4 id="1、概述-1"><a href="#1、概述-1" class="headerlink" title="1、概述"></a>1、概述</h4><p>常见的加密算法通常分为分组加密算法与流密码加密算法两种，两者的实现原理不同。</p><ul><li>分组加密算法基于“分组”（block）进行操作，根据算法的不同，每个分组的长度可能不同。分组加密算法的代表有DES、3-DES、Blowfish、IDEA、AES等。</li><li>流密码加密算法，则每次只处理一个字节，密钥独立于消息之外，两者通过异或实现加密与解密。流密码加密算法的代表有RC4、ORYX、SEAL等。</li></ul><p>针对加密算法的攻击，一般根据攻击者能获得的信息，可以分为：</p><h6 id="（1）唯密文攻击"><a href="#（1）唯密文攻击" class="headerlink" title="（1）唯密文攻击"></a>（1）唯密文攻击</h6><p>攻击者有一些密文，它们是使用同一加密算法和同一密钥加密的。这种攻击是最难的。</p><h6 id="（2）已知明文攻击"><a href="#（2）已知明文攻击" class="headerlink" title="（2）已知明文攻击"></a>（2）已知明文攻击</h6><p>攻击者除了能得到一些密文外，还能得到这些密文对应的明文。本章中针对流密码的一些攻击为已知明文攻击。</p><h6 id="（3）选择明文攻击"><a href="#（3）选择明文攻击" class="headerlink" title="（3）选择明文攻击"></a>（3）选择明文攻击</h6><p>攻击者不仅能得到一些密文和明文，还能选择用于加密的明文。</p><h6 id="（4）选择密文攻击"><a href="#（4）选择密文攻击" class="headerlink" title="（4）选择密文攻击"></a>（4）选择密文攻击</h6><p>攻击者可以选择不同的密文来解密。</p><h4 id="2、Stream-Cipher-Attack"><a href="#2、Stream-Cipher-Attack" class="headerlink" title="2、Stream Cipher Attack"></a>2、Stream Cipher Attack</h4><p>流密码是常用的一种加密算法，与分组加密算法不同，流密码的加密是基于异或（XOR）操作进行的，每次都只操作一个字节。但流密码加密算法的性能非常好，因此也是非常受开发者欢迎的一种加密算法。常见的流密码加密算法有RC4、ORYX、SEAL等。</p><h6 id="（1）Reused-Key-Attack"><a href="#（1）Reused-Key-Attack" class="headerlink" title="（1）Reused Key Attack"></a>（1）Reused Key Attack</h6><p>在流密码的使用中，最常见的错误便是使用同一个密钥进行多次加&#x2F;解密。这将使得破解流密码变得非常简单。这种攻击被称为“Reused Key At-tack”，在这种攻击下，攻击者不需要知道密钥，即可还原出明文。（具体实现办法可以看书哦，这个比较有意思）</p><h6 id="（2）Bit-flipping-Attack"><a href="#（2）Bit-flipping-Attack" class="headerlink" title="（2）Bit-flipping Attack"></a>（2）Bit-flipping Attack</h6><p>当知道A的明文、B的明文、A的密文时，可以推导出B的密文。在密码学中，攻击者在不知道明文的情况下，通过改变密文，使得明文按其需要的方式发生改变的攻击方式，被称为Bit-flipping Attack。</p><p>解决Bit-flipping攻击的方法是<strong>验证密文的完整性</strong>，最常见的方法是增加带有KEY的MAC（消息验证码，Message Authentication Code），通过MAC验证密文是否被篡改。</p><h6 id="（3）弱随机Ⅳ问题"><a href="#（3）弱随机Ⅳ问题" class="headerlink" title="（3）弱随机Ⅳ问题"></a>（3）弱随机Ⅳ问题</h6><p>在authcode()函数中，它默认使用了4字节的IV（就是函数中的keyc），使得破解难度增大。但是4字节的IV实际上是很脆弱的，它不够随机，可以通过“暴力破解”的方式找到重复的IV。</p><h4 id="3、WEP破解"><a href="#3、WEP破解" class="headerlink" title="3、WEP破解"></a>3、WEP破解</h4><p>WEP是一种常用的无线加密传输协议，破解了WEP的密钥，就可以以此密钥连接无线的Access Point。最著名的针对流密码的攻击可能就是WEP密钥的破解。WEP采用RC4算法，也存在这两种攻击方式。WEP在加密过程中，有两个关键因素，一个是初始化向量IV，一个是对消息的CRC-32校验。</p><ul><li>第一步：加载目标。</li><li>第二步：与目标网络进行协商。</li><li>第三步：生成密钥流。</li><li>第四步：构造ARP包。</li><li>第五步：生成自己的ARP包。</li><li>第六步：开始破解。</li></ul><h4 id="4、ECP模式"><a href="#4、ECP模式" class="headerlink" title="4、ECP模式"></a>4、ECP模式</h4><p>对于分组加密算法来说，除去算法本身，还有一些通用的加密模式，不同的加密算法会支持同样的几种加密模式。常见的加密模式有：ECB、CBC、CFB、OFB、CTR等。如果加密模式被攻击，那么不论加密算法的密钥有多长，都可能不再安全。</p><p>ECB模式（电码簿模式）是最简单的一种加密模式，它的每个分组之间相对独立。</p><p><img src="/2023/01/06/%E6%88%91%E7%9A%84%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E5%85%A5%E9%97%A8%EF%BC%88%E3%80%8A%E7%99%BD%E5%B8%BD%E5%AD%90%E8%AE%B2Web%E5%AE%89%E5%85%A8%E3%80%8B%EF%BC%89/11.1.png"></p><p>但ECB模式最大的问题也是出在这种分组的独立性上：攻击者只需要对调任意分组的密文，在经过解密后，所得明文的顺序也是经过对调的。这与链式加密模式（CBC）等是完全不同的，链式加密模式的分组前后之间会互相关联，一个字节的变化，会导致整个密文发生变化。这一特点也可以用于判断密文是否是用ECB模式加密的。</p><p>对于ECB模式来说，改变分组密文的顺序，将改变解密后的明文顺序；替换某个分组密文，解密后该对应分组的明文也会被替换，而其他分组不受影响。</p><p><strong>ECB模式并未完全混淆分组间的关系，因此当分组足够多时，仍然会暴露一些私密信息，而链式模式则避免了此问题</strong>。当需要加密的明文多于一个分组的长度时，应该避免使用ECB模式，而使用其他更加安全的加密模式。</p><h4 id="5、密钥管理"><a href="#5、密钥管理" class="headerlink" title="5、密钥管理"></a>5、密钥管理</h4><p>在密码学里有个基本的原则：<strong>密码系统的安全性应该依赖于密钥的复杂性，而不应该依赖于算法的保密性。</strong></p><p>在安全领域里，选择一个足够安全的加密算法不是困难的事情，难的是密钥管理。在一些实际的攻击案例中，直接攻击加密算法本身的案例很少，而因为密钥没有妥善管理导致的安全事件却很多。对于攻击者来说，他们不需要正面破解加密算法，如果能够通过一些方法获得密钥，则是件事半功倍的事情。</p><p><strong>密钥管理中最常见的错误，就是将密钥硬编码在代码里。</strong></p><ul><li>代码被广泛传播。这种泄露途径常见于一些开源软件；有的商业软件并不开源，但编译后的二进制文件被用户下载，也可能被逆向工程反编译后，泄露硬编码的密钥。</li><li>软件开发团队的成员都能查看代码，从而获知硬编码的密钥。开发团队的成员如果流动性较大，则可能会由此泄露代码。</li></ul><p>密钥管理的主要目的，还是为了防止密钥从非正常的渠道泄露。<strong>定期更换密钥也是一种有效的做法</strong>。一个比较安全的密钥管理系统，可以将所有的密钥（包括一些敏感配置文件）都集中保存在一个服务器（集群）上，并通过Web Service的方式提供获取密钥的API。每个Web应用在需要使用密钥时，通过带认证信息的API请求密钥管理系统，动态获取密钥。<strong>Web应用不能把密钥写入本地文件中，只加载到内存，这样动态获取密钥最大程度地保护了密钥的私密性。密钥集中管理，降低了系统对于密钥的耦合性，也有利于定期更换密钥。</strong></p><h4 id="6、伪随机数问题"><a href="#6、伪随机数问题" class="headerlink" title="6、伪随机数问题"></a>6、伪随机数问题</h4><p>伪随机数（pseudo random number）问题——伪随机数不够随机，是程序开发中会出现的一个问题。一方面，大多数开发者对此方面的安全知识有所欠缺，很容易写出不安全的代码；另一方面，伪随机数问题的攻击方式在多数情况下都只存在于理论中，难以证明，因此在说服程序员修补代码时也显得有点理由不够充分。</p><p>伪随机数，是通过一些数学算法生成的随机数，并非真正的随机数。密码学上的安全伪随机数应该是不可压缩的。对应的“真随机数”，则是通过一些物理系统生成的随机数，比如电压的波动、硬盘磁头读&#x2F;写时的寻道时间、空中电磁波的噪声等。</p><h6 id="（1）进程伪随机"><a href="#（1）进程伪随机" class="headerlink" title="（1）进程伪随机"></a>（1）进程伪随机</h6><p>在OpenSSL的伪随机数生成算法中，唯一的随机因子是pid。而在Linux系统中，pid的最大值也是32768。这是一个很小的范围，因此可以很快地遍历出所有的随机数。</p><h6 id="（2）时间伪随机"><a href="#（2）时间伪随机" class="headerlink" title="（2）时间伪随机"></a>（2）时间伪随机</h6><p>很多伪随机数算法与系统时间有关，而有的程序员甚至就直接使用系统时间代替随机数的生成。这样生成的随机数，是根据时间顺序增长的，可以从时间上进行预测，从而存在安全隐患。在开发程序时，要切记：<strong>不要把时间函数当成随机数使用。</strong></p><h6 id="（3）破解伪随机的方法"><a href="#（3）破解伪随机的方法" class="headerlink" title="（3）破解伪随机的方法"></a>（3）破解伪随机的方法</h6><p>（这里书上主要介绍的是PHP上几个函数的破解方式，大部分以代码为主，感兴趣可以看看）</p><h6 id="（4）安全的随机数"><a href="#（4）安全的随机数" class="headerlink" title="（4）安全的随机数"></a>（4）安全的随机数</h6><p>在重要或敏感的系统中，一定要使用足够强壮的随机数生成算法。</p><ul><li>在Java中，可以使用java.security.SecureRandom。</li><li>在Linux中，可以使用&#x2F;dev&#x2F;random或者&#x2F;dev&#x2F;urandom来生成随机数，只需要读取即可。</li><li>在PHP 5.3.0及其之后的版本中，若是支持openSSL扩展，也可以直接使用函数来生成随机数。</li></ul><p>算法上还可以通过多个随机数的组合，以增加随机数的复杂性。比如通过给随机数使用MD5算法后，再连接一个随机字符，然后再使用MD5算法一次。这些方法，也将极大地增加攻击的难度。</p><h4 id="7、一些注重的细节"><a href="#7、一些注重的细节" class="headerlink" title="7、一些注重的细节"></a>7、一些注重的细节</h4><p>在加密算法的选择和实践上，有以下最佳实践：</p><h6 id="（1）不要使用ECB模式"><a href="#（1）不要使用ECB模式" class="headerlink" title="（1）不要使用ECB模式"></a>（1）不要使用ECB模式</h6><h6 id="（2）不要使用流密码（比如RC4）"><a href="#（2）不要使用流密码（比如RC4）" class="headerlink" title="（2）不要使用流密码（比如RC4）"></a>（2）不要使用流密码（比如RC4）</h6><h6 id="（3）使用HMAC-SHA1代替MD5（甚至是代替SHA1）"><a href="#（3）使用HMAC-SHA1代替MD5（甚至是代替SHA1）" class="headerlink" title="（3）使用HMAC-SHA1代替MD5（甚至是代替SHA1）"></a>（3）使用HMAC-SHA1代替MD5（甚至是代替SHA1）</h6><h6 id="（4）不要使用相同的key做不同的事"><a href="#（4）不要使用相同的key做不同的事" class="headerlink" title="（4）不要使用相同的key做不同的事"></a>（4）不要使用相同的key做不同的事</h6><h6 id="（5）salts与IV需要随机产生"><a href="#（5）salts与IV需要随机产生" class="headerlink" title="（5）salts与IV需要随机产生"></a>（5）salts与IV需要随机产生</h6><h6 id="（6）不要自己实现加密算法，尽量实现安全专家实现好的库"><a href="#（6）不要自己实现加密算法，尽量实现安全专家实现好的库" class="headerlink" title="（6）不要自己实现加密算法，尽量实现安全专家实现好的库"></a>（6）不要自己实现加密算法，尽量实现安全专家实现好的库</h6><h6 id="（7）不要依赖系统的保密性"><a href="#（7）不要依赖系统的保密性" class="headerlink" title="（7）不要依赖系统的保密性"></a>（7）不要依赖系统的保密性</h6><p>当你不知道该如何选择时，有以下建议：</p><h6 id="（1）使用CBC模式的AES256用于加密"><a href="#（1）使用CBC模式的AES256用于加密" class="headerlink" title="（1）使用CBC模式的AES256用于加密"></a>（1）使用CBC模式的AES256用于加密</h6><h6 id="（2）使用HMAC-SHA512用于完整性检查"><a href="#（2）使用HMAC-SHA512用于完整性检查" class="headerlink" title="（2）使用HMAC-SHA512用于完整性检查"></a>（2）使用HMAC-SHA512用于完整性检查</h6><h6 id="（3）使用带salt的SHA-256或SHA-512用于Hashing"><a href="#（3）使用带salt的SHA-256或SHA-512用于Hashing" class="headerlink" title="（3）使用带salt的SHA-256或SHA-512用于Hashing"></a>（3）使用带salt的SHA-256或SHA-512用于Hashing</h6><hr><h2 id="第十二章-Web框架安全"><a href="#第十二章-Web框架安全" class="headerlink" title="第十二章 Web框架安全"></a>第十二章 Web框架安全</h2><p>实施安全方案，要达到好的效果，必须要完成两个目标：</p><ul><li>安全方案正确、可靠；</li><li>能够发现所有可能存在的安全问题，不出现遗漏。</li></ul><h4 id="1、MVC框架安全"><a href="#1、MVC框架安全" class="headerlink" title="1、MVC框架安全"></a>1、MVC框架安全</h4><p>MVC是Model-View-Controller的缩写，它将Web应用分为三层，View层负责用户视图、页面展示等工作；Controller负责应用的逻辑实现，接收View层传入的用户请求，并转发给对应的Model做处理；Model层则负责实现模型，完成数据的处理。</p><p>从数据的流入来看，用户提交的数据先后流经了View层、Controller、Model层，数据的流出则反过来。在设计安全方案时，要牢牢把握住数据这个关键因素。<strong>在MVC框架中，通过切片、过滤器等方式，往往能对数据进行全局处理，这为设计安全方案提供了极大的便利</strong>。</p><p>比如在Spring Security中，通过URL pattern实现的访问控制，需要由框架来处理所有用户请求，在Spring Security获取了URL handler基础上，才有可能将后续的安全检查落实。在SpringSecurity的配置中，第一步就是在web.xml文件中增加一个filter，接管用户数据。</p><h4 id="2、模板引擎与XSS防御"><a href="#2、模板引擎与XSS防御" class="headerlink" title="2、模板引擎与XSS防御"></a>2、模板引擎与XSS防御</h4><p>XSS攻击是在用户的浏览器上执行的，其形成过程则是在服务器端页面渲染时，注入了恶意的HTML代码导致的。从MVC架构来说，是发生在View层，因此使用“输出编码”的防御方法更加合理，这意味着需要针对不同上下文的XSS攻击场景，使用不同的编码方式。</p><p>最好的XSS防御方案，在不同的场景需要使用不同的编码函数，如果统一使用这5个字符的HtmlEncode，则很可能会被攻击者绕过。通过自定义的方法，使得XSS防御的功能得到完善；同时在模板系统中，搜索不安全的变量也有了依据，甚至在代码检测工具中，可以自动判断出需要使用哪一种安全的编码方法，这在安全开发流程中是非常重要的。</p><h4 id="3、Web框架与CSRF防御"><a href="#3、Web框架与CSRF防御" class="headerlink" title="3、Web框架与CSRF防御"></a>3、Web框架与CSRF防御</h4><p>CSRF攻击的目标，一般都会产生“写数据”操作的URL，比如“增”、“删”、“改”；而“读数据”操作并不是CSRF攻击的目标，因为在CSRF的攻击过程中攻击者无法获取到服务器端返回的数据，攻击者只是借用户之手触发服务器动作，所以读数据对于CSRF来说并无直接的意义（但是如果同时存在XSS漏洞或者其他的跨域漏洞，则可能会引起别的问题。</p><p>在Web应用开发中，有必要<strong>对“读操作”和“写操作”予以区分</strong>，比如要求所有的“写操作”都使用HTTP POST。完整的CSRF防御方案，对于Web框架来说有以下几处地方需要改动：</p><ul><li>在Session中绑定token。如果不能保存到服务器端Session中，则可以替代为保存到Cookie里。</li><li>在form表单中自动填入token字段，比如&lt;input type&#x3D;hidden name&#x3D;”anti_csrf_token”value&#x3D;”$token” &#x2F;&gt;。</li><li>在Ajax请求中自动添加token，这可能需要已有的Ajax封装实现的支持。</li><li>在服务器端对比POST提交参数的token与Session中绑定的token是否一致，以验证CSRF攻击。</li></ul><h4 id="4、HTTP-Headers管理"><a href="#4、HTTP-Headers管理" class="headerlink" title="4、HTTP Headers管理"></a>4、HTTP Headers管理</h4><p>在Web框架中，可以对HTTP头进行全局化的处理，针对HTTP返回头的CRLF注入只需要<strong>在“value”中编码所有的\r\n即可</strong>。这里没有提到在“key”中编码\r\n，是因为让用户能够控制“key”是极其危险的事情，在任何情况下都不应该使其发生。对于框架来说，<strong>管理好跳转目的地址是很有必要的</strong>：</p><ul><li>如果Web框架提供统一的跳转函数，则可以在跳转函数内部实现一个白名单，指定跳转地址只能在白名单中；</li><li>控制HTTP的Location字段，限制Location的值只能是哪些地址，也能起到同样的效果，其本质还是白名单。</li></ul><h4 id="5、数据持久层与SQL注入"><a href="#5、数据持久层与SQL注入" class="headerlink" title="5、数据持久层与SQL注入"></a>5、数据持久层与SQL注入</h4><p>使用ORM（Object&#x2F;Relation Mapping）框架对SQL注入是有积极意义的。我们知道对抗SQL注入的最佳方式就是使用“预编译绑定变量”。在实际解决SQL注入时，还有一个难点就是应用复杂后，代码数量庞大，难以把可能存在SQL注入的地方不遗漏地找出来，而ORM框架为我们发现问题提供了一个便捷的途径。使用Web框架提供的功能，在代码风格上更加统一，也更利于代码审计。</p><hr><h2 id="第十三章-应用层拒绝服务攻击"><a href="#第十三章-应用层拒绝服务攻击" class="headerlink" title="第十三章 应用层拒绝服务攻击"></a>第十三章 应用层拒绝服务攻击</h2><p>在互联网中一谈起DDOS攻击，人们往往谈虎色变。DDOS攻击被认为是安全领域中最难解决的问题之一，迄今为止也没有一个完美的解决方案。（没错，现在仍然是主流的威胁之一，不常见的原因是很多企业选用云服务器等方式，DDOS被大企业的方案给过滤掉了，但是不得不说【挺贵的】。。。）</p><h4 id="1、DDOS简介"><a href="#1、DDOS简介" class="headerlink" title="1、DDOS简介"></a>1、DDOS简介</h4><p>DDOS又称为分布式拒绝服务，全称是Distributed Denial of Service。DDOS本是<strong>利用合理的请求造成资源过载，导致服务不可用</strong>。资源是有限的，而服务必须一直提供下去。如果资源都已经被占用了，那么服务也将过载，导致系统停止新的响应。</p><p>分布式拒绝服务攻击，将正常请求放大了若干倍，通过若干个网络节点同时发起攻击，以达成规模效应。这些网络节点往往是黑客们所控制的“肉鸡”，数量达到一定规模后，就形成了一个“僵尸网络”。大型的僵尸网络，甚至达到了数万、数十万台的规模。如此规模的僵尸网络发起的DDOS攻击，几乎是不可阻挡的。</p><p>常见的DDOS攻击有SYN flood、UDP flood、ICMP flood等。其中SYN flood是一种最为经典的DDOS攻击，其发现于1996年，但至今仍然保持着非常强大的生命力。SYN flood如此猖獗是因为它利用了TCP协议设计中的缺陷，而TCP&#x2F;IP协议是整个互联网的基础，牵一发而动全身，如今想要修复这样的缺陷几乎成为不可能的事情。</p><p>在正常情况下，TCP三次握手过程如下：</p><p><img src="/2023/01/06/%E6%88%91%E7%9A%84%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E5%85%A5%E9%97%A8%EF%BC%88%E3%80%8A%E7%99%BD%E5%B8%BD%E5%AD%90%E8%AE%B2Web%E5%AE%89%E5%85%A8%E3%80%8B%EF%BC%89/13.1.png"></p><ul><li>客户端向服务器端发送一个SYN包，包含客户端使用的端口号和初始序列号x；</li><li>服务器端收到客户端发送来的SYN包后，向客户端发送一个SYN和ACK都置位的TCP报文，包含确认号xx1和服务器端的初始序列号y；</li><li>客户端收到服务器端返回的SYNSACK报文后，向服务器端返回一个确认号为yy1、序号为xx1的ACK报文，一个标准的TCP连接完成。</li></ul><p>SYN flood在攻击时，首先伪造大量的源IP地址，分别向服务器端发送大量的SYN包，此时服务器端会返回SYN&#x2F;ACK包，因为源地址是伪造的，所以伪造的IP并不会应答，服务器端没有收到伪造IP的回应，会重试3～5次并且等待一个SYNTime（一般为30秒至2分钟），如果超时则丢弃这个连接。攻击者大量发送这种伪造源地址的SYN请求，服务器端将会消耗非常多的资源（CPU和内存）来处理这种半连接，同时还要不断地对这些IP进行SYN+ACK重试。最后的结果是服务器无暇理睬正常的连接请求，导致拒绝服务。</p><p>对抗SYN flood的主要措施有SYN Cookie&#x2F;SYN Proxy、safereset等算法。SYN Cookie的主要思想是为每一个IP地址分配一个“Cookie”，并统计每个IP地址的访问频率。如果在短时间内收到大量的来自同一个IP地址的数据包，则认为受到攻击，之后来自这个IP地址的包将被丢弃。</p><p>在很多对抗DDOS的产品中，一般会综合使用各种算法，结合一些DDOS攻击的特征，对流量进行清洗。对抗DDOS的网络设备可以串联或者并联在网络出口处。但DDOS仍然是业界的一个难题，<strong>当攻击流量超过了网络设备，甚至带宽的最大负荷时，网络仍将瘫痪。一般来说，大型网站之所以看起来比较能“抗”DDOS攻击，是因为大型网站的带宽比较充足，集群内服务器的数量也比较多。但一个集群的资源毕竟是有限的，在实际的攻击中，DDOS的流量甚至可以达到数G到几十G，遇到这种情况，只能与网络运营商合作，共同完成DDOS攻击的响应。</strong></p><h4 id="2、应用层DDOS"><a href="#2、应用层DDOS" class="headerlink" title="2、应用层DDOS"></a>2、应用层DDOS</h4><p>应用层DDOS，不同于网络层DDOS，由于发生在应用层，因此TCP三次握手已经完成，连接已经建立，所以发起攻击的IP地址也都是真实的。</p><h6 id="（1）CC攻击"><a href="#（1）CC攻击" class="headerlink" title="（1）CC攻击"></a>（1）CC攻击</h6><p>“CC攻击”的前身是一个叫fatboy的攻击程序，当时黑客为了挑战绿盟的一款反DDOS设备开发了它。绿盟是中国著名的安全公司之一，它有一款叫“黑洞（Collapasar）”的反DDOS设备，能够有效地清洗SYN Flood等有害流量。而黑客则挑衅式地将fatboy所实现的攻击方式命名为：Challenge Collapasar（简称CC），意指在黑洞的防御下，仍然能有效完成拒绝服务攻击。</p><p>CC攻击的原理非常简单，就是<strong>对一些消耗资源较大的应用页面不断发起正常的请求，以达到消耗服务端资源的目的</strong>。在Web应用中，查询数据库、读&#x2F;写硬盘文件等操作，相对都会消耗比较多的资源。</p><p>应用层DDOS攻击是针对服务器性能的一种攻击，那么许多优化服务器性能的方法，都或多或少地能缓解此种攻击。比如将使用频率高的数据放在memcache中，相对于查询数据库所消耗的资源来说，查询memcache所消耗的资源可以忽略不计。但很多性能优化的方案并非是为了对抗应用层DDOS攻击而设计的，因此攻击者想要找到一个资源消耗大的页面并不困难。比如当memcache查询没有命中时，服务器必然会查询数据库，从而增大服务器资源的消耗，攻击者只需要找到这样的页面即可。同时攻击者除了触发“读”数据操作外，还可以触发“写”数据操作，“写”数据的行为一般都会导致服务器操作数据库。</p><h6 id="（2）限制请求频率"><a href="#（2）限制请求频率" class="headerlink" title="（2）限制请求频率"></a>（2）限制请求频率</h6><p>最常见的针对应用层DDOS攻击的防御措施，是在应用中<strong>针对每个“客户端”做一个请求频率的限制</strong>。例如：通过IP地址与Cookie 定位一个客户端，如果客户端的请求在一定时间内过于频繁，则对之后来自该客户端的所有请求都重定向到一个出错页面。</p><p>然而这种防御方法并不完美，因为它在客户端的判断依据上并不是永远可靠的。这个方案中有两个因素用以定位一个客户端：一个是IP地址，另一个是Cookie。但用户的IP地址可能会发生改变，而Cookie又可能会被清空，如果IP地址和Cookie同时都发生了变化，那么就无法再定位到同一个客户端了。</p><h6 id="（3）解决应用层DDOS"><a href="#（3）解决应用层DDOS" class="headerlink" title="（3）解决应用层DDOS"></a>（3）解决应用层DDOS</h6><ul><li>应用代码要做好性能优化。合理地使用memcache就是一个很好的优化方案，将数据库的压力尽可能转移到内存中。此外还需要及时地释放资源，比如及时关闭数据库连接，减少空连接等消耗。</li><li>在网络架构上做好优化。善于利用负载均衡分流，避免用户流量集中在单台服务器上。同时可以充分利用好CDN和镜像站点的分流作用，缓解主站的压力。</li><li><strong>实现一些对抗手段，比如限制每个IP地址的请求频率</strong>。</li></ul><p>一种比较可靠的方法是让客户端解析一段JavaScript，并给出正确的运行结果。因为大部分的自动化脚本都是直接构造HTTP包完成的，并非在一个浏览器环境中发起的请求。因此一段需要计算的JavaScript，可以判断出客户端到底是不是浏览器。类似的，发送一个flash让客户端解析，也可以起到同样的作用。但需要注意的是，这种方法并不是万能的，有的自动化脚本是内嵌在浏览器中的“内挂”，就无法检测出来了。</p><h4 id="3、资源耗尽攻击"><a href="#3、资源耗尽攻击" class="headerlink" title="3、资源耗尽攻击"></a>3、资源耗尽攻击</h4><p>攻击者还可能利用一些WebServer的漏洞或设计缺陷，直接造成拒绝服务。</p><h6 id="（1）Slowloris攻击"><a href="#（1）Slowloris攻击" class="headerlink" title="（1）Slowloris攻击"></a>（1）Slowloris攻击</h6><p>原理是以极低的速度往服务器发送HTTP请求。由于WebServer对于并发的连接数都有一定的上限，因此若是恶意地占用住这些连接不释放，那么Web Server的所有连接都将被恶意连接占用，从而无法接受新的请求，导致拒绝服务。这种攻击几乎针对所有的Web Server都是有效的。从这种方式可以看出：<strong>此类拒绝服务攻击的本质，实际上是对有限资源的无限制滥用。</strong></p><h6 id="（2）HTTP-POST-DOS"><a href="#（2）HTTP-POST-DOS" class="headerlink" title="（2）HTTP POST DOS"></a>（2）HTTP POST DOS</h6><p>原理是在发送HTTP POST包时，指定一个非常大的Content-Length值，然后以很低的速度发包，比如10～100s发一个字节，保持住这个连接不断开。这样当客户端连接数多了以后，占用住了Web Server的所有可用连接，从而导致DOS。</p><p>这种攻击的本质也是针对Apache的MaxClients限制的。要解决此类问题，可以使用Web应用防火墙，或者一个定制的Web Server安全模块。</p><p><strong>凡是资源有“限制”的地方，都可能发生资源滥用，从而导致拒绝服务，也就是一种“资源耗尽攻击”</strong>。出于可用性和物理条件的限制，内存、进程数、存储空间等资源都不可能无限制地增长，因此如果未对不可信任的资源使用者进行配额的限制，就有可能造成拒绝服务。<strong>内存泄漏是程序员经常需要解决的一种bug，而在安全领域中，内存泄漏则被认为是一种能够造成拒绝服务攻击的方式。</strong></p><h6 id="（3）Server-Limit-DOS"><a href="#（3）Server-Limit-DOS" class="headerlink" title="（3）Server Limit DOS"></a>（3）Server Limit DOS</h6><p>Web Server对HTTP包头都有长度限制，以Apache举例，默认是8192字节。也就是说，Apache所能接受的最大HTTP包头大小为8192字节（这里指的是Request Header，如果是Re-quest Body，则默认的大小限制是2GB）。如果客户端发送的HTTP包头超过这个大小，服务器就会返回一个4xx错误。</p><p>假如攻击者通过XSS攻击，恶意地往客户端写入了一个超长的Cookie，则该客户端在清空Cookie之前，将无法再访问该Cookie所在域的任何页面。这是因为Cookie也是放在HTTP包头里发送的，而Web Server默认会认为这是一个超长的非正常请求，从而导致“客户端”的拒绝服务。</p><p>要解决此问题，需要调整Apache配置参数LimitRequestFieldSize，这个参数设置为0时，对HTTP包头的大小没有限制。</p><h4 id="4、ReDOS正则攻击"><a href="#4、ReDOS正则攻击" class="headerlink" title="4、ReDOS正则攻击"></a>4、ReDOS正则攻击</h4><p>当正则表达式写得不好时，就有可能被恶意输入利用，消耗大量资源，从而造成DOS。这种攻击被称为ReDOS。ReDOS是一种代码实现上的缺陷。我们知道正则表达式是基于NFA（Nondeterministic Finite Au-tomaton）的，它是一个状态机，每个状态和输入符号都可能有许多不同的下一个状态。正则解析引擎将遍历所有可能的路径直到最后。由于每个状态都有若干个“下一个状态”，因此决策算法将逐个尝试每个“下一个状态”，直到找到一个匹配的。</p><p>例如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">^(a+)+$</span><br></pre></td></tr></table></figure><p>输入为“aaaa”时执行过程：</p><p><img src="/2023/01/06/%E6%88%91%E7%9A%84%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E5%85%A5%E9%97%A8%EF%BC%88%E3%80%8A%E7%99%BD%E5%B8%BD%E5%AD%90%E8%AE%B2Web%E5%AE%89%E5%85%A8%E3%80%8B%EF%BC%89/13.2.png"></p><p>但输入“a”数量为16个时，就变成了65536条可能的路径；此后每增加一个“a”，路径的数量都会翻倍。</p><p>这极大地增加了正则引擎解析数据时的消耗。当用户恶意构造输入时，这些有缺陷的正则表达式就会消耗大量的系统资源（比如CPU和内存），从而导致整台服务器的性能下降，表现的结果是系统速度很慢，有的进程或服务失去响应，与拒绝服务的后果是一样的。</p><hr><h2 id="第十四章-PHP安全"><a href="#第十四章-PHP安全" class="headerlink" title="第十四章 PHP安全"></a>第十四章 PHP安全</h2><h4 id="1、文件包含漏洞"><a href="#1、文件包含漏洞" class="headerlink" title="1、文件包含漏洞"></a>1、文件包含漏洞</h4><p>严格来说，文件包含漏洞是“代码注入”的一种。其原理就是注入一段用户能控制的脚本或代码，并让服务器端执行。“代码注入”的典型代表就是文件包含（File Inclusion）。文件包含可能会出现在JSP、PHP、ASP等语言中。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">PHP：include(), include_once(), require(), require_once(), fopen(), readfile(), ...</span><br><span class="line"></span><br><span class="line">JSP/Servlet：ava.io.File(), java.io.FileReader(), ...</span><br><span class="line"></span><br><span class="line">ASP：include file, include virtual, ...</span><br></pre></td></tr></table></figure><p>要想成功利用文件包含漏洞，需要满足下面两个条件：</p><ul><li>include()等函数通过动态变量的方式引入需要包含的文件；</li><li>用户能够控制该动态变量。</li></ul><h6 id="（1）本地文件包含"><a href="#（1）本地文件包含" class="headerlink" title="（1）本地文件包含"></a>（1）本地文件包含</h6><p>能够<strong>打开并包含本地文件的漏洞</strong>，被称为本地文件包含漏洞（Local File Inclusion，简称LFI）。文件包含漏洞能够读取敏感文件或者服务器端脚本的源代码，从而为攻击者实施进一步攻击奠定基础。</p><h6 id="（2）远程文件包含"><a href="#（2）远程文件包含" class="headerlink" title="（2）远程文件包含"></a>（2）远程文件包含</h6><p>如果PHP的配置选项allow_url_include为ON的话，则include&#x2F;require函数是可以加载远程文件的，这种漏洞被称为远程文件包含漏洞（Re-mote File Inclusion，简称RFI）。</p><h4 id="2、变量覆盖漏洞"><a href="#2、变量覆盖漏洞" class="headerlink" title="2、变量覆盖漏洞"></a>2、变量覆盖漏洞</h4><h6 id="（1）全局变量覆盖"><a href="#（1）全局变量覆盖" class="headerlink" title="（1）全局变量覆盖"></a>（1）全局变量覆盖</h6><p>变量如果未被初始化，且能被用户所控制，那么很可能会导致安全问题。而在PHP中，这种情况在register_globals为ON时尤其严重。</p><h6 id="（2）extract-变量覆盖"><a href="#（2）extract-变量覆盖" class="headerlink" title="（2）extract()变量覆盖"></a>（2）extract()变量覆盖</h6><p>extract()函数能将变量从数组导入当前的符号表，其函数定义如下：</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> <span class="title function_ invoke__">extract</span> ( <span class="keyword">array</span> <span class="variable">$var_array</span> [, <span class="keyword">int</span> </span><br><span class="line"></span><br><span class="line"><span class="variable">$extract_type</span> [, <span class="keyword">string</span> <span class="variable">$prefix</span> ]] )</span><br></pre></td></tr></table></figure><p>第二个参数指定函数将变量导入符号表时的行为，最常见的两个值是“EXTR_OVER-WRITE”和“EXTR_SKIP”。</p><p>当值为“EXTR_OVERWRITE”时，在将变量导入符号表的过程中，如果变量名发生冲突，则覆盖已有变量；值为“EXTR_SKIP”则表示跳过不覆盖。若第二个参数未指定，则在默认情况下使用“EXTR_OVERWRITE”。</p><h6 id="（3）类似还有几个函数"><a href="#（3）类似还有几个函数" class="headerlink" title="（3）类似还有几个函数"></a>（3）类似还有几个函数</h6><ul><li>遍历初始化变量</li><li>impoet_request_variables变量覆盖</li><li>parse_str()变量覆盖</li></ul><h4 id="3、代码执行漏洞"><a href="#3、代码执行漏洞" class="headerlink" title="3、代码执行漏洞"></a>3、代码执行漏洞</h4><hr><h2 id="第十五章-Web-Server配置安全"><a href="#第十五章-Web-Server配置安全" class="headerlink" title="第十五章 Web Server配置安全"></a>第十五章 Web Server配置安全</h2><p>Web服务器是Web应用的载体，如果这个载体出现安全问题，那么运行在其中的Web应用程序的安全也无法得到保障。因此Web服务器的安全不容忽视。Web服务器安全，考虑的是应用布署时的运行环境安全。这个运行环境包括Web Server、脚本语言解释器、中间件等软件，这些软件所提供的一些配置参数，也可以起到安全保护的作用。</p><h4 id="1、Apache安全（Apache-Httpd）"><a href="#1、Apache安全（Apache-Httpd）" class="headerlink" title="1、Apache安全（Apache Httpd）"></a>1、Apache安全（Apache Httpd）</h4><p>Web Server的安全我们关注两点：一是WebServer本身是否安全；二是Web Server是否提供了可使用的安全功能。纵观Apache的漏洞史，它曾经出现过许多次高危漏洞。但这些高危漏洞，大部分是由Apache的Module造成的，Apache核心的高危漏洞几乎没有。Apache有很多官方与非官方的Module，默认启动的Module出现过的高危漏洞非常少，大多数的高危漏洞集中在默认没有安装或enable的Module上。</p><p>检查Apache安全的第一件事情，就是检查Apache的Module安装情况，根据“最小权限原则”，应该尽可能地减少不必要的Module，对于要使用的Module，则检查其对应版本是否存在已知的安全漏洞。</p><p>定制好了Apache的安装包后，接下来需要做的，就是指定Apache进程以单独的用户身份运行，这通常需要为Apache单独建立一个user&#x2F;group。<strong>Apache以root身份或者admin身份运行是一个非常糟糕的决定。这里的admin身份是指服务器管理员在管理机器时使用的身份。这个身份的权限也是比较高的，因为管理员有操作管理脚本、访问配置文件、读&#x2F;写日志等需求。</strong>（在这里我们就能意识到，如果你看过一些配置虚拟机、使用Linux服务的教学视频，老师们都会告诉你配置一个个人用户【即使有时候root用户操作更方便】，但也有少数情况是root用户执行会导致程序的警告or报错，但其实根源大多是项目不建议你使用root就行管理【例如HDFS等节点的启动】）</p><p>使用高权限身份运行Apache的结果可能是灾难性的，它会带来两个可怕的后果：</p><ul><li>当黑客入侵Web成功时，将直接获得一个高权限（比如root或admin）的shell；</li><li>应用程序本身将具备较高权限，当出现bug时，可能会带来较高风险，比如删除本地重要文件、杀死进程等不可预知的结果。</li></ul><p>比较好的做法是使用专门的用户身份运行Apache，这个用户身份不应该具备shell，它唯一的作用就是用来运行Web应用。</p><h4 id="2、Nginx安全"><a href="#2、Nginx安全" class="headerlink" title="2、Nginx安全"></a>2、Nginx安全</h4><p>从安全的角度来看，Nginx近年来出现的影响默认安装版本的高危漏洞却比Apache要多。在Nginx的官方网站有这些安全问题的列表。</p><p>多多关注Nginx的漏洞信息，并及时将软件升级到安全的版本，是非常有必要的一件事情。从历史的经验来看，如果一个软件出现的漏洞较多，那么说明代码维护者的安全意识与安全经验有所欠缺，同时由于破窗效应，这个软件未来往往会出现更多的漏洞。</p><p>就软件安全本身来看，Nginx与Apache最大的区别在于，检查Apache安全时更多的要关注Module的安全，而Nginx则需要注意软件本身的安全，及时升级软件版本。</p><h4 id="3、jBoss远程命令执行"><a href="#3、jBoss远程命令执行" class="headerlink" title="3、jBoss远程命令执行"></a>3、jBoss远程命令执行</h4><p>jBoss是J2EE环境中一个流行的Web容器，但是jBoss在默认安装时提供的一些功能却不太安全，如果配置不得当，则可能直接造成远程命令执行。</p><p>由于jBoss在默认安装时会有一个管理后台，叫做JMX-Console，它提供给管理员一些强大的功能，其中包括配置MBeans，这同样也会为黑客们打开方便之门。通过8080端口（默认安装时会监听8080端口）访问&#x2F;jmx-console能够进入到这个管理界面。默认安装时访问JMX-Console是没有任何认证的。</p><h4 id="4、Tomacat远程命令执行"><a href="#4、Tomacat远程命令执行" class="headerlink" title="4、Tomacat远程命令执行"></a>4、Tomacat远程命令执行</h4><p>Apache Tomcat与jBoss一样，默认也会运行在8080端口。它提供的Tomcat Manager的作用与JMX-Console类似，管理员也可以在Tomcat Manager中部署war包。</p><p>虽然Tomcat后台有密码认证，但强烈建议删除这一后台，因为攻击者可以通过暴力破解等方式获取后台的访问权限，从安全的角度看，这增加了系统的攻击面，得不偿失。</p><h4 id="5、HTTP-Parameter-Pollution"><a href="#5、HTTP-Parameter-Pollution" class="headerlink" title="5、HTTP Parameter Pollution"></a>5、HTTP Parameter Pollution</h4><p>通过GET或POST向服务器发起请求时，提交两个相同的参数，那么服务器会如何选择呢？</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/?a=test&amp;a=test1</span><br></pre></td></tr></table></figure><p>在某些服务端环境中，会只取第一个参数；而在另外一些环境中，比如.net环境中，则会变成</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a=test,test1</span><br></pre></td></tr></table></figure><p>这种特性在绕过一些服务器端的逻辑判断时，会非常有用。HPP攻击，与Web服务器环境、服务器端使用的脚本语言有关。HPP本身可以看做服务器端软件的一种功能，参数选择的顺序是由服务器端软件所决定的。但是正如我们在本书中所举的很多例子一样，当程序员不熟悉软件的这种功能时，就有可能造成误用，或者程序逻辑涵盖范围不够全面，从而形成漏洞。</p><hr><h2 id="第十六章-互联网业务安全"><a href="#第十六章-互联网业务安全" class="headerlink" title="第十六章 互联网业务安全"></a>第十六章 互联网业务安全</h2><h4 id="产品安全"><a href="#产品安全" class="headerlink" title="产品安全"></a>产品安全</h4><p>一个完整的产品有许多特性，互联网产品亦如此。互联网产品其实是网站提供的在线服务，产品特性包括性能、美观、方便性等方面，同时也包括安全。一般来说，<strong>安全是产品的一个特性</strong>。</p><p>安全本身可视作产品的一个组成部分。一个好的产品，在设计之初，就应该考虑是否会存在安全隐患，从而提前准备好对策。<strong>将安全视为产品特性，往往也就解决了业务与安全之间的矛盾</strong>。其实业务与安全之间本来是没有冲突的，出现冲突往往是因为安全方案设计得不够完美。比如安全方案的实现成本相对较高，从而不得不牺牲一些产品功能上的需求，有时候牺牲的可能还有性能。</p><h6 id="（1）互联网产品对安全的需求"><a href="#（1）互联网产品对安全的需求" class="headerlink" title="（1）互联网产品对安全的需求"></a>（1）互联网产品对安全的需求</h6><p><strong>当一个产品功能有缺陷、用户体验极差，甚至是整天宕机的时候，是谈不上安全性的，因为产品本身可能都已经无法存在下去了。但是当一个产品其他方面都做得很好的时候，安全有可能会成为产品的一种核心竞争力，成为拉开产品与竞争对手之间差距的秘密武器。只有安全也做得好的产品，才能成为真正的好产品。</strong></p><p>安全是产品特性的一个组成部分，具备了安全性，产品才是完整的；安全做好了，产品最终才能真正成熟。</p><h6 id="（2）好的产品方案"><a href="#（2）好的产品方案" class="headerlink" title="（2）好的产品方案"></a>（2）好的产品方案</h6><p>一个优秀的安全方案，除了可以有效地解决问题以外，至少还必须具备两个条件：</p><ul><li>良好的用户体验</li><li>优秀的性能</li></ul><h4 id="关于本章"><a href="#关于本章" class="headerlink" title="关于本章"></a>关于本章</h4><p>本章的其他部分，强烈建议各位去看一下书，并不是因为不会摘取&#x2F;没什么重点。相反，涉及思想的东西每个人看了会有每个人的感悟，开发流程往往会根据实际情况来变。之前的内容中也少有例子解析，但是经验之谈需要看大量的例子才能摸索到别人的一丝经验。希望大家看完之后也能在issue上留下点自己的感悟。</p><hr><h2 id="第十七章-安全开发流程（SDL）"><a href="#第十七章-安全开发流程（SDL）" class="headerlink" title="第十七章 安全开发流程（SDL）"></a>第十七章 安全开发流程（SDL）</h2><p>安全开发流程，能够帮助企业以最小的成本提高产品的安全性。它符合“Secure at theSource”的战略思想。实施好安全开发流程，对企业安全的发展来说，可以起到事半功倍的效果。</p><h4 id="1、简介-1"><a href="#1、简介-1" class="headerlink" title="1、简介"></a>1、简介</h4><p>SDL的全称是 Security Development Lifecy-cle，即：安全开发生命周期。它是由微软最早提出的，在软件工程中实施，是帮助解决软件安全问题的办法。SDL是一个安全保证的过程，其重点是软件开发，它在开发的所有阶段都引入了安全和隐私的原则。自2004年起，SDL一直都是微软在全公司实施的强制性策略。SDL的大致步骤如下：</p><p><img src="/2023/01/06/%E6%88%91%E7%9A%84%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E5%85%A5%E9%97%A8%EF%BC%88%E3%80%8A%E7%99%BD%E5%B8%BD%E5%AD%90%E8%AE%B2Web%E5%AE%89%E5%85%A8%E3%80%8B%EF%BC%89/17.1.png"></p><p>SDL中的方法，试图从安全漏洞产生的根源上解决问题。通过对软件工程的控制，保证产品的安全性。<strong>（详细每个阶段的过程可以参考书本）</strong></p><h4 id="2、敏捷SDL"><a href="#2、敏捷SDL" class="headerlink" title="2、敏捷SDL"></a>2、敏捷SDL</h4><p>敏捷开发往往是采用“小步快跑”的方式，不断地完善产品，并没有非常规范的流程，文档也尽可能简单。这样做有利于产品的快速发布，但是对于安全来说，往往是一场灾难。需求无法在一开始非常明确，一些安全设计可能也会随之变化。微软为敏捷开发专门设计了敏捷SDL。</p><p>敏捷SDL的思想其实就是<strong>以变化的观点实施安全的工作</strong>。需求和功能可能一直在变化，代码可能也在发生变化，这要求在实施SDL时需要在<strong>每个阶段更新威胁模型和隐私策略，在必要的环节迭代模糊测试、代码安全分析</strong>等工作。</p><h4 id="3、实战校验"><a href="#3、实战校验" class="headerlink" title="3、实战校验"></a>3、实战校验</h4><p>对于互联网公司来说，更倾向于使用敏捷开发，快速迭代开发出产品。因此微软的SDL从各方面来看，都显得较为厚重，需要经过一些定制和裁剪才能适用于各种不同的环境。大体遵守以下准则：</p><ul><li>准则一：与项目经理进行充分沟通，排出足够的时间。</li><li>准则二：规范公司的立项流程，确保所有项目都能通知到安全团队，避免遗漏。</li><li>准则三：树立安全部门的权威，项目必须由安全部门审核完成后才能发布。</li><li>准则四：将技术方案写入开发、测试的工作手册中。</li><li>准则五：给工程师培训安全方案。</li><li>准则六：记录所有的安全bug，激励程序员编写安全的代码。</li></ul><p>互联网公司对产品、用户体验的重视程度非常高，大多数的产品都要求在短时间内发布，因此在SDL的实施上有着自己的特色。</p><h4 id="4、需求分析与设计阶段"><a href="#4、需求分析与设计阶段" class="headerlink" title="4、需求分析与设计阶段"></a>4、需求分析与设计阶段</h4><p>需求分析阶段与设计阶段是项目的初始阶段。需求分析阶段将论证项目的目标、可行性、实现方向等问题。在需求阶段，安全工程师需要关心产品主要功能上的安全强度和安全体验是否足够，主要需要思考安全功能。</p><p>需要注意的是，在安全领域中，“安全功能”与“安全的功能”是两个不同的概念。<strong>“安全功能”是指产品本身提供给用户的安全功能，比如数字证书、密码取回问题等功能。而“安全的功能”，则指在产品具体功能的实现上要做到安全，不要出现漏洞而被黑客利用。</strong>在需求分析阶段，可以对项目经理、产品经理或架构师进行访谈，以了解产品背景和技术架构，并给出相应的建议。在实际使用时，更多的要依靠安全工程师的经验做出判断。</p><h4 id="5、开发阶段"><a href="#5、开发阶段" class="headerlink" title="5、开发阶段"></a>5、开发阶段</h4><p>开发阶段是安全工作的一个重点。依据“安全是为业务服务”这一指导思想，在需求层面，安全改变业务的地方较少，因此应当力求代码实现上的安全，也就是做到“安全的功能”。要达到这个目标，首先要分析可能出现的漏洞，并从代码上提供可行的解决方案。</p><ul><li>使用提供安全的函数</li><li>使用代码安全审计工具</li></ul><h4 id="6、测试阶段"><a href="#6、测试阶段" class="headerlink" title="6、测试阶段"></a>6、测试阶段</h4><p>测试阶段是产品发布前的最后一个阶段，在此阶段需要对产品进行充分的安全测试，验证需求分析、设计阶段的安全功能是否符合预期目标，并验证在开发阶段发现的所有安全问题是否得到解决。<strong>安全测试应该独立于代码审计而存在</strong>。“安全测试”相对于“代码审计”而言，至少有两个好处：</p><ul><li>有一些代码逻辑较为复杂，通过代码审计难以发现所有问题，而通过安全测试可以将问题看得更清楚；</li><li>有一些逻辑漏洞通过安全测试，可以更快地得到结果。</li></ul><p>安全测试，一般分为自动化测试和手动测试两种方式：</p><ul><li>自动化测试以覆盖性的测试为目的，可以通过“Web安全扫描器”对项目或产品进行漏洞扫描。</li><li>Web安全扫描器针对“XSS”、“SQL Injection”、“Open Redirect”、“PHP File Include”等漏洞的检测技术已经比较成熟。这是因为这些漏洞的检测方法主要是检测返回结果的字符串特征。</li><li>对于“CSRF”、“越权访问”、“文件上传”等漏洞，却难以达到自动化检测的效果。这是因为这些漏洞涉及系统逻辑或业务逻辑，有时候还需要人机交互参与页面流程。因此这类漏洞的检测更多的需要依靠手动测试完成。</li></ul><hr><h2 id="第十八章-安全运营"><a href="#第十八章-安全运营" class="headerlink" title="第十八章 安全运营"></a>第十八章 安全运营</h2><p>俗话说，<strong>安全是“三分技术，七分管理”</strong>。安全对于企业来说，结果才是最重要的。安全方案设计完成后，即使看起来再美好，也需要经受实践的检验。</p><p><strong>（这里和第十六章一样，同样是以理论为主，感兴趣的小伙伴自行看书吧，运营这个我应该会单开一个栏目来说【毕竟我现在的身份是工作室运营！！区别于运维哦！！】书已经借好了，大概是张亮写的《从零开始做运营》……跑远了哈）</strong></p><hr><h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>这里并不是本书的结语，而是我个人的一些反思&#x2F;感想。首先非常感谢吴翰清老师的这本书，带我成功走进了网络安全的世界（因为太好看了，让我产生了对网络安全的浓厚兴趣，因此又借了些其他关于网络安全的书，之后应该也会看到我看其他网安的书的笔记）。虽然这本书出版的时间比较早（12年），计算机行业的技术发展是非常快的，但是放到现在来看很多观点仍然具有非常高的参考价值。即使PHP等已经逐渐退出了当前的环境（PHP天下第一，PHP爱好者别打我！），但是其中的应用&#x2F;反思乃至设计放到任何一个语言来说都是适用的。旧的语言不会一直热门，因为新的业务会让带来新的挑战；新的语言也不一定辉煌，因为即便是迭代也有其基石。</p><p>网络安全是一块大蛋糕，并且是一块随时代发展越来越大的蛋糕。简单的映射到专业来说，计科是基石，软件是生产，物联是虚实结合，大数据是新兴热门，那么网安就是互联网的守门人。我是在读完一遍纸质书后才进行的这一边笔记整理，基本约等于读了一遍半吧。作为入门，它显得有点过于深奥了，但是却在其中让我反思到了不少生产的道理：</p><p>我在假期给别人写过个小系统，用的是Spring Security和jwt，但是并不算理解整个体系架构和组成部分，有些依赖都是一知半解（虽然现在也是）。但是读完这本书后也真切地理解了配置在property中的一些jwt字段是啥（其实就是加密中提到的salt），同时也理解了鉴权Authorization、Token之类的真实含义与作用。即使他让我掌握的只有一点，我也觉得万分超值（或许我的潜意识学会了也说不定）。</p><p>最后对于本书最后的”（附）谈谈互联网企业安全的发展方向“这篇文章进行强烈推荐，感受一个人的NB不应该只源自于他对知识的理解，我认为还有他能对所处的事业的侃侃而谈。我深知现如今我的状态是啥都感兴趣学一点，但是大多都不是很精通，但是多听多看多学总是好的，不希冀于成长到和他一般对行业具有前瞻，但是确切的在学习中得到满足。这就是我读这本书的意义。</p><p>这句话同样送给在看的你。——Alexie-Z-Yevich 2023.1.6</p>]]></content>
      
      
      <categories>
          
          <category> TalkingAbout </category>
          
          <category> 网络安全 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 网络安全 </tag>
            
            <tag> 前后端 </tag>
            
            <tag> DDOS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大数据存储技术（《深入分布式缓存：从原理到实践》）</title>
      <link href="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/"/>
      <url>/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>前言：</strong></p><p>这份文档不仅来自个人根据老师给的提纲参考书籍手敲完成，还参考了上届学姐的复习资料，同时融合了老师的PPT和网络上一些我认为比较好的博客。如果在大题后面打了【*】，就说明这是上届学长学姐没有考过的习题，老师不会平白无故往里面加重点吧。。。所以个人认为考到的概率较大。</p><p>并且，这份文档的内容会超出复习范围不少，因为是一边学一边写的，所以把我认为有助于大家理解的部分都敲进去了，如果只是为了背书的话，那大概率看每个题目下的最后一个小问差不多了，前面的大部分都是为了进行铺垫。</p><p>同样的，如果以后的学弟学妹画完重点后发现又多了许多新玩意，欢迎大家在Issues上Q我，最好是直接push进来，让文档成为一个可升级迭代的Project。</p></blockquote><h2 id="一、CAP理论"><a href="#一、CAP理论" class="headerlink" title="一、CAP理论"></a>一、CAP理论</h2><h4 id="分布式系统的三个特性"><a href="#分布式系统的三个特性" class="headerlink" title="分布式系统的三个特性"></a>分布式系统的三个特性</h4><ul><li>一致性【Consistency】：在分布式系统中的所有数据备份，在<strong>同一时刻</strong>是否有同样的值。（等同于所有节点访问同一份最新的数据副本）</li><li>可用性【Availability】：在集群中一部分<strong>节点故障</strong>后，集群整体是否还能响应客户端的读写请求。（对数据更新具备高可用性）</li><li>分区容忍性【Partition tolerance】：以实际效果而言，分区相当于对通信的<strong>时限要求</strong>。系统如果不能在一定时间内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择。</li></ul><p>高可用、数据一致是很多系统设计的目标，但是分区又是不可避免地事情，由此引出了以下几种选择：</p><h4 id="（1）CA-without-P"><a href="#（1）CA-without-P" class="headerlink" title="（1）CA without P"></a>（1）CA without P</h4><p>如果不要求P（不允许分区），则C（强一致性）和A（可用性）是可以保证的。但其实分区不是你想不想的问题，而是始终会存在，因此<strong>CA的系统更多的是允许分区后各子系统依然保持CA</strong>。</p><p>典型放弃分区容忍性的例子有<strong>关系型数据库、LDAP</strong>等。</p><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/1.1%E6%94%BE%E5%BC%83%E5%88%86%E5%8C%BA%E5%AE%B9%E5%BF%8D%E6%80%A7.png" alt="放弃分区容忍性"></p><h4 id="（2）CP-without-A"><a href="#（2）CP-without-A" class="headerlink" title="（2）CP without A"></a>（2）CP without A</h4><p>如果不要求A（可用性），相当于<strong>每个请求都需要在Server 之间强一致，而P（分区）会导致同步时间无限延长</strong>，如此CP也是可以保证的。很多<strong>传统的数据库</strong>分布式事务都属于这种模式，分布式锁也属于此种情况。</p><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/1.2%E6%94%BE%E5%BC%83%E5%8F%AF%E7%94%A8%E6%80%A7.png" alt="放弃可用性"></p><h4 id="（3）AP-without-C"><a href="#（3）AP-without-C" class="headerlink" title="（3）AP without C"></a>（3）AP without C</h4><p>要高可用并允许分区，则需放弃一致性。一旦分区发生，节点之间可能会失去联系，为了高可用，每个节点只能用本地数据提供服务，而这样会导致全局数据的不一致性。现在众多的NoSQL都属于此类。</p><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/1.3%E6%94%BE%E5%BC%83%E4%B8%80%E8%87%B4%E6%80%A7.png" alt="放弃一致性"></p><p>该理论由brewer提出，2002年Lynch与其他人证明了Brewer猜想，从而把CAP上升为一个Lynch定理。</p><p>Lynch的证明采用<strong>反证法</strong>，如果三者可同时满足，则因为允许P的存在，一定存在Server之间的丢包，如此则不能保证C。在该证明中，Lynch对CAP定义进行了更加明确的声明。</p><h4 id="更加明确的CAP声明（圣经）"><a href="#更加明确的CAP声明（圣经）" class="headerlink" title="更加明确的CAP声明（圣经）"></a>更加明确的CAP声明（圣经）</h4><ul><li>C：一致性被称为<strong>原子对象</strong>，任何的读写都应该看起来是“原子”的，或串行的。</li><li>A：对任何非失败节点都应该在有限的时间内给出请求的回应。（请求的可终止性）</li><li>P：允许节点之间丢失任意多的消息，当网络分区发生时，节点之间的消息可能会完全丢失。</li></ul><p><strong>（没有一个软件系统同时满足CAP。这里的C指的是强一致性。针对分布式系统而言，一定满足P，即存在网络分区【网络延时】）</strong></p><hr><h2 id="二、Raft算法"><a href="#二、Raft算法" class="headerlink" title="二、Raft算法"></a>二、Raft算法</h2><p>Raft提供了和Paxos算法相同的功能和性能，但是它的算法结构和Paxos不同。Raft算法更加容易理解并且更容易构建实际的系统。为了提升可理解性，Raft将一致性算法分解成了几个关键模块，例如<strong>领导人选举</strong>【Leader Election】、<strong>日志复制</strong>【Log Replication】和<strong>安全性</strong>【Safety】<strong>（三个子问题）</strong>。同时它通过实施一个更强的一致性来减少需要考虑的状态的数量。Raft算法还包括一个新的机制来允许集群成员的动态改变，它利用重叠的大多数来保证安全性。</p><p>Paxos和Raft都是为了实现<strong>一致性</strong>目标，两者的区别在于<strong>选举的具体过程不同</strong>。</p><h4 id="Raft选举过程"><a href="#Raft选举过程" class="headerlink" title="Raft选举过程"></a>Raft选举过程</h4><p>在Raft中，任何一个服务器可以扮演下面角色之一：</p><ul><li>领导者【Leader】：处理所有客户端交互、日志复制等动作，一般一次只有一个领导者。</li><li>选民【Follower】：类似选民，完全被动的角色，这样的服务器等待被通知投票。</li><li>候选人【Candidate】：候选人就是在选举过程中提名自己的实体，一旦选举成功，则成为领导者。</li></ul><p>Raft算法分为两个阶段，首先是选举过程，然后在选举出来的领导人带领进行正常操作，比如日志复制等。</p><p>（1）任何一个服务器都可以成为一个候选者，它向其他服务器（选民）发出要求选举自己的请求。</p><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/2.1candidate%E5%8F%91%E5%87%BA%E8%AF%B7%E6%B1%82.png" alt="candidate发出请求"></p><p>（2）其他服务器同意了，回复OK（同意）指令。</p><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/2.2follower%E8%BF%94%E5%9B%9E%E8%AF%B7%E6%B1%82.png" alt="follower返回请求"></p><p>（3）这样，这个候选者就成为领导者，它可以向选民们发出要执行具体操作动作的指令，比如日志复制。</p><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/2.3candidate%E5%8F%91%E5%87%BA%E6%93%8D%E4%BD%9C%E6%8C%87%E7%A4%BA.png" alt="candidate发出操作指示"></p><p>（4）如果一旦这个Leader宕机崩溃了，那么Follower中会有一个成为候选者，发出邀票选举，相当于再次执行（1）~（2）的步骤。</p><p><strong>总结：（1）~（2）是选举过程，（3）是具体协同执行操作的过程。</strong></p><hr><h2 id="三、Nginx负载均衡策略"><a href="#三、Nginx负载均衡策略" class="headerlink" title="三、Nginx负载均衡策略"></a>三、Nginx负载均衡策略</h2><h4 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h4><p>负载均衡集群：其关键在于使用堕胎集群服务器共同分担计算任务，把网络请求及计算分配到集群可用服务器上去，从而达到可用性及较好的用户操作体验。</p><p>不同用户访问应用，通过负载均衡器分配到不同的节点。</p><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/3.1%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt="负载均衡示意图"></p><p>负载均衡器有硬件解决方案和软件解决方案。硬件解决方案：F5；软件解决方案：LVS、HAProxy、Nginx等。</p><h4 id="Nginx下的负载均衡策略"><a href="#Nginx下的负载均衡策略" class="headerlink" title="Nginx下的负载均衡策略"></a>Nginx下的负载均衡策略</h4><ul><li><strong>轮询</strong>：即Round Robin，根据Nginx配置文件中的顺序，一次把客户端的Web请求分发到不同的后端服务器。（<strong>每个请求</strong>会按<strong>时间</strong>顺序<strong>逐一</strong>分配到<strong>不同</strong>的后台服务器上。轮询策略适合服务器配置相当，无状态且短平快的服务使用<strong>【依序逐一分发】</strong>）</li><li><strong>最少连接</strong>：当前谁连接最少，分发给谁。（请求转发给<strong>连接数最少</strong>的后端服务器。前面的轮询策略是把请求<strong>平均</strong>地转发给集群中的每个后台服务器，使得它们的负载大致相同，但是有些请求可能占用的时间会很长，可能导致所在的后端负载过高。这种情况下<strong>选用least conn策略就能达到更好的负载均衡效果。适合在请求处理时间长短不一造成服务器过载的场景。【谁少分给谁】</strong>）</li><li><strong>IP地址哈希</strong>：确定<strong>相同IP请求</strong>可以转发给<strong>同一个后端节点</strong>处理，以方便session保持。（按照客户端的IP去分配服务器，使同一个客户端的请求都转发到同一个后台服务器，保证了Session的统一性，<strong>可以用来解决Session的跨域问题。【相同IP可转发】</strong>）</li><li><strong>基于权重的负载均衡</strong>：配置Nginx把请求更多地分发到高配置的后端服务器上，把相对较少的请求分发到低配服务器。（在轮询策略的基础上，另外<strong>指定</strong>了<strong>轮询的几率</strong>。权重策略可以与least conn和ip hash结合使用。权重策略比较<strong>适合服务器的硬件配置差别较大的情况【多请求高配置】</strong>）</li></ul><hr><h2 id="四、一致性Hash算法"><a href="#四、一致性Hash算法" class="headerlink" title="四、一致性Hash算法"></a>四、一致性Hash算法</h2><p>一致性哈希算法是在1997年由麻省理工学院提出的一种<strong>分布式哈希(DHT)实现算法</strong>。主要解决<strong>单调性( Monotonicity)和分散性（Spread）</strong>的问题。单调性简单描述是哈希的结果应能够保证原有已分配的内容可以被映射到原有缓冲中去，避免在节点增减过程中导致不能命中。</p><p>按照常用的hash算法来将对应的key哈希到一个具有2^32 次方个桶的空间中，即0~( 2^32) -1的数字空间中。现在我们可以将这些数字头尾相连，想象成一个闭合的环形。</p><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/4.1%E5%9C%86%E5%BD%A2%E7%A9%BA%E9%97%B4%E5%AF%B9%E5%BA%94%E5%93%88%E5%B8%8C.png" alt="圆形空间对应哈希"></p><p>在一致性哈希算法中，如果一台服务器不可用，则受影响的数据仅仅是此服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其他不会受到影响。</p><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/4.2%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%A4%BA%E6%84%8F.png" alt="一致性哈希示意"></p><p>一致性哈希的<strong>优点</strong>在于<u>可以任意动态添加、删除节点，每次添加、删除一个节点仅影响一致性哈希环上相邻的节点</u>。为了尽可能均匀地分布节点和数据，一种常见的改进算法是引入虚节点的概念，系统会创建许多<strong>虚拟节点</strong>，个数远大于当前节点的个数，均匀分布到一致性哈希值域环上。这种增强型方案主要解决平衡性问题，所谓平衡性（Balance）是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。</p><h4 id="具体实现流程"><a href="#具体实现流程" class="headerlink" title="具体实现流程"></a>具体实现流程</h4><p>一致性Hash算法将整个哈希值空间组织成一个虚拟的圆环。如假设某哈希函数H的值空间为0-2^32-1（即哈希值是一个32位无符号整型），整个哈希环如下图。（整个空间按顺时针方向组织，圆环的正上方的点代表0，0点右侧的第一个点代表1，以此类推，2、3、4、5、6……直到2^32-1。也就是说0点左侧的第一个点代表2^32-1，0和2^32-1在零点中方向重合，我们把这个由2^32-1个点组成的圆环成为Hash环）</p><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/4.3%E5%93%88%E5%B8%8C%E7%8E%AF.png" alt="哈希环"></p><ul><li>服务器Hash到Hash环</li></ul><p>Node A，B，C，D四台机器，利用其IP地址进行hash<strong>取模</strong>。</p><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/4.4%E5%93%88%E5%B8%8C%E5%8F%96%E6%A8%A1.png" alt="哈希取模"></p><ul><li>数据Key到Hash环</li></ul><p>将数据key使用相同的函数Hash计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针 “行走”，第⼀台遇到的服务器就是其应该定位到的服务器。</p><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/4.5%E5%93%88%E5%B8%8C%E8%AE%A1%E7%AE%97.png" alt="哈希计算"></p><h4 id="一致性Hash算法的容错性和可扩展性"><a href="#一致性Hash算法的容错性和可扩展性" class="headerlink" title="一致性Hash算法的容错性和可扩展性"></a>一致性Hash算法的容错性和可扩展性</h4><ul><li>Node C宕机</li></ul><p>![Node C宕机](大数据存储技术备考&#x2F;4.6Node C宕机.png)</p><ul><li>增加一台机器Node X</li></ul><p>![Node X](大数据存储技术备考&#x2F;4.7Node X.png)</p><p>因此，一致性Hash算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。</p><h4 id="Hash环的数据倾斜问题"><a href="#Hash环的数据倾斜问题" class="headerlink" title="Hash环的数据倾斜问题"></a>Hash环的数据倾斜问题</h4><p>一致性Hash算法在服务节点太少时，容易因为<strong>节点分布不均匀而造成数据倾斜</strong>（被缓存的对象大部分集中缓存在某一台服务器上）问题，例如系统中只有两台服务器。</p><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/4.8%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C.png" alt="数据倾斜"></p><p>具体做法可以在服务器IP或主机名的后面增加编号来实现。</p><p>为每台服务器计算三个<strong>虚拟节点</strong>，于是可以分别计算“Node A#1”、“Node A#2”、“Node A#3”、“Node B#1”、“Node B#2”、“Node B#3”的哈希值，于是形成六个虚拟节点。</p><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/4.9%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C2.png" alt="数据倾斜2"></p><p>这样就解决了服务节点少时数据倾斜的问题。在实际应用中，通常将虚拟节点的数设置为32甚至更大，因此即使很少的服务节点也能做到相对均匀的数据分布。</p><hr><h2 id="五、全局ID生成算法-【-】"><a href="#五、全局ID生成算法-【-】" class="headerlink" title="五、全局ID生成算法 【*】"></a>五、全局ID生成算法 【*】</h2><p>目前TDDL（Taobao Distribute Data Layer）提供的id生成主要还是<strong>依托数据库</strong>来进行的，Oracle可以直接使用sequence来完成id生成，MySQL则需要DBA建立一个表专门用于生成id。</p><p>在分布式环境下，数据库是可以拆分（sharding）的，一张表的自增机制（比如MySQL）只能保证该表唯一，在数据合并到历史库，迁移或者查询，如果<strong>出现id冲突无异于噩梦</strong>。</p><p>另外，由于数据库访问时高成本操作，也要避免每次INSERT都要到id生成器做DB层面的查询。</p><h4 id="1、UUID"><a href="#1、UUID" class="headerlink" title="1、UUID"></a>1、UUID</h4><p>UUID由一下几部分构成：</p><ul><li>当前日期和时间，UUID的第一个部分与时间有关，如果你在生成一个UUID之后，过几秒又生成一个UUID，则第一个部分不同，其余相同。</li><li>时钟序列。</li><li>全局唯一的IEEE机器识别码，如果有网卡，从网卡MAC地址获得，没有网卡以其他方式获得。</li></ul><p><strong>优点：</strong>API简单、易用</p><p><strong>缺点：</strong>占用空间大、字符串本身无法加工，可读性不强。</p><h4 id="2、ID生成表模式"><a href="#2、ID生成表模式" class="headerlink" title="2、ID生成表模式"></a>2、ID生成表模式</h4><p>使用id生成表，比较经典的是Flicker的案例，Flicker在解决全局ID生成方案里就采用了MySQL自增长ID的机制。先创建单独的数据库，然后创建一个表：</p><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/5.1%E5%88%9B%E5%BB%BA%E8%A1%A8.png" alt="创建表"></p><p>在我们的应用端需要做下面这两个操作，在一个事务会话里提交：</p><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/5.2%E6%8F%90%E4%BA%A4%E4%BA%8B%E5%8A%A1.png" alt="提交事务"></p><p>这样就能拿到不断增长且不重复的ID了。从高可用角度考虑，要解决单点故障问题，Flicker的方案是启用两台数据库服务器来生成ID，通过区分auto_increment的起始值和步长来生成奇偶数的ID。</p><p><strong>优点：</strong>简单易用，也有一定的高可用方案。</p><p><strong>缺点：</strong>使用了mysql数据库的独特语法REPLACE INTO。</p><h4 id="3、Snowflake"><a href="#3、Snowflake" class="headerlink" title="3、Snowflake"></a>3、Snowflake</h4><p>Twitter在把存储系统从MySQL迁移到Cassandra的过程中由于Cassandra没有顺序ID生成机制，于是自己开发了一套全局唯一ID生成服务：Snowflake。GitHub地址：https:!1github.com&#x2F;twitter&#x2F;snowflake。根据twitter的业务需求，snowflake系统生成64位的ID。由3部分组成:</p><ul><li><p>41位的时间序列（精确到毫秒，41位的长度可以使用69年）；</p></li><li><p>10位的机器标识（10位的长度最多支持部署1024个节点）；</p></li><li><p>12位的计数顺序号(12位的计数顺序号支持每个节点每毫秒产生4096个ID序号)。</p></li></ul><p><strong>优点：</strong>高性能，低延迟;独立的应用；按时间有序。</p><p><strong>缺点：</strong>需要独立的开发和部署。</p><h4 id="4、结合缓存方案"><a href="#4、结合缓存方案" class="headerlink" title="4、结合缓存方案"></a>4、结合缓存方案</h4><p>可以采取ID生成表模式成批获取id比如1000放到本地缓存（Local cache），这样在client使用的时候可进一步提升性能。</p><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/5.3%E6%89%B9%E9%87%8F%E8%8E%B7%E5%8F%96ID%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt="批量获取ID示意图"></p><p><strong>优点：</strong>高性能，低延迟。</p><p><strong>缺点：</strong>ID不连贯。</p><hr><h2 id="六、设计一个缓存框架（参考课本或者课件都可以）"><a href="#六、设计一个缓存框架（参考课本或者课件都可以）" class="headerlink" title="六、设计一个缓存框架（参考课本或者课件都可以）"></a>六、设计一个缓存框架（参考课本或者课件都可以）</h2><p>参考开源缓存组件EhCache和Guava，提取它们的公共方法，可以得到最核心的，也是我们最关心的一些方法：</p><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/6.1%E7%AE%80%E5%8D%95%E7%BC%93%E5%AD%98%E7%9A%84%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95.png" alt="简单缓存的常用方法"></p><p>可以知道缓存框架需要基本的get（获取缓存）、put（放入缓存）、remove（根据key值删除缓存）、clear（清空缓存）方法。</p><h4 id="1、缓存架构介绍"><a href="#1、缓存架构介绍" class="headerlink" title="1、缓存架构介绍"></a>1、缓存架构介绍</h4><p>通过JSR107规范，我们将框架定义为客户端层、缓存提供层、缓存管理层、缓存存储层。其中缓存存储层又分为基本存储层、LRU存储层和Weak存储层。</p><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/6.2%E7%BC%93%E5%AD%98%E5%88%86%E5%B1%82%E5%9B%BE.png" alt="缓存分层图"></p><ul><li><strong>客户端层</strong>：使用者直接通过该层与数据进行交互。</li><li><strong>缓存提供层</strong>：主要对缓存管理层的生命周期进行维护，负责缓存管理层的创建、保存、获取以及销毁。</li><li><strong>缓存管理层</strong>：主要对缓存客户端的生命周期进行维护，负责缓存客户端的创建、保存、获取以及销毁。</li><li><strong>缓存存储层</strong>：负责数据以什么样的形式进行存储。</li><li><strong>基本存储层</strong>：是以普通的ConcurrentHashMap为存储核心，数据不淘汰。</li><li><strong>LRU存储层</strong>：是以最近最少用为原则进行的数据存储和缓存淘汰机制。</li><li><strong>Weak存储层</strong>：是以弱引用原则的数据存储和缓存淘汰机制。</li></ul><h4 id="2、设计思路及知识点详解"><a href="#2、设计思路及知识点详解" class="headerlink" title="2、设计思路及知识点详解"></a>2、设计思路及知识点详解</h4><ul><li><strong>设计类图</strong></li></ul><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/6.3%E7%B1%BB%E5%9B%BE.png" alt="类图"></p><p>根据规范，CacheProvider、CacheManager、Cache是抽象出来的最基础的缓存接口。其中 Cache是提供最终缓存实现的基础接口，其实现类是CsCache107，初始化时即持有一个BasicDataStore对象。</p><ul><li><strong>缓存框架的SPI机制</strong></li></ul><p>在工程结构中的META-INF&#x2F;services&#x2F;下面有一个javax.cache.spi.CachingProvider配置文件，里面有一个org.cachestudy.writeitbyself.jsr107.CsCaching107Provider实现类，这个配置文件实际上是利用的Java SPI机制进行组件的发现与加载。</p><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/6.4SPI%E7%BA%A6%E5%AE%9A%E7%BB%93%E6%9E%84%E5%9B%BE.png" alt="SPI约定结构图"></p><p>SPI的全名为<strong>Service Provider Interface</strong>，是JDK内置的一种<strong>服务提供发现机制</strong>，在Java.util.ServiceLoader的文档里有比较详细的介绍。</p><p>Java SPI机制的思想简单来说是:在面向的对象的设计里，我们一般推荐模块之间基于接口编程，模块之间不对实现类进行硬编码。一旦代码里涉及具体的实现类，就违反了可拔插的原则，如果需要替换一种实现，就需要修改代码。为了实现在模块装配的时候能不在程序里动态指明，这就需要一种服务发现机制。Java SPI就是提供了这样的一个机制，为某个接口寻找服务实现的机制。有点类似IoC的思想，就是<strong>将装配的控制权移到程序之外</strong>，在模块化设计中这个机制尤其重要。</p><ul><li><strong>解读缓存数据层（淘汰算法）</strong></li></ul><p>缓存数据层实际承担的责任主要是缓存数据的存储和缓存的淘汰机制，数据的存储和淘汰是基于DataStore这个接口来实现的，而这一实现则是数据存储层。目前框架一共实现了三个实现类分别是:LRUDataStore、WeakDataStore和 BaseDataStore。</p><p><strong>（1）基于引用的淘汰算法</strong></p><p>基于引用的淘汰算法，是一种简单有效的算法，由JVM的GC进行回收。Java的引用主要分为强引用、软引用、弱引用、虚引用。</p><p><strong>强引用（StrongReference）：强引用是使用最普遍的引用。</strong>如果一个对象具有强引用，那垃圾回收器绝不会回收它。当内存空间不足，Java 虚拟机宁愿抛出OutOfMemoryError错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足的问题。</p><p><strong>软引用（SoftReference）：如果一个对象只具有软引用，则内存空间足够，垃圾回收器就不会回收它；如果内存空间不足了，就会回收这些对象的内存。</strong>只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存。软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收器回收，Java 虚拟机就会把这个软引用加入到与之关联的引用队列中。</p><p><strong>弱引用（WeakReference）：弱引用与软引用的区别在于:只具有弱引用的对象拥有更短暂的生命周期。</strong>在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程，因此不一定会很快发现那些只具有弱引用的对象。弱引用可以和一个引用队列(ReferenceQueue)联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加人到与之关联的引用队列中。</p><p><strong>虚引用（PhantomReference）：“虚引用”顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。</strong>如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。</p><p><strong>（2）基于LRU的淘汰算法</strong></p><p><strong>LRU （Least recently used，最近最少使用）算法根据数据的历史访问记录来进行淘汰数据</strong>，其核心思想是“如果数据最近被访问过，那么将来被访问的概率也更高”。</p><p>缓存框架的LRU简单实现逻辑如下：我们通过维护entry的列表，在get、put时维护entry列表实现，使最少访问的键值对维持在entry列表的最尾部。在数据量超过缓存容量需要做LRU淘汰时，我们通过删除链表尾部的数据，来实现简单的LRU数据淘汰机制。</p><ul><li><strong>解读缓存管理层（CacheManager）</strong></li></ul><p>接口类CacheManager所对应的正式缓存管理层，在缓存框架中CacheManager的实现类，主要负责<strong>管理多个Cache客户端实例，以及负责缓存客户端实例的创建、销毁、获取等</strong>。</p><p>缓存实例的创建和获取实际上主要是基于一个缓存池来实现的，在代码中使用的是一个ConcurrentHashMap类，可以根据多个不同的缓存名称创建多个缓存实例，从而可以并发的读取。</p><ul><li><strong>解读数据客户端层</strong></li></ul><p>缓存客户端层主要是针对实际使用者的，在工程结构中主要涉及两个类，其中一个使<strong>用代理模式对缓存框架进行的包装</strong>。用户在使用的时候，通过缓存管理层的CacheManager对象就可以获得其客户端对象，从而可以实现对缓存的直接操作。</p><p>整个过程其实较为简单，对象的构造方法中有一个DataStore对象，这个对象正是缓数据存储与淘汰策略对象，这个机制已经在解读缓存数据层小节中进行了详解，get方法则是从 DataStore中获取缓存数据，put方法则是往DataStore对象中存入数据。</p><h4 id="简述"><a href="#简述" class="headerlink" title="简述"></a>简述</h4><p>一定一定要去看书本<strong>P62-P75</strong>的缓存框架的实现，虽然上述的内容都是截取自书本内容，但是省略掉了很多容易导致阅读障碍。看书上的实例能让你对整个流程有一个大概的认知，在看上面的就是节选出来的重点了。</p><p>也可以直接看《<a href="https://blog.51cto.com/u_15057858/2691862">手把手教你从0到1写一个简单的缓存框架</a>》，这个和书本上是一样的。</p><hr><h2 id="七、缓存击穿、穿透、雪崩现象及解决办法"><a href="#七、缓存击穿、穿透、雪崩现象及解决办法" class="headerlink" title="七、缓存击穿、穿透、雪崩现象及解决办法"></a>七、缓存击穿、穿透、雪崩现象及解决办法</h2><h4 id="1、缓存击穿"><a href="#1、缓存击穿" class="headerlink" title="1、缓存击穿"></a>1、缓存击穿</h4><ul><li>缓存里<strong>没有Key</strong>，<strong>数据库里有数据</strong>。</li><li>某一个Key失效，通常是热点数据，导致<strong>高并发</strong>情况下，请求直接打到DB上，DB直接崩掉。</li></ul><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/7.1%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF.png" alt="缓存击穿"></p><p><strong>（大量的Key同时失效就会导致缓存雪崩）</strong></p><h4 id="2、缓存击穿的解决办法"><a href="#2、缓存击穿的解决办法" class="headerlink" title="2、缓存击穿的解决办法"></a>2、缓存击穿的解决办法</h4><p>在<strong>第一个查询数据</strong>的请求上使用一个<strong>互斥锁</strong>来锁住它。其他的线程走到这一步拿不到锁就等着，等第一个线程查询到了数据，然后做缓存。后面的线程近来发现<strong>已经有缓存了，就直接走缓存</strong>。</p><ul><li>引申：Redis的分布式锁和redission框架。</li></ul><h4 id="3、缓存穿透"><a href="#3、缓存穿透" class="headerlink" title="3、缓存穿透"></a>3、缓存穿透</h4><ul><li>缓存里没有数据，数据库里面也没有数据。</li><li>大量不存在的id去查询数据，会产生<strong>大量的请求</strong>到数据库去查询，可能会导致DB由于压力过大而宕机。</li></ul><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/7.2%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F.png" alt="缓存穿透"></p><h4 id="4、缓存穿透的解决办法"><a href="#4、缓存穿透的解决办法" class="headerlink" title="4、缓存穿透的解决办法"></a>4、缓存穿透的解决办法</h4><ul><li><strong>对空值缓存</strong>：如果一个查询返回的数据为空（不管数据是否存在），我们仍然把这个空结果（null）进行缓存，设置空结果的过期时间会很短，最长不超过五分钟。<strong>（保留但及时释放）</strong></li><li><strong>BloomFilter（布隆过滤器）</strong>：在缓存之前再加一层BloomFilter，在查询的时候先去BloomFilter去查询Key是否存在，如果不存在就直接返回，存在再走缓存去查DB。</li></ul><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/7.3%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95.png" alt="缓存穿透解决办法"></p><h4 id="5、缓存雪崩"><a href="#5、缓存雪崩" class="headerlink" title="5、缓存雪崩"></a>5、缓存雪崩</h4><ul><li><strong>Key对应的数据存在</strong>，但在redis中<strong>过期</strong>，此时若有<strong>大量并发请求</strong>过来，这些请求发现缓存过期一般都会从DB加载数据并回设到缓存，这个时候大并发的请求可能会<strong>瞬间把后端DB压垮</strong>。</li><li>缓存雪崩与缓存击穿的区别在于这里针对很多Key缓存，后者则是某一个Key。</li></ul><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/7.4%E6%AD%A3%E5%B8%B8%E8%AE%BF%E9%97%AE.png" alt="正常访问"></p><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/7.5%E7%BC%93%E5%AD%98%E5%A4%B1%E6%95%88%E7%9E%AC%E9%97%B4.png" alt="缓存失效瞬间"></p><h4 id="6、缓存雪崩的解决办法"><a href="#6、缓存雪崩的解决办法" class="headerlink" title="6、缓存雪崩的解决办法"></a>6、缓存雪崩的解决办法</h4><ul><li><strong>构建多级缓存架构</strong>：Nginx缓存 + Redis缓存 + 其他缓存（Encache等）</li><li><strong>将缓存失效时间分散开</strong>：比如我们可以在原有的失效时间基础上增加一个随机值，比如1~5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。</li><li><strong>互斥锁</strong>：<ul><li>在第一个请求去查询数据库的时候对它加一个互斥锁，其余的查询请求都会被阻塞住，直到锁被释放，从而保护数据库。</li><li><strong>降低吞吐量</strong>，应用时要慎重。</li></ul></li></ul><hr><h2 id="八、Ehcache的注解【-】"><a href="#八、Ehcache的注解【-】" class="headerlink" title="八、Ehcache的注解【*】"></a>八、Ehcache的注解【*】</h2><p>Ehcache是一个用Java实现的简单、高速、线程安全的缓存管理类库，其提供了用内存、磁盘文件存储，以及分布式存储等多种灵活的管理方案。Ehcache具有快速、简单、低消耗、依赖性小、扩展性强、支持对象或序列化缓存或元素的失效、提供LRU&#x2F;LFU&#x2F;FIFO缓存策略、支持内存缓存及磁盘缓存、采用分布式缓存机制等特点。</p><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/8.1Ehcache%E6%9E%B6%E6%9E%84%E5%9B%BE.png" alt="Ehcache架构图"></p><h4 id="Ehcache主要特点"><a href="#Ehcache主要特点" class="headerlink" title="Ehcache主要特点"></a>Ehcache主要特点</h4><ul><li>快速，简单。</li><li>多种缓存策略。</li><li>缓存数据有两级，</li><li>缓存数据会在虚拟机重启的过程中写入磁盘。</li><li>可以通过RMI、可插入API等方式进行分布式缓存。</li><li>具有缓存和缓存管理器的侦听接口。<ul><li>缓存管理器监听器。</li><li>缓存事件监听器。</li></ul></li><li>提供Hibernate的缓存实现。</li></ul><h4 id="Spring中Ehcache缓存注解"><a href="#Spring中Ehcache缓存注解" class="headerlink" title="Spring中Ehcache缓存注解"></a>Spring中Ehcache缓存注解</h4><ul><li>开启注解：&lt;cache:annotation-driven cache-manager&#x3D;”cacheManager”&#x2F;&gt;</li><li>使用标记注解：通过对一个类进行注解修饰的方式在这个类中使用缓存注解。</li></ul><p>部分注解用法：</p><ul><li><p><strong>@Cacheable</strong>  表明所修饰的方法是可以缓存的：当第一次调用这个方法时，它的结果会被缓存下来，在缓存的有效时间内，以后访问这个方法都直接返回缓存结果，不再执行方法中的代码段。</p><p>这个注解可以用condition属性来设置条件，如果不满足条件，就不使用缓存能力，直接执行方法。 可以使用key属性来指定 key 的生成规则。</p></li></ul><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/8.2Cacheable%E5%B1%9E%E6%80%A7%E8%A1%A8.png" alt="Cacheable属性表"></p><ul><li><strong>@CachePut</strong>  与@Cacheable不同，@CachePut不仅会缓存方法的结果，还会执行方法的代码段。 它支持的属性和用法都与@Cacheable一致。</li></ul><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/8.3CachePut%E5%B1%9E%E6%80%A7%E8%A1%A8.png" alt="CachePut属性表"></p><ul><li><strong>@CacheEvict</strong>  与@Cacheable功能相反，@CacheEvict表明所修饰的方法是用来删除失效或无用的缓存数据。</li></ul><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/8.4CachEvict%E5%B1%9E%E6%80%A7%E8%A1%A8.png" alt="CachEvict属性表"></p><ul><li><strong>@Caching</strong> 如果需要使用同一个缓存注解（@Cacheable、@CacheEvict或@CachePut）多次修饰一个方法，就需要用到@Caching。</li><li><strong>@CacheConfig</strong> 与前面的缓存注解不同，这是一个类级别的注解。 如果类的所有操作都是缓存操作，你可以使用@CacheConfig来指定类，省去一些配置。</li></ul><hr><h2 id="九、Memcached的内存管理机制【-】"><a href="#九、Memcached的内存管理机制【-】" class="headerlink" title="九、Memcached的内存管理机制【*】"></a>九、Memcached的内存管理机制【*】</h2><p>Memcached是以LiveJournal旗下Danga Interactive公司的Brad Fitzpatric为首开发的一款软件。现在已成为mixi、Twitter、Facebook、Vox、LiveJournal等众多服务中提高Web应用扩展性的重要手段。随着数据量的增大、访问的集中，就会造成RDBMS的负担加重、数据库响应恶化、网站显示延迟等重大影响。<strong>减轻数据库压力，避免大量访问穿透到数据库</strong>是Memcached主要的用武之地。Memcached是<strong>高性能的分布式缓存服务器</strong>。一般使用目的是，<strong>通过缓存数据库查询结果，减少数据库访问次数，以提高动态Web应用的速度，提高可扩展性</strong>。</p><h4 id="1、Memcached使用场景"><a href="#1、Memcached使用场景" class="headerlink" title="1、Memcached使用场景"></a>1、Memcached使用场景</h4><p>Memcached主要应用在减少数据库压力的场景，第一次访问，缓存数据未命中，则从数据库中获取数据并存储到Memcached中，第二次访问则直接从缓存中获取数据。</p><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/9.1%E6%9F%A5%E8%AF%A2%E9%93%BE%E8%B7%AF%E5%9B%BE.png" alt="查询链路图"></p><p>更新链路，应用服务器对key进行更新，先对DB进行更新后，再对缓存进行更新。</p><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/9.2%E6%9B%B4%E6%96%B0%E9%93%BE%E8%B7%AF%E5%9B%BE.png" alt="更新链路图"></p><h4 id="2、Memcached特征"><a href="#2、Memcached特征" class="headerlink" title="2、Memcached特征"></a>2、Memcached特征</h4><ul><li><strong>协议简单</strong>：Memcached和客户端通信并不使用复杂的XML等格式，而是使用简单的基于文本协议或者二进制协议。</li><li><strong>基于libevent的事件处理</strong>：由于epoll，kqueue，&#x2F;dev&#x2F;poll每个接口都有自己的特点，程序移植非常困难，libevent这个程序库就应运而生了。他将Linux的epoll、BSD类操作系统的kqueue等事件处理功能封装成统一的接口。Memcached使用libevent库，因此能在Linux、BSD、Solaris等操作系统上发挥其高性能。</li><li><strong>内置内存存储方式</strong>：为了提高性能，Memcached中保存的数据都存储在Memcached内置的内存存储空间中。由于数据仅存在于内存中，因此重启Memcached或者重启操作系统会导致全部数据消失。另外，内存容量达到指定的值之后，Memcached会自动删除不使用的内存。缓存数据的回收采用的是LRU ( Least Recently Used)算法。</li><li><strong>Memcached客户端分布式</strong>：Memcached尽管是“分布式”缓存服务器，但服务器端并没有分布式功能。各个Memcached实例不会互相通信以共享信息。它的分布式主要是通过客户端实现的。</li></ul><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/9.3Memcached%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84%E5%9B%BE.png" alt="Memcached基本结构图"></p><h4 id="3、Memcached的一些问题"><a href="#3、Memcached的一些问题" class="headerlink" title="3、Memcached的一些问题"></a>3、Memcached的一些问题</h4><ul><li><strong>无法备份，重启无法恢复</strong>：重启无法恢复的问题，只能通过持久化解决。兼容Memcached的协议，持久化的解决方案有MemcacheDB，以及Tokyo Cabinet和Tokyo Tyrant配合使用。Tokyo Cabinet是一个DBM数据库，而Tokyo Tyrant是兼容Memcached协议的网络协议。</li><li><strong>无法查询</strong>：前面谈过Memcached 的存储机制，不能按各种条件的key查询，比如范围查询。</li><li><strong>没有提供内置的安全机制</strong>：当然你可以找到一些解决方案。</li><li><strong>单点故障failover</strong>：Memcached不支持任何fail-over&#x2F;high-availability机制，因为它是作为cache使用的，不是原始数据源，这也是其一大特点。面对单点故障，可以通过主从模式解决问题。</li></ul><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/9.4%E4%B8%BB%E4%BB%8E%E7%BC%93%E5%AD%98%E7%BB%93%E6%9E%84.png" alt="主从缓存结构"></p><h4 id="4、Memcache机制"><a href="#4、Memcache机制" class="headerlink" title="4、Memcache机制"></a>4、Memcache机制</h4><ul><li>守护进程机制<ul><li>UNIX daemon</li></ul></li><li>Socket事件处理机制<ul><li>non-blocked：非阻塞</li><li>libevent：异步事件处理</li><li>epoll&#x2F;kqueue</li></ul></li><li><strong>内存管理机制</strong><ul><li><strong>Slab：内存分配机制</strong></li><li><strong>LRU：对象清楚机制</strong></li><li><strong>Hash机制：快速检索item</strong></li></ul></li><li>多线程处理机制：pthread（POSIX）线程模式<ul><li>编译时开启：.&#x2F;configure -enable-threads</li><li>目前还比较粗糙，锁机制locking不够完善</li><li>负载过重时，可以开启（-t线程数为CPU核数）</li></ul></li></ul><h4 id="5、Memcache内存管理机制"><a href="#5、Memcache内存管理机制" class="headerlink" title="5、Memcache内存管理机制"></a>5、Memcache内存管理机制</h4><ul><li>Slab内存处理机制<ul><li>提前分配但没存slab 1MB，再进行小对象填充chunk</li><li>避免大量重复的初始化和清理<strong>（减轻内存管理器负担）</strong></li><li>避免频繁malloc&#x2F;free<strong>（系统碎片）</strong></li></ul></li><li>懒惰检测机制<ul><li>不检测item对象是否超时</li><li>get时检查item对象是否应该删除</li></ul></li><li>懒惰删除机制<ul><li>删除item对象时，不释放内存，做删除标记，指针放入slot回收插槽，下次分配的时候直接使用</li></ul></li></ul><p><strong>（东西只有这么点，但是如果需要详细了解过程的话建议去看下Slab的具体工作流程【PPT第6章 缓存鼻祖Memcached】以及Slab Allocation机制、Item【书本P102-P106】）</strong></p><hr><h2 id="十、关系型数据库和非关系型数据库的优缺点分析"><a href="#十、关系型数据库和非关系型数据库的优缺点分析" class="headerlink" title="十、关系型数据库和非关系型数据库的优缺点分析"></a>十、关系型数据库和非关系型数据库的优缺点分析</h2><h4 id="1、关系型数据库和非关系型数据库的比较"><a href="#1、关系型数据库和非关系型数据库的比较" class="headerlink" title="1、关系型数据库和非关系型数据库的比较"></a>1、关系型数据库和非关系型数据库的比较</h4><table><thead><tr><th align="center">比较标准</th><th align="center">RDBMS</th><th align="center">NoSQL</th><th align="left">备注</th></tr></thead><tbody><tr><td align="center">数据库原理</td><td align="center">完全支持</td><td align="center">部分支持</td><td align="left">RDBMS<strong>有关系代数理论作为基础</strong>；</td></tr><tr><td align="center">NoSQL没有统一的理论基础</td><td align="center"></td><td align="center"></td><td align="left"></td></tr><tr><td align="center">数据规模</td><td align="center">大</td><td align="center">超大</td><td align="left">RDBMS很难实现横向<strong>扩展</strong>，纵向扩展的空间也比较有限，性能会随着数据规模的增大而降低；</td></tr><tr><td align="center">NoSQL可以很容易通过添加更多设备来支持更大规模的数据</td><td align="center"></td><td align="center"></td><td align="left"></td></tr><tr><td align="center">数据库模式</td><td align="center">固定</td><td align="center">灵活</td><td align="left">RDBMS需要定义<strong>数据库模式</strong>，严格<strong>遵守数据定义和相关约束条件</strong>；</td></tr><tr><td align="center">NoSQL不存在数据库模式，可以自由灵活定义并存储各种不同类型的数据</td><td align="center"></td><td align="center"></td><td align="left"></td></tr><tr><td align="center">查询效率</td><td align="center">快</td><td align="center">可以实现高效的简单查询，但是不具备高度结构化查询等特性，复杂查询的性能不尽人意</td><td align="left">RDBMS借助于<strong>索引机制</strong>可以实现快速查询（包括记录查询和范围查询）；</td></tr><tr><td align="center">很多NoSQL数据库没有面向复杂查询的索引，虽然NoSQL可以使用MapReduce来加速查询，但是，在<strong>复杂查询</strong>方面的性能仍然不如RDBMS</td><td align="center"></td><td align="center"></td><td align="left"></td></tr><tr><td align="center">一致性</td><td align="center">强一致性</td><td align="center">弱一致性</td><td align="left">RDBMS严格遵守事务ACID模型，可以保证事务强一致性；</td></tr><tr><td align="center">很多NoSQL数据库放松了对事务ACID四性的要求，而是<strong>遵守BASE模型</strong>，只能保证最终一致性</td><td align="center"></td><td align="center"></td><td align="left"></td></tr><tr><td align="center">数据完整性</td><td align="center">容易实现</td><td align="center">很难实现</td><td align="left">任何一个RDBMS都可以很容易实现数据完整性，比如通过主键或者非空约束来实现实体完整性，通过主键、外键来实现参照完整性，通过约束或者触发器来实现用户自定义完整性；</td></tr><tr><td align="center">但是，在<strong>NoSQL数据库却无法实现</strong></td><td align="center"></td><td align="center"></td><td align="left"></td></tr><tr><td align="center">扩展性</td><td align="center">一般</td><td align="center">好</td><td align="left">RDBMS很难实现横向扩展，纵向扩展的空间也比较有限；</td></tr><tr><td align="center">NoSQL在设计之初就充分考虑了横向扩展的需求，可以很容易通过添加廉价设备实现扩展</td><td align="center"></td><td align="center"></td><td align="left"></td></tr><tr><td align="center">可用性</td><td align="center">好</td><td align="center">很好</td><td align="left">RDBMS在任何时候都以保证数据一致性为优先目标，其次才是优化系统性能，随着数据规模的增大，RDBMS为了保证严格的一致性，只能提供相对较弱的可用性；</td></tr><tr><td align="center">大多数NoSQL都能提供较高的可用性</td><td align="center"></td><td align="center"></td><td align="left"></td></tr><tr><td align="center">标准化</td><td align="center">是</td><td align="center">否</td><td align="left">RDBMS已经标准化（SQL）；</td></tr><tr><td align="center"><strong>NoSQL还没有行业标准</strong>，不同的NoSQL数据库都有自己的查询语言，很难规范应用程序接口；</td><td align="center"></td><td align="center"></td><td align="left"></td></tr><tr><td align="center">Stone Braker认为：NoSQL缺乏统一查询语言，将会拖慢NoSQL发展</td><td align="center"></td><td align="center"></td><td align="left"></td></tr><tr><td align="center">技术支持</td><td align="center">高</td><td align="center">低</td><td align="left">RDBMS经过几十年的发展，已经非常成熟，Oracle等大型厂商都可以提供很好的技术支持；</td></tr><tr><td align="center">NoSQL在技术支持方面仍然处于起步阶段，还不成熟，缺乏有力的技术支持</td><td align="center"></td><td align="center"></td><td align="left"></td></tr><tr><td align="center">可维护性</td><td align="center">复杂</td><td align="center">复杂</td><td align="left">RDBMS需要专门的数据库管理员(DBA)维护；</td></tr><tr><td align="center">NoSQL数据库虽然没有DBMS复杂，也难以维护</td><td align="center"></td><td align="center"></td><td align="left"></td></tr></tbody></table><ul><li>关系数据库</li></ul><p>优势：以完善的关系代数理论作为基础，有严格的标准，支持事务ACID四性，借助索引机制可以实现高效的查询，技术成熟，有专业公司的技术支持。</p><p>劣势：可扩展性较差，无法较好支持海量数据存储，数据模型过于死板、无法较好支持Web2.0应用，事务机制影响了系统的整体性能等。</p><ul><li>NoSQL数据库</li></ul><p>优势：可以支持超大规模数据存储，灵活的数据模型可以很好地支持Web2.0应用，具有强大的横向扩展能力等。</p><p>劣势：缺乏数学理论基础，复杂查询性能不高，大都不能实现事务强一致性，很难实现数据完整性，技术尚不成熟，缺乏专业团队的技术支持，维护较困难等。</p><h4 id="2、关系型数据库和非关系型数据库的优缺点"><a href="#2、关系型数据库和非关系型数据库的优缺点" class="headerlink" title="2、关系型数据库和非关系型数据库的优缺点"></a>2、关系型数据库和非关系型数据库的优缺点</h4><p>（上面那个表太复杂了，基本知识不到位的直接看下面这个表吧）</p><table><thead><tr><th align="center">数据库类型</th><th>特性</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td align="center">关系型数据库<br>SQLite、Oracle、MySQL</td><td>1、关系型数据库，是指采用了<strong>关系模型来组织数据</strong>的数据库；<br>2、关系型数据库的最大特点就是<strong>事物的一致性</strong>；<br>3、简单来说，关系模型指的就是二维表格模型，而一个关系型数据库就是<strong>由二维表及其之间的联系所组成的</strong>一个数据组织。</td><td>1、<strong>容易理解</strong>：二维表结构是非常贴近逻辑世界的一个概念，关系模型相对网状、层次等其他模型来说更容易理解；<br>2、<strong>使用方便</strong>：通用的SQL语言使得操作关系型数据库非常方便；<br>3、<strong>易于维护</strong>：丰富的完整性（实体完整性、参照完整性和用户定义的完整性）大大降低了数据冗余和数据不一致的概率；<br>4、<strong>支持SQL，可用于复杂的查询</strong>。</td><td>1、为了维护一致性所付出的巨大代价就是其读写<strong>性能比较差</strong>；<br>2、固定的表结构；<br>3、高并发读写需求；<br>4、海量数据的高效率读写。</td></tr><tr><td align="center">非关系型数据库MongoDb、Redis、HBase</td><td>1、使用<strong>键值对</strong>存储数据；<br>2、<strong>分布式</strong>；<br>3、一般<strong>不支持ACID特性</strong>；<br>4、非关系型数据库严格上不是一种数据库，应该是<strong>一种数据结构化存储方法的集合</strong>。</td><td>1、<strong>无需经过SQL层的解析，读写性能很高</strong>；<br>2、基于键值对，数据<strong>没有耦合性，容易扩展</strong>；<br>3、存储数据的格式：NoSQL的存储格式是<strong>Key，Value形式、文档形式、图片形式</strong>等等，二关系型数据库则只支持基础类型。</td><td>1、不提供SDQL支持，学习和使用成本较高；<br>2、无事务处理，附加功能BI和报表等支持也不好。</td></tr></tbody></table><hr><h2 id="十一、Redis的数据结构"><a href="#十一、Redis的数据结构" class="headerlink" title="十一、Redis的数据结构"></a>十一、Redis的数据结构</h2><p>Redis（Remote Dictionary Server）远程字典服务器是一个<strong>key-value存储系统</strong>，由Salvatore Sanfilippo开发，使用ANSI C语言编写，遵守BSD协议。</p><p>Redis运行于独立的进程，通过网络协议和应用交互，将数据保存在内存中，并提供多种手段持久化内存数据。<strong>Redis具备跨服务器的水平拆分、复制的分布式特性</strong>。Redis不同于Memcached将value视作黑盒，Redis的value本身具有结构化的特点，对于value提供了丰富的操作。<strong>基于内存存储的特点使得Redis与传统的关系型数据库相比，拥有极高的吞吐量和响应性能</strong>。</p><h4 id="0、Redis的特点"><a href="#0、Redis的特点" class="headerlink" title="0、Redis的特点"></a>0、Redis的特点</h4><ul><li><strong>支持多种数据结构</strong>。Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。</li><li><strong>支持数据持久化</strong>。Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。</li><li><strong>支持数据备份</strong>。Redis支持数据的备份，即master-slave模式的数据备份。</li></ul><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/11.1Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.png" alt="Redis数据结构"></p><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/11.2Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%842.png" alt="Redis数据结构2"></p><p>Redis没有传统关系型数据库的table模型。schema所对应的db仅以编号区分，同一个db内，key 作为顶层模型，其值是<strong>扁平化</strong>的，即db本身就是key值的命名空间。实际使用中，通常以“:‘号作为分隔符，将命名空间值和业务key连接，作为Redis中当前db下的key值，如“article:12345”作为key值，表示article这个命名空间下id为12345的元素的key，类似于关系型数据库中的article表主键为12345的行。</p><p>因为扁平化的特点，在Redis 中，针对key的操作变得很简单:所有操作针对1到几个（常数个） key进行，不存在关系型数据库中的类似列表查询类的操作。但是业务的多样性通常需要存储系统具有更丰富的数据结构，Redis将这样的功能放到了单条key-value 的内部，用<strong>结构化的value对象满足业务多样性的需求</strong>。</p><p>Redis常用的value包含5种类型：<strong>string、list、set、map、sorted-set</strong>。</p><h4 id="1、String"><a href="#1、String" class="headerlink" title="1、String"></a>1、String</h4><p>字符串类型是Redis中最基本的数据结构，它能存储任何类型的数据，包括二进制数据，序列化后的数据，JSON化的对象，甚至是一张图片，最大512M。包括3种值的类型：字符串、整数、浮点数。</p><p>String 的底层存储：String类型的数据结构<strong>存储方式有三种int、raw、embstr</strong>。</p><p>String的应用场景：String用来存储图片，统计微博数、统计粉丝数等。</p><p>SDS是在原本字符数组之上，<strong>增加了三个元数据:：len、alloc、flags</strong>，用来解决C语言字符串的缺陷。为尽可能降低响应时间，降低某些操作的时间复杂度，并可能兼容一些C语言字符串APl，实现十分巧妙。</p><h4 id="2、List"><a href="#2、List" class="headerlink" title="2、List"></a>2、List</h4><p>列表对象，用于存储String序列。按照插入顺序排序，元素可以重复。你可以添加一个元素到列表的头部(左边)或者尾部(右边)，底层是个链表结构。</p><p>Redis的列表相当于Java语言中的LinkedList，注意它是链表而不是数组。这意味着**list的插入和删除操作非常快，时间复杂度为O(1)，但是索引定位很慢，时间复杂度为O(n)**。C语言本身没有链表这个数据结构的，所以Redis自己设计了一个链表数据结构。</p><p>List的应用场景∶</p><ul><li>List实现队列：消息排队和异步逻辑处理</li><li>文章列表或者数据分页展示的应用</li></ul><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/11.3List%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.png" alt="List数据结构"></p><h4 id="3、Hash（Map）"><a href="#3、Hash（Map）" class="headerlink" title="3、Hash（Map）"></a>3、Hash（Map）</h4><p>Redis hash是一个string类型的field和value的映射表，hash特别适合用于存储对象。</p><p>Hash冲突解决：被分配到同一个哈希桶上的多个节点可以用这个单项链表连接起来。</p><p>链式哈希局限性也很明显，随着链表长度的增加，在查询这一位置上的数据的耗时就会增加，毕竟链表的查询的时间复杂度是O(n)。这时要采取rehash，对哈希表的大小进行扩展。</p><p>如果哈希表1的数据量非常大，那么在迁移至哈希表2的时候，因为会涉及大量的数据拷贝，此时可能会对Redis造成阻塞，无法服务其他请求。</p><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/11.4Hash%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.png" alt="Hash数据结构"></p><p><strong>渐进式hash</strong></p><ul><li>Redis采用了渐进式rehash，也就是将数据的迁移的工作不再是一次性迁移完成，而是分多次迁移。</li><li>在rehash进行期间：<ul><li>每次哈希表元素进行新增、删除、查找或者更新操作时，Redis除了会执行对应的操作之外，还会顺序将「哈希表1」中索引位置上的所有key-value迁移到「哈希表2」上；</li><li><strong>查找</strong>一个key 的值的话，先会在「哈希表1」里面进行查找，如果没找到，就会继续到哈希表2里面进行查找。</li><li><strong>新增</strong>一个key-value时，<strong>会被保存到「哈希表2」里面</strong>，而「哈希表1」则不再进行任何添加操作，这样保证了「<strong>哈希表1」的key-value数量只会减少</strong>，随着 rehash操作的完成，最终「哈希表1」就会变成空表。</li></ul></li></ul><h4 id="4、Set"><a href="#4、Set" class="headerlink" title="4、Set"></a>4、Set</h4><p>Set是类似List，<strong>是String类型的无序无重复集合</strong>。相当于Java语言中的HashSet，它<strong>内部的键值对是无序、唯一的</strong>。它的内部实现相当于一个特殊的字典，字典中所有的value都是一个值NULL。</p><ul><li><p>Set的底层实现：</p><ul><li>针对非整型的数据，采用hashtable；</li><li>针对整型的数据，采用 intset。如果元素个数超过set-max-intset-entries（默认值：512），也会用hashtable存储。</li></ul></li><li><p>Set的应用场景</p><ul><li>标签。比如博客网站经常用到的文章分类标签</li><li>去重，共同好友</li><li>随机化展示</li></ul></li></ul><h4 id="5、Zset（Sorted-set）"><a href="#5、Zset（Sorted-set）" class="headerlink" title="5、Zset（Sorted-set）"></a>5、Zset（Sorted-set）</h4><p><strong>（zset就是sorted set。为了避免sorted set简写sset导致命令冲突，所以改为zset。）</strong></p><p>Redis<strong>有序</strong>集合zset和集合set一样也是string类型元素的集合，且不允许重复的成员。不同的是<strong>zset的每个元素都会关联一个分数(分数可以重复)<strong>，redis通过分数来为集合中的成员进行</strong>从小到大</strong>的排序。</p><p>Zset 的底层实现︰</p><ul><li><p>Zset对象是唯一一个同时<strong>使用了两个数据结构</strong>来实现的Redis对象，这两个数据结构一个是跳表，一个是哈希表。这样的好处是既能<strong>进行高效的范围查询，也能进行高效单点查询</strong>。</p></li><li><p>Zset对象能支持范围查询(如ZRANGEBYSORE操作)，这是因为它的数据结构设计采用了跳表（跳表是在链表基础上改进过来的，实现了一种多层的有序链表,这样的好处是能快读定位数据。)，而又能以常数复杂度获取元素权重(如ZSCORE操作)，这是因为它同时采用了哈希表进行索引。</p></li></ul><p>Zset的应用场景</p><ul><li>在首页推荐10个最热门的帖子，也就是阅读量由高到低，排行榜的实现等业务。</li><li>IM中最近的会话列表</li></ul><h4 id="（编外）Redis-Cluster"><a href="#（编外）Redis-Cluster" class="headerlink" title="（编外）Redis-Cluster"></a>（编外）Redis-Cluster</h4><p>Redis Cluster着眼于<strong>提高并发量</strong>。群集至少需要3主3从，且每个实例使用不同的配置文件。</p><p>在redis-cluster架构中，redis-master节点一般用于接收读写，而redis-slave节点则一般只用于备份，其与对应的master拥有相同的slot集合，若某个redis-master意外失效，则再将其对应的slave进行升级为临时redis-master。</p><p>Redis的官方文档：在cluster架构下，默认的，一般redis-master用于接收读写，而redis-slave则用于备份，<strong>当有请求是在向slave发起时，会直接重定向到对应key所在的master来处理</strong>。但如果不介意读取的是redis-cluster中有可能过期的数据并且对写请求不感兴趣时，则亦可<strong>通过readonly命令，将slave设置成可读，然后通过slave获取相关的key，达到读写分离</strong>。</p><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/11.4Redis-Cluster.png" alt="Redis-Cluster"></p><p><strong>优点</strong>：</p><ul><li>解决分布式负载均衡的问题。具体解决方案是分片&#x2F;虚拟操slot。</li><li>可实现动态扩容。</li><li>P2P模式，无中心化。</li></ul><p><strong>缺点</strong>：</p><ul><li>为了性能提升，客户端需要缓存路由器信息。</li><li>Slave在集群中充当”冷备“，不能缓解读压力。</li></ul><hr><h2 id="十二、Redis的持久化方式"><a href="#十二、Redis的持久化方式" class="headerlink" title="十二、Redis的持久化方式"></a>十二、Redis的持久化方式</h2><p>Redis对外提供数据访问服务时使用的是驻存在内存中的数据，这些数据在Redis重启之后将消失。为了让数据在重启之后得以恢复，Redis具备将数据持久化到本地磁盘的能力。</p><p>Redis持久化有两种方法：<strong>全量模式</strong>和<strong>增量模式</strong>。</p><h4 id="基于全量模式的持久化"><a href="#基于全量模式的持久化" class="headerlink" title="基于全量模式的持久化"></a>基于全量模式的持久化</h4><ul><li>书本上的部分：</li></ul><p>Redis作为一个状态节点，其”状态“可以用实例内部所有db的key-value值来定义，每一次Redis处理一个数据访问写命令修改了db的key-value数据时，Redis就发生了一次状态变迁。基于全量的持久化触发的时刻，将当时的状态（所有db的key-value值）完全保存下来，形成一个snapshot。</p><p>当Redis重启时，通过加载最近一个snapshot数据，可将Redis恢复至最近一次持久化时的状态上。</p><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/12.1%E5%85%A8%E9%87%8F%E6%A8%A1%E5%BC%8F%E6%8C%81%E4%B9%85%E5%8C%96.png" alt="全量模式持久化"></p><ul><li>PPT上的内容（PPT上将这种模式称之为<strong>RDB【快照模式】</strong>）</li></ul><p>RDB：Redis将内存中的<strong>所有数据全量</strong>写入到文件中</p><p><strong>优点</strong>：</p><p>1、每隔一段时间进行备份，<strong>全量备份</strong></p><p>2、灾备简单，可以<strong>远程传输</strong></p><p>3、备份是fork一个<strong>子进程</strong>，对当前进行数据访问主进程不影响</p><p><strong>劣势</strong>：</p><p>1、发生故障时，有可能<strong>丢失最后一次备份的数据</strong>（原因︰突然宕机，子进程已经生成了rdb文件，但主进程还没来得及用该文件覆盖旧的rdb文件。）</p><p>2、子进程进行<strong>数据备份时会复制内存数据导致内存膨胀两倍</strong>，如果复制的数据量很大就会导致CPU和内存负载往高产生卡顿</p><p>3、RDB数据持久化适合于大规模的数据恢复，并且还原速度快，如果对数据的完整性不是特别敏感（可能存在最后一次丢失的情况），那么RDB持久化方式非常合适。</p><p><strong>原理</strong>：</p><p>1、RDB即快照模式，它是Redis默认的数据持久化方式，它会将数据库的快照保存在dump.rdb这二进制文件中。</p><p>2、Redis使用操作系统的多进程COW（Copy On Write）机制来实现快照持久化操作。</p><p>3、RDB 实际上是Redis内部的一个定时器事件，它每隔一段固定时间就去检查触发条件。当满足条件时，Redis就会通过操作系统调用fork()来创建一个子进程，该子进程与父进程享有<strong>相同的地址空间</strong>。</p><p><strong>数据已经持久化到RDB文件，如何恢复?</strong></p><p>只需要把dump.rdb复制到dir目录中，redis在启动的时候机会<strong>自动加载</strong>。</p><h4 id="基于增量模式的持久化"><a href="#基于增量模式的持久化" class="headerlink" title="基于增量模式的持久化"></a>基于增量模式的持久化</h4><ul><li>书本上的部分：</li></ul><p>基于全量的持久化保存的是数据的”状态“，而增量持久化保存的则是状态的每一次”变迁“。当初始状态给定，经过相同的”变迁“序列之后，最终的状态也是确定的。因此，基于增量持久化数据，可以通过对给定初始状态之后的变迁回放，恢复出数据的终态。</p><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/12.2%E5%A2%9E%E9%87%8F%E6%A8%A1%E5%BC%8F%E6%8C%81%E4%B9%85%E5%8C%96.png" alt="增量模式持久化"></p><p>在Redis中，增量持久化成为AOF（append-only file）方式，在此基础上以rewrite机制优化性能，Redis仅对数据的变化进行存储。</p><ul><li>PPT上的内容（PPT上将这种模式称之为<strong>AOF【追加模式】</strong>）</li></ul><p>AOF被称为追加模式，或日志模式，是Redis提供的另⼀种持久化策略，它能够<strong>存储Redis服务器已经执行过的命令</strong>， 并且<strong>只记录对内存有过修改的命令</strong>，这种数据记录方法，被叫做“<strong>增量复制</strong>”，其默认存储文件为 <strong>appendonly.aof</strong>。</p><p>以日志的形式来记录用户的请求<strong>写操作</strong>（特别像MySQL的binlog）， <strong>读操作不会保存</strong>；以<strong>追加</strong>的形式进行记录到appendonly.aof 这个文件中；Redis的<strong>aof恢复</strong>其实就是把追加的文件从头到尾全部执行⼀遍。</p><p>写入机制：内容不直接写入到磁盘，而是放到内存缓冲区，填满才落盘；</p><p>重写机制：长期运行，aof文件会越变越长。</p><p>如果AOF和RDB同时开启，Redis <strong>只读取AOF文件的内容</strong></p><p>解决：在运行中修改appendonly为yes:config set appendonly yes</p><h4 id="RDB-amp-amp-AOF-持久化总结"><a href="#RDB-amp-amp-AOF-持久化总结" class="headerlink" title="RDB &amp;&amp; AOF 持久化总结"></a>RDB &amp;&amp; AOF 持久化总结</h4><table><thead><tr><th>RDB持久化</th><th>AOF持久化</th></tr></thead><tbody><tr><td>全量备份，一次保存整个数据库。</td><td>增量备份，一次只保存一个修改数据库的命令。</td></tr><tr><td>每次执行持久化操作的间隔时间较长。</td><td>保存的间隔默认为一秒钟（Everysec）。</td></tr><tr><td>数据保存为二进制格式，其还原速度快。</td><td>使用文本格式还原数据，所以数据还原速度一般。</td></tr><tr><td>执行SAVE命令时会阻塞服务器，但手动或者自动触发的BGSAVE不会阻塞服务器。</td><td>AOF持久化无论何时都不会阻塞服务器。</td></tr></tbody></table><hr><h2 id="十三、Redis集群的演进【-】"><a href="#十三、Redis集群的演进【-】" class="headerlink" title="十三、Redis集群的演进【*】"></a>十三、Redis集群的演进【*】</h2><p>参考博客<a href="https://blog.csdn.net/huxiaodong1994/article/details/109343165">redis集群架构的演进之路</a></p><h4 id="1、Redis的主从架构"><a href="#1、Redis的主从架构" class="headerlink" title="1、Redis的主从架构"></a>1、Redis的主从架构</h4><p>一开始我们的业务量不大时，一个redis节点就能满足我们的业务需求，当我们的业务量不断上涨，单台redis节点已经不能满足我们的业务需求时，这个时候redis的主从结构就出现了。</p><p>redis主从结构解决的问题：redis可以部署为一个主节点，多个从节点，从节点提供读服务，主节点提供写服务，将我们的业务进行<strong>读写分离</strong>。</p><ul><li>网络中断时，主从结构如何保持数据一致性？</li></ul><p>在redis2.8版本之前，只要主从断开连接，再次连接时，直接就是RDB全量同步；redis2.8版本之后，主从断网重连之后，会采用增量的方式进行同步，当从节点断开连接后，主节点会将操作写入到repl_backlog_buffer这个缓存区中，其中repl_backlog_buffer是一个环形的缓存区结构。</p><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/13.1%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7.png" alt="数据一致性"></p><p>从主节点恢复连接之后，从节点会发送psync命名给主节点，并把自己当前的 slave_repl_offset 发给主库，主节点会根据自身的master_repl_offset与slave_repl_offset进行比较，将两者之间的相差部分命令找到。</p><p>将相差的部分增量同步给从节点，主从集群保持数据一致。</p><ul><li>存在的问题：</li></ul><p>因为主从结构中，只有一个主节点，当主节点出现故障后，无法提供写服务操作，存在单点故障问题，无法提供高可用的服务，这个时候哨兵模式的构架就出现了。</p><h4 id="2、哨兵架构"><a href="#2、哨兵架构" class="headerlink" title="2、哨兵架构"></a>2、哨兵架构</h4><p>哨兵节点就是一个特殊的redis节点，它不提供存放数据，只用来监控其他redis节点情况。</p><p>哨兵节点的主要作用分为三个方面，即监控、选主和通知功能。</p><ul><li><p>监控：哨兵会周期的发送PING命令给所有主从节点，在规定的时间内收到了节点的响应，就认为节点是正常，如果没有在规定时间内给出响应，就认为节点出现了故障，为了防止对主节点的误判操作，引入哨兵集群来对主节点进行监控行为，所以对于redis节点来说，又分为主观下线和客观下线。</p><ul><li>主观下线：单个哨兵节点发送PING命令给所监控的主、从节点，当主从节点对响应超时，哨兵节点就任务redis节点主线故障，将节点标记为主观下线。</li><li>客观下线：当哨兵集群中，超过半数（可以调整，默认半数）以上的节点，认为某个节点发生故障，那个这个节点就被判定为客观下线。</li></ul></li><li><p>选主：当主节点发生故障了，如何从多个从节点中选出主节点？选主的步骤一般是先筛选出符合竞选条件的从节点，然后对这些从节点进行打分操作，分数最高的节点就是新的主节点。</p></li><li><p>通知：就是选举结束后，哨兵需要将新的主节点通过给客户端，让客户端可以继续进行写操作。针对客户端而言，通知可以分为主动获取和被动接受。</p><ul><li>被动接受：哨兵会把新的主节点地址信息写入到实例的pubsub（switch-master）中，客户端需要订阅这个pubsub，来获取新的主节点信息，存在的问题就是当客户端错过了哨兵的通知的话，那么客户端将不会在拿到新的主节点信息。</li><li>主动拉取：客户端在访问主从库时，不能将配置写死在自身的配置中，而是需要从哨兵集群中获取redis节点信息（sentinel get-master-addr-by-name命令）。</li></ul></li><li><p>当主从集群中的主节点故障后，如何将从节点选为新的主节点呢？</p></li></ul><p>先会对从节点进行筛选，筛选的规则就是，主要就是检查从库的当前在线状态和之前的网络情况。对于之前的网络状态判断是通过参数down-after-milliseconds，来判断，如果主从节点超过这个时间点没有通信，就被认为是出现过一次断链，当超过10次以上断连时，哨兵认为其从节点的网络情况不是很好，会主动剔除这部分从节点。然后就对剩下的从节点进行打分操作，打分分为三个纬度，如果每一轮中回出现一个最高分，就会直接选出新的主节点，选举结束。三个层级分别是从库优先级、从库复制进度和从库ID号进行选举。</p><ul><li>存在的问题：</li></ul><p>单个哨兵架构虽然解决了主从结构的单点故障问题，当主节点故障后，通过哨兵发起主从切换，可以保持redis的高可用性，但是此时哨兵节点还是只有一个，哨兵节点还是存在单点故障问题，所以哨兵集群架构就登场了。</p><h4 id="3、哨兵集群结构"><a href="#3、哨兵集群结构" class="headerlink" title="3、哨兵集群结构"></a>3、哨兵集群结构</h4><p>所谓的哨兵集群结构主要解决的问题，就是哨兵的单点故障问题，防止只有一个哨兵节点，当哨兵节点出现故障后，redis集群就不可用的情况。</p><ul><li>多个哨兵之间如何通信呢？</li></ul><p>主要是通过redis本身提供的pub&#x2F;sub机制，每个哨兵和主节点redis进行连接时，会将哨兵自身的ip和port，通过主库上有一个名为“_<em>sentinel</em>_:hello”的频道发送，当哨兵监控这个集群时，就会订阅这个频道的消息，所以通过这种方式，哨兵之间可以拿到其他节点的ip和port。</p><ul><li>哨兵的Leader选举机制？</li></ul><p>当我们的redis主节点出现故障后，需要由哨兵来进行主从切换，将某个从节点变成主节点，整个切换的流程是由哨兵中的某一个节点来进行操作，进行操作的节点我们称之为Leader节点。那么这个Leader节点是怎么来的呢，其选举的流程如下图：</p><p><img src="/2022/11/30/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%A4%87%E8%80%83/13.2%E5%93%A8%E5%85%B5%E7%9A%84%E9%80%89%E4%B8%BE%E6%9C%BA%E5%88%B6.png" alt="哨兵的选举机制"></p><ul><li>存在的问题：</li></ul><p>哨兵集群结构，虽然解决了哨兵的单点问题，但是此时的结构中，只有一个redis主节点，当redis的主节点数据量过大时，redis的持久化，提供写复制时，响应时间存在过长的情况，针对这种情况，redis切片集群就出现了。</p><h4 id="4、Redis-Cluster集群模式"><a href="#4、Redis-Cluster集群模式" class="headerlink" title="4、Redis Cluster集群模式"></a>4、Redis Cluster集群模式</h4><p>采用redis集群模式，可以解决单点节点数据量大、写入量大产生的性能瓶颈的问题。多个节点组成一个集群，可以提高集群的性能和可靠性。redis Cluster采用哈希槽（Hash slot）方法，来处理数据和实例之间的映射关系，哈希槽最多有16384个节点。存放数据的步骤就是先将key值，通过CRC16算法获取值后，然后在和16384进行取模，看这个数据落在那个哈希槽中。</p><p>采用了redis cluster集群后，客户端访问数据时，如何知道我们的数据是落在哪个节点上呢？在我们的redis集群中，每个redis集群节点都有一个额外的TCP端口，每个节点使用TCP连接与每个其他节点连接。检测和故障转移这些步骤基本和哨兵模式类似，每个redis节点都会知道其他节点分配了哪些槽信息，当客户端使用命令来请求服务端时，如何这个命令刚好在这个节点上，直接返回数据，如何不再这个节点上，会返回对应的moved重定向命令，来告知客户端需要访问的数据所在的节点信息。</p><p><strong>（部分Redis Cluster的知识可以参考十一、Redis的数据结构中的编外）</strong></p><hr><h2 id="十四、综合系统设计"><a href="#十四、综合系统设计" class="headerlink" title="十四、综合系统设计"></a>十四、综合系统设计</h2>]]></content>
      
      
      <categories>
          
          <category> 我的大学 </category>
          
          <category> 大三上学期 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 缓存 </tag>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大数据平台基础（《Hadoop大数据原理与应用》）</title>
      <link href="/2022/11/16/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E5%9F%BA%E7%A1%80%E5%A4%87%E8%80%83/"/>
      <url>/2022/11/16/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E5%9F%BA%E7%A1%80%E5%A4%87%E8%80%83/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>前言：</strong></p><p>这是针对老师画的超多考点做的一份大体是抄书的复习文档，在阅读该文档之前，强烈建议大家先自行安装Hadoop、ZooKeeper、HBase的环境，能够配置和使用即可。在此基础上再来阅读下面的部分才能获得比较大的收获。</p><p>不然的话，看这个文档会十分的无趣！！</p></blockquote><h2 id="第一章-大数据概述"><a href="#第一章-大数据概述" class="headerlink" title="第一章 大数据概述"></a>第一章 大数据概述</h2><h3 id="1、简述大数据的内涵"><a href="#1、简述大数据的内涵" class="headerlink" title="1、简述大数据的内涵"></a>1、简述大数据的内涵</h3><p>大数据是大规模数据的集合体，是数据<strong>对象</strong>、数据集成<strong>技术</strong>、数据分析<strong>应用</strong>、<strong>商业模式</strong>、<strong>思维创新</strong>的统一体，也是一门捕捉、管理和处理数据的技术，它代表着一种全新的思维方式。</p><h4 id="（1）从对象角度来看，大数据是数据规模超出传统数据库处理能力的数据集合"><a href="#（1）从对象角度来看，大数据是数据规模超出传统数据库处理能力的数据集合" class="headerlink" title="（1）从对象角度来看，大数据是数据规模超出传统数据库处理能力的数据集合"></a>（1）从对象角度来看，大数据是数据规模超出传统数据库处理能力的数据集合</h4><h4 id="（2）从技术角度来看，大数据是从海量数据中快速获得有价值信息的技术"><a href="#（2）从技术角度来看，大数据是从海量数据中快速获得有价值信息的技术" class="headerlink" title="（2）从技术角度来看，大数据是从海量数据中快速获得有价值信息的技术"></a>（2）从技术角度来看，大数据是从海量数据中快速获得有价值信息的技术</h4><h4 id="（3）从应用角度来看，大数据是对特定数据集合应用相关技术获得价值的行为"><a href="#（3）从应用角度来看，大数据是对特定数据集合应用相关技术获得价值的行为" class="headerlink" title="（3）从应用角度来看，大数据是对特定数据集合应用相关技术获得价值的行为"></a>（3）从应用角度来看，大数据是对特定数据集合应用相关技术获得价值的行为</h4><h4 id="（4）从商业模式角度来看，大数据是企业获得商业价值的业务创新方向"><a href="#（4）从商业模式角度来看，大数据是企业获得商业价值的业务创新方向" class="headerlink" title="（4）从商业模式角度来看，大数据是企业获得商业价值的业务创新方向"></a>（4）从商业模式角度来看，大数据是企业获得商业价值的业务创新方向</h4><h4 id="（5）从思维方式来看，大数据是从第三范式中分离出来的一种科研范式"><a href="#（5）从思维方式来看，大数据是从第三范式中分离出来的一种科研范式" class="headerlink" title="（5）从思维方式来看，大数据是从第三范式中分离出来的一种科研范式"></a>（5）从思维方式来看，大数据是从第三范式中分离出来的一种科研范式</h4><h3 id="2、简述大数据的4V特征"><a href="#2、简述大数据的4V特征" class="headerlink" title="2、简述大数据的4V特征"></a>2、简述大数据的4V特征</h3><p>简单来说就是“量大·样多·速快·便宜”，和老妈子菜市场买菜一样。</p><h4 id="（1）海量化【Volume】"><a href="#（1）海量化【Volume】" class="headerlink" title="（1）海量化【Volume】"></a>（1）海量化【Volume】</h4><p>大数据体量非常大，PB级别将是常态，且增长速度较快。</p><h4 id="（2）多样化【Variety】"><a href="#（2）多样化【Variety】" class="headerlink" title="（2）多样化【Variety】"></a>（2）多样化【Variety】</h4><p>大数据种类繁多，一般包括<strong>结构化</strong>、<strong>半结构化</strong>和<strong>非结构化</strong>等几种类型。这些数据在编码方式、数据格式、应用特征等多个方面存在差异性，多信息源的并发产生了大量的异构数据。此外，不同结构的数据处理和分析方式也有所区别。</p><h4 id="（3）快速化【Velocity】"><a href="#（3）快速化【Velocity】" class="headerlink" title="（3）快速化【Velocity】"></a>（3）快速化【Velocity】</h4><p>数据的快速流动和处理是大数据区分与传统数据挖掘的显著特征。大数据更<strong>强调实时分析</strong>而非批量式分析，数据输入后即刻处理，处理后丢弃。</p><h4 id="（4）价值密度低【Value】"><a href="#（4）价值密度低【Value】" class="headerlink" title="（4）价值密度低【Value】"></a>（4）价值密度低【Value】</h4><p>大数据价值密度的高低与数据总量大小呈反比，单条数据本身并无太多价值，但庞大的数据量累计并隐藏了巨大的财富，其价值具备<strong>稀疏性</strong>、<strong>多样性</strong>和<strong>不确定性</strong>等特点。</p><h3 id="3、举例说明大数据的关键技术"><a href="#3、举例说明大数据的关键技术" class="headerlink" title="3、举例说明大数据的关键技术"></a>3、举例说明大数据的关键技术</h3><p>大数据技术就是从各种类型的数据中快速获得有价值信息的技术。大数据处理的关键技术一般包括大数据采集、大数据预处理、大数据存储及管理、大数据分析及挖掘、大数据展现和应用。</p><p><strong>（简化理解关键技术为一个数据生命周期：获取【采集】——预处理——管理【储存】——分析——展示）</strong></p><h4 id="（1）大数据采集技术"><a href="#（1）大数据采集技术" class="headerlink" title="（1）大数据采集技术"></a>（1）大数据采集技术</h4><p>大数据采集一般分为大数据智能感知层和基础支撑层。大数据智能感知层主要包括数据传感体系、网络通信体系、传感适配体系、智能识别体系及软硬件资源接入系统，用于实现对结构化、半结构化、非结构化的海量数据的智能化识别、定位、跟踪、接入、传输、信号转化、监控、初步处理和管理等，重点针对大数据源的智能识别、感知、适配、传输、接入等技术。基础支撑层提供大数据服务平台所需的虚拟服务器以及结构化、半结构化及非结构化数据的数据库和物联网络资源等基础支撑环境，重点是分布式虚拟存储技术，大数据获取、存储、组织、分析和决策操作的可视化接口技术，大数据的网络传输与压缩技术，大数据隐私保护技术等。</p><h4 id="（2）大数据预处理技术"><a href="#（2）大数据预处理技术" class="headerlink" title="（2）大数据预处理技术"></a>（2）大数据预处理技术</h4><p>通过数据预处理工作，完成对已采集接收数据的辨析、抽取、清洗、归约、变换、离散化、集成等操作处理，可以是残缺的数据完整，将错误的数据纠正，多余的数据去除，进而将所需的数据挑选出来；并且进行数据集成，保证数据的一致性、准确性、完整性、时效性、可信性、可解释性。</p><h4 id="（3）大数据的存储及管理技术"><a href="#（3）大数据的存储及管理技术" class="headerlink" title="（3）大数据的存储及管理技术"></a>（3）大数据的存储及管理技术</h4><p>大数据的存储与管理要用存储器把采集到的数据存储起来，建立相应的数据库，并进行管理和调用，以解决大数据的可存储、可表示、可处理、可靠性及有效传输等关键问题，其研究重点是复杂的结构化、半结构化和非结构化的大数据管理与处理技术。</p><h4 id="（4）大数据的分析和挖掘技术"><a href="#（4）大数据的分析和挖掘技术" class="headerlink" title="（4）大数据的分析和挖掘技术"></a>（4）大数据的分析和挖掘技术</h4><p>大数据分析指的是对规模巨大的数据用适当的统计方法进行分析，以提取有用的信息并形成结论，包括可视化分析、数据挖掘算法、预测性分析、语义引擎、数据质量和数据管理等。</p><p>数据挖掘就是从大量的、不完全的、有噪声的、模糊的、随机的实际应用数据中，提取隐含在其中的、人们事先不知道的，但又潜在有用的信息和知识的过程。</p><h4 id="（5）大数据的展现和应用技术"><a href="#（5）大数据的展现和应用技术" class="headerlink" title="（5）大数据的展现和应用技术"></a>（5）大数据的展现和应用技术</h4><p>大数据技术能够将隐藏于海量数据中的信息和知识挖掘出来，为人类的社会经济活动提供依据，从而提高各个领域的运行效率，大大提高整个社会经济的集约化程度。</p><h3 id="4、简述大数据、云计算、5G、物联网以及人工智能之间的区别和联系"><a href="#4、简述大数据、云计算、5G、物联网以及人工智能之间的区别和联系" class="headerlink" title="4、简述大数据、云计算、5G、物联网以及人工智能之间的区别和联系"></a>4、简述大数据、云计算、5G、物联网以及人工智能之间的区别和联系</h3><p>物联网、云计算和5G是大数据的底层架构，大数据以来云计算来处理大数据，人工智能是大数据的应用场景。5G发展落地物联网才能发展，而物联网和云计算的发展则是推动大数据快速发展的主要原因，进而推动机器学习、计算机视觉、自然语言处理以及机器人学等人工智能领域迎来新的发展机遇。</p><p><img src="/2022/11/16/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E5%9F%BA%E7%A1%80%E5%A4%87%E8%80%83/1%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B8%8E%E7%89%A9%E8%81%94%E7%BD%91%E3%80%81%E4%BA%91%E8%AE%A1%E7%AE%97%E3%80%81%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E3%80%815G%E7%9A%84%E5%85%B3%E7%B3%BB.jpg" alt="大数据与物联网、云计算、人工智能、5G的关系"></p><p>大数据指<strong>无法再一定时间范围内用常规软件工具进行捕捉、管理和处理的数据集合，是需要新的处理模式才能有更强的决策力、洞察发现力和流程优化能力的海量、高增长率和多样化的信息资产</strong>。大数据是物联网、Web和传统信息系统发展的必然结果，它在技术体系上与云计算重点都是分布式存储和分布式计算，不同的是云计算注重服务，大数据则注重数据的价值化操作。</p><p>人工智能其实就是大数据、云计算的一个应用场景，包含机器学习，它可以从被动到主动，从模式化实行指令到自主判断根据情况实行不同的指令。</p><p><strong>（这题可能作为开放性送分题，简单来说：物理肯定是最底层的，是载体。有了硬件为依托才有云计算，5G是基于物理的云上计算【中间产物】，人工智能是云计算的产物，物理硬件获得的信息传递到云计算进行处理的数据就是大数据，也是人工智能能够反复学习的对象）</strong></p><hr><h2 id="第二章-初识Hadoop"><a href="#第二章-初识Hadoop" class="headerlink" title="第二章 初识Hadoop"></a>第二章 初识Hadoop</h2><h3 id="1、论述Hadoop生态系统构成及各个组件的基本功能"><a href="#1、论述Hadoop生态系统构成及各个组件的基本功能" class="headerlink" title="1、论述Hadoop生态系统构成及各个组件的基本功能"></a>1、论述Hadoop生态系统构成及各个组件的基本功能</h3><p>（关于生态系统，书本上介绍的是Hadoop2.0的部分，考虑到3.0出现后有些新的技术出现了，所以考试可以参考2.0的图，学习可以参考3.0的图）</p><p><img src="/2022/11/16/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E5%9F%BA%E7%A1%80%E5%A4%87%E8%80%83/2.1Hadoop3.0%E7%94%9F%E6%80%81%E7%B3%BB%E7%BB%9F.png" alt="Hadoop3.0生态系统"></p><p><strong>（上3下2，3中的Common、Kafka没有画出）</strong></p><p><img src="/2022/11/16/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E5%9F%BA%E7%A1%80%E5%A4%87%E8%80%83/2.2Hadoop2.0%E7%94%9F%E6%80%81%E7%B3%BB%E7%BB%9F.jpg" alt="Hadoop2.0生态系统"></p><h4 id="（1）Hadoop-Common"><a href="#（1）Hadoop-Common" class="headerlink" title="（1）Hadoop Common"></a>（1）Hadoop Common</h4><p>Hadoop Common是Hadoop体系中最底层的一个模块，为Hadoop各子项目提供了各种工具，是其他模块的基础。</p><h4 id="（2）HDFS【Hadoop-Distributed-File-System】"><a href="#（2）HDFS【Hadoop-Distributed-File-System】" class="headerlink" title="（2）HDFS【Hadoop Distributed File System】"></a>（2）HDFS【Hadoop Distributed File System】</h4><p>HDFS是Hadoop分布式文件系统，是Hadoop三大核心之一，是针对谷歌文件系统GFS的开源实现。HDFS是一个具有高容错性的文件系统，适合部署在廉价的机器上，且能提供高吞吐量的数据访问，非常适合大规模数据集的应用。</p><h4 id="（3）YARN【Yet-Another-Resource-Negotiator】"><a href="#（3）YARN【Yet-Another-Resource-Negotiator】" class="headerlink" title="（3）YARN【Yet Another Resource Negotiator】"></a>（3）YARN【Yet Another Resource Negotiator】</h4><p>YARN是统一资源管理和调度框架，它解决了Hadoop1.0资源利用率低和不能兼容异构计算框架等多种问题，提供了资源隔离方案和双调度器解决方案，可在YARN上运行MapReduce、Spark、Storm、Tez等不同类型的计算框架。</p><h4 id="（4）MapReduce"><a href="#（4）MapReduce" class="headerlink" title="（4）MapReduce"></a>（4）MapReduce</h4><p>Hadoop MapReduce是一个分布式的、并行处理的编程模型，是针对谷歌MapReduce的开源实现。MapReduce利用函数式编程思想，将复杂的、运行于大规模集群上的并行计算过程高度抽象为Map和Reduce两个函数，其中Map是对可以并行处理的小数据集进行本地计算并输出中间结果，Reduce是对各个Map的输出结果进行汇总计算得到最终结果。</p><h4 id="（5）Spark"><a href="#（5）Spark" class="headerlink" title="（5）Spark"></a>（5）Spark</h4><p>Spark是加州伯克利大学AMP实验室开发的新一代计算框架，对迭代计算很有优势。和MapReduce计算框架相比，Spark的性能提升明显，并且都可以与YARN进行集成。</p><h4 id="（6）HBase"><a href="#（6）HBase" class="headerlink" title="（6）HBase"></a>（6）HBase</h4><p>HBase是一个分布式的、面向列族的开源数据库，一般采用HDFS作为底层存储。HBase是针对谷歌Bigable的开源实现的，二者采用相同的数据类型，具有强大的非结构化数据存储能力。HBase使用ZooKeeper进行管理。</p><h4 id="（7）ZooKeeper"><a href="#（7）ZooKeeper" class="headerlink" title="（7）ZooKeeper"></a>（7）ZooKeeper</h4><p>ZooKeeper是Geogle Chubby的开源实现，是一个分布式的、开放源码的分布式应用程序协调框架，为大型分布式系统提供了高效且可靠的分布式协调服务以及诸如统一命名服务、配置服务、分布式锁等分布式基础服务，并广泛应用于Hadoop、HBase、Kafka等大型分布式系统。</p><h4 id="（8）Hive"><a href="#（8）Hive" class="headerlink" title="（8）Hive"></a>（8）Hive</h4><p>Hive是一个基于Hadoop的数据仓库工具，最早由FaceBook开发并使用。Hive还可以将SQL语句转换为MapReduce作业，并提交到Hadoop集群上运行。</p><h4 id="（9）Pig"><a href="#（9）Pig" class="headerlink" title="（9）Pig"></a>（9）Pig</h4><p>Pig和Hive类似，也是对大型数据集进行分析和评估的工具。不过和Hive提供的SQL接口不同的是，它提供了一种高层的、面向领域的抽象语言Pig Latin。</p><h4 id="（10）Impala"><a href="#（10）Impala" class="headerlink" title="（10）Impala"></a>（10）Impala</h4><p>Impala由Cloudera公司开发的，提供了HDFS、HBase上的海量数据进行交互式查询的SQL接口，其优点是查询非常迅速，其性能大幅领先于Hive。</p><h4 id="（11）Mahout"><a href="#（11）Mahout" class="headerlink" title="（11）Mahout"></a>（11）Mahout</h4><p>Mahout是一个机器学习和数据挖掘库，它具有许多功能，包括聚类、分类、推荐过滤等。</p><h4 id="（12）Flume"><a href="#（12）Flume" class="headerlink" title="（12）Flume"></a>（12）Flume</h4><p>Flume是由Cloudera提供的一个高可用、高可靠、分布式的海量日志采集、聚合和传输的框架。Flume支持在日志系统中定制各类数据发送方，用于收集数据，同时1也可提供对数据进行简单处理并写道各种数据接收方。</p><h4 id="（13）Sqoop"><a href="#（13）Sqoop" class="headerlink" title="（13）Sqoop"></a>（13）Sqoop</h4><p>Sqoop是SQL to Hadoop的缩写，主要用于关系数据库和Hadoop之间的数据双向交换。可以借助Sqoop完成Mysql、Oracle、PostgreSQL等关系型数据库到Hadoop生态系统中HDFS、HBase、Hive等的数据导入导出操作，整个导入导出操作都是由MapReduce计算框架实现的，非常高效。</p><h4 id="（14）Kafka"><a href="#（14）Kafka" class="headerlink" title="（14）Kafka"></a>（14）Kafka</h4><p>Kafka是一种高吞吐量、分布式的发布订阅消息系统，可以处理消费者在网站中的所有动作流数据。它采用Scala和Java语言编写，是一个分布式、支持分区的、多副本的，基于ZooKeeper协调的分布式消息系统。</p><h4 id="（15）Ambari"><a href="#（15）Ambari" class="headerlink" title="（15）Ambari"></a>（15）Ambari</h4><p>Apache Ambari是一个基于Web的工具，支持Apache Hadoop集群的安装、部署、配置和管理。</p><h3 id="2、试述Hadoop的体系架构"><a href="#2、试述Hadoop的体系架构" class="headerlink" title="2、试述Hadoop的体系架构"></a>2、试述Hadoop的体系架构</h3><p>Hadoop集群采用主从架构（Master&#x2F;Slave），NameNode与ResourceManager为Master，DataNode与NodeManager为Slave，守护进程NameNode和DataNode负责完成HDFS的工作，守护进程ResourceManager和NodeManager则完成YARN的工作。</p><p><img src="/2022/11/16/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E5%9F%BA%E7%A1%80%E5%A4%87%E8%80%83/2.3Hadoop%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84.jpg" alt="Hadoop集群架构"></p><h3 id="3、试述Hadoop的运行模式及其优缺点"><a href="#3、试述Hadoop的运行模式及其优缺点" class="headerlink" title="3、试述Hadoop的运行模式及其优缺点"></a>3、试述Hadoop的运行模式及其优缺点</h3><p><strong>主要区别在计算机数量、节点数量、采用文件系统【NameNode和DataNode位置】</strong></p><h4 id="（1）单机模式【Local-x2F-Standalone-Mode】"><a href="#（1）单机模式【Local-x2F-Standalone-Mode】" class="headerlink" title="（1）单机模式【Local&#x2F;Standalone Mode】"></a>（1）单机模式【Local&#x2F;Standalone Mode】</h4><p>只在一台计算机上运行，不需要任何配置。在这种模式下，Hadoop所有的守护进程都变成了一个Java进程；存储采用本地文件系统，没有采用分布式文件系统HDFS。<strong>（单机模式配置最简单，但它与用户交互的方式不同于全分布式模式）</strong></p><h4 id="（2）伪分布式模式【Pseudo-Distributed-Mode】"><a href="#（2）伪分布式模式【Pseudo-Distributed-Mode】" class="headerlink" title="（2）伪分布式模式【Pseudo-Distributed Mode】"></a>（2）伪分布式模式【Pseudo-Distributed Mode】</h4><p>只在一台计算机上运行。在这种模式下，Hadoop所有的守护进程运行在一个节点上，在一个节点上模拟了一个具有Hadoop完整功能的微型集群；存储采用分布式文件系统HDFS，但是HDFS的名称节点和数据节点都位于同一台计算机上。<strong>（节点数目受限的初学者可以采用伪分布式模式，虽然只有一个节点支撑整个Hadoop集群，但是Hadoop在伪分布式模式下的操作方式与在全分布式下的操作几乎完全相同）</strong></p><h4 id="（3）全分布式模式【Fully-Distributed-Mode】"><a href="#（3）全分布式模式【Fully-Distributed-Mode】" class="headerlink" title="（3）全分布式模式【Fully-Distributed Mode】"></a>（3）全分布式模式【Fully-Distributed Mode】</h4><p>在多台计算机上运行。在这种模式下，Hadoop的守护进程运行在多个节点上，形成一个真正意义上的集群；存储采用分布式文件系统HDFS，且HDFS的名称节点和数据节点位于不同计算机上。<strong>（全分布式模式是使用Hadoop的最佳方式，现实中Hadoop集群的运行均采用该模式，但它需要的配置工作和架构所需要的机器集群也都是最多的）</strong></p><hr><h2 id="第三章-分布式系统HDFS"><a href="#第三章-分布式系统HDFS" class="headerlink" title="第三章 分布式系统HDFS"></a>第三章 分布式系统HDFS</h2><h3 id="1、简述HDFS的功能及其体系架构"><a href="#1、简述HDFS的功能及其体系架构" class="headerlink" title="1、简述HDFS的功能及其体系架构"></a>1、简述HDFS的功能及其体系架构</h3><p>相对于传统本地文件系统而言，分布式文件系统是一种通过网络实现文件在多台主机上进行分布式存储的文件系统。分布式文件系统的设计一般采用“客户机&#x2F;服务器”（Client&#x2F;Server）模式，客户端以特定的通信协议通过网络与服务器建立连接，提出文件访问请求。</p><p>HDFS文件系统的<strong>基本特征</strong>包括以下几个方面：</p><h4 id="（1）高容错性"><a href="#（1）高容错性" class="headerlink" title="（1）高容错性"></a>（1）高容错性</h4><p>HDFS把硬件出错看作一种常态，设计了能够进行快速自动进行错误检测和恢复的相应机制。</p><h4 id="（2）数据容量大"><a href="#（2）数据容量大" class="headerlink" title="（2）数据容量大"></a>（2）数据容量大</h4><p>HDFS集群可以支持数百个节点，以支持应用程序的大数据需求。</p><h4 id="（3）可扩展性"><a href="#（3）可扩展性" class="headerlink" title="（3）可扩展性"></a>（3）可扩展性</h4><p>HDFS的水平扩展性强，数据节点可以根据需要进行增删。</p><h4 id="（4）高吞吐量"><a href="#（4）高吞吐量" class="headerlink" title="（4）高吞吐量"></a>（4）高吞吐量</h4><p>HDFS的传输速率高，支持高并发大数据应用程序。</p><h4 id="（5）就近计算"><a href="#（5）就近计算" class="headerlink" title="（5）就近计算"></a>（5）就近计算</h4><p>客户请求尽可能在数据节点上直接完成计算任务，以便在大数据的业务中降低网络负担，增加吞吐量。</p><p>HDFS采用Master&#x2F;Slave架构模型，一个HDFS集群包括一个NameNode和多个DataNode。名称节点NameNode为主节点，数据节点DataNode为从节点，文件被划分为一系列的数据块（Block）存储在从节点DataNode上。NameNode是中心服务器，不存储数据，负责管理文件系统的命名空间（Namespace）以及客户端对文件的访问。</p><p>HDFS的体系架构中主要包括名称节点NameNode和数据节点DataNode。</p><p><img src="/2022/11/16/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E5%9F%BA%E7%A1%80%E5%A4%87%E8%80%83/3.1HDFS%E7%9A%84%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84.jpg" alt="HDFS的体系架构"></p><h3 id="2、简述HDFS的数据的读取过程"><a href="#2、简述HDFS的数据的读取过程" class="headerlink" title="2、简述HDFS的数据的读取过程"></a>2、简述HDFS的数据的读取过程</h3><p>HDFS的真实数据分散存储在DataNode上，但是读取数据时需要先经过NameNode。</p><h4 id="基本过程"><a href="#基本过程" class="headerlink" title="基本过程"></a>基本过程</h4><p>首先，客户端连接到NameNode<strong>询问</strong>某个文件的元数据信息，NameNode返回给客户端一个包含该文件各个<strong>块位置信息</strong>（存储在哪个DataNode）的列表；然后，客户端直接连接对应的DataNode来<strong>并行读取</strong>块数据；最后，当客户得到所有块后，再按照<strong>顺序进行组装</strong>，得到完整文件。</p><p><img src="/2022/11/16/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E5%9F%BA%E7%A1%80%E5%A4%87%E8%80%83/3.2HDFS%E6%95%B0%E6%8D%AE%E7%9A%84%E8%AF%BB%E5%8F%96%E8%BF%87%E7%A8%8B.jpg" alt="HDFS数据的读取过程"></p><h4 id="详细过程"><a href="#详细过程" class="headerlink" title="详细过程"></a>详细过程</h4><p>（1）客户端生成一个FileSystem实例（DistributedFileSystem对象），并使用此实例的open()方法打开HDFS上的一个文件。</p><p>（2）DistributedFileSystem通过RPC调用向NameNode发出请求，得到文件的位置信息，即数据块编号和所在DataNode地址。对于每一个数据块，名称节点返回保存数据块的数据节点的地址，通常按照DataNode地址与客户端的距离从近到远排序。</p><p>（3）FileSystem实例获得地址信息后，生成一个FSDataInputStream对象实例返回给客户端。此实例封装了一个DFSInputStream对象，负责存储数据块信息和DataNode地址信息，并负责后续的文件内容读取内容。</p><p>（4）客户端向FSDataInputStream发出读取数据的read()调用。</p><p>（5）FSDataInputStream收到read()调用请求后，其封装的DFSInputStream选择与第一个数据块最近的DataNode，并读取相应的数据信息返回给客户端。数据块读取完成后，DFSInputStream负责关闭到对应DataNode的链接。</p><p>（6）DFSInputStream依次选择后续数据块的最近Datanode节点，并读取数据返回给客户端，直到最后一个数据块读取完毕。DFSInputStream从DataNode读取数据时，可能会碰上某个DataNode失效的情况，此时会自动选择下一个包含此数据块的最近的DataNode去读取。</p><p>（7）客户端读取完所有数据块，然后调用FSDataInputStream的close()方法关闭文件。</p><h3 id="3、简述HDFS的数据的写入过程"><a href="#3、简述HDFS的数据的写入过程" class="headerlink" title="3、简述HDFS的数据的写入过程"></a>3、简述HDFS的数据的写入过程</h3><p>HDFS的设计遵循“<strong>一次写入，多次读取</strong>”的原则，所有数据只能添加不能更新。数据会被划分为等尺寸的块写入不同的DataNode中，每个块通常保存指定数量的副本（默认3个）。</p><h4 id="基本过程-1"><a href="#基本过程-1" class="headerlink" title="基本过程"></a>基本过程</h4><p>客户端向NameNode发送文件写请求，NameNode给客户分配写权限，并随机分配块的写入地址——DataNode的IP，同时兼顾副本数量和块Rack自适应算法。</p><p><img src="/2022/11/16/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E5%9F%BA%E7%A1%80%E5%A4%87%E8%80%83/3.3HDFS%E6%95%B0%E6%8D%AE%E5%86%99%E5%85%A5%E7%9A%84%E5%9F%BA%E6%9C%AC%E8%BF%87%E7%A8%8B.jpg" alt="HDFS数据写入的基本过程"></p><h4 id="详细过程-1"><a href="#详细过程-1" class="headerlink" title="详细过程"></a>详细过程</h4><p>（1）创建和初始化FileSystem，客户端调用create()来创建。</p><p>（2）FileSystem用RPC调用名称节点，在文件系统的命名空间中创建一个新的文件。名称节点首先确定文件原来不存在，并且客户端有创建文件的权限，然后才能创建新文件。</p><p>（3）FileSystem返回DFSOutputStream，客户端开始写入数据。</p><p>（4）DFSOutputStream将数据分成块，写入data queue。data queue由Data Streamer读取，并通知名称节点分配数据节点，用来存储数据块（每块默认复制三块）。分配的数据节点放在一个数据流管道（pipeline）里。Data Streamer将数据块写入pipeline中的第一个数据节点，第一个数据节点将数据块发送给第二个数据节点，第二个数据节点将数据块发送给第三个数据节点。</p><p>（5）DFSOutputStream为发出去的数据块保存了ack queue，等待pipeline中的数据节点告知数据写入成功。</p><p>（6）客户端结束写入数据后调用close()函数。此操作将所有的数据块写入pipeline中的数据节点，并等待ack queue返回成功。</p><p>（7）通知名称节点写入完毕。</p><h3 id="4、简述HDFS有哪些可靠性机制。备份节点和Secondary-NameNode的区别是什么？（工作原理）"><a href="#4、简述HDFS有哪些可靠性机制。备份节点和Secondary-NameNode的区别是什么？（工作原理）" class="headerlink" title="4、简述HDFS有哪些可靠性机制。备份节点和Secondary NameNode的区别是什么？（工作原理）"></a>4、简述HDFS有哪些可靠性机制。备份节点和Secondary NameNode的区别是什么？（工作原理）</h3><p>高可靠性的主要目标之一就是即使在系统出错的情况下也要保证数据存储的正常。常见的三种出错情况是：NameNode出错、DataNode出错和数据出错。</p><p>NameNode是HDFS集群中的单点故障所在。如果NameNode节点出现故障，是需要手工干预的。</p><p>HDFS通过<strong>心跳检测</strong>（heartbeat）来检测DataNode是否出错。正常工作情况下，每个DataNode节点周期性地向NameNode发送心跳信号。网络割裂可能破坏一部分DataNode和NameNode的通信。NameNode通过心跳信号的缺失来检测这一情况，并将这些近期不再发送心跳信号DataNode标记为“宕机”，不会再将新的I&#x2F;O请求发送给它们，任何存储在宕机DataNode上的数据将不再有效。DataNode的宕机可能会引起一些数据块副本系数低于指定值，NameNode会不断检测这些需要复制的数据块，一旦发现就启动复制操作。</p><p>网络传输和磁盘错误等因素都会造成数据错误。客户端再读取到数据后，会采用MD5和SHA1对数据进行校验，以确保读取到正确的数据。当客户端创建一个心得HDFS文件时，会对每一个文件块进行信息摘录，并把这些信息作为一个单独的隐藏文件保存在同一个HDFS的命名空间下。当客户端读取文件内容时，会先读取该信息文件，然后利用该信息文件对每个读取的数据块进行校验。如果校验出错，客户端可以选择从其他DataNode获取该数据块的副本，并且向NameNode报告这个文件块有错；NameNode会定期检查并重新复制这个块。</p><h4 id="（1）元数据备份"><a href="#（1）元数据备份" class="headerlink" title="（1）元数据备份"></a>（1）元数据备份</h4><p>在服务器系统中，发生硬件故障或者软件错误是难以避免的，所以需要对重要数据进行备份。元数据是HDFS的核心数据，可通过它对整个HDFS进行管理。FsImage和EditLog是最重要的元数据文件，所以，NameNode通常会配置支持维护多个FsImage和EditLog副本。任何对FsImage和EditLog的修改都将同步到它们的副本上。</p><h4 id="（2）Secondary-NameNode"><a href="#（2）Secondary-NameNode" class="headerlink" title="（2）Secondary NameNode"></a>（2）Secondary NameNode</h4><p>HDFS中除了有名称节点NameNode外，还有一个辅助NameNode，称为第二名称节点Secondary NameNode。Secondary NameNode有它自身的独立角色和功能，通常认为它和NameNode是协同工作的。它是HDFS高可用的一个解决方案，但不支持热备，使用前配置即可；定期对NameNode中内存元数据进行更新和备份；默认安装在NameNode相同的节点，但是建议安装在不同的节点，以提高可靠性。</p><h4 id="（3）Backup-Node备份"><a href="#（3）Backup-Node备份" class="headerlink" title="（3）Backup Node备份"></a>（3）Backup Node备份</h4><p>Hadoop2.0以后的版本新提供了一个真正意义上的备用节点，即Backup Node。Backup Node再内存中维护了一份从NameNode同步过来的FsImage，同时它还从NameNode接受EditLog文件的日志流，并把它们持久化到硬盘。Backup Node在内存中维护与NameNode一样的元数据。</p><h4 id="（4）HDFS-NameNode-HA的高可用机制"><a href="#（4）HDFS-NameNode-HA的高可用机制" class="headerlink" title="（4）HDFS NameNode HA的高可用机制"></a>（4）HDFS NameNode HA的高可用机制</h4><p>在Hadoop1.0时代，NameNode存在单点故障问题，一旦NameNode进程不能正常工作，就会造成整个HDFS也无法使用。这可能导致生产集群上的很多框架都无法正常使用，而通过重启NameNode来进行数据恢复十分耗时。</p><p>在Hadoop2.0中，HDFS NameNode的单点故障问题得到了解决，这就是HDFS NameNode High Availability（HDFS NameNode高可用机制）。</p><h4 id="（5）HDFS-NameNode-Federation的联邦机制"><a href="#（5）HDFS-NameNode-Federation的联邦机制" class="headerlink" title="（5）HDFS NameNode Federation的联邦机制"></a>（5）HDFS NameNode Federation的联邦机制</h4><p>Hadoop集群的元数据信息是存放在NameNode的内存中的，当集群扩大到一定规模后，NameNode内存中存放的元数据信息可能会非常大。由于HDFS所有操作都会和NameNode进行交互，当集群很大时，NameNode的内存限制将会成为制约集群横向扩展的瓶颈。在Hadoop2.0诞生之前，HDFS中只能有一个命名空间，对于HDFS中的文件没有办法完成隔离。</p><p>在Hadoop2.0中引入了HDFS Federation联邦机制，解决了如下问题：</p><ul><li><strong>集群扩展性</strong>。多个NameNode分管一部分目录，使得一个集群可以扩展到更多节点，不再像Hadoop1.0中由于内存的限制而制约文件存储目录。</li><li><strong>性能更高效</strong>。多个NameNode管理不同的数据，且同时对外提供服务，将为用户提高更高的读&#x2F;写吞吐率。</li><li><strong>良好的隔离性</strong>。用户可以根据需要将不同的业务数据交由不同的NameNode管理，这样可以大大降低不同业务之间的影响。</li></ul><h4 id="（6）HDFS-Snapshots的快照机制"><a href="#（6）HDFS-Snapshots的快照机制" class="headerlink" title="（6）HDFS Snapshots的快照机制"></a>（6）HDFS Snapshots的快照机制</h4><p>HDFS快照是文件系统在某一时刻的只读镜像，可以是一个完整的文件系统，也可以是某个目录的镜像。快照分为两种：一种是建立文件系统的索引，每次更新文件不会真正改变文件，而是开辟一个空间用来保存更改的文件；另一种是拷贝所有的文件系统。HDFS快照属于前者。</p><p>HDFS快照常用于以下场景：<strong>（快照的操作远低于外部备份的开销，可以作为备份HDFS最常用的方式）</strong></p><ul><li>防止用户的错误操作。管理员可以通过滚动的方式周期性地设置一个只读快照，这样在文件系统上就有若干份只读快照。如果用户意外删除一个文件，可以使用包含该文件的最新只读快照来进行恢复。</li><li>备份。管理员可以根据需求来备份整个文件系统、一个目录或单一文件。如设置一个只读快照，并使用这个快照作为整个全量备份的开始点；再如，增量备份可以通过比较两个快照的差异来产生。</li><li>试验&#x2F;测试。当用户需要在数据集上测试一个应用程序时，如果不做该数据集的全量备份，测试应用程序会覆盖&#x2F;损坏原来的生产数据集，这是非常危险的。管理员可以为用户设置一个生产数据集的快照，以便用户测试使用。在快照上的任何改变不会影响原有数据集。</li><li>灾难恢复。只读快照可以用于创建一个一致的时间点镜像，以便于拷贝到远程站点作为灾备冗余。</li></ul><h4 id="备份节点和Secondary-NameNode的区别"><a href="#备份节点和Secondary-NameNode的区别" class="headerlink" title="备份节点和Secondary NameNode的区别"></a>备份节点和Secondary NameNode的区别</h4><p>NameNode记录了每个文件中各个块所在的数据节点的位置信息，但是并不持久化存储这些信息，而是在系统每次启动时扫描所有数据节点重构得到这些信息。只有在NameNode重启时，EditLog才会合并到FsImage文件中，从而得到一个文件系统的最新快照。但是在生产环境集群中NameNode是很少重启的，这意味着当NameNode运行很长时间后，EditLog文件会变得很大，这种情况下就会出现以下问题：</p><ul><li>EditLog文件变得很大后，如何去管理这个文件？</li><li>NameNode的重启会花费很长时间，因为有很多改动要合并到FsImage文件上；</li><li>如果NameNode宕机，那就丢失了很多改动，因为此时的FsImage文件时间戳比较旧。</li></ul><p>Secondary NameNode就是为了帮助解决上述问题提出的，它的主要职责是将NameNode的EditLog合并到FsImage文件中，即对元数据进行定期更新和备份。</p><h4 id="详细过程-2"><a href="#详细过程-2" class="headerlink" title="详细过程"></a>详细过程</h4><ul><li>Secondary NameNode通知NameNode切换EditLog文件；</li><li>Secondary NameNode通过网络从NameNode下载FsImage和EditLog；</li><li>Secondary NameNode将FsImage载入内存，然后开始合并EditLog日志；</li><li>Secondary NameNode将新的FsImage发回NameNode；</li><li>NameNode用新的FsImage替换旧的FsImage。</li></ul><p>NameNode在重启时使用新的FsImage，从而减少启动时合并EditLog文件的时间。Secondary NameNode的整个目的实在HDFS中提供一个Checkpoint Node。</p><h3 id="5、试述HDFS一个名称节点的优点、缺点"><a href="#5、试述HDFS一个名称节点的优点、缺点" class="headerlink" title="5、试述HDFS一个名称节点的优点、缺点"></a>5、试述HDFS一个名称节点的优点、缺点</h3><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ul><li>一个名称节点，负责所有元数据的管理，简化分布式文件系统结构，可以保证数据不会脱离名称节点的控制；</li><li>用户数据不会经过名称节点，减轻名称节点负担，方便数据管理，数据节点扩展不会带来性能下降</li></ul><h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ul><li><strong>命名空间限制</strong>；命名空间中的对象如文件、目录、文件块、数据节点等这些信息占用一定字节。NameNode保存全局命名空间，NameNode的内存有上限，因此保存的命名空间的大小有限制。</li><li><strong>性能瓶颈</strong>。整个分布式文件系统的吞吐量受限于单个名称节点的吞吐量。</li><li><strong>隔离问题</strong>。由于集群问题中只有一个名称节点，只有一个命名空间，因此无法对不同应用程序进行隔离。</li><li><strong>集群可用性</strong>。唯一的名称节点发送故障，导致整个节点变得不可用。</li></ul><hr><h2 id="第四章-分布式计算框架MapReduce"><a href="#第四章-分布式计算框架MapReduce" class="headerlink" title="第四章 分布式计算框架MapReduce"></a>第四章 分布式计算框架MapReduce</h2><h3 id="1、试述MapReduce作业的执行流程"><a href="#1、试述MapReduce作业的执行流程" class="headerlink" title="1、试述MapReduce作业的执行流程"></a>1、试述MapReduce作业的执行流程</h3><p>MapReduce作业的执行流程主要包括InputFormat、Map、Shuffle、Reduce、OutputFormat五个阶段。</p><p><img src="/2022/11/16/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E5%9F%BA%E7%A1%80%E5%A4%87%E8%80%83/4.1MapReduce%E7%9A%84%E4%BD%9C%E4%B8%9A%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B.jpg" alt="MapReduce的作业执行流程"></p><h4 id="（1）InputFormat"><a href="#（1）InputFormat" class="headerlink" title="（1）InputFormat"></a>（1）InputFormat</h4><p>InputFormat模块首先<strong>对输入数据做预处理</strong>，比如验证输入格式是否符合输入定义；然后将输入文件切分为逻辑上的多个InputSplit（InputSplit是MapReduce对文件进行处理和运算的输入单位，并没有对文件进行实际切割）；由于InputSplit是逻辑切分而非物理切分，所以还需要通过RecordReader根据InputSplit中的信息来处理InputSplit中的具体记录，加载数据并转换为适合Map任务读取的键值对&lt;key, value&gt;，输入给Map任务。</p><h4 id="（2）Map"><a href="#（2）Map" class="headerlink" title="（2）Map"></a>（2）Map</h4><p>Map模块会根据用户自定义的映射规则，输出一系列的&lt;key, value&gt;作为中间结果。</p><h4 id="（3）Shuffle"><a href="#（3）Shuffle" class="headerlink" title="（3）Shuffle"></a>（3）Shuffle</h4><p>为了让Reduce可以并行处理Map的结果，需要对Map的输出进行一定的<strong>排序、分区、合并、归并</strong>等操作，得到&lt;key, List(value)&gt;形式的中间结果，再交给对应的Reduce进行处理。这个过程叫做Shuffle。</p><h4 id="4-Reduce"><a href="#4-Reduce" class="headerlink" title="(4)Reduce"></a>(4)Reduce</h4><p>Reduce以一系列的&lt;key, List(value)&gt;中间结果作为输入，执行用户定义的逻辑，输出&lt;key, value&gt;形式的结果给OutputFormat。</p><h4 id="（5）OutputFormat"><a href="#（5）OutputFormat" class="headerlink" title="（5）OutputFormat"></a>（5）OutputFormat</h4><p>OutputFormat模块会验证输出目录是否已经存在以及输出结果类型是否符合配置文件中的配置类型，如果都满足，就将Reduce的结果输出到分布式系统。</p><h3 id="2、与Java类型相比较，MapReduce中定义的数据类型有哪些特点？"><a href="#2、与Java类型相比较，MapReduce中定义的数据类型有哪些特点？" class="headerlink" title="2、与Java类型相比较，MapReduce中定义的数据类型有哪些特点？"></a>2、与Java类型相比较，MapReduce中定义的数据类型有哪些特点？</h3><h4 id="MapReduce中常见的数据类型"><a href="#MapReduce中常见的数据类型" class="headerlink" title="MapReduce中常见的数据类型"></a>MapReduce中常见的数据类型</h4><table><thead><tr><th align="center">数据类型</th><th align="center">说明</th></tr></thead><tbody><tr><td align="center">IntWritable</td><td align="center">整型类型</td></tr><tr><td align="center">LongWritable</td><td align="center">长整型类型</td></tr><tr><td align="center">FloatWritable</td><td align="center">单精度浮点数类型</td></tr><tr><td align="center">DoubleWritable</td><td align="center">双精度浮点数类型</td></tr><tr><td align="center">ByteWritable</td><td align="center">字节类型</td></tr><tr><td align="center">BooleanWritable</td><td align="center">布尔类型</td></tr><tr><td align="center">Text</td><td align="center">UTF-8格式存储的文本类型</td></tr><tr><td align="center">NullWritable</td><td align="center">空对象</td></tr></tbody></table><p>（1）MapReduce是集群运算，因此必然会在执行期间进行网络传输，然而在网络中传输的数据必须是可序列化的类型。</p><p>（2）为了良好地匹配MapReduce专门设计了一套数据类型。</p><p><strong>（简单来说就是适配Hadoop设计的一套序列化数据类型）</strong></p><h3 id="3、试述Shuffle机制各个阶段的主要作用（重点）"><a href="#3、试述Shuffle机制各个阶段的主要作用（重点）" class="headerlink" title="3、试述Shuffle机制各个阶段的主要作用（重点）"></a>3、试述Shuffle机制各个阶段的主要作用（重点）</h3><h4 id="Shuffle的作用"><a href="#Shuffle的作用" class="headerlink" title="Shuffle的作用"></a>Shuffle的作用</h4><p>对Map的输出进行一定的排序、分区、合并、归并等操作，得到&lt;key, List(value)&gt;形式的中间结果，再交给对应的Reduce进行处理。</p><p>（1）Shuffle会持续接收Map阶段发来的数据，并将数据写到一个“环形缓冲区”中。缓冲区被填满时就会将覆盖掉的部分数据溢出存放到“溢出文件”中。</p><p>（2）Shuffle会对溢出文件中的数据进行排序，然后再将排序后的数据进行分区。</p><p>（3）Shuffle会生成很多个排序且分区后的溢出文件，最后会将所有溢出文件中相同分区号的内容进行合并，形成最终的第0区内容、第1区内容……</p><p><strong>（以上为书本上简单的Shuffle作用介绍，下面是网络上给出的各阶段的具体作用）</strong></p><h6 id="（1）collect阶段"><a href="#（1）collect阶段" class="headerlink" title="（1）collect阶段"></a>（1）collect阶段</h6><p>将MapTask的结果输出到默认大小为 100M 的环形缓冲区，保存的是 key&#x2F;value，Partition 分区信息等。</p><h6 id="（2）spill阶段"><a href="#（2）spill阶段" class="headerlink" title="（2）spill阶段"></a>（2）spill阶段</h6><p>当内存中的数据量达到一定的阀值的时候，就会将数据写入本地磁盘，在将数据写入磁盘之前需要对数据进行一次排序的操作，如果配置了 combiner，还会将有相同分区号和 key 的数据进行排序。</p><h6 id="（3）merge阶段"><a href="#（3）merge阶段" class="headerlink" title="（3）merge阶段"></a>（3）merge阶段</h6><p>把所有溢出的临时文件进行一次合并操作，以确保一个MapTask 最终只产生一个中间数据文件。</p><h6 id="（4）copy阶段"><a href="#（4）copy阶段" class="headerlink" title="（4）copy阶段"></a>（4）copy阶段</h6><p>ReduceTask 启动 Fetcher 线程到已经完成 MapTask 的节点上复制一份属于自己的数据，这些数据默认会保存在内存的缓冲区中，当内存的缓冲区达到一定的阀值的时候，就会将数据写到磁盘之上。</p><h6 id="（5）merge阶段"><a href="#（5）merge阶段" class="headerlink" title="（5）merge阶段"></a>（5）merge阶段</h6><p>在 ReduceTask 远程复制数据的同时，会在后台开启两个线程对内存到本地的数据文件进行合并操作。</p><h6 id="（6）sort阶段"><a href="#（6）sort阶段" class="headerlink" title="（6）sort阶段"></a>（6）sort阶段</h6><p>在对数据进行合并的同时，会进行排序操作，由于 MapTask阶段已经对数据进行了局部的排序，ReduceTask 只需保证 Copy 的数据的最终整体有效性即可。</p><hr><h2 id="第五章-统一资源管理和调度框架YARN"><a href="#第五章-统一资源管理和调度框架YARN" class="headerlink" title="第五章 统一资源管理和调度框架YARN"></a>第五章 统一资源管理和调度框架YARN</h2><h4 id="1、试述YARN与MapReduce1-0相比有哪些优势"><a href="#1、试述YARN与MapReduce1-0相比有哪些优势" class="headerlink" title="1、试述YARN与MapReduce1.0相比有哪些优势"></a>1、试述YARN与MapReduce1.0相比有哪些优势</h4><h6 id="简述MapReduce1-0存在的问题"><a href="#简述MapReduce1-0存在的问题" class="headerlink" title="简述MapReduce1.0存在的问题"></a>简述MapReduce1.0存在的问题</h6><p>在Hadoop1.0中，MapReduce采用Master&#x2F;Slave架构，有两类守护进程控制作业的执行过程，即一个JobTracker和多个TaskTracker。JobTracker负责资源管理和作业调度；TaskTracker定期向JobTracker汇报本节点的健康状况、资源使用情况、任务执行情况以及接受来自JobTracker的命令并执行。随着集群规模负载的增加，MapReduce JobTracker在内存消耗、扩展性、可靠性、性能等方面暴露出了各种缺点，具体包括以下几个方面：</p><p>（1）单点故障问题。</p><p>（2）可扩展性瓶颈。</p><p>（3）资源划分不合理。</p><p>（4）仅支持MapReduce一个计算框架。</p><h6 id="YARN"><a href="#YARN" class="headerlink" title="YARN"></a>YARN</h6><p>Apache Hadoop YARN是Hadoop2.0资源管理和调度框架，其设计基本思路就是“放权”，即不让JobTracker承担过多功能，把MapReduce1.0中JobTracker三大功能资源管理、任务调度和任务监控进行拆分，分别交给不同的新组件承担。重新设计后YARN包括ResourceManager、ApplicationMaster和NodeManager，其中，ResourceManager负责资源管理，ApplicationMaster负责任务调度和任务监控，NodeManage负责承担原TaskTracker的功能。且源资源被划分的Slot重新设计为容器Container，NodeManage能够启动和监控容器Container。另外，原JobTracker负责存储已完成作业的作业历史。</p><h6 id="Mapreduce1-0与YARN的组成比较"><a href="#Mapreduce1-0与YARN的组成比较" class="headerlink" title="Mapreduce1.0与YARN的组成比较"></a>Mapreduce1.0与YARN的组成比较</h6><table><thead><tr><th align="center">MapReduce1.0</th><th align="center">YARN</th></tr></thead><tbody><tr><td align="center">JobTracker</td><td align="center">ResourceManager、ApplicationMaster、Timeline Server</td></tr><tr><td align="center">TaskTracker</td><td align="center">NodeManager</td></tr><tr><td align="center">Slot</td><td align="center">Container</td></tr></tbody></table><p>在Hadoop1.0中，MapReduce既是一个计算框架，又是一个资源管理和调度框架。到了Hadoop2.0以后，MapReduce中资源管理和调度功能被单独分割出来形成YARN。YARN是一个纯粹的资源管理调度框架，被剥离的资源管理调度功能的MapReduce变成了MRv2。MRv2是运行在YARN上的一个纯粹的计算框架。</p><h5 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h5><h6 id="（1）可扩展性【Scalability】"><a href="#（1）可扩展性【Scalability】" class="headerlink" title="（1）可扩展性【Scalability】"></a>（1）可扩展性【Scalability】</h6><p>与MapReduce1.0相比，YARN可以在更大规模的集群上运行。YARN利用ResourceManager和ApplicationMaster分离的架构优点可以扩展将近10000个节点和100000个任务。另外，YARN Federation的联邦机制进一步增强了集群的水平横向扩展性。</p><h6 id="（2）可用性【Availablity】"><a href="#（2）可用性【Availablity】" class="headerlink" title="（2）可用性【Availablity】"></a>（2）可用性【Availablity】</h6><p>当守护进程失败时，通常需要另一个守护进程复制接管工作所需的状态，以便其继续提供服务，从而获得高可用性。</p><p>YARn对MapReduce1.0的体系架构进行了重新设计，ResourceManager和ApplicationMaster分别承担了MapReduce1.0中JobTracker的功能，高可用的服务随之成为一个分而治之的问题：先为ResourceManager提供高可用性，再为YARN应用提供高可用性。YARN的ResourceManagerHA特性通过Active&#x2F;Standby ResourceManager保证了YARN的高可用性；ResourceManager Restart特性保证了若ResourceManager发生单点故障，ResourceManager能尽快自动重启。</p><h6 id="（3）利用率【Utillzation】"><a href="#（3）利用率【Utillzation】" class="headerlink" title="（3）利用率【Utillzation】"></a>（3）利用率【Utillzation】</h6><p>MapReduce1.0使用Slot表示各个节点上的计算资源。区分Slot类别的资源管理方案在一定程度上降低了Slot的利用率。同时，这种基于无类别Slot的资源划分粒度过大，往往会造成资源利用率过高或者过低。</p><p>在YARN中，一个NodeManager管理一个资源池，而不是指定固定数目的Slot。YARN上运行的MapReduce不会出现MapReduce1.0中由于集群中只有Map Slot可用而导致Reduce Task必须等待的情况。如果能够获取运行任务的资源，那么运行应用程序就会正常进行。而且，YARN中的资源是精细化管理的，每个应用程序都能够按需请求资源，而不是请求一个不可分割的、对于特定任务而言可能太大（浪费资源）或太小（可能导致失败）的Slot。</p><h6 id="（4）多租户【Multitenancy】"><a href="#（4）多租户【Multitenancy】" class="headerlink" title="（4）多租户【Multitenancy】"></a>（4）多租户【Multitenancy】</h6><p>在某种程度上可以说，YARN最大的优点是向MapReduce以外的其他分布式计算框架开放了Hadoop。MapReduce仅是许多YARN应用中的一个，Spark、Tez、Storm等计算框架也都可以运行在YARN上。另外，用户甚至可以在同一个YARN集群上运行不同版本的MapReduce，这使得升级MapReduce更好管理。</p><h4 id="2、试述YARN体系架构中三大核心组件及各自功能"><a href="#2、试述YARN体系架构中三大核心组件及各自功能" class="headerlink" title="2、试述YARN体系架构中三大核心组件及各自功能"></a>2、试述YARN体系架构中三大核心组件及各自功能</h4><p>YARN采用主从架构（Master&#x2F;Slave），其核心组件包括ResourceManager、ApplicationMaster和NodeManager三个。其中，ResourceManager是主进程，NodeManager是从进程，一个ResourceManager对应多个NodeManager，每个应用程序拥有一个ApplicationMaster。</p><h6 id="（1）ResourceManager"><a href="#（1）ResourceManager" class="headerlink" title="（1）ResourceManager"></a>（1）ResourceManager</h6><p>整个集群只有一个ResourceManager，负责集群资源的统一管理和调度，具体承担的功能包括：</p><ul><li>处理来自客户端的请求，包括启动&#x2F;终止应用程序；</li><li>启动&#x2F;监控ApplicationMaster。一旦某个ApplicationMaster出现故障，ResourceManager将会在另一个节点上启动ApplicationMaster。</li><li>监控NodeManager，接受NodeManager汇报的心跳信息并分配任务给NodeManager去执行。一旦某个NodeManager出现故障，标记该NodeManager的任务，并告诉对应的ApplicationMaster如何处理。</li></ul><h6 id="（2）NodeManager"><a href="#（2）NodeManager" class="headerlink" title="（2）NodeManager"></a>（2）NodeManager</h6><p>整个集群有多个NodeManager，负责单节点资源的管理和使用，具体承担的功能包括：</p><ul><li>周期性向ResourceManager汇报本节点上的资源的使用情况和各个Container的运行状态。</li><li>接受并处理来自ApplicationMaster的Container启动&#x2F;停止的各种命令。</li></ul><h6 id="（3）ApplicationMaster"><a href="#（3）ApplicationMaster" class="headerlink" title="（3）ApplicationMaster"></a>（3）ApplicationMaster</h6><p>每个应用程序拥有一个AppliationMaster，负责管理应用资源，具体承担的功能包括：</p><ul><li>数据切分。</li><li>为应用程序&#x2F;作业向ResourceManager申请资源（Container），并分配给内部任务。</li><li>与NodeManager通信，以停止&#x2F;启动任务。</li><li>任务监控和容错，在任务执行失败时重新为该任务申请资源并重启任务。</li><li>接收并处理ResourceManager发出的命令。</li></ul><h4 id="3、试述联邦机制YARN-Federation是为了解决何种问题而设计的，并简述其实现原理"><a href="#3、试述联邦机制YARN-Federation是为了解决何种问题而设计的，并简述其实现原理" class="headerlink" title="3、试述联邦机制YARN Federation是为了解决何种问题而设计的，并简述其实现原理"></a>3、试述联邦机制YARN Federation是为了解决何种问题而设计的，并简述其实现原理</h4><p>YARN可以扩展数千个节点。YARN的可伸缩性由ResourceManager确定，并且与节点数、活跃的应用程序、活跃的容器和心跳概率成比例。降低心跳可以提高可扩展性，但对利用率有害。基于联邦（Federation）的方法，通过联合多个YARN子集，可以将单个YARN集群扩展到数万个节点。YARN Federation是指将大的（10~100千个节点）集群划分成子集群的较小单元，每个集群具有自己的ResourceManager和NodeManager。联合系统（Federation System）将这些子集群拼接在一起，使它们成为应用程序的一个大型YARN集群。在此联合环境中运行的应用程序将看到单个大型YARN集群，并且能够在联合集群的任何节点上计划任务。联合集群将与子集群的ResourceManager协商并为应用程序提供资源，目标是允许单个作业无缝地“跨越”子集群。</p><p>这种设计在结构上是可扩展的，因为通过限制每个ResourceManager负责的节点数量，并且采用适当的策略可保证大多数应用程序驻留在单个子集群中，因此每个ResourceManager看到的应用程序数量也是有限的。这意味着几乎可以通过简单地添加子集的方法来线性扩展。</p><hr><h2 id="第六章-分布式协调框架ZooKeeper"><a href="#第六章-分布式协调框架ZooKeeper" class="headerlink" title="第六章 分布式协调框架ZooKeeper"></a>第六章 分布式协调框架ZooKeeper</h2><p>Apache ZooKeeper是一个分布式的、开放源码的分布式应用程序协调框架，是Geogle Chubby的开源实现，它为大型分布式系统中的各种协调问题提供了一个解决方案，主要用于解决分布式应用中经常遇到的一些数据管理问题，如配置问题、命名服务、分布式同步、集群管理等。</p><p><strong>（详细了解参考书本P155 6.2.4 ZooKeeper的基本概念或者自行百度）</strong></p><h4 id="1、试述ZooKeeper如何保证分布式数据的原子性操作"><a href="#1、试述ZooKeeper如何保证分布式数据的原子性操作" class="headerlink" title="1、试述ZooKeeper如何保证分布式数据的原子性操作"></a>1、试述ZooKeeper如何保证分布式数据的原子性操作</h4><p>ZooKeeper中为数据节点引入了<strong>版本</strong>的概念，每个数据节点都具有三种类型的版本信息，对数据节点的任何更新操作都会引起版本的变化。</p><h6 id="（1）version"><a href="#（1）version" class="headerlink" title="（1）version"></a>（1）version</h6><p>当前数据节点数据内容的版本号<strong>（强调的是变更次数，也是保证分布式数据的原子性操作的关键）</strong></p><h6 id="（2）cversion"><a href="#（2）cversion" class="headerlink" title="（2）cversion"></a>（2）cversion</h6><p>当前数据节点子节点的版本号</p><h6 id="（3）aversion"><a href="#（3）aversion" class="headerlink" title="（3）aversion"></a>（3）aversion</h6><p>当前数据节点的ACl版本号</p><p>ZooKeeper中的版本概念和传统意义上的软件版本有很大的区别，它表示对数据节点的数据内容、子节点列表或节点ACL信息的修改次数。在ZooKeeper中，version属性正是用来<strong>实现乐观锁机制</strong>中的“写入校验”的。在写入校验阶段，事务会检查数据在读取阶段后是否有其他事务对数据进行过更新，以确保数据更新的一致性。</p><h4 id="2、试述ZooKeeper如何保障数据安全"><a href="#2、试述ZooKeeper如何保障数据安全" class="headerlink" title="2、试述ZooKeeper如何保障数据安全"></a>2、试述ZooKeeper如何保障数据安全</h4><p>ZooKeeper提供了一套完善的ACL（Acess Control List）权限控制机制来保障数据的安全。ACL即访问控制列表，是一种相对来说比较新颖且更细粒度的权限管理方式，可以针对任意用户和组进行细粒度的权限控制。</p><h6 id="（1）权限模式"><a href="#（1）权限模式" class="headerlink" title="（1）权限模式"></a>（1）权限模式</h6><p>权限模式用来确定权限验证过程中使用的检验策略。在ZooKeeper中，开发人员使用最多的就是以下四种权限模式。</p><ul><li>IP<ul><li>IP模式通过IP地址粒度进行权限控制。</li></ul></li><li>Digest<ul><li>Digest是最常用的控制权限模式，也更符合对于权限控制的认识，它以类似于“username:password”形式的权限标识来进行权限配置，通过区分不同应用来进行权限控制。但通过“username:password”形式配置了权限标识后，ZooKeeper会对其进行两次编码处理，分别是SHA-1算法加密和BASE64编码。</li></ul></li><li>World<ul><li>World是一种最开放的权限控制模式。事实上这种权限控制方式几乎没有任何作用，数据节点的访问权限对所有用户开放，即所有用户都可以在不进行任何权限校验的情况下操作该数据节点。另外，World模式也可以看作是一种特殊的Digest模式，它只有一个权限标识“world:anyone”。</li></ul></li><li>Super<ul><li>Super模式顾名思义就是超级用户的意思，也是一种特殊的Digest模式。在Super模式下，超级用户可以对任意ZooKeeper上的数据节点进行任何操作。</li></ul></li></ul><h6 id="（2）授权对象【ID】"><a href="#（2）授权对象【ID】" class="headerlink" title="（2）授权对象【ID】"></a>（2）授权对象【ID】</h6><p>授权对象指的是权限赋予的用户或一个指定的实体，例如IP地址或机器等。在不同的授权模式下，授权对象是不同的。</p><h6 id="（3）权限"><a href="#（3）权限" class="headerlink" title="（3）权限"></a>（3）权限</h6><p>权限就是指那些通过权限检查后可以被允许执行的操作。在ZooKeeper中，所有对数据的操作权限被分为以下五大类：</p><ul><li>CREATE【C】：数据节点的创建权限，允许授权对象在该数据节点下创建子节点。</li><li>DELETE【D】：子节点的删除权限，允许授权对象删除该数据节点下的子节点。</li><li>READ【R】：数据节点的读取权限，允许授权对象访问该数据节点并读取其数据内容或子节点列表等。</li><li>WRITE【W】：数据节点的更新权限，允许授权对象对该数据节点进行更新操作。</li><li>ADMIN【A】：数据节点的管理权限，允许授权对象对数据节点进行ACl相关的设置操作。</li></ul><h4 id="3、试述ZooKeeper数据一致性的核心算法ZAB"><a href="#3、试述ZooKeeper数据一致性的核心算法ZAB" class="headerlink" title="3、试述ZooKeeper数据一致性的核心算法ZAB"></a>3、试述ZooKeeper数据一致性的核心算法ZAB</h4><p>ZooKeeper并没有完全采用Paxos算法，而是使用了一种称为ZooKeeper Atomic Broadcast（ZAB，ZooKeeper原子消息广播协议）的协议作为其数据一致性的核心算法。</p><p>ZAB协议是专门为分布式协调系统ZooKeeper设计的一种支持崩溃恢复的原子广播协议。基于该协议ZooKeeper实现了一种主备模式的系统架构来保持集群中各副本之间数据的一致性。具体来说，ZooKeeper使用一个单一的主进程来接收并处理客户端的所有事务请求，并采用ZAB的原子广播协议将服务器数据的状态进行变更，以事务Proposal的形式广播到所有的副本进程上去。ZAB协议的主备模型架构保证了同一时刻集群只能够有一个主进程来广播服务器的状态变更，因此能够很好的处理客户端大量的并发请求。另一方面，考虑到在分布式环境中，顺序执行的一些状态在变更其前后会存在一定的依赖关系，有些状态变更必须依赖于比它早生成的那些状态变更。</p><p>ZAB协议的核心是定义了那些会改变ZooKeeper服务器数据状态的事务请求的处理方式，即所有事务请求必须由一个全局唯一的服务器来协调处理，这个服务器就是Leader，而其他服务器则成为Follower。Leader服务器负责将一个客户端事务请求转换成一个事务Proposal（提议），并将该Proposal分发给集群中的所有Follower，之后Leader需要等待所有Follower的反馈。一旦超过半数Follower服务器进行了正确的反馈后，那么Leader就会再次向所有的Follower分发Commit消息，要求其将前一个Proposal进行提交。</p><h6 id="具体内容"><a href="#具体内容" class="headerlink" title="具体内容"></a>具体内容</h6><p>ZAB协议包括崩溃恢复和消息广播两种基本模式。</p><p>当整个服务器框架在启动过程中，或是当Leader服务器出现网络中断、崩溃推出与重启等异常情况时，ZAB协议就会进入崩溃恢复模式并选举产生新的Leader服务器。当选举产生了新的Leader服务器，同时集群中已经有过半的机器与该Leader服务器完成了状态同步后，ZAB协议就会退出崩溃恢复模式进入消息广播模式。其中，所谓的状态同步是指数据同步，用来保证集群中存在过半的机器能够和Leader服务器的数据状态保持一致。</p><p>ZooKeeper只允许唯一的一个Leader服务器来进行事务请求的处理。Leader服务器在接收到客户端的事务请求后，会生成对应的事务提议并发起一轮广播协议；而如果集群中的其他机器接收到客户端的事务请求，那么这些非Leader服务器会首先将这个事务请求转发给Leader服务器。</p><p>当Leader出现崩溃退出或是机器重启，亦或是集群中已经不存在过半的服务器与该Leader保持正常通信时，那么在重新开始新一轮的原子广播事务操作之前，所有进程首先会使用崩溃恢复协议来使彼此达到一个一致的状态，于是整个ZAB流程就会从消息广播模式进入到崩溃恢复模式。</p><p>一个机器要成为新的Leader，必须获得过半进程的支持，同时由于每个进程都有可能会崩溃，因此，在ZAB协议运行过程中，前后会出现多个Leader，并且每个进程也有可能会多次成为Leader。进入崩溃恢复模式后，只要集群中存在过半的服务器能够彼此进行正常通信，那么就可以产生一个新的Leader并再次进入消息广播模式。</p><hr><h2 id="第七章-分布式数据库HBase"><a href="#第七章-分布式数据库HBase" class="headerlink" title="第七章 分布式数据库HBase"></a>第七章 分布式数据库HBase</h2><h4 id="1、简述HBase数据模型"><a href="#1、简述HBase数据模型" class="headerlink" title="1、简述HBase数据模型"></a>1、简述HBase数据模型</h4><p>逻辑上，HBase以表的形式呈现给最终用户；物理上，HBase以文件的形式存储在HDFS中。为了高效管理数据，HBase设计的一些元数据库表来提高数据存取效率。</p><h6 id="逻辑模型"><a href="#逻辑模型" class="headerlink" title="逻辑模型"></a>逻辑模型</h6><p>HBase以表（Table）的形式存储数据，每个表由行和列组成，每个列属于一个特定的列族（Column Family）。表中行和列确定的存储单元称为一个元素（Cell），每个元素保存了同一份数据的多个版本，由时间戳（Time Stamp）来标识。行键（Row Key）是数据行在表中的唯一标识，并作为检索记录的主键。在HBase中访问表中的行只有三种方式：通过单个行键访问、给定行键的范围扫描、全表扫描。行键可以是任意字符串，默认按字段顺序存储。表中的列定义为&lt;familiy&gt;:&lt;qualifier&gt;（&lt;列族&gt;:&lt;限定符&gt;），通过列族和限定符两部分可以唯一指定一个数据的存储列。元素由行键、列（&lt;列族&gt;:&lt;限定符&gt;）和时间戳唯一确定，元素中的数据以字节码的形式存储，没有类型之分。</p><p><img src="/2022/11/16/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E5%9F%BA%E7%A1%80%E5%A4%87%E8%80%83/7.1HBase%E9%80%BB%E8%BE%91%E6%A8%A1%E5%9E%8B%E8%AE%BE%E8%AE%A1%E7%9A%84%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5%E5%8F%8A%E8%AF%B4%E6%98%8E.jpg" alt="HBase逻辑模型设计的相关概念及说明"></p><h6 id="物理模型"><a href="#物理模型" class="headerlink" title="物理模型"></a>物理模型</h6><p>HBase是按照列存储的稀疏行&#x2F;列矩阵，其物理模型实际上就是把逻辑模型中的一个行进行分割，并按照列族存储。HBase会按照列族分别存储，属于同一个列族的数据保存在一起。同时，和每个列族一起存放的还包括行键和时间戳。</p><p>在表的逻辑视图中，有些列是空的，即这些列不存在值。在物理视图中，这些空的列不会被存储成NULL，而是根本就不会被存储。当请求这些空白单元格的时候，会返回NULL。</p><p>HBase中所有数据文件都存储在HDFS文件系统上，主要包括HFile和HLog两种文件类型。</p><h6 id="元数据表"><a href="#元数据表" class="headerlink" title="元数据表"></a>元数据表</h6><p>HBase的大部分操作都是在HRegionServer中完成，客户端想要插入、删除和查询数据都需要先找到对应的HRegionServer。客户端需要通过两个元数据表来找到HRegionServer和HRegion之间的对应关系，即-ROOT-和.META。它们是HBase的两张系统表，用于管理普通数据，其存储和操作方式与普通表相似，差别在于它们存储的是Region的分布情况和每个Region的详细信息，而不是普通数据。</p><p>HBase使用类似B+树的三层结构来保存Region位置信息。</p><p><img src="/2022/11/16/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E5%9F%BA%E7%A1%80%E5%A4%87%E8%80%83/7.3%E5%85%83%E6%95%B0%E6%8D%AE%E8%A1%A8.jpg" alt="元数据表"></p><h4 id="2、简述HBase的体系架构"><a href="#2、简述HBase的体系架构" class="headerlink" title="2、简述HBase的体系架构"></a>2、简述HBase的体系架构</h4><p>HBase采用Master&#x2F;Slave架构，HBase集群成员包括Client、ZooKeeper集群、HMaster节点、HRegionServer节点。在底层，HBase将数据存储于HDFS中。</p><p><img src="/2022/11/16/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E5%9F%BA%E7%A1%80%E5%A4%87%E8%80%83/7.4HBase%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84.jpg" alt="HBase体系架构"></p><h6 id="（1）Client"><a href="#（1）Client" class="headerlink" title="（1）Client"></a>（1）Client</h6><p>HBase Client使用HBase的RPC机制与HMaster和HRegionServer进行通信。对于管理类操作，Client与HMaster进行RPC；对于数据读&#x2F;写操作，Client与HRegionServer进行RPC。客户端包含访问HBase的接口，通常维护一些缓存来加快HBase数据的访问速度。</p><h6 id="（2）ZooKeeper"><a href="#（2）ZooKeeper" class="headerlink" title="（2）ZooKeeper"></a>（2）ZooKeeper</h6><p>ZooKeeper作为管理者，保证任何时候集群中只有一个Master。对于HBase，ZooKeeper提供以下基本功能：</p><ul><li>存储-ROOT-表、HMaster和HRegionServer的地址。</li><li>通过ZooKeeper，HMaster可以随时感知到各个HRegionServer的健康状态。</li><li>ZooKeeper避免HMaster单点故障问题。HBase中可以启动多个Master，通过ZooKeeper的选举机制确保只有一个为当前HBase集群的Master。</li></ul><h6 id="（3）HMaster"><a href="#（3）HMaster" class="headerlink" title="（3）HMaster"></a>（3）HMaster</h6><p>HMaster是HBase的主服务程序。HBase中可以启动多个HMaster，通过ZooKeeper选举机制保证每个时刻只有一个HMaster运行。HMaster主要完成以下任务：</p><ul><li>管理HRegionServer，实现其负载均衡。</li><li>管理和分配HRegion。</li><li>实现DDL操作，即NameSpace和Table及Column Family的增删改等。</li><li>管理NameSpace和Table的元数据（实际存储在HDFS上）。</li><li>权限控制（ACL）。</li></ul><h6 id="（4）HRegionServer"><a href="#（4）HRegionServer" class="headerlink" title="（4）HRegionServer"></a>（4）HRegionServer</h6><p>HRegionServer是HBase的从服务程序。HBase集群中可以有多个HRegionServer，其主要功能主要包括以下几个方面：</p><ul><li>存放和管理本地HRegion。</li><li>读&#x2F;写HDFS，管理Table中的数据。</li><li>Client直接通过HRegionServer读&#x2F;写数据（从HMaster中获取元数据，找到RowKey所在的HRegion&#x2F;HRegionServer后）进行数据读写。</li><li>HRegionServer和DataNode一般会放在相同的Server上，以实现数据的本地化。</li></ul><hr><h2 id="第八章-数据仓库Hive"><a href="#第八章-数据仓库Hive" class="headerlink" title="第八章 数据仓库Hive"></a>第八章 数据仓库Hive</h2><h4 id="1、简述Hive和传统关系数据库的区别和联系"><a href="#1、简述Hive和传统关系数据库的区别和联系" class="headerlink" title="1、简述Hive和传统关系数据库的区别和联系"></a>1、简述Hive和传统关系数据库的区别和联系</h4><p>Hive由Facebook公司开源，主要用于<strong>解决海量结构化日志数据的离线分析</strong>。Hive是一个基于Hadoop的数据仓库工具，可以将结构化的数据文件映射为一张表，并提供了类SQL查询语言HiveQL。Hive本质是将HiveQL语句转换成MapReduce程序，并提交到Hadoop集群上运行。Hive可让不熟悉MapReduce的开发人员直接编写SQL语句来实现对大规模数据的统计分析操作，大大降低了学习门槛，同时也提升了开发效率。Hive处理的数据存储在HDFS上，分析数据底层的实现是MapReduce，程序运行在YARN上。</p><p><img src="/2022/11/16/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E5%9F%BA%E7%A1%80%E5%A4%87%E8%80%83/8.1Hive%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.jpg" alt="Hive的基本工作流程"></p><p>与传统数据库相比，从内部实现原理和HiveQL语言的运行机制来看，Hive具有如下特征：</p><h6 id="（1）查询语言与SQL接近"><a href="#（1）查询语言与SQL接近" class="headerlink" title="（1）查询语言与SQL接近"></a>（1）查询语言与SQL接近</h6><p>由于SQL被广泛应用在数据仓库中，因此研究人员专门针对Hive的特性设计了类SQL的查询语言HiveQL，熟悉SQL开发的开发者可以很方便地使用Hive进行开发。Hive对查询语句的解释、优化、生成查询计划是由Hive引擎完成的。</p><h6 id="（2）并行执行"><a href="#（2）并行执行" class="headerlink" title="（2）并行执行"></a>（2）并行执行</h6><p>Hive中大多数查询的执行是通用Hadoop提供的MapReduce来实现的，查询计划被转化为MapReduce任务，在Hadoop中执行（注意：有些查询没有MR任务，如select * from table）。而传统数据库通常由自己的执行引擎。</p><h6 id="（3）使用HDFS存储"><a href="#（3）使用HDFS存储" class="headerlink" title="（3）使用HDFS存储"></a>（3）使用HDFS存储</h6><p>Hive是建立在Hadoop之上的，所有Hive数据都存储在HDFS中。而数据库则可以将数据保存在块设备或者本地文件系统中。Hadoop和Hive都采用UTF-8编码。</p><h6 id="（4）支持多种数据格式"><a href="#（4）支持多种数据格式" class="headerlink" title="（4）支持多种数据格式"></a>（4）支持多种数据格式</h6><p>Hive中没有定义专门的数据格式，数据格式可以由用户指定。用户定义数据格式需要指定三个属性，即列分隔符（通常为空格、“\t”、“\x001”）、行分隔符（“\n”）以及读取文件数据的方法（Hive默认的文件格式包括TextFile、SequenceFile、RCFile等）。由于在加载数据的过程中，不需要从用户数据格式到Hive定义的数据格式的转换，因此，Hive在加载的过程中不会对数据本身进行任何修改，只是将数据内容复制或者移动到相应的HDFS目录中。而在数据库中，不同的数据库有不同的存储引擎，定义了自己的数据格式。所有数据都会按照一定的组织存储，因此，数据库加载数据的过程会比较耗时。</p><h6 id="（5）不支持数据更新"><a href="#（5）不支持数据更新" class="headerlink" title="（5）不支持数据更新"></a>（5）不支持数据更新</h6><p>由于Hive是针对数据仓库应用设计的，因此，Hive中不支持对数据的修改和添加，所有的数据都是在加载时确定好的。而数据库中的数据通常是需要反复进行修改的，因此可以使用INSERT INTO…VALUES添加数据，使用UPDATES…SET修改数据。</p><h6 id="（6）不支持索引"><a href="#（6）不支持索引" class="headerlink" title="（6）不支持索引"></a>（6）不支持索引</h6><p>Hive要访问数据中满足条件的特定值时，需要暴力扫描整个数据，因此访问延迟较高。由于MapReduce的引入，Hive可以并行访问数据，因此即使没有索引，对于大数据量的访问，Hive仍然可以体现出优势。在数据库中，通常会针对一个或者几个列建立索引，因此对于少量特定条件的数据的访问，数据库可以有很高的效率和较低的延迟。</p><h6 id="（7）执行延迟高"><a href="#（7）执行延迟高" class="headerlink" title="（7）执行延迟高"></a>（7）执行延迟高</h6><p>Hive在查询数据的时候，由于没有索引，需要扫描整个表，因此延迟较高，另一个导致Hive执行延迟高的因素时MapReduce框架。由于MapReduce本身具有较高的延迟，因此在利用MapReduce执行Hive查询时，也会有较高的延迟。相对来说，数据库的执行延迟较低。当然，这个低是有条件的，即数据规模较小。当数据规模大到超过数据库处理能力的时候，Hive的并行计算优势就能够显现出来了。由于数据的访问延迟较高，决定了Hive不适合在线数据查询。</p><h6 id="（8）可扩展性高"><a href="#（8）可扩展性高" class="headerlink" title="（8）可扩展性高"></a>（8）可扩展性高</h6><p>由于Hive是建立在Hadoop之上的，因此Hive的可扩展性和Hadoop的可扩展性是一致的。而数据库由于ACID语义的严格限制，扩展性非常有限。</p><h6 id="（9）数据规模大"><a href="#（9）数据规模大" class="headerlink" title="（9）数据规模大"></a>（9）数据规模大</h6><p>由于Hive建立在集群上并可以利用MapReduce进行并行计算，因此可以支持很大规模的数据。对应的，数据库可以支持的数据规模较小。</p><h4 id="2、试述Hive的体系架构以及各组件的功能"><a href="#2、试述Hive的体系架构以及各组件的功能" class="headerlink" title="2、试述Hive的体系架构以及各组件的功能"></a>2、试述Hive的体系架构以及各组件的功能</h4><p>Hive通过给用户提供一系列交互接口，接收到用户提交的Hive脚本后，使用自身的驱动器Driver，结合元数据Metastore，将这些脚本翻译成MapReduce，并提交到Hadoop集群中执行，最后将执行结果输出到用户交互接口。</p><p>Hive的体系架构中主要包括如下组件：CLI、JDBC&#x2F;ODBC、Thrift Server、HWI、Metastore和Driver，这些组件可以分为客户端组件和服务端组件两类。另外，Hive还需要Hadoop的支持，它使用HDFS就行存储，使用MapReduce进行计算。</p><p><img src="/2022/11/16/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E5%9F%BA%E7%A1%80%E5%A4%87%E8%80%83/8.2Hive%E7%9A%84%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84.jpg" alt="Hive的体系架构"></p><h5 id="客户端组件"><a href="#客户端组件" class="headerlink" title="客户端组件"></a>客户端组件</h5><h6 id="（1）CLI【Command-Line-Interface】"><a href="#（1）CLI【Command-Line-Interface】" class="headerlink" title="（1）CLI【Command Line Interface】"></a>（1）CLI【Command Line Interface】</h6><p>CLI是Hive命令行接口，是最常用的一种用户接口。CLI启动会同时启动一个Hive副本。CLI是和Hive交互的最简单也是最常用的方式，只需要在一个具备完整Hive环境下的Shell终端中键入hive即可启动服务。不过Hive CLI不适应于高并发的生产环境，仅仅是Hive管理员的好工具。</p><h6 id="（2）JDBC-x2F-ODBC"><a href="#（2）JDBC-x2F-ODBC" class="headerlink" title="（2）JDBC&#x2F;ODBC"></a>（2）JDBC&#x2F;ODBC</h6><p>JDBC是Java DataBase Connection规范，它定义了一系列Java访问各类数据库的访问接口，因此Hive-JDBC其实本质上扮演了一个协议转换的角色，把JDBC标准协议转换为访问Hive Server服务的协议。Hive-JDBC除了扮演网络协议转化的工作，并不承担其他工作，比如SQL的合法性校验和解析等。ODBC是一组对数据库访问的标准API，它的底层实现源码是采用C&#x2F;C++编写的。JDBC&#x2F;ODBC都是通过Hive Client与Hive Server保持通信的，借助Thrift RPC协议来实现交互。</p><h6 id="（3）HWI【Hive-Web-Interface】"><a href="#（3）HWI【Hive-Web-Interface】" class="headerlink" title="（3）HWI【Hive Web Interface】"></a>（3）HWI【Hive Web Interface】</h6><p>HWI是Hive的Web访问接口，提供了一种可以通过浏览器来访问Hive服务的功能。</p><h5 id="服务端组件"><a href="#服务端组件" class="headerlink" title="服务端组件"></a>服务端组件</h5><h6 id="（1）Thrift-Server"><a href="#（1）Thrift-Server" class="headerlink" title="（1）Thrift Server"></a>（1）Thrift Server</h6><p>Thrift是Facebook开发的一个软件框架，它用来进行可扩展且跨语言的服务开发，Hive集成了Thrift Server服务，能让Java、Python等不同的编程语言调用Hive接口。</p><h6 id="（2）元数据【Metastore】"><a href="#（2）元数据【Metastore】" class="headerlink" title="（2）元数据【Metastore】"></a>（2）元数据【Metastore】</h6><p>元数据组件用于存储Hive的元数据，包括表名、表所属的数据库（默认是default）、表的拥有者、列&#x2F;分区字段、表的类型（是否是外部表）、表的数据所在目录等。Hive元数据默认存储在自带的Derby数据库中，推荐使用MySQL存储Metastore。元数据对于Hive十分重要，因此Hive支持把Metastore服务独立出来，安装到远程的服务器集群里，从而解耦Hive服务和Metastore服务，保证Hive运行的健壮性。</p><h6 id="（3）驱动器【Driver】"><a href="#（3）驱动器【Driver】" class="headerlink" title="（3）驱动器【Driver】"></a>（3）驱动器【Driver】</h6><p>驱动器组建的作用是将用户编写的HiveQL语句进行解析、编译、优化，生成执行计划，然后调用底层的MapReduce计算框架。</p><hr><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>写完这篇文档才发现：写的太多了，太详细了。。。足足1w6的字数，也不知道我这敲下来是个什么感受（可能是新键盘到了，还在体验ing）。</p><p>如果你已经能够独立自主的把前言中提到的环境都安装好，并且能够基本使用，那么这篇文档你All In基本上能加深你对Hadoop的基本理解，了解一些你在配环境时背后的意义；但如果你只是为了考试不挂科的话，（额，一般情况下老师也不会挂的）那么你至少要保证h6格式的标题的内容你都能背下来。</p><p>图片纯纯是给会配环境的人看的，而且在敲这篇文档的时候，我一直在反思：Hadoop3.x和Hadoop2.x的区别会不会很大，但是还好，我在敲完后去看了几篇讲解Hadoop3.x新特性的博客后，发现和书本上的内容并不冲突。感兴趣的可以参考如下博客：</p><p><a href="https://blog.csdn.net/web18296061989/article/details/124264120">(269条消息) hadoop 3.0新特性简单介绍_普通网友的博客-CSDN博客_hadoop3.0新特性</a></p><p>大体是在细节方面有了一些优化，但是对于上面敲的，都是鸡蛋里挑骨头了，所以放心看没毛病。不过在配置环境时我才用的已经是CentOS Stream 9、Hadoop3.3.4、JDK11了，技术的迭代肯定会造成许多问题，在配置的时候也遇到了不少的问题，很多地方和书本上也是大相径庭。如果你遇到了问题，可以第一时间——查CSDN，就别Q我了！！尚硅谷的视频是完全按照3.x的特性来讲的，如果你想认真学的话，把那个看完是个不错的选择，但是跟着别人来有时候并不能显著提升自己的水平，我的评价是：可以多去帮别人装装环境。书本上的虽然是2.x的环境，但是安装流程同样使用（大部分情况下）。</p><p>最后，这门课有用吧？真没用！没用吧？或许有用。感兴趣的各位可以学着玩玩，个人建议还是把精力放在同期的分布式上面。</p><p>——Alexie·Z·Yevich</p>]]></content>
      
      
      <categories>
          
          <category> 我的大学 </category>
          
          <category> 大三上学期 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据组件 </tag>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>人工智能导论</title>
      <link href="/2022/07/01/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA/"/>
      <url>/2022/07/01/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA/</url>
      
        <content type="html"><![CDATA[<h1 id="人工智能导论"><a href="#人工智能导论" class="headerlink" title="人工智能导论"></a>人工智能导论</h1><blockquote><p><strong>前言：</strong></p><p>文档完善于考试之后，考试之前天真的认为东西没有多少，所以文档只做了我觉得重点的一小部分，但是考试的时候被噗噗噗打脸了：大题全在我的掌握之中，但是30分选择题真的一个不会，所以在放假初决定还是把这个文档完善一下。但是写到一半发现如果真的全写完实在是太多了，很多东西需要手敲太花时间了，如果不想敲直接贴图又太没有诚意了，所以只完善前五章的内容。之后的内容会在附录中附上页码供大家自行学习参考。——By Alexie-Z-Yevich 2022.7.1</p></blockquote><h2 id="第一章-概述与工具"><a href="#第一章-概述与工具" class="headerlink" title="第一章 概述与工具"></a>第一章 概述与工具</h2><h4 id="1、什么是人工智能？人工智能得研究意义、目标和策略是什么？"><a href="#1、什么是人工智能？人工智能得研究意义、目标和策略是什么？" class="headerlink" title="1、什么是人工智能？人工智能得研究意义、目标和策略是什么？"></a>1、什么是人工智能？人工智能得研究意义、目标和策略是什么？</h4><ul><li><p>概念</p><p>人工智能就是人造智能。具体来讲，目前“人工智能”一词是指用计算机模拟或实现的智能。因此，人工智能又称机器智能。</p></li><li><p>研究目标</p><p>研究目标是制造智能机器和智能系统，实现智能化社会，使计算机不仅具有脑智能和群智能，还要具有看、听、说、写等感知、理解和交流能力。要使计算机具有自主发现规律、解决问题和发明创造的能力，从而大大扩展和延伸人的智能，实现人类社会的全面智能化。</p></li><li><p>研究策略</p><p>先部分地或某种程度地实现机器的智能，并运用智能技术解决各种实际问题特别是工程问题，从而使现有的计算机更灵活、更好用和更有用，成为人类的智能化信息处理工具，进而逐步扩展和延伸人的智能，实现智能化。</p></li></ul><hr><h4 id="2、人工智能有哪些研究途径和方法？他们的关系如何？"><a href="#2、人工智能有哪些研究途径和方法？他们的关系如何？" class="headerlink" title="2、人工智能有哪些研究途径和方法？他们的关系如何？"></a>2、人工智能有哪些研究途径和方法？他们的关系如何？</h4><ul><li><p>研究途径和方法<br>基于脑智能的符号智能和基于群智能的计算智能是人工智能的两种研究途径与方法，但仍可细分：</p><ul><li>心理模拟，符号推演：从人脑的宏观心理层面入手，以智能行为的心理模型为依据，将问题或知识表示成某种逻辑网络，采用符号推演的方法，模拟人脑的逻辑思维过程，实现人工智能。</li><li>生物模拟，神经计算：从人脑的生理层面，即微观结构和工作机理入手，以智能行为的生理模型为依据，采用数值计算的方法，模拟脑神经网络工作的过程，实现人工智能。人工神经网络作为信息和知识的载体，用称为神经计算的数值计算方法来实现网络的学习、记忆、联想、识别和推理等功能。</li><li>行为模拟，控制进化：模拟人和动物在与环境的交互、控制过程中的智能活动和行为特性，如反应、适应、学习、寻优等，来研究和实现人工智能。</li><li>群体模拟，仿生计算：模拟生物群落的群体智能行为，从而实现人工智能。</li><li>博采广鉴，自然计算：模拟自然智能。</li><li>着眼数据，统计建模：着眼于事务或问题的外部表现和关系，收集、采集、整理相关信息并做成样本数据，然后基于样本数据用统计学、概率论和其他数学理论和方法建立数学模型，并采用适当的算法和策略进行计算，以期从事务外在表现的样本数据中推测事物的内在模式或规律，并用之于解决相关实际问题。</li></ul></li><li><p>关系</p><p>并不能互相取代，而是并存和互补的关系。</p></li></ul><hr><h4 id="3、人工智能有哪些研究内容？（考试简答5分）"><a href="#3、人工智能有哪些研究内容？（考试简答5分）" class="headerlink" title="3、人工智能有哪些研究内容？（考试简答5分）"></a>3、人工智能有哪些研究内容？（考试简答5分）</h4><p>研究内容归纳为：搜索与求解、知识与推理、学习和发现、发明和创造、感知与相应、理解与交流、记忆与联想、竞争与协作、</p><p>系统与建造、应用与工程等十个方面。（具体内容书P8-P11）</p><hr><h4 id="4、人工智能有哪些分支领域和研究方向？"><a href="#4、人工智能有哪些分支领域和研究方向？" class="headerlink" title="4、人工智能有哪些分支领域和研究方向？"></a>4、人工智能有哪些分支领域和研究方向？</h4><p>从研究内容上看，人工智能可分为搜索与求解、知识与推理、学习和发现等十大分支领域（它们构成了人工智能学科的总体方向）。</p><p>从研究途径和智能层次来看，人工智能可分为符号智能、计算智能、统计智能和交互智能等四大分支领域。</p><hr><h4 id="5、人工智能有哪些应用领域或课题？"><a href="#5、人工智能有哪些应用领域或课题？" class="headerlink" title="5、人工智能有哪些应用领域或课题？"></a>5、人工智能有哪些应用领域或课题？</h4><ul><li>难题求解</li><li>自动规划、调度与配置</li><li>机器博弈</li><li>机器翻译与机器写作</li><li>机器定理证明</li><li>自动程序设计</li><li>智能控制</li><li>智能管理</li><li>智能决策</li><li>智能通信</li><li>智能预测</li><li>智能仿真</li><li>智能设计与制造</li><li>智能车辆与智能交通</li><li>智能诊断与治疗</li><li>智能生物信息处理</li><li>智能教育</li><li>智能人-机接口</li><li>模式识别</li><li>智能机器人</li><li>数据挖掘与知识发现</li><li>计算机辅助创新</li><li>计算机文艺创作</li></ul><hr><h4 id="6、简述人工智能的发展概况"><a href="#6、简述人工智能的发展概况" class="headerlink" title="6、简述人工智能的发展概况"></a>6、简述人工智能的发展概况</h4><ul><li><p>孕育与诞生</p><p>正式诞生于1956年。</p></li><li><p>符号主义先声夺人</p><p>1956年，逻辑理论机的计算机程序系统，模拟了人用数理逻辑证明定理时的思维逻辑规律；研制成功具有自学习、自组织、自适应能力的跳棋程序；</p><p>1959年，证明平面几何问题的程序；模式识别程序；</p><p>1960年，通用问题求解程序；面向人工智能程序设计的表处理语言LISP；</p><p>1965年，可以分辨积木构造的程序；消解原理；基于领域知识和专家知识的名为DENDRL的程序系统（专家系统）</p></li><li><p>连接主义不畏坎坷</p><p>1943年，形式神经元的数学模型（MP模型）；</p><p>1944年，改变神经元连接强度的Hebb规则；</p><p>1957年，称为感知器的单层神经网络；</p><p>1962年，自适应线性元件；</p><p>1985年，开发了名为NETtalk英语读音学习用的神经网络处理器；</p><p>1987年6月，第一届国际神经网络会议召开。</p></li><li><p>计算智能异军突起</p><p>1962年，进化程序设计（进化规划的概念和方法）；</p><p>1964年，进化策略的搜索算法；</p><p>1967年，遗传算法的初步思想；</p><p>1975年，遗传算法的理论基础；</p><p>1980年，实现基于遗传算法的机器学习系统——分类器系统；</p><p>1994年，首届计算智能大会。</p></li><li><p>统计智能默默奉献</p></li><li><p>智能主体一统江湖，Agent&amp;Robot</p></li><li><p>知识工程东山再起，机器学习领衔高歌</p></li><li><p>现状与趋势</p><ul><li>多种方法齐头并进，多种方法协作互补</li><li>新思想、新技术不断涌现，新领域、新方向不断开拓</li><li>理论研究更加深入，应用研究愈发广泛</li><li>企业公司进军AI，协作竞争你追我赶</li><li>研究队伍日益壮大，AI教育蔚然成风</li><li>各类活动空前活跃，社会影响与日俱增</li></ul></li></ul><hr><h2 id="第三章-图搜索于问题求解"><a href="#第三章-图搜索于问题求解" class="headerlink" title="第三章 图搜索于问题求解"></a>第三章 图搜索于问题求解</h2><p>下文所提到的OPEN表和CLOSE表样式：</p><ul><li>OPEN表</li></ul><table><thead><tr><th align="center">节点</th><th align="center">父节点编号</th></tr></thead><tbody><tr><td align="center"></td><td align="center"></td></tr><tr><td align="center"></td><td align="center"></td></tr></tbody></table><ul><li>CLOSE表</li></ul><table><thead><tr><th align="center">编号</th><th align="center">节点</th><th align="center">父节点编号</th></tr></thead><tbody><tr><td align="center"></td><td align="center"></td><td align="center"></td></tr><tr><td align="center"></td><td align="center"></td><td align="center"></td></tr></tbody></table><h4 id="1、状态图搜索"><a href="#1、状态图搜索" class="headerlink" title="1、状态图搜索"></a>1、状态图搜索</h4><h6 id="（1）树式搜索算法"><a href="#（1）树式搜索算法" class="headerlink" title="（1）树式搜索算法"></a>（1）树式搜索算法</h6><p>【1】把初始节点S0放入OPEN表中。</p><p>【2】若OPEN表为空，则搜索失败，退出。</p><p>【3】移出OPEN表中的第一个节点N放入CLOSE表中，并冠以顺序序号n。</p><p>【4】若目标节点Sg &#x3D; N，则搜索成功，结束。</p><p>【5】若N不可扩展，则转【2】。</p><p>【6】扩展N，生成一组子节点，对这组子节点做如下处理：</p><ul><li>删除N的先辈节点（如果有的话）。</li><li>对已存在OPEN表的节点（如果有的话）也删除之；但删除之前要比较其返回初始节点的新路径与原路径，如果新路径”短“，则修改这些节点在OPEN表中的原返回指针，使其沿新路径返回。</li><li>对已存在于CLOSE表中的节点（如果有的话）做与上面一样的处理，并且再将其移出CLOSE表，放入OPEN表重新扩展（为了重新计算代价）。</li><li>对其余子节点配上指向N的返回指针后放入OPEN表中某处，或对OPEN表进行重新排序，转【2】.</li></ul><p><img src="/2022/07/01/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA/%E7%8A%B6%E6%80%81%E5%9B%BE%E6%90%9C%E7%B4%A2%E8%BF%87%E7%A8%8B%E4%B8%AD%E4%BF%AE%E6%94%B9%E8%BF%94%E5%9B%9E%E6%8C%87%E9%92%88%E7%A4%BA%E4%BE%8B.jpg" alt="状态图搜索过程中修改返回指针示例"></p><p><strong>说明：</strong></p><p>【1】这里的返回指针也就是父节点在CLOSE表中的编号。</p><p>【2】步骤【6】中修改返回指针的原因是，这些节点又被二次生成，所以他们返回初始路径的节点已有两条，但这两条路径的”长度“可能不同。当新路径短时就会走新路径。</p><p>【3】这里路径的长短是按路径上的节点数来衡量的,后面将会看到路径的长短也可以按其“代价”(如距离﹑费用,时间等)衡量。若按其代价衡量,则在需修改返回指针的同时修改相应的代价值,或者不修改返回指针但要修改代价值(为了实现代价小者优先扩展)。</p><h6 id="（2）不回溯的线式搜索"><a href="#（2）不回溯的线式搜索" class="headerlink" title="（2）不回溯的线式搜索"></a>（2）不回溯的线式搜索</h6><p>【1】把初始节点S0。放入CLOSED表中。</p><p>【2】令N&#x3D;S0。</p><p>【3】若N是目标节点,则搜索成功,结束。</p><p>【4】若N不可扩展,则搜索失败,退出。</p><p>【5】扩展N,选取其一个未在CLOSED表中出现过的子节点N1放入CLOSED表中,令N&#x3D;N1，转步骤【3】。</p><h6 id="（3）可回溯的线式搜索"><a href="#（3）可回溯的线式搜索" class="headerlink" title="（3）可回溯的线式搜索"></a>（3）可回溯的线式搜索</h6><p>【1】把初始节点S0。放入CLOSED表中。</p><p>【2】令N&#x3D;S0。</p><p>【3】若N是目标节点,则搜索成功,结束。</p><p>【4】若N不可扩展,则移出CLOSED表的末端节点Ne,若Ne&#x3D;S0,则搜索失败,退出。否则,以CLOSED表新的末端节点N。作为N,即令N&#x3D;Ne。,转步骤(3)。</p><p>【5】扩展N,选取其一个未在CLOSED表中出现过的子节点N,,放人CLOSED 表中,令N&#x3D;N1，转步骤【3】。</p><h6 id="（4）广度优先搜索算法"><a href="#（4）广度优先搜索算法" class="headerlink" title="（4）广度优先搜索算法"></a>（4）广度优先搜索算法</h6><p>【1】把初始节点S0放入OPEN表中。</p><p>【2】若OPEN表为空，则搜索失败，退出。</p><p>【3】移出OPEN表中的第一个节点N放入CLOSE表中，并冠以顺序序号n。</p><p>【4】若目标节点Sg &#x3D; N，则搜索成功，结束。</p><p>【5】若N不可扩展，则转【2】。</p><p>【6】扩展N，将其所有的子节点配上指向N的指针依次放入OPEN表尾部，转步骤【2】。</p><h6 id="（5）深度优先搜索"><a href="#（5）深度优先搜索" class="headerlink" title="（5）深度优先搜索"></a>（5）深度优先搜索</h6><p>【1】把初始节点S0放入OPEN表中。</p><p>【2】若OPEN表为空，则搜索失败，退出。</p><p>【3】移出OPEN表中的第一个节点N放入CLOSE表中，并冠以顺序序号n。</p><p>【4】若目标节点Sg &#x3D; N，则搜索成功，结束。</p><p>【5】若N不可扩展，则转【2】。</p><p>【6】扩展N，将其所有的子节点配上指向N的返回指针依次放入OPEN表的首部，转步骤【2】。</p><h6 id="（6）有界深度优先搜索"><a href="#（6）有界深度优先搜索" class="headerlink" title="（6）有界深度优先搜索"></a>（6）有界深度优先搜索</h6><p>【1】把初始节点S0放入OPEN表中，置S0的深度d（S0）&#x3D;0。</p><p>【2】若OPEN表为空，则搜索失败，退出。</p><p>【3】移出OPEN表中的第一个节点N放入CLOSE表中，并冠以顺序序号n。</p><p>【4】若目标节点Sg &#x3D; N，则搜索成功，结束。</p><p>【5】若N的深度d（N）&#x3D; dm（深度限制值），或者N无子节点，则转【2】。</p><p>【6】扩展N，将其所有的子节点配上指向N的返回指针依次放入OPEN表中前部，置d（Ni） &#x3D; d（N）+ 1，转步骤【2】。</p><hr><h4 id="2、启发式搜索"><a href="#2、启发式搜索" class="headerlink" title="2、启发式搜索"></a>2、启发式搜索</h4><h6 id="（1）全局择优搜索（考试大题10分）"><a href="#（1）全局择优搜索（考试大题10分）" class="headerlink" title="（1）全局择优搜索（考试大题10分）"></a>（1）全局择优搜索（考试大题10分）</h6><p><img src="/2022/07/01/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA/%E5%85%A8%E5%B1%80%E6%8B%A9%E4%BC%98%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95.png" alt="全局择优搜索算法"></p><p><img src="/2022/07/01/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA/%E5%A4%A7%E9%A2%981.png" alt="大题1"></p><h6 id="（2）A算法"><a href="#（2）A算法" class="headerlink" title="（2）A算法"></a>（2）A算法</h6><p><img src="/2022/07/01/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA/A%E7%AE%97%E6%B3%951.png" alt="A算法1"></p><p><img src="/2022/07/01/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA/A%E7%AE%97%E6%B3%952.png" alt="A算法2"></p><hr><h2 id="第四章-基于遗传算法的随即优化搜索"><a href="#第四章-基于遗传算法的随即优化搜索" class="headerlink" title="第四章 基于遗传算法的随即优化搜索"></a>第四章 基于遗传算法的随即优化搜索</h2><h4 id="1、基本遗传算法"><a href="#1、基本遗传算法" class="headerlink" title="1、基本遗传算法"></a>1、基本遗传算法</h4><h6 id="（1）流程图"><a href="#（1）流程图" class="headerlink" title="（1）流程图"></a>（1）流程图</h6><p><img src="/2022/07/01/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA/%E5%9F%BA%E6%9C%AC%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B%E5%9B%BE.png" alt="基本遗传算法流程图"></p><h6 id="（2）具体描述"><a href="#（2）具体描述" class="headerlink" title="（2）具体描述"></a>（2）具体描述</h6><p><img src="/2022/07/01/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA/%E5%9F%BA%E6%9C%AC%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E5%85%B7%E4%BD%93%E6%8F%8F%E8%BF%B0.png" alt="基本遗传算法具体描述"></p><h6 id="（3）具体实例"><a href="#（3）具体实例" class="headerlink" title="（3）具体实例"></a>（3）具体实例</h6><p>详情见书P90-P93例题4-1、4-2，要求理解两个例题的具体步骤，实操要求在老师上机课时基本了解数据集内容以及调用库作用。</p><hr><h2 id="第五章-基于一阶谓词的机器推理"><a href="#第五章-基于一阶谓词的机器推理" class="headerlink" title="第五章 基于一阶谓词的机器推理"></a>第五章 基于一阶谓词的机器推理</h2><p>基于一阶谓词的机器推理也称自动推理，它是早期人工智能的主要研究内容之一。一阶谓词是一种表达力很强的形式语言，而且这种语言很适合数字计算机处理，因而称为知识表示的首选。</p><p>简单的知识介绍还请各位参照书本，这里不做过多讲解。</p><h4 id="1、常用逻辑等价式"><a href="#1、常用逻辑等价式" class="headerlink" title="1、常用逻辑等价式"></a>1、常用逻辑等价式</h4><p>$$<br>\begin{align}<br>(1) &amp;\neg \neg P \Leftrightarrow P 【双重否定律】 \<br>(2) &amp;P \land Q \Leftrightarrow Q \land P \<br>&amp;P \lor Q \Leftrightarrow Q \lor P 【交换律】\<br>(3) &amp; P \land (Q \lor R) \Leftrightarrow (P \land Q) \lor (P \land R) \<br>&amp; P \lor (Q \land R) \Leftrightarrow (P \lor Q) \land (P \lor R) 【分配律】\<br>(4) &amp; \neg (P \land Q) \Leftrightarrow \neg P \lor \neg Q \<br>&amp; \neg (P \lor Q) \Leftrightarrow \neg P \land \neg Q 【摩根律】\<br>(5) &amp; P \longrightarrow Q \Leftrightarrow \neg P \lor Q 【蕴含表达式】\<br>(6) &amp; P \longrightarrow Q \Leftrightarrow \neg Q \longrightarrow \neg P 【逆否式】\<br>(7) &amp; \forall x (A(x) \land B(x)) \Leftrightarrow \forall x A(x) \land \forall x B(x) \<br>&amp; \exists x (A(x) \lor B(x)) \Leftrightarrow \exists x A(x) \lor \exists x B(x) 【量词分配律】\<br>(8) &amp; \neg \forall xA(x) \Leftrightarrow \exists x \neg A(x) \<br>&amp; \neg \exists xA(x) \Leftrightarrow \forall x \neg A(x) 【量词转换律】\<br>\end{align}<br>$$</p><p>具体的使用参见书上例题5-5~5-7（<strong>一定要看</strong>）</p><hr><h4 id="2、归结演绎推理"><a href="#2、归结演绎推理" class="headerlink" title="2、归结演绎推理"></a>2、归结演绎推理</h4><h6 id="1、子句与子句集"><a href="#1、子句与子句集" class="headerlink" title="1、子句与子句集"></a>1、子句与子句集</h6><p>原子谓词公式及其否定称为文字，若干个文字的一个析取式称为一个子句，由r个文字组成的子句叫r-文字子句，l-文字子句叫单元子句，不含任何文字的子句称为空子句，记为□或NIL。</p><p>对一个谓词公式G，通过一下步骤得到的子句集和S称为G的子句集：</p><p>【1】消去蕴含式→和等值词↔。<strong>（去箭头）</strong></p><p>【2】缩小否定词的作用范围，直到其仅作用于原子公式。<strong>（消括号&amp;将┐放在存在量词和全称量词里面）</strong></p><p>【3】适当改名，使量词间不含同名指导变元和约束变元。<br>【4】消去存在量词。</p><p>【5】消去所有全称量词。</p><p>【6】化公式为合取范式。</p><p>【7】适当改名，使子句间无同名变元。</p><p>【8】消去合取词∧，以子句为元素组成一个集合S。</p><h6 id="2、归结原理"><a href="#2、归结原理" class="headerlink" title="2、归结原理"></a>2、归结原理</h6><p>归结演绎推理是基于一种称为归结原理（也称为消解原理）的推理规则的推理方法。它是谓词逻辑中一个相当有效的机械化推理方法。归结原理的出现，被认为是自动推理，特别是定理机器证明领域的重大突破。</p><h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><h4 id="大题部分（考试前参考）"><a href="#大题部分（考试前参考）" class="headerlink" title="大题部分（考试前参考）"></a>大题部分（考试前参考）</h4><h6 id="1、遗传算法（参照P90例4-1）（考试大题10分）"><a href="#1、遗传算法（参照P90例4-1）（考试大题10分）" class="headerlink" title="1、遗传算法（参照P90例4-1）（考试大题10分）"></a>1、遗传算法（参照P90例4-1）（考试大题10分）</h6><ul><li>适应度计算（根据公式）</li><li>选择-复制（根据概率）、交叉（交换部分）、变异（变化部分）</li></ul><h6 id="2、一阶谓词推理（考试大题20分）"><a href="#2、一阶谓词推理（考试大题20分）" class="headerlink" title="2、一阶谓词推理（考试大题20分）"></a>2、一阶谓词推理（考试大题20分）</h6><p>详见第五章部分内容，例题可以参考课后习题。</p><ul><li>将句子用一阶谓词表示；</li><li>求解谓词公式的子句集；</li><li>利用归结原理证明。</li></ul><h6 id="3、产生式规则"><a href="#3、产生式规则" class="headerlink" title="3、产生式规则"></a>3、产生式规则</h6><p>简单概率问题，能看懂图会画就行。</p><h6 id="4、决策树（P210）（考试大题15分）"><a href="#4、决策树（P210）（考试大题15分）" class="headerlink" title="4、决策树（P210）（考试大题15分）"></a>4、决策树（P210）（考试大题15分）</h6><ul><li>信息熵和条件熵公式</li></ul><h6 id="5、K-均值聚类算法（P261-P268）（考试大题5分）"><a href="#5、K-均值聚类算法（P261-P268）（考试大题5分）" class="headerlink" title="5、K-均值聚类算法（P261-P268）（考试大题5分）"></a>5、K-均值聚类算法（P261-P268）（考试大题5分）</h6><h4 id="未补全章节"><a href="#未补全章节" class="headerlink" title="未补全章节"></a>未补全章节</h4><h5 id="第七章-几种结构化知识表示及其推理"><a href="#第七章-几种结构化知识表示及其推理" class="headerlink" title="第七章 几种结构化知识表示及其推理"></a>第七章 几种结构化知识表示及其推理</h5><h6 id="1、元组的概念（P143）"><a href="#1、元组的概念（P143）" class="headerlink" title="1、元组的概念（P143）"></a>1、元组的概念（P143）</h6><h6 id="2、框架的概念（P144）"><a href="#2、框架的概念（P144）" class="headerlink" title="2、框架的概念（P144）"></a>2、框架的概念（P144）</h6><hr><h5 id="第八章-不确定和不确定性知识的表示与推理"><a href="#第八章-不确定和不确定性知识的表示与推理" class="headerlink" title="第八章 不确定和不确定性知识的表示与推理"></a>第八章 不确定和不确定性知识的表示与推理</h5><h6 id="基于贝叶斯网络的概率推理（P172-P176）"><a href="#基于贝叶斯网络的概率推理（P172-P176）" class="headerlink" title="基于贝叶斯网络的概率推理（P172-P176）"></a>基于贝叶斯网络的概率推理（P172-P176）</h6><p>重点在于P175的诊断推理中的计算：（考试原题）</p><p><img src="/2022/07/01/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BD%91%E7%BB%9C1.png" alt="贝叶斯网络1"></p><p><img src="/2022/07/01/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BD%91%E7%BB%9C2.png" alt="贝叶斯网络2"></p><p><img src="/2022/07/01/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BD%91%E7%BB%9C3.png" alt="贝叶斯网络2"></p><hr><h5 id="第九章-机器学习：符号学习与交互学习"><a href="#第九章-机器学习：符号学习与交互学习" class="headerlink" title="第九章 机器学习：符号学习与交互学习"></a>第九章 机器学习：符号学习与交互学习</h5><h6 id="决策树学习（P205-P212）"><a href="#决策树学习（P205-P212）" class="headerlink" title="决策树学习（P205-P212）"></a>决策树学习（P205-P212）</h6><p>重点在于P210决策树的ID3算法，需要了解整个流程，能够独立写出P211的所有内容并得出最终结论。</p><hr><h5 id="第十二章-数据挖掘与知识发现"><a href="#第十二章-数据挖掘与知识发现" class="headerlink" title="第十二章 数据挖掘与知识发现"></a>第十二章 数据挖掘与知识发现</h5><h6 id="k-均值聚类算法（P261关联规则开始到P268）"><a href="#k-均值聚类算法（P261关联规则开始到P268）" class="headerlink" title="k-均值聚类算法（P261关联规则开始到P268）"></a>k-均值聚类算法（P261关联规则开始到P268）</h6><p>重点不在书本上，建议自学的话直接在B站上搜索k-均值聚类算法。推荐一个我当时学习的视频：</p><p><a href="https://www.bilibili.com/video/BV1py4y1r7DN?spm_id_from=333.337.search-card.all.click&vd_source=a81ef8427e696b92de364d833142bd10">https://www.bilibili.com/video/BV1py4y1r7DN?spm_id_from=333.337.search-card.all.click&amp;vd_source=a81ef8427e696b92de364d833142bd10</a></p><p><img src="/2022/07/01/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA/k-%E5%9D%87%E5%80%BC%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E8%A7%86%E9%A2%91%E6%8E%A8%E8%8D%90.png" alt="k-均值聚类算法视频推荐"></p><p>笔记鲨UP主的这一系列非常适合算法类（单指人工智能导论中常用的几个）的入门，有时间的话可以都看一下，讲的比较简单也十分容易懂，完成考试内容是完全没有问题的。</p><p>k-均值聚类算法主要还是了解一下算法的具体流程以及簇心的更新、选择流程，考试中占的分值并不大。</p><hr><h5 id="第十六章-专家（知识）系统"><a href="#第十六章-专家（知识）系统" class="headerlink" title="第十六章 专家（知识）系统"></a>第十六章 专家（知识）系统</h5><p>这里我的建议是都看，选择题至少出了三个专家系统，包括专家系统的概念结构、黑板模型等一系列问题，因为我只是粗略的看了下所以考试时选择题基本都不会，全靠大题拉分。所以我的建议是All In。专家系统也是很多学科都会介绍的内容，这里多看点，深入了解绝对不亏的啦！</p>]]></content>
      
      
      <categories>
          
          <category> 我的大学 </category>
          
          <category> 大二下学期 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> 人工智能 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计算智能导论</title>
      <link href="/2022/07/01/%E8%AE%A1%E7%AE%97%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA/"/>
      <url>/2022/07/01/%E8%AE%A1%E7%AE%97%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA/</url>
      
        <content type="html"><![CDATA[<h1 id="计算智能导论"><a href="#计算智能导论" class="headerlink" title="计算智能导论"></a>计算智能导论</h1><blockquote><p><strong>前言：</strong></p><p>首先，这是自用的复习资料，发出来如果未来被本校学弟学妹看见了那是属实荣幸；其次，这本书本身就是有不少问题的，如果在我的文档里发现了bug不要惊慌，属于正常操作，有能力的话还请更改了之后push到Github并在最后留下你的足迹；最后，这只是一个零基础学渣在考前一周的复习，内容完全按照考点来设置，建议给人预习留个念想啥的，以及给摆烂人最后突击用的。</p><p>修改于2022&#x2F;7&#x2F;1，已经考完试了，现在的版本是在原有基础上对整个文档进行的一个补充完善，通过从考试的试卷来阐述只需要完善的复习要点，所有内容都放在第4章之后的2.0补充内容中。</p></blockquote><hr><h2 id="第1章-绪论——从人工智能到计算智能"><a href="#第1章-绪论——从人工智能到计算智能" class="headerlink" title="第1章 绪论——从人工智能到计算智能"></a>第1章 绪论——从人工智能到计算智能</h2><h4 id="1、计算智能定义（P11）"><a href="#1、计算智能定义（P11）" class="headerlink" title="1、计算智能定义（P11）"></a>1、计算智能定义（P11）</h4><p>计算智能系统是在<strong>神经网络、模糊系统、进化计算</strong>三个分支发展相对成熟的基础上，通过相互之间的有机融合而形成的新的科学方法，也是智能理论和技术发展的崭新阶段。当一个系统仅仅处理底层数据，具有模式识别的部分，并且不使用AI意义中的知识，那么这个系统就是计算智能系统。</p><hr><h4 id="2、人工神经网络的特点（P10）"><a href="#2、人工神经网络的特点（P10）" class="headerlink" title="2、人工神经网络的特点（P10）"></a>2、人工神经网络的特点（P10）</h4><p>（1）信息的分布表示记忆在大量神经元中。每个神经元存储许多信息的部分内容，信息在神经网络中的记忆反映在神经元间突触的连接强度上。</p><p>（2）神经网络运算的全局并行和局部操作。神经网络具有高度的并行结构和并行实现能力，因而有较好的耐故障能力和较快的总体处理能力。</p><p>（3）处理的非线性。神经网络具有非线性特性，这源于其近似任何非线性映射（变换）的能力。</p><p>（4）较强的学习能力。神经网络是通过研究系统过去的数据记录进行训练的。一个经过适当训练的神经系统具有归纳全部数据，因此，神经网络能够解决那些由数学模型或描述规则难以处理的控制过程的问题。</p><hr><h2 id="第2章-进化算法"><a href="#第2章-进化算法" class="headerlink" title="第2章 进化算法"></a>第2章 进化算法</h2><h4 id="1、遗传算法的基本框架（P40）"><a href="#1、遗传算法的基本框架（P40）" class="headerlink" title="1、遗传算法的基本框架（P40）"></a>1、遗传算法的基本框架（P40）</h4><p><img src="/2022/07/01/%E8%AE%A1%E7%AE%97%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A1%86%E6%9E%B6.png" alt="遗传算法的基本框架"></p><hr><h4 id="2、遗传算法的优点（P40）"><a href="#2、遗传算法的优点（P40）" class="headerlink" title="2、遗传算法的优点（P40）"></a>2、遗传算法的优点（P40）</h4><p>（1）<strong>遗传算法直接以目标函数值作为搜索信息。</strong>传统的优化算法往往不只需要目标函数值，还需要目标函数的导数等其他信息，这样对于许多函数无法求导或很难求导的函数，遗传算法就比较方便。</p><p>（2）<strong>遗传算法同时进行解空间的多点搜索。</strong>传统的优化算法往往从解空间的一个初始节点开始搜索，这样容易陷入局部极值点。遗传算法进行群体搜索，并且在搜索的过程中引入遗传运算，使群体又可以不断进化，这些是遗传算法所特有的一种隐含并行性，因此，遗传算法更适合大规模复杂问题的优化。</p><p>（3）<strong>遗传算法使用概率搜索技术。</strong>遗传算法属于一种自适应概率搜索技术，其选择、交叉、变异等运算都是以一种概率的方式来进行的，从而增加了其搜索过程的灵活性。实践和理论都已证明，在一定条件下遗传算法总是以概率1收敛于问题的最优解。</p><p>（4）<strong>遗传算法在解空间进行高效启发式搜索</strong>，而非盲目地穷举或完全随机搜索。</p><p>（5）<strong>遗传算法计算简单、功能强。</strong></p><hr><h4 id="3、遗传算法的五个关键问题（P41）"><a href="#3、遗传算法的五个关键问题（P41）" class="headerlink" title="3、遗传算法的五个关键问题（P41）"></a>3、遗传算法的五个关键问题（P41）</h4><p>（1）对问题的潜在解进行基因的表示，即<strong>编码问题</strong>。</p><p>（2）构建一组潜在的解决方案，即<strong>种群初始化问题</strong>。</p><p>（3）根据潜在解的适应性来评价解的好坏，即<strong>个体评价问题</strong>。</p><p>（4）改变后代基因组成的遗传算子（选择、交叉、变异等），即<strong>遗传算子问题</strong>。</p><p>（5）设置遗传算法所用的参数值（种群大小、应用遗传算子的概率等），即<strong>参数选择问题</strong>。</p><hr><h4 id="4、遗传编码（P41）"><a href="#4、遗传编码（P41）" class="headerlink" title="4、遗传编码（P41）"></a>4、遗传编码（P41）</h4><h6 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h6><p>由问题空间向GA编码空间的映射称为编码，而由编码空间向问题空间的映射称为译码。</p><h6 id="1、编码的分类"><a href="#1、编码的分类" class="headerlink" title="1、编码的分类"></a>1、编码的分类</h6><p>（1）根据采用的符号，编码可以分为<strong>二进制编码、实数编码和整数排列编码</strong>等。</p><p>（2）根据编码采用的结构，编码可以分为<strong>一维编码</strong>和<strong>多维编码</strong>。</p><p>（3）根据编码采用的长度，编码可分为<strong>固定长度编码</strong>和<strong>可变长度编码</strong>。</p><p>（4）根据编码的内容，编码可分为<strong>仅对解进行编码的方法</strong>和<strong>对解+参数进行编码的方法</strong>.</p><h6 id="2、码空间和解空间"><a href="#2、码空间和解空间" class="headerlink" title="2、码空间和解空间"></a>2、码空间和解空间</h6><p>遗传算法的一个特点就是个体存在于码空间和解空间：<strong>遗传操作在码空间，而评价和选择在解空间</strong>，通过自然选择将染色体和解连接起来。</p><p><img src="/2022/07/01/%E8%AE%A1%E7%AE%97%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA/%E9%81%97%E4%BC%A0%E7%AE%97%E5%AD%90.png" alt="遗传算子"></p><h6 id="3、非字符编码的三个问题"><a href="#3、非字符编码的三个问题" class="headerlink" title="3、非字符编码的三个问题"></a>3、非字符编码的三个问题</h6><p>（1）<strong>染色体的可行性</strong>，是指染色体经过解码之后，是否存在于给定问题的可行域。</p><p>（2）<strong>染色体的合法性</strong>，编码空间中的染色体必须对应问题空间中的某一潜在解，即每个编码必须有意义。</p><p>（3）<strong>映射的唯一性</strong>，染色体和潜在解必须一一对应。</p><h6 id="4、编码性能评价"><a href="#4、编码性能评价" class="headerlink" title="4、编码性能评价"></a>4、编码性能评价</h6><p>码空间到解空间有以下三种情况：1对1映射、n对1映射和1对n映射。</p><p>1对1映射是三种映射中最好的；1对n映射是三种映射中最差的，存在适应度评价问题；n对1映射则会存在资源的浪费。</p><p>（1）<strong>不冗余</strong>：码空间到解空间是1对1映射；</p><p>（2）<strong>合法性</strong>：对编码的任意排列对应一个解；</p><p>（3）<strong>完备性</strong>：任意一个解都对应一个排列。</p><hr><h4 id="5、适应度函数（P54）"><a href="#5、适应度函数（P54）" class="headerlink" title="5、适应度函数（P54）"></a>5、适应度函数（P54）</h4><p>遗传算法在进化搜索中基本不用外部信息，仅以目标函数即适应度函数为依据，利用种群每个个体的适应度来指导搜索。遗传算法的目标函数不受连续可微的约束，且定义域可以为任意集合。</p><p>适应度函数值是选择操作的依据，适应度函数的选取直接影响到遗传算法的收敛速度以及能否找到最优解。</p><hr><h2 id="第3章-模糊逻辑"><a href="#第3章-模糊逻辑" class="headerlink" title="第3章 模糊逻辑"></a>第3章 模糊逻辑</h2><h4 id="1、概率与模糊（P165）"><a href="#1、概率与模糊（P165）" class="headerlink" title="1、概率与模糊（P165）"></a>1、概率与模糊（P165）</h4><h6 id="相似之处"><a href="#相似之处" class="headerlink" title="相似之处"></a>相似之处</h6><p>（1）都可以用来刻画不确定性。</p><p>（2）都通过单位间隔【0，1】中的数来表述不确定性，即映射的值域是相同的，均为【0，1】。</p><p>（3）都兼有集合和命题的结合律、交换律、分配律。</p><h6 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h6><p>$$<br>（1）经典集合论中A\cap A^C &#x3D; \varnothing,P(A\cap A^C) &#x3D; P(\varnothing) &#x3D; 0代表概率上不可能的事件；模糊集合建立在A\cap A^C &#x3D; \varnothing的基础上。<br>$$</p><p>（2）经典集合A中某个元素x的概率在x发生之后，就会变为0或1；模糊集合A中某个元素x的隶属度不会发生变化。</p><p>（3）概率是事件是否发生的不确定性；模糊是事件发生的程度。</p><hr><h4 id="2、模糊集合的表示方法（P170）"><a href="#2、模糊集合的表示方法（P170）" class="headerlink" title="2、模糊集合的表示方法（P170）"></a>2、模糊集合的表示方法（P170）</h4><h6 id="列举法"><a href="#列举法" class="headerlink" title="列举法"></a>列举法</h6><p>只适用于有限集合。当论域U是离散域时，一般可以用扎德（Zadeh）表示法、序偶表示法和向量表示法表示。这三种方法均属于列举法。</p><p>（具体三者的公式见书P170）</p><h6 id="描述法"><a href="#描述法" class="headerlink" title="描述法"></a>描述法</h6><p>对于无限集，可以使用描述法表示集合，即<br>$$<br>A &#x3D; {x | P(x) }<br>$$<br>其中，P(x)表示x满足性质P。</p><h6 id="隶属度函数法（重点）"><a href="#隶属度函数法（重点）" class="headerlink" title="隶属度函数法（重点）"></a>隶属度函数法（重点）</h6><p>论域E上的模糊集合A是由隶属度函数确定的，所以可以用隶属度函数来表示模糊集合A。模糊集合可表示为：<br>$$<br>\mu(x) &#x3D;<br>\begin{cases}<br>1, 当x\in A \<br>0 &lt; \mu_A(x) &lt; 1,当A在一定程度上属于A时 \<br>0, 当x\notin A<br>\end{cases}<br>$$</p><hr><h4 id="3、模糊集合的几何图示（P172）"><a href="#3、模糊集合的几何图示（P172）" class="headerlink" title="3、模糊集合的几何图示（P172）"></a>3、模糊集合的几何图示（P172）</h4><p>详细见书P172。</p><hr><h4 id="4、模糊集合的基本运算（P174）"><a href="#4、模糊集合的基本运算（P174）" class="headerlink" title="4、模糊集合的基本运算（P174）"></a>4、模糊集合的基本运算（P174）</h4><h6 id="（1）相关运算的定义"><a href="#（1）相关运算的定义" class="headerlink" title="（1）相关运算的定义"></a>（1）相关运算的定义</h6><p>$$<br>相等：  A &#x3D; B \Leftrightarrow \mu_A(x) &#x3D; \mu_B(x) \<br>包含：  A \subseteq B \Leftrightarrow \mu_A(x) \leq \mu_B(x) \<br>交集：  C &#x3D; A \cap B \Leftrightarrow \mu_A(x) &#x3D; min(\mu_A(x), \mu_B(x)) &#x3D; \mu_A(x) \land \mu_A(x) \<br>其中,“\land”为Zadeh算子，表示“取最小值”运算 \<br>并集：  C &#x3D; A \cup B \Leftrightarrow \mu_A(x) &#x3D; max(\mu_A(x), \mu_B(x)) &#x3D; \mu_A(x) \lor \mu_B(x) \<br>其中,“\lor”为Zadeh算子，表示“最大”运算 \<br>补集：  \overline{A} \Leftrightarrow \mu_\overline{A}(x) &#x3D; 1 - \mu_A(x) \<br>代数集： 模糊集的代数集，记为AB，其隶属度函数定义为 \mu_{AB} &#x3D; \mu_A \mu_B \<br>代数和：模糊集A、B的代数和，记为A⊕B，其隶属度函数定义为 \mu_{A⊕B} &#x3D; \mu_A + \mu_B - \mu_{AB} \<br>绝对差：模糊集A、B的代数差，以|A - B|表示，其隶属度函数定义为\mu_{|A-B|} &#x3D; \mu_A - \mu_B<br>$$</p><h6 id="（2）基本定律"><a href="#（2）基本定律" class="headerlink" title="（2）基本定律"></a>（2）基本定律</h6><p>$$<br>幂等律： A \cap A &#x3D; A  \<br>\ \ \ \ \ \ \ \ \ \ \ \ \ A \cup A &#x3D; A \<br>结合律：A \cap (B \cap C) &#x3D; (A \cap B) \cap C \<br>\ \ \ \ \ \ \ \ \ \ \ \ \ A \cup (B \cup C) &#x3D; (A \cup B) \cup C \<br>交换律：A \cap B &#x3D; B \cap A \<br>\ \ \ \ \ \ \ \ \ \ \ \ \ A \cup B &#x3D; B \cup A \<br>分配律：A \cap (B \cup C) &#x3D; (A \cap B) \cup (A \cap C) \<br>\ \ \ \ \ \ \ \ \ \ \ \ \ A \cup (B \cap C) &#x3D; (A \cup B) \cap (A \cup C) \<br>同一律：A \cap U &#x3D; A \<br>\ \ \ \ \ \ \ \ \ \ \ \ \ A \cup \varnothing &#x3D; A \<br>零一律：A \cup U &#x3D; U \<br>\ \ \ \ \ \ \ \ \ \ \ \ \ A \cap \varnothing &#x3D; \varnothing \<br>吸收律：A \cap (A \cup B) &#x3D; A \<br>\ \ \ \ \ \ \ \ \ \ \ \ \ A \cup (A \cap B) &#x3D; A \<br>德-摩根律：\overline{A \cap B} &#x3D; \overline{A} \cup \overline{B} \<br>\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \overline{A \cup B} &#x3D; \overline{A} \cap \overline{B} \<br>双重否定率：\overline{\overline A} &#x3D; A<br>$$</p><h6 id="3-一些常用的算子"><a href="#3-一些常用的算子" class="headerlink" title="(3)一些常用的算子"></a>(3)一些常用的算子</h6><p>$$<br>\begin{aligned}<br>Zadeh算子（\land，\lor）：&amp; a \lor b &#x3D; max{a,b} \<br>&amp; a \land b &#x3D; min{a,b} \<br>取大、乘积算子（\lor，\cdot）： &amp; a \lor b &#x3D; max{a,b} \<br>&amp; a \cdot b &#x3D; ab \<br>环和、乘积算子（⨣，）：&amp; a ⨣ b &#x3D; a + b - ab \<br>&amp; a \cdot b &#x3D; ab \<br>有界和、取小算子（⊕，\land）：&amp; a ⊕ b &#x3D; 1 \land (a + b) \<br>&amp; a \land b &#x3D; min{a, b} \<br>有界和、乘积算子（⊕，\cdot）：&amp; a ⊕ b &#x3D; 1 \land (a + b) \<br>&amp; a \cdot b &#x3D; ab \<br>Einsain算子（ε^+，ε^-）：&amp; a ε^+ b &#x3D; \frac{a + b}{1 + ab} \<br>&amp; a ε^- b &#x3D; \frac{ab}{1 + (1-a)(1 - b)}<br>\end{aligned}<br>$$</p><hr><h4 id="5、隶属度函数定义（P178）"><a href="#5、隶属度函数定义（P178）" class="headerlink" title="5、隶属度函数定义（P178）"></a>5、隶属度函数定义（P178）</h4><p>论域U上的一个模糊集A由隶属函数<em>μ</em>A(x)唯一确定，表示x隶属于集合A的程度，故认为二者是等同的，即<br>$$<br>\mu_A: U \longrightarrow[0,1]<br>$$</p><hr><h4 id="6、α水平载集的定义和计算（P189）"><a href="#6、α水平载集的定义和计算（P189）" class="headerlink" title="6、α水平载集的定义和计算（P189）"></a>6、α水平载集的定义和计算（P189）</h4><p>α水平载集是指隶属度大于等于α的元素组成的集合，可表示为<br>$$<br>A_\alpha &#x3D;  { x | \mu_A(x)}<br>$$<br><strong>注意：</strong>模糊子集本身没有确定边界，其水平载集有确定边界，并且不再是模糊集合，而是一个确定集合。</p><hr><h4 id="7、模糊集合（P194）"><a href="#7、模糊集合（P194）" class="headerlink" title="7、模糊集合（P194）"></a>7、模糊集合（P194）</h4><p>（1）如果关系R是XxY的一个模糊子集，则称R为XxY的一个模糊关系，其隶属度函数为<em>μ</em>R(x，y)。</p><p><strong>注意：</strong>隶属度函数<em>μ</em>R(x，y）表示x、y具有R的程度。</p><p>（2）若一个矩阵元素取值在【0，1】区间内，则称该矩阵为模糊矩阵。同普通矩阵一样，模糊单位阵记为I；模糊零矩阵记为0。</p><p>（3）模糊矩阵的表示。当X和Y都是有限集合时，模糊关系也可以用MR来表示。设X &#x3D; { x1 , x2 , …  , xi , …xn }，Y &#x3D; { y1 , y2 , …  , yi , …yn }，则MR可以表示为<br>$$<br>M_R &#x3D; [r_{ij}]<em>{m \times n} , r</em>{ij} &#x3D; \mu_R(x_i,y_i)<br>$$<br>(关于3，建议大家还是看一下书本P194的例题来快速理解，当然这个例题是有错误的，需要大家自己甄别了)</p><hr><h4 id="8、极大运算（P196）"><a href="#8、极大运算（P196）" class="headerlink" title="8、极大运算（P196）"></a>8、极大运算（P196）</h4><h6 id="（1）极大-极小复合运算"><a href="#（1）极大-极小复合运算" class="headerlink" title="（1）极大-极小复合运算"></a>（1）极大-极小复合运算</h6><p>设R1和R2分别是定义在XxY和YxZ上的两个模糊关系，R1和R2的极大-极小复合运算可得到一个模糊关系（集合），可表示为<br>$$<br>R_1 ○ R_2 &#x3D; { [(x , z), \max \limits_{y} \min [\mu_{R_1}(x,y),\mu_{R_2}(y,z)]] }<br>$$</p><h6 id="（2）极大-乘积复合运算"><a href="#（2）极大-乘积复合运算" class="headerlink" title="（2）极大-乘积复合运算"></a>（2）极大-乘积复合运算</h6><p>设R1和R2分别是定义在XxY和YxZ上的两个模糊关系，R1和R2的极大-乘积复合运算可得到一个模糊关系（集合），可表示为<br>$$<br>R_1 ○ R_2 &#x3D; { [(x , z), \max \limits_{y}[\mu_{R_1}(x,y) \times \mu_{R_2}(y,z)]] }<br>$$<br>关于两个的实际运算见书P197，太多了题主懒得打，其实很好理解，拿极大-极小复合运算举例，极大在前面，那么极大就把极小运算包裹，先做一个极小的矩阵运算后对结果矩阵进行一个极大运算。</p><hr><h2 id="第4章-人工神经网络"><a href="#第4章-人工神经网络" class="headerlink" title="第4章 人工神经网络"></a>第4章 人工神经网络</h2><h4 id="1、生物神经系统的特点（P261）"><a href="#1、生物神经系统的特点（P261）" class="headerlink" title="1、生物神经系统的特点（P261）"></a>1、生物神经系统的特点（P261）</h4><p>（1）生物神经元之间相互连接，其连接强度决定了信号传递的强弱；</p><p>（2）神经元之间的连接强度是可以随着训练改变的；</p><p>（3）信号可以起刺激作用，也可以起抑制作用；</p><p>（4）一个神经元接收信号的累积效果决定了该神经元的状态；</p><p>（5）每一个神经元有一个动作阈值。</p><hr><h4 id="2、激活函数（P263）"><a href="#2、激活函数（P263）" class="headerlink" title="2、激活函数（P263）"></a>2、激活函数（P263）</h4><p>激活函数模拟的是生物神经元对输入信息的处理。激活函数对输入感知器的信息进行处理，并决定其是否有对应的输出以及输出幅度有多大，也可以称为激励函数、活化函数、传递函数等，表达式为<br>$$<br>y &#x3D; \varphi(u + b)<br>$$<br>其中<em>φ</em>(*)表示激活函数。激活函数是感知器处理的核心部分，<strong>引入激活函数增加了神经网络的非线性特性</strong>，从而使得神经网络能够实现各种复杂功能。如果没有激活函数，无论叠加多少层神经网络，起计算过程都只是线性计算，结果也是个普通矩阵而失去了强大的映射能力。激活函数在神经网络中的地位可见一斑。常见的激活函数：</p><h6 id="（1）硬极限传输函数"><a href="#（1）硬极限传输函数" class="headerlink" title="（1）硬极限传输函数"></a>（1）硬极限传输函数</h6><p>$$<br>f(n) &#x3D;<br>\begin{cases}<br>\beta, n \geq \theta \</p><ul><li>\gamma , n &lt; \theta<br>\end{cases}<br>$$</li></ul><p>其中，β、<em>γ</em>、<em>θ</em>均为非负实数，<em>θ</em>为阈值。当β&#x3D;1、<em>γ</em>&#x3D;0时，函数表现为二值形式；当β&#x3D;1、<em>γ</em>&#x3D;1时，函数表示为双极形式。</p><h6 id="（2）线性传输函数"><a href="#（2）线性传输函数" class="headerlink" title="（2）线性传输函数"></a>（2）线性传输函数</h6><p>$$<br>f(n) &#x3D; w^Tp + b<br>$$</p><p>当b &#x3D; 0时，传输函数关于原点中心对称，这是常见的一种形式。</p><h6 id="（3）对数S型函数"><a href="#（3）对数S型函数" class="headerlink" title="（3）对数S型函数"></a>（3）对数S型函数</h6><p>对数S型函数的两种形式分别为逻辑斯特函数和压缩函数。</p><p>【1】逻辑斯特函数（Logistic Function）<br>$$<br>f(n) &#x3D; \frac{1}{1 + e^{-d \times n}}<br>$$<br>其中，d为常实数，函数的饱和值为0和1。</p><p>【2】压缩函数（Squashing Function）<br>$$<br>f(n) &#x3D; \frac{g + h}{1 + e^{-d \times n}}<br>$$<br>其中，g、h、d为常数，函数的饱和值为g和g+h。</p><h6 id="（4）其他常见传输函数"><a href="#（4）其他常见传输函数" class="headerlink" title="（4）其他常见传输函数"></a>（4）其他常见传输函数</h6><p>【1】硬极限函数（Hardlim）<br>$$<br>f &#x3D;<br>\begin{cases}<br>0, n &lt; 0 \<br>1, n \geq 0<br>\end{cases}<br>$$<br>【2】对称极限函数（Hardlims）<br>$$<br>f &#x3D;<br>\begin{cases}<br>-1, n &lt; 0 \<br>1, n \geq 0<br>\end{cases}<br>$$<br>【3】线性函数（Pureline）<br>$$<br>f &#x3D; n<br>$$<br>【4】饱和线性函数（Satlin）<br>$$<br>f &#x3D;<br>\begin{cases}<br>0, n &lt; 0 \<br>n, 0 \leq n \leq 1 \<br>1, n &gt; 1<br>\end{cases}<br>$$<br>【5】对称饱和线性函数（Satlins）<br>$$<br>f &#x3D; \frac{1}{1 + e^{-n}}<br>$$<br>【6】双曲正切S型函数（Tansigs）<br>$$<br>f &#x3D; \frac{e^n - e^{-n}}{e^n + e^{-n}}<br>$$<br>【7】正线性函数（Poslin）<br>$$<br>f &#x3D;<br>\begin{cases}<br>0, n &lt; 0 \<br>n, n \geq 0<br>\end{cases}<br>$$</p><hr><h4 id="3、离散单输出感知机训练算法（P268）"><a href="#3、离散单输出感知机训练算法（P268）" class="headerlink" title="3、离散单输出感知机训练算法（P268）"></a>3、离散单输出感知机训练算法（P268）</h4><p>训练样本集为{（X，Y）| Y }，其中Y为输入向量X对应的输出。权向量W &#x3D; （<em>ω</em>1，<em>ω</em>2，…，<em>ω</em>n），其中n为输入向量的维数。输入向量X &#x3D; （x1，x2，…，xn ），其中n为输入向量的维数。输出向量O&#x3D;（0，1）。激活函数为f。</p><h6 id="算法的具体流程"><a href="#算法的具体流程" class="headerlink" title="算法的具体流程"></a>算法的具体流程</h6><p>（1）随机初始化权向量W；</p><p>（2）对每个样本（X，Y），计算O &#x3D; f（XW），对i∈[ 1 , n ]，n为样本数，执行下式：<br>$$<br>W_i &#x3D;<br>\begin{cases}<br>W_i + X_i, O &lt; Y \<br>W_i - X_i, O &gt; Y<br>\end{cases}<br>$$<br>（3）重复第（2）项，直到训练完成。</p><hr><h4 id="4、梯度下降方法（P276）"><a href="#4、梯度下降方法（P276）" class="headerlink" title="4、梯度下降方法（P276）"></a>4、梯度下降方法（P276）</h4><p>梯度下降方法是最常见的训练神经网络参数的方法之一。</p><h6 id="1、损失函数"><a href="#1、损失函数" class="headerlink" title="1、损失函数"></a>1、损失函数</h6><p>在机器学习中每个算法都会有一个目标函数，而算法的运行求解过程通常也就是这个算法的优化求解过程。在一些算法求解问题中，常会使用损失函数作为目标函数。损失函数代表的是预测值和真实值之间的差异程度，那么只要找到一个解使得二者之间的差异最小，该解就可以理解为此时的一个最优解。通常损失函数越好，则模型的性能也越好。常见的损失函数有如下几种：</p><p>【1】0 - 1损失函数（0 - 1 Loss Function）：<br>$$<br>L(Y, f(x)) &#x3D;<br>\begin{cases}<br>1, Y \neq f(x) \<br>0, Y &#x3D; f(x)<br>\end{cases}<br>$$<br>【2】平方损失函数（Quadratic Loss Function）：<br>$$<br>L(Y, f(x)) &#x3D; (Y - f(x)) ^ 2<br>$$<br>【3】绝对损失函数（Absolute Loss Function）：<br>$$<br>L(Y, f(x)) &#x3D; ||Y - f(x)||<br>$$<br>【4】对数损失函数（Logarithmic Loss Function）或对数似然损失函数（Log-Likelihood Loss Function）：<br>$$<br>L(Y, P(Y|X)) &#x3D; -\lg P(Y|X)<br>$$</p><h6 id="2、梯度的理解"><a href="#2、梯度的理解" class="headerlink" title="2、梯度的理解"></a>2、梯度的理解</h6><p>在多元函数中对各个参数求偏导，最后把各个参数的偏导数用向量的方式表示出来即梯度。从二维到三维函数的图像中可知，梯度可以代表函数在这个参数上的变化速度快慢，梯度越大则变化越快。沿着梯度变换的方向直至梯度为0，该处通常是一个局部的高点或者低点，即极大值或者极小值，在函数中这恰恰可以视为函数的最终解。</p><p>在人工神经网络的训练中，需要最小化损失函数时，可以通过梯度下降方法来进行多次迭代求得最优解。在函数图像上，最低点就是最小化的损失函数结果。同理，如果要求解梯度的最大值，则可以采用梯度上升的方式得到一个梯度最大值，其对应的是损失函数的极大值。两者之间也可以互相转换，例如原本是求损失函数的极大值，经过取反可以变为求解一个损失函数的极小值。另外，这种求解方法求得的解是局部极大或极小值，但不一定是全局最大或最小值。</p><h6 id="3、梯度下降的学习规则"><a href="#3、梯度下降的学习规则" class="headerlink" title="3、梯度下降的学习规则"></a>3、梯度下降的学习规则</h6><p><strong>学习率 X 负梯度</strong></p><h6 id="4、梯度下降方法的实现"><a href="#4、梯度下降方法的实现" class="headerlink" title="4、梯度下降方法的实现"></a>4、梯度下降方法的实现</h6><p>（1）确定优化模型的假设函数和损失函数。以线性回归为例，假设函数如下：<br>$$<br>h_\theta(x_1, x_2, \cdots, x_n) &#x3D; \theta_0 + \theta_1x_1 + \cdots + \theta_xx_n<br>$$<br>其中，θi（i &#x3D; 0，1，2，…，θn）为模型参数，xi（i &#x3D; 0，1，2，…，n ）为每个样本的n个特征值。θ0可以看作θ0x0（x0&#x3D;1），故<br>$$<br>h_\theta(x_1, x_2, \cdots, x_n) &#x3D; \sum_{i&#x3D;0}^n \theta_ix_i<br>$$<br>对应的损失函数为<br>$$<br>J(x_1, x_2, \cdots, x_n) &#x3D; \frac{1}{2m} \sum_{j&#x3D;0}^m (h_\theta (x_0^j, x_1^j, \cdots, x_n^j) - y_j)^2<br>$$<br>（2）初始化参数：θi（i &#x3D; 0，1，2，…，θn）、算法终止误差为ε、梯度下降步长为α。θ可以随机生成，步长初始化为1；ε根据需要的精确度来设置，ε越小可能算法运行时间就越长。后续可以根据运行结果再调整参数。</p><p>（3）算法过程如下：</p><p>【1】求梯度：<br>$$<br>\nabla_i &#x3D; \alpha \frac{\partial}{\partial \theta}J(\theta_0, \theta_1,\cdots, \theta_n)<br>$$<br>【2】若|∇i| &lt; ε，则运行结束，输出θi（i&#x3D; 0，1，2，…，n）；若|∇i| &gt;&#x3D; ε，则运行下一步；</p><p>【3】更新所有的θ：<br>$$<br>\theta_i &#x3D; \theta_i -  \alpha \frac{\partial}{\partial \theta}J(\theta_0, \theta_1,\cdots, \theta_n)<br>$$<br>更新完，转步骤【1】。<strong>（重点公式）</strong></p><p>【4】加快收敛的方法：</p><ul><li>特征缩放。在多特征问题中保证特征有相近的尺度将有利于梯度下降。</li><li>通过调整学习率来更改收敛速度。学习率过小会导致梯度下降方法收敛过慢，但过大也可能使得网络不能收敛。</li></ul><p>【5】多种梯度下降方法：</p><ul><li>批量梯度下降方法（Batch Gradient Descent）</li></ul><p>这是梯度下降方法中使用最多的形式之一，其具体操作是在更新参数时，使用所有的样本来进行更新。缺点在于由于训练的样本大，训练速度会变慢。</p><ul><li>随机梯度下降方法（Stochastic Grandient Descent）</li></ul><p>该方法和批量梯度下降方法原理类似，区别在于求梯度时没有采用所有的样本数据，而仅仅选取一个样本求解梯度。其优点在于只采用一个样本迭代，故训练速度极快；缺点在于迭代方向变化很大，不过很快收敛到局部最优解。</p><ul><li>小批量梯度下降方法（Mini-batch Gradient Descent）</li></ul><p>该方法综合了上述两种方式的优缺点，即对于m个样本，就采用x个样本来迭代，1&lt;x&lt;m，可以根据样本数据调整x的值。</p><hr><h4 id="5、误差反向传播算法-P280最后一个大题"><a href="#5、误差反向传播算法-P280最后一个大题" class="headerlink" title="5、误差反向传播算法(P280最后一个大题)"></a>5、误差反向传播算法(P280最后一个大题)</h4><h6 id="原理（选择题）"><a href="#原理（选择题）" class="headerlink" title="原理（选择题）"></a>原理（选择题）</h6><p>在消息正向传播的过程中，信息经过输入层到达隐含层，再经过多个隐含层的处理后到达输出层；比较输出结果和正确结果，将误差作为一个目标函数进行反向传播，对每一层依次求神经元权值的偏导数，构成目标函数对权值的梯度，网络权重再依次完成更新调整。依此往复，直到输出达到目标值完成训练。</p><h6 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h6><p>利用输出误差推算前一层的误差，再用推算误差算出更前一层的误差，直到计算出所有层的误差估计。</p><h6 id="前向传播"><a href="#前向传播" class="headerlink" title="前向传播"></a>前向传播</h6><p>前向传播简而言之就是从输入层开始，信号输入神经元，经过加权偏置激活函数的处理输出，称为下一级的输入参数，如此往复直到从输出层输出。</p><p><strong>主要公式</strong><br>$$<br>z^l &#x3D; W^la^{l-1} + b^l \<br>a^l &#x3D; f(z^l)<br>$$</p><h6 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h6><p>反向传播以前向传播为基础，从前向传播得到的参数前反向推导更新每一层的权重和偏置。</p><p>假定以误差平方作为损失函数，将该目标函数作为优化目标：<br>$$<br>J (W, b) &#x3D; \frac{1}{2} \sum_{j &#x3D; 1}^l (\hat y_i - y_i) ^2<br>$$<br>其中，两个yi分别表示神经网络的输出结果和数据集给出的真实结果。</p><p>根据梯度下降方法的原理，可以按照如下方式更新参数：<br>$$<br>W^l &#x3D; W^l - \alpha \frac{\partial J (W, b)}{\partial W ^ l} \ \ \ \ \ （权值调整）<br>$$</p><hr><h2 id="2-0补充"><a href="#2-0补充" class="headerlink" title="2.0补充"></a>2.0补充</h2><p>该部分内容为考试结束后进行实况整理分为选择题、填空题、大题三个部分（简答题并不固定，也一并放在大题之间）。</p><h4 id="选择题"><a href="#选择题" class="headerlink" title="选择题"></a>选择题</h4><p>选择题主要以背记部分为主，字面意义上的背记部分，比如遗传算法的特点、生物神经算法的特点等内容，也就是说在简答题自己对简答题的背记能够完全应付考试中的选择题部分。</p><hr><h4 id="填空题"><a href="#填空题" class="headerlink" title="填空题"></a>填空题</h4><p>填空题部分需要大家多对老师上课的知识内容进行留意（特指老师讲过5遍以上的内容），这次的填空题5空10分，后三空是一个简单的大题（参考P189 α水平载集例题改编），第一二空为：</p><ul><li>老师上课常说的“假小明”指的是什么？（A：我写的是不同的输入，但是不确定答案的正确性）</li><li>老师上课最常说的七字学习规则是什么？（A：学习率x负梯度）</li></ul><hr><h4 id="大题"><a href="#大题" class="headerlink" title="大题"></a>大题</h4><p>大题出的中规中矩，其余不做过多说明，最后一个大题可以参考用例：</p><p><img src="/2022/07/01/%E8%AE%A1%E7%AE%97%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA/%E5%A4%A7%E9%A2%981.png" alt="大题1"></p><p><img src="/2022/07/01/%E8%AE%A1%E7%AE%97%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA/%E5%A4%A7%E9%A2%982.png" alt="大题2"></p><p><img src="/2022/07/01/%E8%AE%A1%E7%AE%97%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA/%E5%A4%A7%E9%A2%983.png" alt="大题3"></p><h2 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h2><p>这个文档到这里就告一段落了，东西不算多，但也决说不上少了，可以看出整个科目便向数学计算和理论算法，所以真正想学好的话还是需要个人去把（丢掉的）数学学好吧。这个文档不适合作为学科学习，但可以作为入门参考资料，应付考试的理论部分看这个文档基本上是够用了，但是解题部分我更建议大家去看看书上的例题，就像我标记了重点的那几页的例题必须是需要自己去看去了解的。</p><p>因为例题太难敲了所以我就没放到文档里，不然真成应试文档了（😀），希望有机会看到这个文档的还是需要花时间去啃下这些硬骨头，后续还会慢慢出学习文档的。但是也会有出着出着自己学会了就不想出的（比如说《人工智能导论》）。最后希望能够帮到大家吧，培养优质大数据打工人！——By Alexie-Z-Yevich 2022.6.22</p><p>这门课考试还真没为难大家，比较难的就最后一题需要计算，但是其实老师上课都已经讲过了并且在复习阶段都已经教过大家怎么去写。分值也不算太高，最后一个大题占16分，其余都是送分题，需要补充的东西并不多，基本上以这个文档内容来说完全足够了。——By Alexie-Z-Yevich 2022.7.1</p>]]></content>
      
      
      <categories>
          
          <category> 我的大学 </category>
          
          <category> 大二下学期 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> 计算智能 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>算法设计与分析</title>
      <link href="/2022/06/12/%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%88%86%E6%9E%90/"/>
      <url>/2022/06/12/%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h2 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h2><h6 id="vector"><a href="#vector" class="headerlink" title="vector"></a>vector</h6><p>C++ STL中的verctor好比是C语言中的数组，但是vector又具有数组没有的一些高级功能。与数组相比，vector就是一个可以不用再初始化就必须制定大小的边长数组。</p><p>算法中常见的vector<int> L(n, 0)表示生成一个L包含n个重复的元素，每个元素值为0。</int></p><p><img src="/2022/06/12/%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%88%86%E6%9E%90/vector%E8%AF%B4%E6%98%8E.png" alt="vector说明"></p><h6 id="set"><a href="#set" class="headerlink" title="set"></a>set</h6><p>set就是集合，STL的set用二叉树实现，集合中的每个元素只出现一次(参照数学中集合的互斥性)，并且是排好序的(默认按键值升序排列)</p><p>访问元素的时间复杂度是O(log2n) 。</p><h6 id="queue"><a href="#queue" class="headerlink" title="queue"></a>queue</h6><p>queue是一种容器转换器模板，调用#include&lt; queue&gt;即可使用队列类。在算法中通常是作为FIFO队列使用。</p><p>常见形式：queue&lt;Type, Container&gt; (&lt;数据类型，容器类型&gt;）</p><h6 id="functional"><a href="#functional" class="headerlink" title="functional"></a>functional</h6><p>类模板std::function是通用多态函数封装器。 std::function的实例能存储、复制及调用任何可调用函数、 lambda表达式、 bind表达式或其他函数对象，还有指向成员函数指针和指向数据成员指针。</p><p>简单来说就是在函数中实现内嵌函数，但是内嵌函数同样适用于递归，且可以获得外层函数的参数。</p><h6 id="结构体"><a href="#结构体" class="headerlink" title="结构体"></a>结构体</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">BtNode</span></span><br><span class="line">&#123; </span><br><span class="line">    T data;</span><br><span class="line"> <span class="type">int</span> depth = <span class="number">1</span>;</span><br><span class="line"> BtNode *left = <span class="number">0</span>, *right = <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>结构体属于用户自定义的数据类型，允许用户存储不同的数据类型。写法如上述。</p><h6 id="Matrix"><a href="#Matrix" class="headerlink" title="Matrix"></a>Matrix</h6><p>矩阵运算库，在算法中以老师给的Matrix.hpp为准，建议浏览一下内容，知道诸如.row()函数、G(x,y)等运算都来源于自建库，附上我使用版本的Matrix.hpp：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Matrix.hpp</span></span><br><span class="line"><span class="meta">#<span class="keyword">pragma</span> once</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Matrix</span></span><br><span class="line">&#123;  </span><br><span class="line">   vector&lt;T&gt; buf; <span class="comment">// 用一维数组保存矩阵元素</span></span><br><span class="line">   <span class="type">size_t</span> r = <span class="number">0</span>, c = <span class="number">0</span>; <span class="comment">// 行数和列数</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">   <span class="built_in">Matrix</span>() = <span class="keyword">default</span>; <span class="comment">// 默认初始化</span></span><br><span class="line">   <span class="built_in">Matrix</span>(<span class="type">const</span> Matrix &amp;m) = <span class="keyword">default</span>; <span class="comment">// 使用另一矩阵初始化</span></span><br><span class="line">   ~<span class="built_in">Matrix</span>() = <span class="keyword">default</span>; <span class="comment">// 析构</span></span><br><span class="line">   Matrix &amp;<span class="keyword">operator</span>=(<span class="type">const</span> Matrix &amp;) = <span class="keyword">default</span>; <span class="comment">// 赋值</span></span><br><span class="line">   <span class="built_in">Matrix</span>(<span class="type">size_t</span> row, <span class="type">size_t</span> col): <span class="comment">// 根据行数和列数初始化</span></span><br><span class="line">      <span class="built_in">buf</span>(<span class="built_in">vector</span>&lt;T&gt;(row * col)), <span class="built_in">r</span>(row), <span class="built_in">c</span>(col) &#123;&#125;</span><br><span class="line">   <span class="built_in">Matrix</span>(<span class="type">size_t</span> row, <span class="type">size_t</span> col, <span class="type">const</span> T &amp;v): <span class="comment">// 用行数和列数及指定值初始化</span></span><br><span class="line">      <span class="built_in">buf</span>(<span class="built_in">vector</span>&lt;T&gt;(row * col, v)), <span class="built_in">r</span>(row), <span class="built_in">c</span>(col) &#123;&#125;</span><br><span class="line">   <span class="comment">// 使用初始值列表初始化, 即使用&#123;&#125;初始化</span></span><br><span class="line">   <span class="built_in">Matrix</span>(<span class="type">const</span> initializer_list&lt;initializer_list&lt;T&gt;&gt; &amp;m):</span><br><span class="line">      <span class="built_in">buf</span>(<span class="built_in">begin</span>(m)-&gt;<span class="built_in">begin</span>(), <span class="built_in">rbegin</span>(m)-&gt;<span class="built_in">end</span>()), <span class="comment">// 指定元素</span></span><br><span class="line">      <span class="built_in">r</span>(m.<span class="built_in">size</span>()), <span class="built_in">c</span>(<span class="built_in">begin</span>(m)-&gt;<span class="built_in">size</span>()) <span class="comment">// 指定行数和列数</span></span><br><span class="line">   &#123;&#125;</span><br><span class="line">   <span class="function"><span class="type">void</span> <span class="title">assign</span><span class="params">(<span class="type">const</span> T &amp;v)</span> <span class="comment">// 每个元素都是v</span></span></span><br><span class="line"><span class="function">   </span>&#123;  </span><br><span class="line">      buf.<span class="built_in">assign</span>(r * c, v);</span><br><span class="line">   &#125; <span class="comment">// 耗时O(size)</span></span><br><span class="line">   <span class="comment">// 元素类型简写</span></span><br><span class="line">   <span class="keyword">using</span> reference = <span class="keyword">typename</span> vector&lt;T&gt;::reference; <span class="comment">// 元素引用</span></span><br><span class="line">   <span class="keyword">using</span> const_reference = <span class="keyword">typename</span> vector&lt;T&gt;::const_reference; <span class="comment">// const引用</span></span><br><span class="line">   <span class="function">reference <span class="title">operator</span><span class="params">()</span><span class="params">(<span class="type">size_t</span> i, <span class="type">size_t</span> j)</span> <span class="comment">// 使用M(i, j)的形式访问矩阵元素</span></span></span><br><span class="line"><span class="function">   </span>&#123;  </span><br><span class="line">      <span class="keyword">return</span> buf[i * c + j];</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="function">const_reference <span class="title">operator</span><span class="params">()</span><span class="params">(<span class="type">size_t</span> i, <span class="type">size_t</span> j)</span> <span class="type">const</span></span></span><br><span class="line"><span class="function">   </span>&#123;  </span><br><span class="line">      <span class="keyword">return</span> buf[i * c + j];</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="function"><span class="type">size_t</span> <span class="title">rows</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> r; &#125; <span class="comment">// 行数</span></span><br><span class="line">   <span class="function"><span class="type">size_t</span> <span class="title">cols</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> c; &#125; <span class="comment">// 列数</span></span><br><span class="line">   <span class="comment">//</span></span><br><span class="line">   <span class="comment">// extend</span></span><br><span class="line">   <span class="comment">//</span></span><br><span class="line">   <span class="built_in">Matrix</span>(Matrix &amp;&amp;m): <span class="built_in">buf</span>(<span class="built_in">move</span>(m.buf)), <span class="built_in">r</span>(m.r), <span class="built_in">c</span>(m.c) &#123;&#125;</span><br><span class="line">   Matrix &amp;<span class="keyword">operator</span>=(Matrix &amp;&amp;m)</span><br><span class="line">   &#123;  </span><br><span class="line">      buf = <span class="built_in">move</span>(m.buf), r = m.r, c = m.c;</span><br><span class="line">      <span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">   &#125;</span><br><span class="line">   Matrix &amp;<span class="keyword">operator</span>=(<span class="type">const</span> initializer_list&lt;T&gt; &amp;m)</span><br><span class="line">   &#123;  </span><br><span class="line">      buf.<span class="built_in">assign</span>(m);</span><br><span class="line">      <span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">   &#125; <span class="comment">// 使用列表赋值，即将&#123;&#125;中的元素复制到*this</span></span><br><span class="line">   <span class="function"><span class="type">size_t</span> <span class="title">size</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> r * c; &#125; <span class="comment">// 元素数</span></span><br><span class="line">   <span class="comment">//</span></span><br><span class="line">   <span class="comment">// end extend</span></span><br><span class="line">   <span class="comment">//</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt; <span class="comment">// 输出矩阵的所有元素</span></span><br><span class="line">ostream &amp;<span class="keyword">operator</span>&lt;&lt;(ostream &amp;out, <span class="type">const</span> Matrix&lt;T&gt; &amp;m)</span><br><span class="line">&#123;  </span><br><span class="line">   <span class="type">size_t</span> r = m.<span class="built_in">rows</span>(), c = m.<span class="built_in">cols</span>();</span><br><span class="line">   <span class="keyword">for</span>(<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; r; ++i)</span><br><span class="line">   &#123;  </span><br><span class="line">       <span class="keyword">for</span>(<span class="type">size_t</span> j = <span class="number">0</span>; j &lt; c; ++j)</span><br><span class="line">         out &lt;&lt; <span class="built_in">m</span>(i, j) &lt;&lt; <span class="string">&#x27; &#x27;</span>;</span><br><span class="line">      out &lt;&lt; endl; <span class="comment">// 输出一行元素后换行</span></span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">return</span> out;</span><br><span class="line">&#125; <span class="comment">// 耗时O(size)</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// extend</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt; <span class="comment">// 两个矩阵相加</span></span><br><span class="line"><span class="keyword">auto</span> <span class="keyword">operator</span>+(<span class="type">const</span> Matrix&lt;T&gt; &amp;X, <span class="type">const</span> Matrix&lt;T&gt; &amp;Y)</span><br><span class="line">&#123;  </span><br><span class="line">   <span class="type">size_t</span> r = <span class="built_in">min</span>(X.<span class="built_in">rows</span>(), Y.<span class="built_in">rows</span>()), c = <span class="built_in">min</span>(X.<span class="built_in">cols</span>(), Y.<span class="built_in">cols</span>());</span><br><span class="line">   <span class="function">Matrix&lt;T&gt; <span class="title">Z</span><span class="params">(r, c)</span></span>;</span><br><span class="line">   <span class="keyword">for</span>(<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; r; ++i)</span><br><span class="line">      <span class="keyword">for</span>(<span class="type">size_t</span> j = <span class="number">0</span>; j &lt; c; ++j)</span><br><span class="line">         <span class="built_in">Z</span>(i, j) = <span class="built_in">X</span>(i, j) + <span class="built_in">Y</span>(i, j);</span><br><span class="line">   <span class="keyword">return</span> Z;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt; <span class="comment">// 两个矩阵相减</span></span><br><span class="line"><span class="keyword">auto</span> <span class="keyword">operator</span>-(<span class="type">const</span> Matrix&lt;T&gt; &amp;X, <span class="type">const</span> Matrix&lt;T&gt; &amp;Y)</span><br><span class="line">&#123;  </span><br><span class="line">   <span class="type">size_t</span> r = <span class="built_in">min</span>(X.<span class="built_in">rows</span>(), Y.<span class="built_in">rows</span>()), c = <span class="built_in">min</span>(X.<span class="built_in">cols</span>(), Y.<span class="built_in">cols</span>());</span><br><span class="line">   <span class="function">Matrix&lt;T&gt; <span class="title">Z</span><span class="params">(r, c)</span></span>;</span><br><span class="line">   <span class="keyword">for</span>(<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; r; ++i)</span><br><span class="line">      <span class="keyword">for</span>(<span class="type">size_t</span> j = <span class="number">0</span>; j &lt; c; ++j)</span><br><span class="line">         <span class="built_in">Z</span>(i, j) = <span class="built_in">X</span>(i, j) - <span class="built_in">Y</span>(i, j);</span><br><span class="line">   <span class="keyword">return</span> Z;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt; <span class="comment">// 两个矩阵相乘</span></span><br><span class="line"><span class="keyword">auto</span> <span class="keyword">operator</span>*(<span class="type">const</span> Matrix&lt;T&gt; &amp;X, <span class="type">const</span> Matrix&lt;T&gt; &amp;Y)</span><br><span class="line">&#123;  </span><br><span class="line">   <span class="type">size_t</span> r = X.<span class="built_in">rows</span>(), c = Y.<span class="built_in">cols</span>(), m = <span class="built_in">min</span>(X.<span class="built_in">cols</span>(), Y.<span class="built_in">rows</span>());</span><br><span class="line">   <span class="function">Matrix&lt;T&gt; <span class="title">Z</span><span class="params">(r, c)</span></span>;</span><br><span class="line">   <span class="keyword">for</span>(<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; r; ++i)</span><br><span class="line">      <span class="keyword">for</span>(<span class="type">size_t</span> j = <span class="number">0</span>; j &lt; c; ++j)</span><br><span class="line">      &#123;  </span><br><span class="line">         <span class="built_in">Z</span>(i, j) = <span class="built_in">X</span>(i, <span class="number">0</span>) * <span class="built_in">Y</span>(<span class="number">0</span>, j);</span><br><span class="line">         <span class="keyword">for</span>(<span class="type">size_t</span> k = <span class="number">1</span>; k &lt; m; ++k)</span><br><span class="line">            <span class="built_in">Z</span>(i, j) = <span class="built_in">Z</span>(i, j) + <span class="built_in">X</span>(i, k) * <span class="built_in">Y</span>(k, j);</span><br><span class="line">      &#125;</span><br><span class="line">   <span class="keyword">return</span> Z;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">T</span>, <span class="keyword">class</span> <span class="title class_">T2</span>&gt; <span class="comment">// 加上一个值</span></span><br><span class="line"><span class="keyword">auto</span> <span class="keyword">operator</span>+(<span class="type">const</span> Matrix&lt;T&gt; &amp;X, <span class="type">const</span> T2 &amp;v)</span><br><span class="line">&#123;  </span><br><span class="line">   <span class="type">size_t</span> r = X.<span class="built_in">rows</span>(), c = X.<span class="built_in">cols</span>();</span><br><span class="line">   <span class="function">Matrix&lt;T&gt; <span class="title">Z</span><span class="params">(r, c)</span></span>; <span class="comment">// 结果矩阵</span></span><br><span class="line">   <span class="keyword">for</span>(<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; r; ++i)</span><br><span class="line">      <span class="keyword">for</span>(<span class="type">size_t</span> j = <span class="number">0</span>; j &lt; c; ++j)</span><br><span class="line">         <span class="built_in">Z</span>(i, j) = <span class="built_in">X</span>(i, j) + v;</span><br><span class="line">   <span class="keyword">return</span> Z;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">T</span>, <span class="keyword">class</span> <span class="title class_">T2</span>&gt; <span class="comment">// 减去一个值</span></span><br><span class="line"><span class="keyword">auto</span> <span class="keyword">operator</span>-(<span class="type">const</span> Matrix&lt;T&gt; &amp;X, <span class="type">const</span> T2 &amp;v)</span><br><span class="line">&#123;  </span><br><span class="line">   <span class="type">size_t</span> r = X.<span class="built_in">rows</span>(), c = X.<span class="built_in">cols</span>();</span><br><span class="line">   <span class="function">Matrix&lt;T&gt; <span class="title">Z</span><span class="params">(r, c)</span></span>; <span class="comment">// 结果矩阵</span></span><br><span class="line">   <span class="keyword">for</span>(<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; r; ++i)</span><br><span class="line">      <span class="keyword">for</span>(<span class="type">size_t</span> j = <span class="number">0</span>; j &lt; c; ++j)</span><br><span class="line">         <span class="built_in">Z</span>(i, j) = <span class="built_in">X</span>(i, j) - v;</span><br><span class="line">   <span class="keyword">return</span> Z;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">T</span>, <span class="keyword">class</span> <span class="title class_">T2</span>&gt; <span class="comment">// 乘以一个值</span></span><br><span class="line"><span class="keyword">auto</span> <span class="keyword">operator</span>*(<span class="type">const</span> Matrix&lt;T&gt; &amp;X, <span class="type">const</span> T2 &amp;v)</span><br><span class="line">&#123;  </span><br><span class="line">   <span class="type">size_t</span> r = X.<span class="built_in">rows</span>(), c = X.<span class="built_in">cols</span>();</span><br><span class="line">   <span class="function">Matrix&lt;T&gt; <span class="title">Z</span><span class="params">(r, c)</span></span>; <span class="comment">// 结果矩阵</span></span><br><span class="line">   <span class="keyword">for</span>(<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; r; ++i)</span><br><span class="line">      <span class="keyword">for</span>(<span class="type">size_t</span> j = <span class="number">0</span>; j &lt; c; ++j)</span><br><span class="line">         <span class="built_in">Z</span>(i, j) = <span class="built_in">X</span>(i, j) * v;</span><br><span class="line">   <span class="keyword">return</span> Z;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">T</span>, <span class="keyword">class</span> <span class="title class_">T2</span>&gt; <span class="comment">// 除以一个值</span></span><br><span class="line"><span class="keyword">auto</span> <span class="keyword">operator</span>/(<span class="type">const</span> Matrix&lt;T&gt; &amp;X, <span class="type">const</span> T2 &amp;v)</span><br><span class="line">&#123;  </span><br><span class="line">   <span class="type">size_t</span> r = X.<span class="built_in">rows</span>(), c = X.<span class="built_in">cols</span>();</span><br><span class="line">   <span class="function">Matrix&lt;T&gt; <span class="title">Z</span><span class="params">(r, c)</span></span>; <span class="comment">// 结果矩阵</span></span><br><span class="line">   <span class="keyword">for</span>(<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; r; ++i)</span><br><span class="line">      <span class="keyword">for</span>(<span class="type">size_t</span> j = <span class="number">0</span>; j &lt; c; ++j)</span><br><span class="line">         <span class="built_in">Z</span>(i, j) = <span class="built_in">X</span>(i, j) / v;</span><br><span class="line">   <span class="keyword">return</span> Z;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt; <span class="comment">// 负</span></span><br><span class="line"><span class="keyword">auto</span> <span class="keyword">operator</span>-(<span class="type">const</span> Matrix&lt;T&gt; &amp;X)</span><br><span class="line">&#123;  </span><br><span class="line">   <span class="keyword">return</span> X * (<span class="number">-1</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt; <span class="comment">// 转置</span></span><br><span class="line"><span class="function"><span class="keyword">auto</span> <span class="title">transpose</span><span class="params">(<span class="type">const</span> Matrix&lt;T&gt; &amp;X)</span></span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">   <span class="type">size_t</span> r = X.<span class="built_in">cols</span>(), c = X.<span class="built_in">rows</span>();</span><br><span class="line">   <span class="function">Matrix&lt;T&gt; <span class="title">Z</span><span class="params">(r, c)</span></span>;</span><br><span class="line">   <span class="keyword">for</span>(<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; r; ++i)</span><br><span class="line">      <span class="keyword">for</span>(<span class="type">size_t</span> j = <span class="number">0</span>; j &lt; c; ++j)</span><br><span class="line">         <span class="built_in">Z</span>(i, j) = <span class="built_in">X</span>(j, i);</span><br><span class="line">   <span class="keyword">return</span> Z;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// end extend</span></span><br><span class="line"><span class="comment">//</span></span><br></pre></td></tr></table></figure><h2 id="渐进符号"><a href="#渐进符号" class="headerlink" title="渐进符号"></a>渐进符号</h2><h4 id="渐进符号O（上界）【考点】"><a href="#渐进符号O（上界）【考点】" class="headerlink" title="渐进符号O（上界）【考点】"></a>渐进符号O（上界）【考点】</h4><h6 id="1、符号O的定义"><a href="#1、符号O的定义" class="headerlink" title="1、符号O的定义"></a>1、符号O的定义</h6><p>f(n) &#x3D; O(g(n))当且仅当存在正整数c和n0，使得n &gt;&#x3D; n0时，有f(n) &lt;&#x3D; c * g(n)。此时，称g(n)是f(n)的一个上界。</p><table><thead><tr><th align="center"><strong>常数函数</strong></th><th align="center">f(n) &#x3D; C0 &#x3D; O(1)</th><th align="center">c &#x3D; C0, n0 &#x3D; 0</th></tr></thead><tbody><tr><td align="center"><strong>线性函数</strong></td><td align="center"><strong>3n + 2 &#x3D; O(n)</strong></td><td align="center"><strong>c &#x3D; 4, n0 &#x3D; 2</strong></td></tr><tr><td align="center"><strong>线性函数</strong></td><td align="center"><strong>100n + 6lnn &#x3D; O(n)</strong></td><td align="center"><strong>c &#x3D; 102, n0 &#x3D; 6</strong></td></tr><tr><td align="center"><strong>平方函数</strong></td><td align="center"><strong>10n ^ 2 + 4n + 3 &#x3D; O(n ^ 2)</strong></td><td align="center"><strong>c &#x3D; 11, n0 &#x3D; 5</strong></td></tr><tr><td align="center"><strong>平方函数</strong></td><td align="center"><strong>nlogn + n ^ 2 &#x3D; O(n ^ 2)</strong></td><td align="center"><strong>c &#x3D; 2, n0 &#x3D; 3</strong></td></tr><tr><td align="center"><strong>指数函数</strong></td><td align="center"><strong>6 x 2 ^ n + n ^ 2 &#x3D; O(2 ^ n)</strong></td><td align="center"><strong>c &#x3D; 7, n0 &#x3D; 4</strong></td></tr><tr><td align="center"><strong>松散界限</strong></td><td align="center"><strong>3n + 2 &#x3D; O(n ^ 2)</strong></td><td align="center"><strong>c &#x3D; 3, n0 &#x3D; 2</strong></td></tr><tr><td align="center"><strong>错误界限</strong></td><td align="center"><strong>3n + 2 ≠ O(1)</strong></td><td align="center"></td></tr></tbody></table><p><strong>注意：</strong></p><p>（1）不要产生松散界限；（2）不要产生错误界限；（3）f(n)与g(n)顺序不能调转。</p><h6 id="2、【大O比率定理】"><a href="#2、【大O比率定理】" class="headerlink" title="2、【大O比率定理】"></a>2、【大O比率定理】</h6><p>$$<br>对于函数f(n)和g(n)，如果\lim_{n\rightarrow + \infty}\frac{f(n)}{g(n)}存在，则f(n) &#x3D; O(g(n))当且仅当c &gt; 0,使得\lim_{n\rightarrow + \infty}\frac{f(n)}{g(n)} ≤ c。<br>$$</p><h6 id="3、【常用上界关系定理】-由大O比率定理证明"><a href="#3、【常用上界关系定理】-由大O比率定理证明" class="headerlink" title="3、【常用上界关系定理】 (由大O比率定理证明)"></a>3、【常用上界关系定理】 (由大O比率定理证明)</h6><p>$$<br>对于任何正数x和ε，<br>\log^{-x}n &#x3D; O(1),<br>x &#x3D; O(\log^{ε}n),<br>\log^{x}n &#x3D; O(\log^{x + ε}n),<br>\log^{x}n &#x3D; O(n^{ε}),\<br>n^x &#x3D; O(n^{x + ε}),<br>n^x &#x3D; O(2^n)和2^n &#x3D; O(2!)<br>等上界关系都成立。<br>$$</p><p><strong>总结：</strong>常用上界关系就是通常所说的向上约分，需要注意的是常用上界关系定理中的转换公式，理解与学会转换诸如：<br>$$<br>\log^{20}n &#x3D; O(n^{1.5})<br>$$</p><h4 id="渐进符号Ω（下界）"><a href="#渐进符号Ω（下界）" class="headerlink" title="渐进符号Ω（下界）"></a>渐进符号Ω（下界）</h4><h6 id="1、符号Ω的定义"><a href="#1、符号Ω的定义" class="headerlink" title="1、符号Ω的定义"></a>1、符号Ω的定义</h6><p>f(n) &#x3D; Ω(g(n))当且仅当存在正常数c和n0，使得当n ≥ n0时，有f(n) &gt;&#x3D; c * g(n)。</p><h6 id="2、【大Ω比率定理】"><a href="#2、【大Ω比率定理】" class="headerlink" title="2、【大Ω比率定理】"></a>2、【大Ω比率定理】</h6><p>$$<br>对于f(n)和g(n)，如果\lim_{n\rightarrow + \infty}\frac{g(n)}{f(n)}存在，则f(n) &#x3D; Ω(g(n))当且仅当存在c &gt; 0，使得\lim_{n\rightarrow + \infty}\frac{g(n)}{f(n)} &lt;&#x3D; c。<br>$$</p><h4 id="渐进符号Θ（双界）"><a href="#渐进符号Θ（双界）" class="headerlink" title="渐进符号Θ（双界）"></a>渐进符号Θ（双界）</h4><h6 id="1、符号Θ的定义"><a href="#1、符号Θ的定义" class="headerlink" title="1、符号Θ的定义"></a>1、符号Θ的定义</h6><p>f(n) &#x3D; Θ(g(n))当且仅当存在正常数c1，c2和n0，使得当n &gt;&#x3D; n0时，有c1 * g(n) &lt;&#x3D; f(n) &lt;&#x3D; c2 * g(n)。</p><h6 id="2、【大Θ比率定理】"><a href="#2、【大Θ比率定理】" class="headerlink" title="2、【大Θ比率定理】"></a>2、【大Θ比率定理】</h6><p>$$<br>对于函数f(n)和g(n)，如果\lim_{n\rightarrow + \infty}\frac{f(n)}{g(n)}与\lim_{n\rightarrow + \infty}\frac{g(n)}{f(n)}都存在，则f(n) &#x3D; Θ(g(n))当且仅当存在正常数c1，c2，\<br>使得\lim_{n\rightarrow + \infty}\frac{g(n)}{f(n)} &lt;&#x3D; c1, \lim_{n\rightarrow + \infty}\frac{f(n)}{g(n)} &lt;&#x3D; c2。<br>$$</p><ul><li>大Θ比率定理是大O比率定理与大Ω比率定理的结合。</li></ul><h4 id="简化Master定理【考点】"><a href="#简化Master定理【考点】" class="headerlink" title="简化Master定理【考点】"></a>简化Master定理【考点】</h4><h6 id="1、定理适用范围"><a href="#1、定理适用范围" class="headerlink" title="1、定理适用范围"></a>1、定理适用范围</h6><p>当a &gt; 0, b &gt; 1, α &gt;&#x3D; 0时，对于形如T(n) &#x3D; aT(n &#x2F; b) + X(n ^ α)（其中，X代表O、Ω、Θ之一，n &#x2F; b可以理解为[n &#x2F; b]【这里无法描述】）的递归函数，可以使用简化Master定理找到他们的渐进函数。</p><h6 id="2、简化Master定理"><a href="#2、简化Master定理" class="headerlink" title="2、简化Master定理"></a>2、简化Master定理</h6><p>$$<br>当a &gt; 0, b &gt; 1, α &gt;&#x3D; 0时，递归函数T(n) &#x3D; aT(n &#x2F; b) + X(n ^ α)(X代表O、Ω、Θ之一)的渐进函数为 \<br>T(n) &#x3D;<br>\begin{cases}<br>X(n^{\log_ba}), α &lt; \log_ba \<br>X(n^αlogn), α &#x3D; \log_ba \<br>X(n^α), α &gt; \log_ba<br>\end{cases}<br>$$</p><ul><li>通过简化Master定理我们求的是<strong>Θ的渐进函数</strong>。</li></ul><h2 id="排序算法"><a href="#排序算法" class="headerlink" title="排序算法"></a>排序算法</h2><h6 id="选择排序（升序排列）"><a href="#选择排序（升序排列）" class="headerlink" title="选择排序（升序排列）"></a>选择排序（升序排列）</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">class</span> T&gt;</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">Max</span><span class="params">(T X[], <span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="type">int</span> pos = <span class="number">0</span>;</span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>; i &lt; n; ++i)</span><br><span class="line"> <span class="keyword">if</span>(X[pos] &lt; X[i]) pos = i;</span><br><span class="line"> <span class="keyword">return</span> pos;  <span class="comment">// 返回数组最大值的下标</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">class</span> T&gt;</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">SelectionSort</span><span class="params">(T X[], <span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> m = n; m &gt; <span class="number">1</span>; --m)&#123; </span><br><span class="line">        <span class="type">int</span> i = <span class="built_in">Max</span>(X, m);  <span class="comment">// 找到当前数组的最大值</span></span><br><span class="line"> <span class="built_in">swap</span>(X[i], X[m - <span class="number">1</span>]);  <span class="comment">// 将最大值与数组未遍历末位交换</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 时间复杂度为O(n ^ 2)</span></span><br></pre></td></tr></table></figure><h6 id="插入排序（升序排列且不含重复元素）"><a href="#插入排序（升序排列且不含重复元素）" class="headerlink" title="插入排序（升序排列且不含重复元素）"></a>插入排序（升序排列且不含重复元素）</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 将元素插入到有序数组中</span></span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">class</span> T, <span class="keyword">class</span> T2&gt;</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">Insert</span><span class="params">(T X[], <span class="type">int</span> m, <span class="type">const</span> T2 &amp;v)</span>  <span class="comment">// v为要插入的元素</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="type">int</span> p;</span><br><span class="line"> <span class="keyword">for</span>(p = m - <span class="number">1</span>; p &gt;= <span class="number">0</span> <span class="keyword">and</span> X[p] &gt; v; --p) &#123;&#125;  <span class="comment">// 用p记录第一个比v小的数组下标</span></span><br><span class="line"> <span class="keyword">if</span>(X[p] == v) <span class="keyword">return</span> m;  <span class="comment">// 如果两数据相等，不执行插入操作</span></span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i = m - <span class="number">1</span>; i &gt; p; --i)</span><br><span class="line"> X[i + <span class="number">1</span>] = X[i];  <span class="comment">// 所有数据向后移一位</span></span><br><span class="line"> X[p + <span class="number">1</span>] = v;</span><br><span class="line"> <span class="keyword">return</span> m + <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 时间复杂度为O(m)</span></span><br></pre></td></tr></table></figure><h6 id="插入排序（升序排列）"><a href="#插入排序（升序排列）" class="headerlink" title="插入排序（升序排列）"></a>插入排序（升序排列）</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 将无序数组进行插入排序</span></span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">class</span> T&gt;</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Insert</span><span class="params">(T X[], <span class="type">int</span> m, <span class="type">const</span> T &amp;v)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line"><span class="type">int</span> i;</span><br><span class="line"> <span class="keyword">for</span>(i = m - <span class="number">1</span>; i &gt;= <span class="number">0</span> <span class="keyword">and</span> X[i] &gt; v; --i)  <span class="comment">// 找到第一个比传入元素小的下标，将其他元素向后移动</span></span><br><span class="line"> X[i + <span class="number">1</span>] = X[i];</span><br><span class="line"> X[i + <span class="number">1</span>] = v;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">class</span> T&gt;</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">InsertionSort</span><span class="params">(T X[], <span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> m = <span class="number">1</span>; m &lt; n; ++m)&#123; </span><br><span class="line"><span class="keyword">auto</span> v = X[m];</span><br><span class="line"> <span class="built_in">Insert</span>(X, m, v);</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 时间复杂度为O(n ^ 2)</span></span><br></pre></td></tr></table></figure><h2 id="图遍历方法"><a href="#图遍历方法" class="headerlink" title="图遍历方法"></a>图遍历方法</h2><h6 id="一般树的先序遍历"><a href="#一般树的先序遍历" class="headerlink" title="一般树的先序遍历"></a>一般树的先序遍历</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">BtNode</span></span><br><span class="line">&#123; </span><br><span class="line">    T data;</span><br><span class="line"> BtNode *left = <span class="number">0</span>, *right = <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">class</span> T, <span class="keyword">class</span> Func&gt;</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">PreOrder</span><span class="params">(BtNode&lt;T&gt; *x, Func Visit)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="keyword">if</span>(x == <span class="number">0</span>) <span class="keyword">return</span>;</span><br><span class="line"> <span class="built_in">Visit</span>(x);</span><br><span class="line"> <span class="built_in">PreOrder</span>(x-&gt;left, Visit);</span><br><span class="line"> <span class="built_in">PreOrder</span>(x-&gt;right, Visit);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="二叉树的层次遍历"><a href="#二叉树的层次遍历" class="headerlink" title="二叉树的层次遍历"></a>二叉树的层次遍历</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">BtNode</span></span><br><span class="line">&#123; </span><br><span class="line">    T data;</span><br><span class="line"> BtNode *left = <span class="number">0</span>, *right = <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">class</span> T, <span class="keyword">class</span> Func&gt;</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">LevelOrder</span><span class="params">(BtNode&lt;T&gt; *x, Func Visit)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="keyword">if</span>(x == <span class="number">0</span>) <span class="keyword">return</span>;</span><br><span class="line">queue&lt;BtNode&lt;T&gt; *&gt; Q;  <span class="comment">// 创建队列（先入先出）</span></span><br><span class="line"> <span class="built_in">Visit</span>(x), Q.<span class="built_in">push</span>(x);</span><br><span class="line"> <span class="keyword">while</span>(<span class="keyword">not</span> Q.<span class="built_in">empty</span>())&#123; </span><br><span class="line">        x = Q.<span class="built_in">front</span>(), Q.<span class="built_in">pop</span>();  <span class="comment">// 取Q队列的第一个元素出队。</span></span><br><span class="line"> <span class="keyword">auto</span> left = x-&gt;left, right = x-&gt;right;</span><br><span class="line"> <span class="keyword">if</span>(left != <span class="number">0</span>)</span><br><span class="line"> <span class="built_in">Visit</span>(left), Q.<span class="built_in">push</span>(left);  <span class="comment">// 将x左子树元素入队</span></span><br><span class="line"> <span class="keyword">if</span>(right != <span class="number">0</span>)</span><br><span class="line"> <span class="built_in">Visit</span>(right), Q.<span class="built_in">push</span>(right);  <span class="comment">// 将x右子树元素入队</span></span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 其实类似先序遍历，都是先执行Visit操作后再进行左右子树判断；</span></span><br><span class="line"><span class="comment">// 主要区别在于层次遍历是一个入队出队操作，先判断队列中是否有元素，再去将元素的左右子树依次入队。</span></span><br></pre></td></tr></table></figure><h6 id="连通图的宽度优先搜索算法"><a href="#连通图的宽度优先搜索算法" class="headerlink" title="连通图的宽度优先搜索算法"></a>连通图的宽度优先搜索算法</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">class</span> Fun&gt;</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">BFS</span><span class="params">(Matrix&lt;<span class="type">bool</span>&gt; &amp;G, <span class="type">int</span> v, vector&lt;<span class="type">bool</span>&gt; &amp;Visited, Fun Visit)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="type">int</span> n = G.<span class="built_in">rows</span>();</span><br><span class="line"> queue&lt;<span class="type">int</span>&gt; Q;</span><br><span class="line"> <span class="built_in">Visit</span>(v), Visited[v] = <span class="number">1</span>, Q.<span class="built_in">push</span>(v);  <span class="comment">// Visit函数代表进行访问操作，数组Visited记录元素元素是否被访问</span></span><br><span class="line"> <span class="keyword">while</span>(<span class="keyword">not</span> Q.<span class="built_in">empty</span>())&#123; </span><br><span class="line">        v = Q.<span class="built_in">front</span>(), Q.<span class="built_in">pop</span>();</span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> w = <span class="number">0</span>; w &lt; n; ++w)</span><br><span class="line"> <span class="keyword">if</span>(<span class="keyword">not</span> Visited[w] <span class="keyword">and</span> <span class="built_in">G</span>(v, w) == <span class="number">1</span>)</span><br><span class="line"> <span class="built_in">Visit</span>(w), Visited[w] = <span class="number">1</span>, Q.<span class="built_in">push</span>(w);</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 和树的层次遍历一模一样，区别就是树一般为二叉树，只有两个子节点，但是图是每个节点都有可能相连；</span></span><br><span class="line"><span class="comment">// 所以在宽度搜索时是将没有访问过的一排节点（相连）全部入队。</span></span><br></pre></td></tr></table></figure><h6 id="连通图的深度优先算法"><a href="#连通图的深度优先算法" class="headerlink" title="连通图的深度优先算法"></a>连通图的深度优先算法</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">class</span> Fun&gt;</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">DFS</span><span class="params">(Matrix&lt;<span class="type">bool</span>&gt; &amp;G, <span class="type">int</span> v, vector&lt;<span class="type">bool</span>&gt; &amp;Visited, Fun Visit)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="type">int</span> n = G.<span class="built_in">rows</span>();</span><br><span class="line"> <span class="built_in">Visit</span>(v), Visited[v] = <span class="number">1</span>;</span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> w = <span class="number">0</span>; w &lt; n; ++w)</span><br><span class="line"> <span class="keyword">if</span>(<span class="keyword">not</span> Visited[w] <span class="keyword">and</span> <span class="built_in">G</span>(v, w) == <span class="number">1</span>)</span><br><span class="line"> <span class="built_in">DFS</span>(G, w, Visited, Visit);  <span class="comment">// 递归去寻找未访问的节点</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="二叉树的深度优先搜索（改）计算每个节点的深度"><a href="#二叉树的深度优先搜索（改）计算每个节点的深度" class="headerlink" title="二叉树的深度优先搜索（改）计算每个节点的深度"></a>二叉树的深度优先搜索（改）计算每个节点的深度</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">BtNode</span></span><br><span class="line">&#123; </span><br><span class="line">    T data;</span><br><span class="line"> <span class="type">int</span> depth = <span class="number">1</span>;</span><br><span class="line"> BtNode *left = <span class="number">0</span>, *right = <span class="number">0</span>; <span class="comment">// 左子树, 右子树</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;  <span class="comment">// 使用后根遍历的方法计算深度</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">Depth</span><span class="params">(BtNode&lt;T&gt; *x)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="keyword">if</span>(x == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"> x-&gt;depth = std::<span class="built_in">max</span>(<span class="built_in">Depth</span>(x-&gt;left), <span class="built_in">Depth</span>(x-&gt;right)) + <span class="number">1</span>;  <span class="comment">// 递归向上回溯深度</span></span><br><span class="line"> <span class="keyword">return</span> x-&gt;depth;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="一般树的深度优先搜索（改）计算每个节点的层次"><a href="#一般树的深度优先搜索（改）计算每个节点的层次" class="headerlink" title="一般树的深度优先搜索（改）计算每个节点的层次"></a>一般树的深度优先搜索（改）计算每个节点的层次</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">TreeNode</span></span><br><span class="line">&#123; </span><br><span class="line">    T data;</span><br><span class="line"> <span class="type">int</span> level = <span class="number">1</span>;</span><br><span class="line"> TreeNode *first = <span class="number">0</span>, *next = <span class="number">0</span>;  <span class="comment">// first、next的作用类似于首位坐标</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;  <span class="comment">// 使用先根遍历的方法计算层次</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Level</span><span class="params">(TreeNode&lt;T&gt; *x, <span class="type">int</span> level)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="keyword">if</span>(x == <span class="number">0</span>) <span class="keyword">return</span>;</span><br><span class="line"> x-&gt;level = level;  <span class="comment">// </span></span><br><span class="line"> <span class="keyword">for</span>(<span class="keyword">auto</span> w = x-&gt;first; w != <span class="number">0</span>; w = w-&gt;next)  <span class="comment">// 这里就是层次遍历的体现，将first开始到最后一个next节点</span></span><br><span class="line"> <span class="built_in">Level</span>(w, level + <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="连通图的深度优先遍历算法（改）计算每个顶点的层次"><a href="#连通图的深度优先遍历算法（改）计算每个顶点的层次" class="headerlink" title="连通图的深度优先遍历算法（改）计算每个顶点的层次"></a>连通图的深度优先遍历算法（改）计算每个顶点的层次</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;Matrix.hpp&quot;</span>  <span class="comment">// 图计算的依赖</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;ios.hpp&quot;</span></span></span><br><span class="line">    <span class="meta">#<span class="keyword">include</span> <span class="string">&lt;functional&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">auto</span> <span class="title">Level</span><span class="params">(<span class="type">const</span> Matrix&lt;<span class="type">bool</span>&gt; &amp;G, <span class="type">int</span> u = <span class="number">0</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="type">int</span> n = G.<span class="built_in">rows</span>();</span><br><span class="line"> <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">L</span><span class="params">(n, <span class="number">0</span>)</span></span>;  <span class="comment">// 设置L中有n个元素，每个元素值为0</span></span><br><span class="line"> function&lt;<span class="type">void</span>(<span class="type">int</span>, <span class="type">int</span>)&gt;</span><br><span class="line"> Level = [&amp;](<span class="type">int</span> u, <span class="type">int</span> level)&#123;  <span class="comment">// 区别于外面一圈Level函数，可以调用外圈Level中的参数</span></span><br><span class="line">        L[u] = level;</span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> w = <span class="number">0</span>; w &lt; n; ++w)</span><br><span class="line"> <span class="keyword">if</span>(L[w] == <span class="number">0</span> <span class="keyword">and</span> <span class="built_in">G</span>(u, w) == <span class="number">1</span>)</span><br><span class="line"> <span class="built_in">Level</span>(w, level + <span class="number">1</span>);</span><br><span class="line"> &#125;;</span><br><span class="line"> <span class="built_in">Level</span>(u, <span class="number">1</span>);</span><br><span class="line"> <span class="keyword">return</span> L;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="图的宽度优先遍历算法（改）输出图的每个连通分支"><a href="#图的宽度优先遍历算法（改）输出图的每个连通分支" class="headerlink" title="图的宽度优先遍历算法（改）输出图的每个连通分支"></a>图的宽度优先遍历算法（改）输出图的每个连通分支</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;../algorithm.h&quot;</span></span></span><br><span class="line"><span class="function"><span class="keyword">auto</span> <span class="title">BFS</span><span class="params">(Matrix&lt;<span class="type">bool</span>&gt; &amp;G, <span class="type">int</span> v, vector&lt;<span class="type">bool</span>&gt; &amp;Visited)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="type">int</span> n = G.<span class="built_in">rows</span>();</span><br><span class="line"> queue&lt;<span class="type">int</span>&gt; Q;</span><br><span class="line"> set&lt;<span class="type">int</span>&gt; part;</span><br><span class="line"> part &lt;&lt; v, Visited[v] = <span class="number">1</span>, Q.<span class="built_in">push</span>(v);</span><br><span class="line"> <span class="keyword">while</span>(<span class="keyword">not</span> Q.<span class="built_in">empty</span>())&#123; </span><br><span class="line">        v = Q.<span class="built_in">front</span>(), Q.<span class="built_in">pop</span>();</span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> w = <span class="number">0</span>; w &lt; n; ++w)</span><br><span class="line"> <span class="keyword">if</span>(<span class="keyword">not</span> Visited[w] <span class="keyword">and</span> <span class="built_in">G</span>(v, w) == <span class="number">1</span>)</span><br><span class="line"> part &lt;&lt; w, Visited[w] = <span class="number">1</span>, Q.<span class="built_in">push</span>(w);</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">return</span> part;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">auto</span> <span class="title">BFT</span><span class="params">(Matrix&lt;<span class="type">bool</span>&gt; &amp;G)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="type">int</span> n = G.<span class="built_in">rows</span>();</span><br><span class="line"> <span class="function">vector&lt;<span class="type">bool</span>&gt; <span class="title">Visited</span><span class="params">(n, <span class="number">0</span>)</span></span>;</span><br><span class="line"> vector&lt;set&lt;<span class="type">int</span>&gt;&gt; parts;  <span class="comment">// 创建一个动态大小的数组parts记录int集合</span></span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> v = <span class="number">0</span>; v &lt; n; ++v)</span><br><span class="line"> <span class="keyword">if</span>(<span class="keyword">not</span> Visited[v])</span><br><span class="line"> parts &lt;&lt; <span class="built_in">BFS</span>(G, v, Visited);  <span class="comment">// 将每个节点都遍历一遍</span></span><br><span class="line"> <span class="keyword">return</span> parts;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 和连通图的主要差别就是BFT函数将所有节点扫一遍，避免出现有些节点单出来的情况。</span></span><br><span class="line"><span class="comment">//[1,1,1,0,0],</span></span><br><span class="line"><span class="comment">//[1,1,1,0,0],</span></span><br><span class="line"><span class="comment">//[1,1,1,0,0],</span></span><br><span class="line"><span class="comment">//[0,0,0,1,1],</span></span><br><span class="line"><span class="comment">//[0,0,0,1,1]</span></span><br></pre></td></tr></table></figure><h2 id="分治方法"><a href="#分治方法" class="headerlink" title="分治方法"></a>分治方法</h2><h6 id="折半搜索（升序数组）"><a href="#折半搜索（升序数组）" class="headerlink" title="折半搜索（升序数组）"></a>折半搜索（升序数组）</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 从一个升序数组中查找一个元素</span></span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">class</span> T, <span class="keyword">class</span> T2&gt;</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">search</span><span class="params">(T X[], <span class="type">int</span> n, <span class="type">const</span> T2 &amp;v)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">   <span class="type">int</span> low = <span class="number">0</span>, up = n;</span><br><span class="line"> <span class="keyword">while</span>(low &lt; up)&#123; </span><br><span class="line">        <span class="type">int</span> m = (low + up) / <span class="number">2</span>;</span><br><span class="line"> <span class="keyword">if</span>(v == X[m]) <span class="keyword">return</span> m;</span><br><span class="line"> <span class="keyword">else</span> <span class="keyword">if</span>(v &lt; X[m]) up = m;</span><br><span class="line"> <span class="keyword">else</span> low = m + <span class="number">1</span>;</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 时间复杂度为O(log(n))</span></span><br></pre></td></tr></table></figure><h6 id="归并排序"><a href="#归并排序" class="headerlink" title="归并排序"></a>归并排序</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">class</span> T&gt;</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Merge</span><span class="params">(T W[], <span class="type">int</span> low, <span class="type">int</span> m, <span class="type">int</span> up)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="function">vector <span class="title">X</span><span class="params">(W + low, W + m)</span></span>;  <span class="comment">// 创建动态数组X长度为low~m，存入low~m的数据</span></span><br><span class="line"> <span class="function">vector <span class="title">Y</span><span class="params">(W + m, W + up)</span></span>;  <span class="comment">// 创建动态数组Y长度为m~up，存入m~up的数据</span></span><br><span class="line"> <span class="type">int</span> nx = <span class="built_in">size</span>(X), ny = <span class="built_in">size</span>(Y);</span><br><span class="line"> <span class="type">int</span> i = <span class="number">0</span>, j = <span class="number">0</span>, k = low;</span><br><span class="line"> <span class="keyword">while</span>(i &lt; nx <span class="keyword">and</span> j &lt; ny)  <span class="comment">// 将X、Y中数据进行比较，存入W数组</span></span><br><span class="line"> <span class="keyword">if</span>(X[i] &lt; Y[j])</span><br><span class="line"> W[k] = X[i], ++k, ++i;</span><br><span class="line"> <span class="keyword">else</span></span><br><span class="line"> W[k] = Y[j], ++k, ++j;</span><br><span class="line"> <span class="keyword">while</span>(i &lt; nx)  <span class="comment">// 将比较完后未存入的元素存入</span></span><br><span class="line"> W[k] = X[i], ++k, ++i;</span><br><span class="line"> <span class="keyword">while</span>(j &lt; ny)</span><br><span class="line"> W[k] = Y[j], ++k, ++j;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">class</span> T&gt;</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">MergeSort</span><span class="params">(T X[], <span class="type">int</span> low, <span class="type">int</span> up)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="keyword">if</span>(up - low &lt;= <span class="number">1</span>) <span class="keyword">return</span>;</span><br><span class="line"> <span class="type">int</span> m = (low + up) / <span class="number">2</span>;</span><br><span class="line"> <span class="built_in">MergeSort</span>(X, low, m);  <span class="comment">// 左右递归再向上排序</span></span><br><span class="line"> <span class="built_in">MergeSort</span>(X, m, up);</span><br><span class="line"> <span class="built_in">Merge</span>(X, low, m, up);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 时间复杂度为Θ(n * log(n))</span></span><br></pre></td></tr></table></figure><h6 id="快速排序"><a href="#快速排序" class="headerlink" title="快速排序"></a>快速排序</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">class</span> T&gt;</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">Partition</span><span class="params">(T X[], <span class="type">int</span> low, <span class="type">int</span> up)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="type">int</span> key = up - <span class="number">1</span>, p = low;</span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> i = low; i &lt; key; ++i)  <span class="comment">// 每次将比最后一个数小的数排到数组的前面</span></span><br><span class="line"> <span class="keyword">if</span>(X[i] &lt; X[key])</span><br><span class="line"> <span class="built_in">swap</span>(X[i], X[p]), ++p;</span><br><span class="line"> <span class="built_in">swap</span>(X[key], X[p]);  <span class="comment">// 如果前面所有数都比X[key]小，那么swap(X[key], X[p])实际为swap(X[key], X[key])</span></span><br><span class="line"> <span class="keyword">return</span> p;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">class</span> T&gt;</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">QuickSort</span><span class="params">(T X[], <span class="type">int</span> low, <span class="type">int</span> up)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="keyword">if</span>(up - low &lt;= <span class="number">1</span>) <span class="keyword">return</span>;</span><br><span class="line"> <span class="type">int</span> m = <span class="built_in">Partition</span>(X, low, up);</span><br><span class="line"> <span class="built_in">QuickSort</span>(X, low, m);  <span class="comment">// 不断缩小左右区间，直到完成排序</span></span><br><span class="line"> <span class="built_in">QuickSort</span>(X, m + <span class="number">1</span>, up);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 平均时间复杂度为O(n * log(n))，最坏时间复杂度为O(n ^ 2)</span></span><br></pre></td></tr></table></figure><h6 id="线性时间选择算法"><a href="#线性时间选择算法" class="headerlink" title="线性时间选择算法"></a>线性时间选择算法</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">class</span> T&gt;</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">Partition</span><span class="params">(T X[], <span class="type">int</span> low, <span class="type">int</span> up)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="type">int</span> key = up - <span class="number">1</span>, p = low;</span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> i = low; i &lt; key; ++i)</span><br><span class="line"> <span class="keyword">if</span>(X[i] &lt; X[key])</span><br><span class="line"> <span class="built_in">swap</span>(X[i], X[p]), ++p;</span><br><span class="line"> <span class="built_in">swap</span>(X[key], X[p]);</span><br><span class="line"> <span class="keyword">return</span> p;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">class</span> T&gt;</span></span><br><span class="line"><span class="function">T &amp;<span class="title">Select</span><span class="params">(T X[], <span class="type">int</span> n, <span class="type">int</span> k)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="type">int</span> low = <span class="number">0</span>, up = n;</span><br><span class="line"> <span class="keyword">for</span>(;;)&#123; </span><br><span class="line">        <span class="type">int</span> m = <span class="built_in">Partition</span>(X, low, up);</span><br><span class="line"> <span class="keyword">if</span>(k == m) <span class="keyword">return</span> X[m];  <span class="comment">// 找到指定元素，算法终止</span></span><br><span class="line"> <span class="keyword">else</span> <span class="keyword">if</span>(k &lt; m) up = m;</span><br><span class="line"> <span class="keyword">else</span> low = m + <span class="number">1</span>;</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 平均时间复杂度为O(n)，最坏时间复杂度为O(n ^ 2)</span></span><br><span class="line"><span class="comment">// 显而易见，这里的Partition函数和上题的一模一样，因此最坏情况（数组降序）时时间复杂度为O(n ^ 2)</span></span><br><span class="line"><span class="comment">// 这个算法主要是用来在乱序数组中寻找指定元素</span></span><br></pre></td></tr></table></figure><h6 id="合并数组（不含重复元素）"><a href="#合并数组（不含重复元素）" class="headerlink" title="合并数组（不含重复元素）"></a>合并数组（不含重复元素）</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">class</span> T&gt;</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">Merge</span><span class="params">(T X[], <span class="type">int</span> m, T Y[], <span class="type">int</span> n, T W[])</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="type">int</span> i = <span class="number">0</span>, j = <span class="number">0</span>, k = <span class="number">0</span>;</span><br><span class="line"> <span class="keyword">while</span>(i &lt; m <span class="keyword">and</span> j &lt; n)</span><br><span class="line"> <span class="keyword">if</span>(X[i] &lt; Y[j])</span><br><span class="line"> W[k] = X[i], ++k, ++i;</span><br><span class="line"> <span class="keyword">else</span> <span class="keyword">if</span>(X[i] &gt; Y[j])</span><br><span class="line"> W[k] = Y[j], ++k, ++j;</span><br><span class="line"> <span class="keyword">else</span></span><br><span class="line"> W[k] = X[i], ++k, ++i, ++j;</span><br><span class="line"> <span class="keyword">while</span>(i &lt; m)</span><br><span class="line"> W[k] = X[i], ++k, ++i;</span><br><span class="line"> <span class="keyword">while</span>(j &lt; n)</span><br><span class="line"> W[k] = Y[j], ++k, ++j;</span><br><span class="line"> <span class="keyword">return</span> k;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 和归并排序的merge函数基本一模一样，就不做赘述</span></span><br></pre></td></tr></table></figure><h6 id="奇偶划分"><a href="#奇偶划分" class="headerlink" title="奇偶划分"></a>奇偶划分</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">Partition</span><span class="params">(<span class="type">int</span> X[], <span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="type">int</span> p = <span class="number">0</span>;</span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; ++i)</span><br><span class="line"> <span class="keyword">if</span>(X[i] % <span class="number">2</span> == <span class="number">1</span>)</span><br><span class="line"> <span class="built_in">swap</span>(X[i], X[p]), ++p;</span><br><span class="line"> <span class="keyword">return</span> p;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="贪心算法"><a href="#贪心算法" class="headerlink" title="贪心算法"></a>贪心算法</h2><h6 id="装载问题"><a href="#装载问题" class="headerlink" title="装载问题"></a>装载问题</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">vector&lt;<span class="type">bool</span>&gt; <span class="title">Load</span><span class="params">(vector&lt;<span class="type">double</span>&gt; &amp;W, <span class="type">double</span> M)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="type">int</span> n = W.<span class="built_in">size</span>();</span><br><span class="line"> <span class="built_in">sort</span>(<span class="built_in">begin</span>(W), <span class="built_in">end</span>(W));  <span class="comment">// 从小到大排序</span></span><br><span class="line"> <span class="function">vector&lt;<span class="type">bool</span>&gt; <span class="title">X</span><span class="params">(n, <span class="number">0</span>)</span></span>;</span><br><span class="line"> <span class="type">double</span> rc = M;</span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; n <span class="keyword">and</span> W[i] &lt;= rc; ++i)</span><br><span class="line"> X[i] = <span class="number">1</span>, rc -= W[i];</span><br><span class="line"> <span class="keyword">return</span> X;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="背包问题"><a href="#背包问题" class="headerlink" title="背包问题"></a>背包问题</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">Sort</span><span class="params">(vector&lt;<span class="type">double</span>&gt; &amp;V, vector&lt;<span class="type">double</span>&gt; &amp;W)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">oType</span> &#123; <span class="type">double</span> v, w; &#125;;  <span class="comment">// 一个物品具有价值、重量两个属性</span></span><br><span class="line"> <span class="keyword">auto</span> cmp = [](oType p, oType q)&#123; </span><br><span class="line">        <span class="keyword">return</span> p.v / p.w &gt; q.v / q.w;</span><br><span class="line"> &#125;;</span><br><span class="line"> <span class="type">int</span> n = <span class="built_in">min</span>(V.<span class="built_in">size</span>(), W.<span class="built_in">size</span>());</span><br><span class="line"> <span class="function">vector&lt;oType&gt; <span class="title">X</span><span class="params">(n)</span></span>;</span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; ++i)</span><br><span class="line"> X[i] = &#123;V[i], W[i]&#125;;</span><br><span class="line"> <span class="built_in">sort</span>(<span class="built_in">begin</span>(X), <span class="built_in">end</span>(X), cmp);  <span class="comment">// 这个可能是按照cmp规则对X进行排序（题主C++不太好QWQ）</span></span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; ++i)</span><br><span class="line"> V[i] = X[i].v, W[i] = X[i].w;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function">vector&lt;<span class="type">double</span>&gt; <span class="title">Knap</span><span class="params">(vector&lt;<span class="type">double</span>&gt; &amp;V, vector&lt;<span class="type">double</span>&gt; &amp;W, <span class="type">double</span> M)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="type">int</span> n = <span class="built_in">min</span>(V.<span class="built_in">size</span>(), W.<span class="built_in">size</span>());  <span class="comment">// 避免出现价值、重量不同导致物品个数出问题</span></span><br><span class="line"> <span class="built_in">Sort</span>(V, W);</span><br><span class="line"> <span class="function">vector&lt;<span class="type">double</span>&gt; <span class="title">X</span><span class="params">(n, <span class="number">0</span>)</span></span>;</span><br><span class="line"> <span class="type">double</span> rc = M;</span><br><span class="line"> <span class="type">int</span> t;</span><br><span class="line"> <span class="keyword">for</span>(t = <span class="number">0</span>; t &lt; n <span class="keyword">and</span> W[t] &lt;= rc; ++t)</span><br><span class="line"> X[t] = <span class="number">1</span>, rc -= W[t];</span><br><span class="line"> <span class="keyword">if</span>(t &lt; n)  <span class="comment">// 这一步很多余，毕竟不可能只把一个物品放一部分进背包</span></span><br><span class="line"> X[t] = rc / W[t];</span><br><span class="line"> <span class="keyword">return</span> X;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// Knap函数在Sort函数下部分与装载问题无异，因此Sort函数主要是将价值/重量进行排序</span></span><br></pre></td></tr></table></figure><h6 id="活动安排问题"><a href="#活动安排问题" class="headerlink" title="活动安排问题"></a>活动安排问题</h6><p>已知n个活动E &#x3D; {1，2，…，n}需要使用同一资源，第k个活动的开始和结束时间分别是s_k和f_k，其中s_k &lt; f_k, k &#x3D; 1，2，…，n。</p><p>简单来说就是一个集合中有若干元素，每个元素含有起始（s_k）、结束（f_k）两个值，只有在起始时间才能开始，占用资源直到结束时间结束，经历了起始和结束的元素才能进入子集。求这个集合中能完成的最大子集。</p><p>贪心思想就是当一个活动结束立即找到一个活动开始，优先找到结束时间早的活动。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">Sort</span><span class="params">(vector&lt;<span class="type">double</span>&gt; &amp;S, vector&lt;<span class="type">double</span>&gt; &amp;F)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">oType</span> &#123; <span class="type">double</span> s, f; &#125;;</span><br><span class="line"> <span class="keyword">auto</span> cmp = [](oType p, oType q)&#123; </span><br><span class="line">        <span class="keyword">return</span> p.f &lt; q.f;  <span class="comment">// 按照结束时间进行排序</span></span><br><span class="line"> &#125;;</span><br><span class="line"> <span class="type">int</span> n = <span class="built_in">min</span>(S.<span class="built_in">size</span>(), F.<span class="built_in">size</span>());</span><br><span class="line"> <span class="function">vector&lt;oType&gt; <span class="title">X</span><span class="params">(n)</span></span>;</span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; ++i)</span><br><span class="line"> X[i] = &#123;S[i], F[i]&#125;;</span><br><span class="line"> <span class="built_in">sort</span>(<span class="built_in">begin</span>(X), <span class="built_in">end</span>(X), cmp);</span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; ++i)</span><br><span class="line"> S[i] = X[i].s, F[i] = X[i].f;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function">vector&lt;<span class="type">bool</span>&gt; <span class="title">Action</span><span class="params">(vector&lt;<span class="type">double</span>&gt; &amp;S, vector&lt;<span class="type">double</span>&gt; &amp;F)</span>  <span class="comment">// S是起始时间数组；F是结束时间数组（Start/Final）</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="type">int</span> n = <span class="built_in">min</span>(S.<span class="built_in">size</span>(), F.<span class="built_in">size</span>());</span><br><span class="line"> <span class="built_in">Sort</span>(S, F);</span><br><span class="line"> <span class="function">vector&lt;<span class="type">bool</span>&gt; <span class="title">X</span><span class="params">(n, <span class="number">0</span>)</span></span>;</span><br><span class="line"> X[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>, j = <span class="number">0</span>; i &lt; n; ++i)</span><br><span class="line"> <span class="keyword">if</span>(S[i] &gt;= F[j])</span><br><span class="line"> X[i] = <span class="number">1</span>, j = i;</span><br><span class="line"> <span class="keyword">return</span> X;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 主体和背包问题类似，明确两者的贪心条件区别，可以同时记忆</span></span><br></pre></td></tr></table></figure><h6 id="最小生成树Prim算法"><a href="#最小生成树Prim算法" class="headerlink" title="最小生成树Prim算法"></a>最小生成树Prim算法</h6><p>从图的任一节点开始，每次找到与该节点连通的最短路径的节点（未被访问），直到遍历完所有节点</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// .assign()：C++ string类的成员函数，用于拷贝、赋值操作，它们允许我们顺次地把一个string 对象的部分内容拷贝到另一个string 对象上。</span></span><br><span class="line"><span class="comment">// isinf()函数是cmath标头的库函数，用于检查给定值是否为无限(负无穷大或正无穷大)。如果给定值是无穷大，则返回1；否则，返回0。 </span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">Prim</span><span class="params">(<span class="type">const</span> Matrix&lt;<span class="type">double</span>&gt; &amp;G, <span class="type">int</span> v, vector&lt;<span class="type">int</span>&gt; &amp;prev)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="type">int</span> n = G.<span class="built_in">rows</span>();</span><br><span class="line"> prev.<span class="built_in">assign</span>(n, v); <span class="comment">// prev保存各节点的父亲，初始为根v（这里不写0是因为可能你设置的起始节点不是0）</span></span><br><span class="line"> <span class="function">vector&lt;<span class="type">bool</span>&gt; <span class="title">S</span><span class="params">(n, <span class="literal">false</span>)</span></span>;  <span class="comment">// 记录节点是否被选，初始值为false</span></span><br><span class="line"> S[v] = <span class="literal">true</span>;</span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; n - <span class="number">1</span>; ++i)&#123; </span><br><span class="line">        <span class="type">double</span> min = INFINITY;</span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> w = <span class="number">0</span>; w &lt; n; ++w)</span><br><span class="line"> <span class="keyword">if</span>(<span class="keyword">not</span> S[w] <span class="keyword">and</span> <span class="built_in">G</span>(prev[w], w) &lt; min) </span><br><span class="line">                min = <span class="built_in">G</span>(prev[w], w), v = w;  <span class="comment">// 找到与节点相邻的最短边</span></span><br><span class="line"> <span class="keyword">if</span>(<span class="built_in">isinf</span>(min)) <span class="keyword">return</span> <span class="literal">false</span>;  <span class="comment">// 判断节点间是否连通</span></span><br><span class="line"> S[v] = <span class="literal">true</span>;</span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> w = <span class="number">0</span>; w &lt; n; ++w)</span><br><span class="line"> <span class="keyword">if</span>(<span class="keyword">not</span> S[w] <span class="keyword">and</span> <span class="built_in">G</span>(v, w) &lt; <span class="built_in">G</span>(prev[w], w))  <span class="comment">// 更新未选顶点的父亲）</span></span><br><span class="line">                prev[w] = v;</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 该题主要用于判断无向图是否连通</span></span><br></pre></td></tr></table></figure><h6 id="最小生成树Kruskal算法"><a href="#最小生成树Kruskal算法" class="headerlink" title="最小生成树Kruskal算法"></a>最小生成树Kruskal算法</h6><p>将节点之间的边按照升序排列，选取最短边，在不形成环的情况下遍历完所有节点。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">Kruskal</span><span class="params">(vector&lt;Edge&gt; &amp;Ed, <span class="type">int</span> n, vector&lt;Edge&gt; &amp;X)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="keyword">if</span>(Ed.<span class="built_in">size</span>() &lt; n - <span class="number">1</span>) <span class="keyword">return</span> <span class="literal">false</span>;  <span class="comment">// 边数比节点个数少不可能连通</span></span><br><span class="line"> <span class="built_in">sort</span>(<span class="built_in">begin</span>(Ed), <span class="built_in">end</span>(Ed));</span><br><span class="line"> <span class="function">UnionFind <span class="title">U</span><span class="params">(n)</span></span>;  <span class="comment">// 并查集结构，初始将每个节点作为一个子树</span></span><br><span class="line"> X = &#123;&#125;;</span><br><span class="line"> <span class="keyword">for</span>(<span class="keyword">auto</span> e : Ed)&#123; </span><br><span class="line">        <span class="type">int</span> u = U.<span class="built_in">Find</span>(e.u), v = U.<span class="built_in">Find</span>(e.v);</span><br><span class="line"> <span class="keyword">if</span>(u == v) <span class="keyword">continue</span>;  <span class="comment">// 两节点是一个分支的，不用合并直接进入下一个节点判别</span></span><br><span class="line"> U.<span class="built_in">Union</span>(u, v);</span><br><span class="line"> X.<span class="built_in">push_back</span>(e);  <span class="comment">// 记录节点e已被使用</span></span><br><span class="line"> <span class="keyword">if</span>(X.<span class="built_in">size</span>() &gt;= n - <span class="number">1</span>) <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="多机调度问题"><a href="#多机调度问题" class="headerlink" title="多机调度问题"></a>多机调度问题</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;queue.hpp&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Machine</span> &#123; <span class="type">int</span> i, tm; &#125;; <span class="comment">// 机器号, 使用时间</span></span><br><span class="line"><span class="type">bool</span> <span class="keyword">operator</span>&lt;(<span class="type">const</span> Machine &amp;x, <span class="type">const</span> Machine &amp;y)</span><br><span class="line">&#123; </span><br><span class="line">    <span class="keyword">return</span> x.tm &lt; y.tm; <span class="comment">// 比较使用时间</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">auto</span> <span class="title">InitMachine</span><span class="params">(<span class="type">int</span> m)</span> <span class="comment">// 初始化机器和最小堆</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    minheap&lt;Machine&gt; H;</span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; m; ++i)</span><br><span class="line"> H.<span class="built_in">push</span>(&#123;i, <span class="number">0</span>&#125;);</span><br><span class="line"> <span class="keyword">return</span> H;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">auto</span> <span class="title">LPT</span><span class="params">(vector&lt;<span class="type">int</span>&gt; &amp;J, <span class="type">int</span> m)</span> <span class="comment">// n是作业数, m是机器数, n&gt;m</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="built_in">sort</span>(<span class="built_in">begin</span>(J), <span class="built_in">end</span>(J)); <span class="comment">// 作业按照所需处理时间升序排列</span></span><br><span class="line"> <span class="keyword">auto</span> H = <span class="built_in">InitMachine</span>(m); <span class="comment">// 初始化机器和最小堆</span></span><br><span class="line"> <span class="type">int</span> n = J.<span class="built_in">size</span>(); <span class="comment">// 作业数</span></span><br><span class="line"> <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">X</span><span class="params">(n)</span></span>; <span class="comment">// 当前调度</span></span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> t = n - <span class="number">1</span>; t &gt;= <span class="number">0</span>; --t) <span class="comment">// 从处理时间最长的作业开始</span></span><br><span class="line"> &#123; </span><br><span class="line">        <span class="keyword">auto</span> [i, tm] = H.<span class="built_in">top</span>(); H.<span class="built_in">pop</span>(); <span class="comment">// 选用最早空闲的机器</span></span><br><span class="line"> X[t] = i, tm += J[t]; <span class="comment">// 作业t安排到机器i</span></span><br><span class="line"> H.<span class="built_in">push</span>(&#123;i, tm&#125;);</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">return</span> X;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 因为这题代码过长，强行理解不如按照自己的思路去写一个全新的，所以对于参考代码不做过多赘述。</span></span><br></pre></td></tr></table></figure><p>多级调度问题主要是n个机器、m个作业，每个作业用时不等（可以相等），求最短调度时间。</p><p>整体思路（仅供参考）：</p><p>（1）将作业调度时间降序排列；（2）找到当前时间最短的机器插入作业；（3）判断下一个作业。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">Solution</span><span class="params">(<span class="type">int</span> n, <span class="type">int</span> m, <span class="type">int</span> T[])</span>&#123;</span><br><span class="line">    <span class="type">int</span>[] a = <span class="keyword">new</span> <span class="title class_">int</span>[n];  <span class="comment">// 记录各机器调度时间</span></span><br><span class="line">    Arrays.sort(T,Collections.reverseOrder());  <span class="comment">// 降序排列</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>;i &lt; m;i++)&#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">min</span> <span class="operator">=</span> INFINITY;</span><br><span class="line">        <span class="type">int</span> <span class="variable">pom</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> <span class="number">0</span>;j &lt; n;j++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(a[j] &lt; min)&#123;</span><br><span class="line">                min = a[j];</span><br><span class="line">                pom = j;  <span class="comment">// 记录最短调度机器下标</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        a[pom] += m;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">int</span> <span class="variable">max</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>;i &lt; n;i++)&#123;  <span class="comment">// 找出所有机器中耗时最长的那个</span></span><br><span class="line">        <span class="keyword">if</span>(max &lt; a[i])</span><br><span class="line">            max = a[i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> max;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="动态规划算法"><a href="#动态规划算法" class="headerlink" title="动态规划算法"></a>动态规划算法</h2><h6 id="矩阵连乘最优次序"><a href="#矩阵连乘最优次序" class="headerlink" title="矩阵连乘最优次序"></a>矩阵连乘最优次序</h6><p>主要是n个矩阵进行矩阵乘法运算时，通过括号改变运算的先后顺序，减少运算次数，找到最佳划分方法，求解最少运算次数.</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Matrix&lt;<span class="type">int</span>&gt; <span class="title">MatrixChain</span><span class="params">(<span class="type">int</span> r[], <span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="function">Matrix&lt;<span class="type">int</span>&gt; <span class="title">c</span><span class="params">(n, n, <span class="number">0</span>)</span>, <span class="title">kay</span><span class="params">(n, n)</span></span>;  <span class="comment">// c(i, j)存储矩阵i连乘矩阵j中的最小值，kay记录分段位置</span></span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> i = n - <span class="number">2</span>; i &gt;= <span class="number">0</span>; --i)&#123;  <span class="comment">// 第一层循环从链末尾向前保存最优路径</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j = i + <span class="number">1</span>; j &lt; n; ++j)&#123; </span><br><span class="line">            <span class="built_in">c</span>(i, j) = (<span class="type">int</span>)INFINITY;  <span class="comment">// 初始连乘大小默认最大</span></span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> k = i; k &lt; j; ++k)&#123; </span><br><span class="line">                <span class="type">int</span> t = <span class="built_in">c</span>(i, k) + <span class="built_in">c</span>(k + <span class="number">1</span>, j) + r[i] * r[k + <span class="number">1</span>] * r[j + <span class="number">1</span>];</span><br><span class="line"> <span class="keyword">if</span>(t &lt; <span class="built_in">c</span>(i, j)) <span class="built_in">c</span>(i, j) = t, <span class="built_in">kay</span>(i, j) = k;</span><br><span class="line"> &#125;</span><br><span class="line"> &#125;</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">return</span> kay;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 时间复杂度为O(n ^ 3)</span></span><br><span class="line"><span class="comment">// 关于这题其实有些费解，因为矩阵能够连乘，因此可以近似看成一条链。具体我也说不很清，题主也是让别人教的QWQ</span></span><br></pre></td></tr></table></figure><h6 id="任意顶点间最短路径长度"><a href="#任意顶点间最短路径长度" class="headerlink" title="任意顶点间最短路径长度"></a>任意顶点间最短路径长度</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Matrix&lt; <span class="type">double</span>&gt; <span class="title">Floyd</span><span class="params">(<span class="type">const</span> Matrix&lt;<span class="type">double</span>&gt; &amp;G)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="type">int</span> n = G.<span class="built_in">rows</span>();</span><br><span class="line"> <span class="keyword">auto</span> A = G;</span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> k = <span class="number">0</span>; k &lt; n; ++k)  <span class="comment">// 第一层循环中的k作为中间节点</span></span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; ++i)  <span class="comment">// 二、三层分别为起始节点和终止节点</span></span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> j = <span class="number">0</span>; j &lt; n; ++j)&#123; </span><br><span class="line">                <span class="keyword">auto</span> t = <span class="built_in">A</span>(i, k) + <span class="built_in">A</span>(k, j);  <span class="comment">// 在这里将首尾相连，去除k</span></span><br><span class="line"> <span class="keyword">if</span>(t &lt; <span class="built_in">A</span>(i, j)) </span><br><span class="line">                    <span class="built_in">A</span>(i, j) = t;</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">return</span> A;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 时间复杂度为O(n ^ 3)</span></span><br><span class="line"><span class="comment">// 这个算法是直接将所有节点到任一节点的路径直接算出来了，如果要算任意节点可以直接找到结果</span></span><br></pre></td></tr></table></figure><h6 id="多段图"><a href="#多段图" class="headerlink" title="多段图"></a>多段图</h6><ul><li>多段图是一个带权有向图并且无环</li><li>有且仅有一个起始点（原点source）和一个终止节点（汇点target）</li><li>它有n个阶段，每个阶段由特定的几个结点构成</li><li>每个结点的所有结点都只能指向下一个相邻的阶段，阶段之间不能越界(大概长这样)</li></ul><p><img src="/2022/06/12/%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%88%86%E6%9E%90/%E5%A4%9A%E6%AE%B5%E5%9B%BE.png" alt="多段图"></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">MultiGraph</span><span class="params">(<span class="type">const</span> Matrix&lt;<span class="type">double</span>&gt; &amp;G, <span class="type">int</span> m)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="type">int</span> n = G.<span class="built_in">rows</span>(), t = n - <span class="number">1</span>;  <span class="comment">// n顶点数，t汇点（不包含起始点的中继点）</span></span><br><span class="line"> <span class="function">vector&lt;<span class="type">double</span>&gt; <span class="title">C</span><span class="params">(n, <span class="number">0</span>)</span></span>;  <span class="comment">// C[j]记录从初始节点到汇点的距离，初始为0</span></span><br><span class="line"> <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">Next</span><span class="params">(n)</span></span>;  <span class="comment">// Next记录最短路径上所经过的后继节点</span></span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> j = t - <span class="number">1</span>; j &gt;= <span class="number">0</span>; --j)&#123;  <span class="comment">// 从终点向前计算</span></span><br><span class="line">        <span class="type">int</span> r = j + <span class="number">1</span>;</span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> i = r; i &lt; n; ++i)</span><br><span class="line"> <span class="keyword">if</span>(<span class="built_in">G</span>(j, i) + C[i] &lt; <span class="built_in">G</span>(j, r) + C[r]) </span><br><span class="line">                r = i;</span><br><span class="line"> C[j] = <span class="built_in">G</span>(j, r) + C[r], Next[j] = r;  <span class="comment">// 存入当前节点到终点的最短路径，并且更新当前节点的后继节点</span></span><br><span class="line"> &#125;</span><br><span class="line"> <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">X</span><span class="params">(m)</span></span>;</span><br><span class="line"> X[<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>; i &lt; m; ++i)  <span class="comment">// 将后继节点转为从起点开始的正向顺序</span></span><br><span class="line"> X[i] = Next[X[i - <span class="number">1</span>]];</span><br><span class="line"> <span class="keyword">return</span> X;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 时间复杂度为O(n ^ 2)</span></span><br></pre></td></tr></table></figure><h6 id="两个字符串的最长公共子串"><a href="#两个字符串的最长公共子串" class="headerlink" title="两个字符串的最长公共子串"></a>两个字符串的最长公共子串</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Matrix&lt;<span class="type">int</span>&gt; <span class="title">LCSSize</span><span class="params">(<span class="type">const</span> string &amp;X, <span class="type">const</span> string &amp;Y)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="type">int</span> m = X.<span class="built_in">size</span>(), n = Y.<span class="built_in">size</span>();</span><br><span class="line"> <span class="function">Matrix&lt;<span class="type">int</span>&gt; <span class="title">C</span><span class="params">(m + <span class="number">1</span>, n + <span class="number">1</span>)</span></span>;  <span class="comment">// 构建一个(m + 1, n + 1)大小的矩阵（从1开始，防止越界）</span></span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt;= m; ++i)</span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> j = <span class="number">0</span>; j &lt;= n; ++j)</span><br><span class="line"> <span class="keyword">if</span>(i &lt;= <span class="number">0</span> <span class="keyword">or</span> j &lt;= <span class="number">0</span>)</span><br><span class="line"> <span class="built_in">C</span>(i, j) = <span class="number">0</span>;</span><br><span class="line"> <span class="keyword">else</span> <span class="keyword">if</span>(X[i - <span class="number">1</span>] == Y[j - <span class="number">1</span>])</span><br><span class="line"> <span class="built_in">C</span>(i, j) = <span class="built_in">C</span>(i - <span class="number">1</span>, j - <span class="number">1</span>) + <span class="number">1</span>;  <span class="comment">// 计数代表公共子串有几个元素</span></span><br><span class="line"> <span class="keyword">else</span></span><br><span class="line"> <span class="built_in">C</span>(i, j) = <span class="built_in">max</span>(<span class="built_in">C</span>(i - <span class="number">1</span>, j), <span class="built_in">C</span>(i, j - <span class="number">1</span>));  <span class="comment">// 从当前位置的上方或者左边选取较大值填充不相等区域</span></span><br><span class="line"> <span class="keyword">return</span> C;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function">string <span class="title">LCS</span><span class="params">(<span class="type">const</span> string &amp;X, <span class="type">const</span> string &amp;Y)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="keyword">auto</span> C = <span class="built_in">LCSSize</span>(X, Y);</span><br><span class="line"> <span class="type">int</span> i = X.<span class="built_in">size</span>(), j = Y.<span class="built_in">size</span>(), k = <span class="built_in">C</span>(i, j);  <span class="comment">// k代表最长子串元素个数</span></span><br><span class="line"> string Z;</span><br><span class="line"> <span class="keyword">while</span>(k &gt; <span class="number">0</span>)</span><br><span class="line"> <span class="keyword">if</span>(X[i - <span class="number">1</span>] == Y[j - <span class="number">1</span>])  <span class="comment">// 相等，矩阵脱最外层</span></span><br><span class="line"> Z.<span class="built_in">push_back</span>(X[i - <span class="number">1</span>]), --i, --j, --k;</span><br><span class="line"> <span class="keyword">else</span> <span class="keyword">if</span>(<span class="built_in">C</span>(i, j) == <span class="built_in">C</span>(i - <span class="number">1</span>, j)) --i;</span><br><span class="line"> <span class="keyword">else</span> --j;</span><br><span class="line"> <span class="built_in">reverse</span>(<span class="built_in">begin</span>(Z), <span class="built_in">end</span>(Z));  <span class="comment">// 反转</span></span><br><span class="line"> <span class="keyword">return</span> Z;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 时间复杂度为O(mn)，其中m=|X|, n=|Y|</span></span><br></pre></td></tr></table></figure><h6 id="0-x2F-1背包问题"><a href="#0-x2F-1背包问题" class="headerlink" title="0&#x2F;1背包问题"></a>0&#x2F;1背包问题</h6><p>一共有N件物品，每件物品都有其相应的体积和价值，给你一个背包，背包有容量上限，怎样往背包中装物品，能让背包中的物品价值最高。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;map&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;functional&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="keyword">typedef</span> vector&lt;map&lt;<span class="type">double</span>, <span class="type">double</span>&gt;&gt; RestType;  <span class="comment">// 剩余表, 剩余容量-最优效益对数组</span></span><br><span class="line"><span class="function"><span class="keyword">auto</span> <span class="title">Knap</span><span class="params">(vector&lt;<span class="type">double</span>&gt; &amp;V, vector&lt;<span class="type">double</span>&gt; &amp;W, <span class="type">double</span> c)</span>  <span class="comment">// 效益数组, 重量数组, 容量</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> <span class="type">int</span> n = <span class="built_in">min</span>(V.<span class="built_in">size</span>(), W.<span class="built_in">size</span>()); <span class="comment">// 物品数</span></span><br><span class="line"> <span class="function">RestType <span class="title">M</span><span class="params">(n)</span></span>; <span class="comment">// 剩余容量-最优效益对数组</span></span><br><span class="line"> function&lt;<span class="type">double</span>(<span class="type">int</span>, <span class="type">double</span>)&gt; m = [&amp;](<span class="type">int</span> i, <span class="type">double</span> y)&#123; </span><br><span class="line">        <span class="keyword">if</span>(M[i].<span class="built_in">count</span>(y) &gt; <span class="number">0</span>) </span><br><span class="line">            <span class="keyword">return</span> M[i][y]; <span class="comment">// 已经计算过, 返回</span></span><br><span class="line"> <span class="type">double</span> cv; <span class="comment">// 否则, 开始递归计算</span></span><br><span class="line"> <span class="keyword">if</span>(i &gt;= n - <span class="number">1</span> <span class="keyword">and</span> W[i] &gt; y) </span><br><span class="line">            cv = <span class="number">0</span>;</span><br><span class="line"> <span class="keyword">else</span> <span class="keyword">if</span>(i &gt;= n - <span class="number">1</span>) </span><br><span class="line">            cv = V[i];</span><br><span class="line"> <span class="keyword">else</span> <span class="keyword">if</span>(W[i] &gt; y) </span><br><span class="line">            cv = <span class="built_in">m</span>(i + <span class="number">1</span>, y);</span><br><span class="line"> <span class="keyword">else</span> </span><br><span class="line">            cv = <span class="built_in">max</span>(<span class="built_in">m</span>(i + <span class="number">1</span>, y), <span class="built_in">m</span>(i + <span class="number">1</span>, y - W[i]) + V[i]);</span><br><span class="line"> M[i][y] = cv;</span><br><span class="line"> <span class="keyword">return</span> M[i][y];</span><br><span class="line"> &#125;;  <span class="comment">// 调用m(0, c)耗时O(n^2 * 2^n)</span></span><br><span class="line"> <span class="keyword">auto</span> fv = <span class="built_in">m</span>(<span class="number">0</span>, c);</span><br><span class="line"> <span class="keyword">return</span> M;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>题主表示比较嫌弃这种写法，和众所周知的AcWing上的解法差别还挺大的，因为这只是整体算法的一部分，理解起来反而很困难，但是如果要你把整个算法全部写出来，这样的写法一定非常鸡肋，所以下面是题主的代码，其实是取巧了，不像如上代码一样具有普适性，但是胜在容易理解和比较好写（<del>对我来说</del>）</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">Solution</span><span class="params">(<span class="type">int</span> v[], <span class="type">int</span> w[], <span class="type">int</span> c)</span>&#123;  <span class="comment">// 效益数组, 重量数组, 容量</span></span><br><span class="line">    <span class="type">int</span> <span class="variable">n</span> <span class="operator">=</span> Math.max(v.length, w.length);  <span class="comment">// 物品数</span></span><br><span class="line">    <span class="type">int</span>[][] dp = <span class="keyword">new</span> <span class="title class_">int</span>[n + <span class="number">1</span>][c + <span class="number">1</span>];  <span class="comment">// dp记录背包内选择后的最大价值</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">1</span>;i &lt;= n;i++)&#123;  <span class="comment">// 枚举所有背包占用的情况</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> <span class="number">0</span>; j &lt;= c;j++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(j - w[i] &gt;=<span class="number">0</span>)</span><br><span class="line">                dp[i][j] = Math.max(dp[i - <span class="number">1</span>][j], dp[i - <span class="number">1</span>][j - w[j]] + v[i]);  <span class="comment">// 将第i件物品放入背包的效益与不放入背包的效益进行比较，决定第i件物品是否放入背包。</span></span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                dp[i][j] = dp[i - <span class="number">1</span>][j];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> dp[n][max];</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 这样子只能输出背包最大效益，如果想要知道选取的是哪些元素的话，要么还是参照老师的那种写法，要么在此写法上加上一段回溯。</span></span><br></pre></td></tr></table></figure><p>写在前面：在上这门课之前题主没有接触过后面三个算法，因此基本上对来源什么的都不是很懂，大概估计后面三章会在回溯和剪枝出一道大题、概率出一道大题，一共两道大题20分。题主的建议是直接背吧，如果有兴致会在之后出一张本学年的<del>押题卷</del>，模仿样卷的题型罢了。</p><h2 id="回溯方法"><a href="#回溯方法" class="headerlink" title="回溯方法"></a>回溯方法</h2><h6 id="使用递归方法生成含-n-个分量的所有排列"><a href="#使用递归方法生成含-n-个分量的所有排列" class="headerlink" title="使用递归方法生成含 n 个分量的所有排列"></a>使用递归方法生成含 n 个分量的所有排列</h6><p>求一个数组的全排列。举个例子方便大家理解：有数组[1,2,3]</p><p>全排列为[1,2,3], [1,3,2], [2,1,3], [2,3,1], [3,1,2], [3,2,1]。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// iota函数用于对范围赋值</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">B_Perm</span><span class="params">(<span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">X</span><span class="params">(n)</span></span>;</span><br><span class="line"> function&lt;<span class="type">void</span>(<span class="type">int</span>)&gt; Perm = [&amp;](<span class="type">int</span> t)&#123; </span><br><span class="line">        <span class="keyword">if</span>(t &gt;= n) cout &lt;&lt; X &lt;&lt; endl;</span><br><span class="line"> <span class="keyword">else</span></span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> i = t; i &lt; n; ++i)&#123; </span><br><span class="line">                <span class="built_in">swap</span>(X[t], X[i]);  <span class="comment">// 交换两个数位置</span></span><br><span class="line"> <span class="built_in">Perm</span>(t + <span class="number">1</span>);  <span class="comment">// 交换下一个数（下一层）</span></span><br><span class="line"> <span class="built_in">swap</span>(X[t], X[i]);  <span class="comment">// 保持原数组不变</span></span><br><span class="line"> &#125;</span><br><span class="line"> &#125;;</span><br><span class="line"> <span class="built_in">iota</span>(<span class="built_in">begin</span>(X), <span class="built_in">end</span>(X), <span class="number">0</span>);  <span class="comment">// 将X数组置为有序排列（例如X长度为3，则iota后X = [1,2,3]）</span></span><br><span class="line"> <span class="built_in">Perm</span>(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="使用递归方法生成-n-个元素的所有子集"><a href="#使用递归方法生成-n-个元素的所有子集" class="headerlink" title="使用递归方法生成 n 个元素的所有子集"></a>使用递归方法生成 n 个元素的所有子集</h6><p>求一个数组的所有子集。举个例子方便大家理解：有数组[1,2,3]</p><p>子集为{}, {1}, {2}, {3}, {1,2}, {1,3}, {2,3}, {1,2,3}。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">B_SubSet</span><span class="params">(<span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="function">vector&lt;<span class="type">bool</span>&gt; <span class="title">X</span><span class="params">(n)</span></span>;</span><br><span class="line"> function&lt;<span class="type">void</span>(<span class="type">int</span>)&gt; SubSet = [&amp;](<span class="type">int</span> t)&#123;</span><br><span class="line"><span class="keyword">if</span>(t &gt;= n) cout &lt;&lt; X &lt;&lt; endl;</span><br><span class="line"> <span class="keyword">else</span>&#123;</span><br><span class="line">X[t] = <span class="number">1</span>;  <span class="comment">// 对X[t]元素进行判断，=1就是取，=0就是不取</span></span><br><span class="line"> <span class="built_in">SubSet</span>(t + <span class="number">1</span>);  <span class="comment">// 为两种状况分别构建队列</span></span><br><span class="line"> X[t] = <span class="number">0</span>;</span><br><span class="line"> <span class="built_in">SubSet</span>(t + <span class="number">1</span>);</span><br><span class="line"> &#125;</span><br><span class="line"> &#125;;</span><br><span class="line"> <span class="built_in">SubSet</span>(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="旅行商问题"><a href="#旅行商问题" class="headerlink" title="旅行商问题"></a>旅行商问题</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 旅行商问题可以看成是全排列问题，因为一定存在回路（不存在的边给了个INFINITY），所以只需要将所有节点的排列方式找出来，最短的就是最优路径。</span></span><br><span class="line"><span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">TSP</span><span class="params">(<span class="type">const</span> Matrix&lt;<span class="type">double</span>&gt; &amp;G)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="type">int</span> n = G.<span class="built_in">rows</span>();</span><br><span class="line"> <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">X</span><span class="params">(n)</span>, BX</span>;  <span class="comment">// X存到当前节点的路径；BX存最优路径</span></span><br><span class="line"> <span class="type">double</span> BC = INFINITY;  <span class="comment">// 预设最大耗费</span></span><br><span class="line"> function&lt;<span class="type">void</span>(<span class="type">int</span>, <span class="type">double</span>)&gt; TSP = [&amp;](<span class="type">int</span> t, <span class="type">double</span> C)&#123;</span><br><span class="line">        <span class="keyword">if</span>(t &gt;= n <span class="keyword">and</span> C + <span class="built_in">G</span>(X[n - <span class="number">1</span>], <span class="number">0</span>) &lt; BC)  <span class="comment">// 所有节点都到达且花费更少（答案更优）</span></span><br><span class="line"> BC = C + <span class="built_in">G</span>(X[n - <span class="number">1</span>], <span class="number">0</span>), BX = X;</span><br><span class="line"> <span class="keyword">else</span> <span class="keyword">if</span>(t &lt; n)</span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> i = t; i &lt; n; ++i)&#123;</span><br><span class="line">                <span class="built_in">swap</span>(X[t], X[i]);</span><br><span class="line"> <span class="keyword">if</span>(C + <span class="built_in">G</span>(X[t - <span class="number">1</span>], X[t]) &lt; BC)  <span class="comment">// 如果当前路径比最优短，就接着找，已经超了也就没有找下去的必要了</span></span><br><span class="line"> <span class="built_in">TSP</span>(t + <span class="number">1</span>, C + <span class="built_in">G</span>(X[t - <span class="number">1</span>], X[t]));</span><br><span class="line"> <span class="built_in">swap</span>(X[t], X[i]);</span><br><span class="line"> &#125;</span><br><span class="line"> &#125;;</span><br><span class="line"> <span class="built_in">iota</span>(<span class="built_in">begin</span>(X), <span class="built_in">end</span>(X), <span class="number">0</span>);  <span class="comment">// 初始化</span></span><br><span class="line"> <span class="built_in">TSP</span>(<span class="number">1</span>, <span class="number">0</span>);  <span class="comment">// 从第一站开始考虑，当前耗费为0</span></span><br><span class="line"> <span class="keyword">return</span> BX;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="子集和问题（36输出一个-x2F-不满足-amp-38输出所有）"><a href="#子集和问题（36输出一个-x2F-不满足-amp-38输出所有）" class="headerlink" title="子集和问题（36输出一个&#x2F;不满足 &amp; 38输出所有）"></a>子集和问题（36输出一个&#x2F;不满足 &amp; 38输出所有）</h6><p>简单理解为给定一个数组W，给定一个数字M，求是否W存在子集的子集和等于M。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 从题干就知道这一题类似于子集问题</span></span><br><span class="line"><span class="function">vector&lt;<span class="type">bool</span>&gt; <span class="title">SetSum</span><span class="params">(<span class="type">const</span> vector&lt;<span class="type">int</span>&gt; &amp;W, <span class="type">int</span> M)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="type">int</span> n = W.<span class="built_in">size</span>();</span><br><span class="line"> <span class="function">vector&lt;<span class="type">bool</span>&gt; <span class="title">X</span><span class="params">(n)</span>, Y</span>;</span><br><span class="line"> function&lt;<span class="type">void</span>(<span class="type">int</span>, <span class="type">int</span>, <span class="type">int</span>)&gt; SetSum = [&amp;](<span class="type">int</span> t, <span class="type">int</span> s, <span class="type">int</span> r)&#123; </span><br><span class="line">        <span class="keyword">if</span>(<span class="keyword">not</span> Y.<span class="built_in">empty</span>()) <span class="keyword">return</span>;  <span class="comment">// 不存在，结束</span></span><br><span class="line"> <span class="keyword">if</span>(s == M) Y = X, Y.<span class="built_in">resize</span>(t);</span><br><span class="line"> <span class="keyword">else</span> <span class="keyword">if</span>(t &lt; n)&#123;</span><br><span class="line">            X[t] = <span class="number">1</span>;</span><br><span class="line"> <span class="keyword">if</span>(s + W[t] &lt;= M)  <span class="comment">// 每个元素依然是选或不选两种状态（选了之后仍然小于等于数字M）</span></span><br><span class="line">                <span class="built_in">SetSum</span>(t + <span class="number">1</span>, s + W[t], r - W[t]);</span><br><span class="line"> X[t] = <span class="number">0</span>;</span><br><span class="line"> <span class="keyword">if</span>(s + (r - W[t]) &gt;= M)  <span class="comment">// 不选的话也要保证可选值大于等于数字M</span></span><br><span class="line">                <span class="built_in">SetSum</span>(t + <span class="number">1</span>, s, r - W[t]);</span><br><span class="line"> &#125;</span><br><span class="line"> &#125;;</span><br><span class="line"> <span class="type">int</span> s = <span class="number">0</span>, r = <span class="built_in">accumulate</span>(<span class="built_in">begin</span>(W), <span class="built_in">end</span>(W), <span class="number">0</span>);  <span class="comment">// accumulate求和函数，初始为0，累加X数组</span></span><br><span class="line"> <span class="built_in">SetSum</span>(<span class="number">0</span>, s, r);</span><br><span class="line"> <span class="keyword">return</span> Y;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">SetSum</span><span class="params">(<span class="type">const</span> vector&lt;<span class="type">int</span>&gt; &amp;W, <span class="type">int</span> M)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="type">int</span> n = W.<span class="built_in">size</span>();</span><br><span class="line"> <span class="function">vector&lt;<span class="type">bool</span>&gt; <span class="title">X</span><span class="params">(n)</span></span>;</span><br><span class="line"> function&lt;<span class="type">void</span>(<span class="type">int</span>, <span class="type">int</span>, <span class="type">int</span>)&gt; SetSum = [&amp;](<span class="type">int</span> t, <span class="type">int</span> s, <span class="type">int</span> r)&#123; </span><br><span class="line">        <span class="keyword">if</span>(s == M) cout &lt;&lt; <span class="built_in">to_string</span>(X, t) &lt;&lt; endl;  <span class="comment">// 存在一种情况直接输出</span></span><br><span class="line"> <span class="keyword">else</span> <span class="keyword">if</span>(t &lt; n)&#123;</span><br><span class="line">            X[t] = <span class="number">1</span>;</span><br><span class="line"> <span class="keyword">if</span>(s + W[t] &lt;= M) </span><br><span class="line">                <span class="built_in">SetSum</span>(t + <span class="number">1</span>, s + W[t], r - W[t]);</span><br><span class="line"> X[t] = <span class="number">0</span>;</span><br><span class="line"> <span class="keyword">if</span>(s + (r - W[t]) &gt;= M) </span><br><span class="line">                <span class="built_in">SetSum</span>(t + <span class="number">1</span>, s, r - W[t]);</span><br><span class="line"> &#125;</span><br><span class="line"> &#125;;</span><br><span class="line"> <span class="type">int</span> s = <span class="number">0</span>, r = <span class="built_in">accumulate</span>(<span class="built_in">begin</span>(W), <span class="built_in">end</span>(W), <span class="number">0</span>);</span><br><span class="line"> <span class="built_in">SetSum</span>(<span class="number">0</span>, s, r);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 显而易见，这两个代码块的区别在于Y，以及方法体中if-else中的if部分。优先记第二种，实在不行你把第二种写上老师都不会扣很多分。</span></span><br></pre></td></tr></table></figure><h6 id="最大团问题"><a href="#最大团问题" class="headerlink" title="最大团问题"></a>最大团问题</h6><p>求一个图中连通节点最多的子图</p><ul><li>扫每一个节点，如果和团中所有节点都连通，可以存；</li><li>每个节点都有存和不存两种状态。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">Connected</span><span class="params">(<span class="type">const</span> Matrix&lt;<span class="type">bool</span>&gt; &amp;G, <span class="type">const</span> vector&lt;<span class="type">bool</span>&gt; &amp;X, <span class="type">int</span> t)</span>  <span class="comment">// 检查团与节点t的连接性</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> u = <span class="number">0</span>; u &lt; t; ++u)</span><br><span class="line"> <span class="keyword">if</span>(X[u] == <span class="number">1</span> <span class="keyword">and</span> <span class="built_in">G</span>(t, u) == <span class="number">0</span>)  <span class="comment">// 如果节点在当前团中但是没有与当前没有连接</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"> <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function">vector&lt;<span class="type">bool</span>&gt; <span class="title">Clique</span><span class="params">(<span class="type">const</span> Matrix&lt;<span class="type">bool</span>&gt; &amp;G)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="type">int</span> n = G.<span class="built_in">rows</span>(), fn = <span class="number">-1</span>;  <span class="comment">// fn记录最大团的顶点数</span></span><br><span class="line"> <span class="function">vector&lt;<span class="type">bool</span>&gt; <span class="title">X</span><span class="params">(n)</span>, BX</span>;  <span class="comment">// X记录当前团，BX记录最大团</span></span><br><span class="line"> function&lt;<span class="type">void</span>(<span class="type">int</span>, <span class="type">int</span>)&gt; Clique = [&amp;](<span class="type">int</span> t, <span class="type">int</span> cn)&#123; </span><br><span class="line">        <span class="keyword">if</span>(t &gt;= n <span class="keyword">and</span> cn &gt; fn) fn = cn, BX = X;</span><br><span class="line"> <span class="keyword">else</span> <span class="keyword">if</span>(t &lt; n)&#123; </span><br><span class="line">            X[t] = <span class="number">1</span>;</span><br><span class="line"> <span class="keyword">if</span>(<span class="built_in">Connected</span>(G, X, t)) <span class="built_in">Clique</span>(t + <span class="number">1</span>, cn + <span class="number">1</span>);</span><br><span class="line"> X[t] = <span class="number">0</span>;</span><br><span class="line"> <span class="keyword">if</span>(cn + n - (t + <span class="number">1</span>) &gt; fn) <span class="built_in">Clique</span>(t + <span class="number">1</span>, cn);</span><br><span class="line"> &#125;</span><br><span class="line"> &#125;;</span><br><span class="line"> <span class="built_in">Clique</span>(<span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line"> <span class="keyword">return</span> BX;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="着色问题"><a href="#着色问题" class="headerlink" title="着色问题"></a>着色问题</h6><p>这个算是回溯中最难的一个了，依旧是前面的模板，但是写法稍有不同：</p><ul><li>判断颜色是否和邻边相同，相同就给下一个节点变色，不同则检查下一个节点。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;functional&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;Matrix.hpp&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">legal</span><span class="params">(<span class="type">const</span> Matrix&lt;<span class="type">bool</span>&gt; &amp;G, vector&lt;<span class="type">int</span>&gt; &amp;X, <span class="type">int</span> t)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; t; ++i)</span><br><span class="line"> <span class="keyword">if</span>(<span class="built_in">G</span>(i, t) == <span class="number">1</span> <span class="keyword">and</span> X[i] == X[t])  <span class="comment">// 连通并且颜色相同返回false</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"> <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">auto</span> <span class="title">Chromatic</span><span class="params">(Matrix&lt;<span class="type">bool</span>&gt; &amp;G)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="type">int</span> n = G.<span class="built_in">rows</span>(), fm = n + <span class="number">1</span>; <span class="comment">// 顶点数, fm最优颜色数（其实取n就够了，这里应该是为了让结果更加明显，便于debug）</span></span><br><span class="line"> <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">X</span><span class="params">(n)</span>, BX</span>; <span class="comment">// 当前方案, 最优方案</span></span><br><span class="line"> function&lt;<span class="type">void</span>(<span class="type">int</span>, <span class="type">int</span>)&gt; Chromatic = [&amp;](<span class="type">int</span> t, <span class="type">int</span> m)&#123; <span class="comment">// 搜索解空间树</span></span><br><span class="line"> <span class="keyword">if</span>(t &gt;= n <span class="keyword">and</span> m &lt; fm) <span class="comment">// 答案(颜色数更小)</span></span><br><span class="line"> BX = X, fm = m;</span><br><span class="line"> <span class="keyword">else</span> <span class="keyword">if</span>(t &lt; n)</span><br><span class="line"> <span class="keyword">for</span>(X[t] = <span class="number">1</span>; X[t] &lt;= m; ++X[t])&#123; </span><br><span class="line">                <span class="keyword">auto</span> cm = <span class="built_in">max</span>(X[t] + <span class="number">1</span>, m);  <span class="comment">// 新的颜色数(可能需要增加)</span></span><br><span class="line"> <span class="keyword">if</span>(<span class="built_in">legal</span>(G, X, t) <span class="keyword">and</span> cm &lt; fm)  <span class="comment">// X[t]可用且颜色数可能更小</span></span><br><span class="line"> <span class="built_in">Chromatic</span>(t + <span class="number">1</span>, cm);  <span class="comment">// 下一顶点</span></span><br><span class="line"> &#125;</span><br><span class="line"> &#125;;</span><br><span class="line"> <span class="built_in">Chromatic</span>(<span class="number">0</span>, <span class="number">1</span>);  <span class="comment">// 从顶点0开始, 初始颜色数为1, 上限为n</span></span><br><span class="line"> <span class="keyword">return</span> BX;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="分枝限界方法"><a href="#分枝限界方法" class="headerlink" title="分枝限界方法"></a>分枝限界方法</h2><p>通俗来说就是回溯算法中的剪枝操作，上面的回溯算法用的是深度优先遍历，那么下文的分枝限界算法就是用的宽度优先遍历，个人结论就是和图遍历一样，回溯用递归能解决，剪枝就需要用到队列queue了，如果还不是很懂queue的建议取找个文档简单阅读一下queue的基本操作。</p><h6 id="使用分枝限界方法生成含-n-个分量的所有排列"><a href="#使用分枝限界方法生成含-n-个分量的所有排列" class="headerlink" title="使用分枝限界方法生成含 n 个分量的所有排列"></a>使用分枝限界方法生成含 n 个分量的所有排列</h6><ul><li>首先我们明确一点就是回溯的思想是递归，而分枝限界的思想是递推，也就是说用通项公式来解决问题。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">PermNode</span></span><br><span class="line">&#123; </span><br><span class="line">    vector&lt;<span class="type">int</span>&gt; X;</span><br><span class="line"> <span class="type">int</span> t;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Perm</span><span class="params">(<span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    queue&lt;PermNode&gt; Q;</span><br><span class="line"> <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">X</span><span class="params">(n)</span></span>;  <span class="comment">// X用来存数组中的元素排序，t用来存数组中的元素个数</span></span><br><span class="line"> <span class="built_in">iota</span>(<span class="built_in">begin</span>(X), <span class="built_in">end</span>(X), <span class="number">0</span>);</span><br><span class="line"> Q.<span class="built_in">push</span>(&#123;X, <span class="number">0</span>&#125;);</span><br><span class="line"> <span class="keyword">while</span>(<span class="keyword">not</span> Q.<span class="built_in">empty</span>())&#123; </span><br><span class="line">        <span class="keyword">auto</span> [X, t] = Q.<span class="built_in">front</span>(); Q.<span class="built_in">pop</span>();</span><br><span class="line"> <span class="keyword">if</span>(t &gt;= n) cout &lt;&lt; X &lt;&lt; endl;</span><br><span class="line"> <span class="keyword">else</span> </span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> i = t; i &lt; n; ++i)</span><br><span class="line"> <span class="built_in">swap</span>(X[t], X[i]), Q.<span class="built_in">push</span>(&#123;X, t + <span class="number">1</span>&#125;);  <span class="comment">// 将所有的邻边全部入队</span></span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="使用分枝限界方法生成-n-个元素的所有子集"><a href="#使用分枝限界方法生成-n-个元素的所有子集" class="headerlink" title="使用分枝限界方法生成 n 个元素的所有子集"></a>使用分枝限界方法生成 n 个元素的所有子集</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">SetNode</span></span><br><span class="line">&#123; </span><br><span class="line">    vector&lt;<span class="type">bool</span>&gt; X;</span><br><span class="line"> <span class="type">int</span> t;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">SubSet</span><span class="params">(<span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    queue&lt;SetNode&gt; Q;</span><br><span class="line"> <span class="function">vector&lt;<span class="type">bool</span>&gt; <span class="title">X</span><span class="params">(n)</span></span>;</span><br><span class="line"> Q.<span class="built_in">push</span>(&#123;X, <span class="number">0</span>&#125;);</span><br><span class="line"> <span class="keyword">while</span>(<span class="keyword">not</span> Q.<span class="built_in">empty</span>())&#123; </span><br><span class="line">        <span class="keyword">auto</span>[X, t] = Q.<span class="built_in">front</span>(); Q.<span class="built_in">pop</span>();</span><br><span class="line"> <span class="keyword">if</span>(t &gt;= n) cout &lt;&lt; X &lt;&lt; endl;</span><br><span class="line"> <span class="keyword">else</span>&#123; </span><br><span class="line">            X[t] = <span class="number">1</span>, Q.<span class="built_in">push</span>(&#123;X, t + <span class="number">1</span>&#125;);  <span class="comment">// 为选了X[t]的元素构建一条队列</span></span><br><span class="line"> X[t] = <span class="number">0</span>, Q.<span class="built_in">push</span>(&#123;X, t + <span class="number">1</span>&#125;);  <span class="comment">// 为不选X[t]的元素构建一条队列</span></span><br><span class="line"> &#125;</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>有了以上基础，以下三个就是大同小异了，这里不做过多解释。写不出来的话用前两题的思想套入问题，写写白话吧，毕竟这里不推荐大家背书。。。</p><h6 id="旅行商问题-1"><a href="#旅行商问题-1" class="headerlink" title="旅行商问题"></a>旅行商问题</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">TSPNode</span></span><br><span class="line">&#123; </span><br><span class="line">    vector&lt;<span class="type">int</span>&gt; X;</span><br><span class="line"> <span class="type">int</span> t;</span><br><span class="line"> <span class="type">double</span> C;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="type">bool</span> <span class="keyword">operator</span>&lt;(<span class="type">const</span> TSPNode &amp;X, <span class="type">const</span> TSPNode &amp;Y)</span><br><span class="line">&#123; </span><br><span class="line">    <span class="keyword">return</span> X.C &lt; Y.C;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">TSP</span><span class="params">(<span class="type">const</span> Matrix&lt;<span class="type">double</span>&gt; &amp;G)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    minheap&lt;TSPNode&gt; H;</span><br><span class="line"> <span class="type">int</span> n = G.<span class="built_in">rows</span>();</span><br><span class="line"> <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">X</span><span class="params">(n)</span>, BX</span>;</span><br><span class="line"> <span class="built_in">iota</span>(<span class="built_in">begin</span>(X), <span class="built_in">end</span>(X), <span class="number">0</span>);</span><br><span class="line"> <span class="type">double</span> C = <span class="number">0</span>, BC = INFINITY;</span><br><span class="line"> H.<span class="built_in">push</span>(&#123;X, <span class="number">1</span>, C&#125;);</span><br><span class="line"> <span class="keyword">while</span>(<span class="keyword">not</span> H.<span class="built_in">empty</span>())&#123; </span><br><span class="line">        <span class="keyword">auto</span> [X, t, C] = H.<span class="built_in">top</span>(); H.<span class="built_in">pop</span>();</span><br><span class="line"> <span class="keyword">if</span>(t &gt;= n <span class="keyword">and</span> C + <span class="built_in">G</span>(X[n - <span class="number">1</span>], <span class="number">0</span>) &lt; BC)</span><br><span class="line"> BC = C + <span class="built_in">G</span>(X[n - <span class="number">1</span>], <span class="number">0</span>), BX = X;</span><br><span class="line"> <span class="keyword">else</span> <span class="keyword">if</span>(t &lt; n)</span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> i = t; i &lt; n; ++i)&#123; </span><br><span class="line">                <span class="built_in">swap</span>(X[t], X[i]);</span><br><span class="line"> <span class="keyword">if</span>(C + <span class="built_in">G</span>(X[t - <span class="number">1</span>], X[t]) &lt; BC)</span><br><span class="line"> H.<span class="built_in">push</span>(&#123;X, t + <span class="number">1</span>, C + <span class="built_in">G</span>(X[t - <span class="number">1</span>], X[t])&#125;);</span><br><span class="line"> &#125;</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">return</span> BX;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="最大团问题-1"><a href="#最大团问题-1" class="headerlink" title="最大团问题"></a>最大团问题</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">Connected</span><span class="params">(<span class="type">const</span> Matrix&lt;<span class="type">bool</span>&gt; &amp;G, <span class="type">const</span> vector&lt;<span class="type">bool</span>&gt; &amp;X, <span class="type">int</span> t)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> u = <span class="number">0</span>; u &lt; t; ++u)</span><br><span class="line"> <span class="keyword">if</span>(X[u] == <span class="number">1</span> <span class="keyword">and</span> <span class="built_in">G</span>(t, u) == <span class="number">0</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"> <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">CliqueNode</span></span><br><span class="line">&#123; </span><br><span class="line">    vector&lt;<span class="type">bool</span>&gt; X;</span><br><span class="line"> <span class="type">int</span> t, cn;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="type">bool</span> <span class="keyword">operator</span>&lt;(<span class="type">const</span> CliqueNode &amp;X, <span class="type">const</span> CliqueNode &amp;Y)</span><br><span class="line">&#123; </span><br><span class="line">    <span class="keyword">return</span> X.cn &lt; Y.cn;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function">vector&lt; <span class="type">bool</span>&gt; <span class="title">Clique</span><span class="params">(<span class="type">const</span> Matrix&lt;<span class="type">bool</span>&gt; &amp;G)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    maxheap&lt;CliqueNode&gt; H;</span><br><span class="line"> <span class="type">int</span> n = G.<span class="built_in">rows</span>();</span><br><span class="line"> <span class="function">vector&lt;<span class="type">bool</span>&gt; <span class="title">X</span><span class="params">(n)</span>, BX</span>;</span><br><span class="line"> <span class="type">int</span> cn = <span class="number">0</span>, fn = <span class="number">0</span>;</span><br><span class="line"> H.<span class="built_in">push</span>(&#123;X, <span class="number">0</span>, cn&#125;);</span><br><span class="line"> <span class="keyword">while</span>(<span class="keyword">not</span> H.<span class="built_in">empty</span>())&#123; </span><br><span class="line">        <span class="keyword">auto</span> [X, t, cn] = H.<span class="built_in">top</span>(); H.<span class="built_in">pop</span>();</span><br><span class="line"> <span class="keyword">if</span>(t &gt;= n <span class="keyword">and</span> cn &gt; fn) fn = cn, BX = X;</span><br><span class="line"> <span class="keyword">else</span> <span class="keyword">if</span>(t &lt; n)&#123; </span><br><span class="line">            X[t] = <span class="number">1</span>;</span><br><span class="line"> <span class="keyword">if</span>(<span class="built_in">Connected</span>(G, X, t)) H.<span class="built_in">push</span>(&#123;X, t + <span class="number">1</span>, cn + <span class="number">1</span>&#125;);</span><br><span class="line"> X[t] = <span class="number">0</span>;</span><br><span class="line"> <span class="keyword">if</span>(cn + n - (t + <span class="number">1</span>) &gt; fn) H.<span class="built_in">push</span>(&#123;X, t + <span class="number">1</span>, cn&#125;);</span><br><span class="line"> &#125;</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">return</span> BX;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="子集和问题（44输出所有-amp-45输出一个-x2F-不满足）"><a href="#子集和问题（44输出所有-amp-45输出一个-x2F-不满足）" class="headerlink" title="子集和问题（44输出所有 &amp; 45输出一个&#x2F;不满足）"></a>子集和问题（44输出所有 &amp; 45输出一个&#x2F;不满足）</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">SetSumNode</span></span><br><span class="line">&#123; </span><br><span class="line">    vector&lt;<span class="type">bool</span>&gt; X;</span><br><span class="line"> <span class="type">int</span> t, s, r;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">SetSum</span><span class="params">(<span class="type">const</span> vector&lt;<span class="type">int</span>&gt; &amp;W, <span class="type">int</span> M)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    queue&lt;SetSumNode&gt; Q;</span><br><span class="line"> <span class="type">int</span> n = W.<span class="built_in">size</span>();</span><br><span class="line"> <span class="function">vector&lt;<span class="type">bool</span>&gt; <span class="title">X</span><span class="params">(n)</span></span>;</span><br><span class="line"> <span class="type">int</span> s = <span class="number">0</span>, r = <span class="built_in">accumulate</span>(<span class="built_in">begin</span>(W), <span class="built_in">end</span>(W), <span class="number">0</span>);</span><br><span class="line"> Q.<span class="built_in">push</span>(&#123;X, <span class="number">0</span>, s, r&#125;);</span><br><span class="line"> <span class="keyword">while</span>(<span class="keyword">not</span> Q.<span class="built_in">empty</span>())&#123; </span><br><span class="line">        <span class="keyword">auto</span> [X, t, s, r] = Q.<span class="built_in">front</span>(); Q.<span class="built_in">pop</span>();</span><br><span class="line"> <span class="keyword">if</span>(s == M) cout &lt;&lt; <span class="built_in">to_string</span>(X, t) &lt;&lt; endl;</span><br><span class="line"> <span class="keyword">else</span> <span class="keyword">if</span>(t &lt; n)&#123; </span><br><span class="line">            X[t] = <span class="number">1</span>;</span><br><span class="line"> <span class="keyword">if</span>(s + W[t] &lt;= M)</span><br><span class="line"> Q.<span class="built_in">push</span>(&#123;X, t + <span class="number">1</span>, s + W[t], r - W[t]&#125;);</span><br><span class="line"> X[t] = <span class="number">0</span>;</span><br><span class="line"> <span class="keyword">if</span>(s + (r - W[t]) &gt;= M)</span><br><span class="line"> Q.<span class="built_in">push</span>(&#123;X, t + <span class="number">1</span>, s, r - W[t]&#125;);</span><br><span class="line"> &#125;</span><br><span class="line"> &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">SetSumNode</span></span><br><span class="line">&#123; </span><br><span class="line">    vector&lt;<span class="type">bool</span>&gt; X;</span><br><span class="line"> <span class="type">int</span> t, s, r;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function">vector&lt;<span class="type">bool</span>&gt; <span class="title">SetSum</span><span class="params">(<span class="type">const</span> vector&lt;<span class="type">int</span>&gt; &amp;W, <span class="type">int</span> M)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    queue&lt;SetSumNode&gt; Q;</span><br><span class="line"> <span class="type">int</span> n = W.<span class="built_in">size</span>();</span><br><span class="line"> <span class="function">vector&lt;<span class="type">bool</span>&gt; <span class="title">X</span><span class="params">(n)</span>, Y</span>;</span><br><span class="line"> <span class="type">int</span> s = <span class="number">0</span>, r = <span class="built_in">accumulate</span>(<span class="built_in">begin</span>(W), <span class="built_in">end</span>(W), <span class="number">0</span>);</span><br><span class="line"> Q.<span class="built_in">push</span>(&#123;X, <span class="number">0</span>, s, r&#125;);</span><br><span class="line"> <span class="keyword">while</span>(<span class="keyword">not</span> Q.<span class="built_in">empty</span>())&#123; </span><br><span class="line">        <span class="keyword">if</span>(<span class="keyword">not</span> Y.<span class="built_in">empty</span>()) <span class="keyword">break</span>;</span><br><span class="line"> <span class="keyword">auto</span> [X, t, s, r] = Q.<span class="built_in">front</span>(); Q.<span class="built_in">pop</span>();</span><br><span class="line"> <span class="keyword">if</span>(s == M) Y = X, Y.<span class="built_in">resize</span>(t);</span><br><span class="line"> <span class="keyword">else</span> <span class="keyword">if</span>(t &lt; n)&#123; </span><br><span class="line">            X[t] = <span class="number">1</span>;</span><br><span class="line"> <span class="keyword">if</span>(s + W[t] &lt;= M) Q.<span class="built_in">push</span>(&#123;X, t + <span class="number">1</span>, s + W[t], r - W[t]&#125;);</span><br><span class="line"> X[t] = <span class="number">0</span>;</span><br><span class="line"> <span class="keyword">if</span>(s + (r - W[t]) &gt;= M) Q.<span class="built_in">push</span>(&#123;X, t + <span class="number">1</span>, s, r - W[t]&#125;);</span><br><span class="line"> &#125;</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">return</span> Y;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="概率方法"><a href="#概率方法" class="headerlink" title="概率方法"></a>概率方法</h2><h6 id="随机方法改写快速排序程序"><a href="#随机方法改写快速排序程序" class="headerlink" title="随机方法改写快速排序程序"></a>随机方法改写快速排序程序</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">class</span> T&gt;</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">Partition</span><span class="params">(T X[], <span class="type">int</span> low, <span class="type">int</span> up)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="type">int</span> key = <span class="built_in">rand</span>() % (up - low) + low, p = low;  <span class="comment">// key值随机生成，其他和快速排序一模一样</span></span><br><span class="line"> <span class="built_in">swap</span>(X[key], X[up - <span class="number">1</span>]), key = up - <span class="number">1</span>;</span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> i = low; i &lt; key; ++i)</span><br><span class="line"> <span class="keyword">if</span>(X[i] &lt; X[key]) </span><br><span class="line">            <span class="built_in">swap</span>(X[i], X[p]), ++p;</span><br><span class="line"> <span class="built_in">swap</span>(X[key], X[p]);</span><br><span class="line"> <span class="keyword">return</span> p;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">class</span> T&gt;</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">QuickSort</span><span class="params">(T X[], <span class="type">int</span> low, <span class="type">int</span> up)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="keyword">if</span>(up - low &lt;= <span class="number">1</span>) <span class="keyword">return</span>;</span><br><span class="line"> <span class="type">int</span> m = <span class="built_in">Partition</span>(X, low, up);</span><br><span class="line"> <span class="built_in">QuickSort</span>(X, low, m);</span><br><span class="line"> <span class="built_in">QuickSort</span>(X, m + <span class="number">1</span>, up);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="随机方法改写基于划分的选择程序"><a href="#随机方法改写基于划分的选择程序" class="headerlink" title="随机方法改写基于划分的选择程序"></a>随机方法改写基于划分的选择程序</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">class</span> T&gt;</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">Partition</span><span class="params">(T X[], <span class="type">int</span> low, <span class="type">int</span> up)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="type">int</span> key = <span class="built_in">rand</span>() % (up - low) + low, p = low;  <span class="comment">// key值随机生成，其他和选择排序一模一样</span></span><br><span class="line"> <span class="built_in">swap</span>(X[key], X[up - <span class="number">1</span>]), key = up - <span class="number">1</span>;</span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> i = low; i &lt; key; ++i)</span><br><span class="line"> <span class="keyword">if</span>(X[i] &lt; X[key]) </span><br><span class="line">            <span class="built_in">swap</span>(X[i], X[p]), ++p;</span><br><span class="line"> <span class="built_in">swap</span>(X[key], X[p]);</span><br><span class="line"> <span class="keyword">return</span> p;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">class</span> T&gt;</span></span><br><span class="line"><span class="function">T &amp;<span class="title">Select</span><span class="params">(T X[], <span class="type">int</span> n, <span class="type">int</span> k)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="type">int</span> low = <span class="number">0</span>, up = n;</span><br><span class="line"> <span class="keyword">for</span>(;;)&#123; </span><br><span class="line">        <span class="type">int</span> m = <span class="built_in">Partition</span>(X, low, up);</span><br><span class="line"> <span class="keyword">if</span>(k == m) <span class="keyword">return</span> X[m];</span><br><span class="line"> <span class="keyword">else</span> <span class="keyword">if</span>(k &lt; m) up = m;</span><br><span class="line"> <span class="keyword">else</span> low = m + <span class="number">1</span>;</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="随机洗牌算法"><a href="#随机洗牌算法" class="headerlink" title="随机洗牌算法"></a>随机洗牌算法</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">class</span> T&gt;</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Shuffle</span><span class="params">(T X[], <span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="keyword">for</span>(--n; n &gt; <span class="number">0</span>; --n)</span><br><span class="line"> <span class="built_in">swap</span>(X[n], X[<span class="built_in">rand</span>() % n]);  <span class="comment">// 随机交换元素，将数组完全打乱</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="插入说明："><a href="#插入说明：" class="headerlink" title="插入说明："></a>插入说明：</h6><p>虽然题库里都是拉斯维加斯算法的求解过程，但是生活处处充满惊喜，谁也不知道他会不会出一个算法以外的题或者其他算法的题给你，因此在这里题主详细但又简洁的介绍下三种概率方法（蒙特卡洛算法、拉斯维加斯算法、舍伍德算法）</p><ul><li>拉斯维加斯算法：不会得到错误解，但是有可能找不到解。（在下面的题目中形容得比较简单，对于需要排序的问题就是在开始将数组随机打乱；而对于需要求子集的问题，就是在判断一个元素选还是不选时引入随机数，就这么看来，概率算法其实是试卷的送分题【基础题型加一句随机数描述】）</li><li>蒙特卡洛算法：用于求问题的准确解，但是这个解不能保证是正确的。</li><li>舍伍德算法：总能得到问题的一个解，且得到的解一定是正确的。（通过确定算法引入随机数，消除&#x2F;减少好坏实例之间的区别）</li></ul><p>了解了这三个随机算法的区别后，考试的时候怎么办？如果真的出现了其他的概率算法怎么写？题主的建议是全按照拉斯维加斯算法的过程写，因为都是在基础题型上加上随机判断，三个算法的区别就是随机算法安插的位置和次数（1~2次）不同，所以没必要纠结之间的差别，拿个大头就好！</p><h6 id="拉斯维加斯算法求解旅行商问题（是否存在耗费不超过t的旅行）"><a href="#拉斯维加斯算法求解旅行商问题（是否存在耗费不超过t的旅行）" class="headerlink" title="拉斯维加斯算法求解旅行商问题（是否存在耗费不超过t的旅行）"></a>拉斯维加斯算法求解旅行商问题（是否存在耗费不超过t的旅行）</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">TSP</span><span class="params">(<span class="type">const</span> Matrix&lt;<span class="type">double</span>&gt; &amp;G, <span class="type">double</span> t, vector&lt;<span class="type">int</span>&gt; &amp;X)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="type">int</span> n = G.<span class="built_in">rows</span>();</span><br><span class="line"> <span class="built_in">iota</span>(<span class="built_in">begin</span>(X), <span class="built_in">end</span>(X), <span class="number">0</span>);</span><br><span class="line"> <span class="built_in">random_shuffle</span>(<span class="built_in">begin</span>(X), <span class="built_in">end</span>(X));  <span class="comment">// 对一个数组随机排列</span></span><br><span class="line"> <span class="type">double</span> s = <span class="number">0</span>;</span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> k = <span class="number">0</span>; k &lt; n; ++k)&#123; </span><br><span class="line">        s += <span class="built_in">G</span>(X[k % n], X[(k + <span class="number">1</span>) % n]);</span><br><span class="line"> <span class="keyword">if</span>(s &gt; t) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="拉斯维加斯算法求解0-x2F-1背包问题（是否存在效益和不少于t的装包方式）"><a href="#拉斯维加斯算法求解0-x2F-1背包问题（是否存在效益和不少于t的装包方式）" class="headerlink" title="拉斯维加斯算法求解0&#x2F;1背包问题（是否存在效益和不少于t的装包方式）"></a>拉斯维加斯算法求解0&#x2F;1背包问题（是否存在效益和不少于t的装包方式）</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">Knap</span><span class="params">(<span class="type">const</span> vector&lt;<span class="type">double</span>&gt; &amp;V, <span class="type">const</span> vector&lt;<span class="type">double</span>&gt; &amp;W,</span></span></span><br><span class="line"><span class="params"><span class="function"><span class="type">double</span> c, <span class="type">double</span> t, vector&lt;<span class="type">bool</span>&gt; &amp;X)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="type">int</span> n = <span class="built_in">min</span>(V.<span class="built_in">size</span>(), W.<span class="built_in">size</span>());</span><br><span class="line"> <span class="type">double</span> fv = <span class="number">0</span>, fw = <span class="number">0</span>;</span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; ++i)&#123; </span><br><span class="line">        <span class="keyword">if</span>(<span class="built_in">rand</span>() % <span class="number">2</span> == <span class="number">1</span>)</span><br><span class="line"> X[i] = <span class="number">1</span>, fv += V[i], fw += W[i];</span><br><span class="line"> <span class="keyword">else</span></span><br><span class="line"> X[i] = <span class="number">0</span>;</span><br><span class="line"> <span class="keyword">if</span>(fw &gt; c) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">return</span> fv &gt;= t;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="拉斯维加斯算法求解Hamilton回路问题（是否有Hamilton回路）"><a href="#拉斯维加斯算法求解Hamilton回路问题（是否有Hamilton回路）" class="headerlink" title="拉斯维加斯算法求解Hamilton回路问题（是否有Hamilton回路）"></a>拉斯维加斯算法求解Hamilton回路问题（是否有Hamilton回路）</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">Hamilton</span><span class="params">(<span class="type">const</span> Matrix&lt;<span class="type">bool</span>&gt; &amp;G, vector&lt;<span class="type">int</span>&gt; &amp;X)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="type">int</span> n = G.<span class="built_in">rows</span>();</span><br><span class="line"> <span class="built_in">iota</span>(<span class="built_in">begin</span>(X), <span class="built_in">end</span>(X), <span class="number">0</span>);</span><br><span class="line"> <span class="built_in">random_shuffle</span>(<span class="built_in">begin</span>(X), <span class="built_in">end</span>(X));</span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> k = <span class="number">0</span>; k &lt; n; ++k)&#123; </span><br><span class="line">        <span class="type">int</span> i = X[k], j = X[(k + <span class="number">1</span>) % n];</span><br><span class="line"> <span class="keyword">if</span>(<span class="built_in">G</span>(i, j) != <span class="number">1</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="拉斯维加斯算法求解子集和问题（是否存在和为t的子集）"><a href="#拉斯维加斯算法求解子集和问题（是否存在和为t的子集）" class="headerlink" title="拉斯维加斯算法求解子集和问题（是否存在和为t的子集）"></a>拉斯维加斯算法求解子集和问题（是否存在和为t的子集）</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">SetSum</span><span class="params">(<span class="type">const</span> vector&lt;<span class="type">int</span>&gt; &amp;W, <span class="type">int</span> t, vector&lt;<span class="type">bool</span>&gt; &amp;X)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="type">int</span> s = <span class="number">0</span>;</span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; W.<span class="built_in">size</span>(); ++i)&#123; </span><br><span class="line">        <span class="keyword">if</span>(<span class="built_in">rand</span>() % <span class="number">2</span> == <span class="number">1</span>)</span><br><span class="line"> X[i] = <span class="number">1</span>, s += W[i];</span><br><span class="line"> <span class="keyword">else</span></span><br><span class="line"> X[i] = <span class="number">0</span>;</span><br><span class="line"> <span class="keyword">if</span>(s &gt; t) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">return</span> s == t;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="拉斯维加斯算法求解团问题（是否存在顶点数不小于k的团）"><a href="#拉斯维加斯算法求解团问题（是否存在顶点数不小于k的团）" class="headerlink" title="拉斯维加斯算法求解团问题（是否存在顶点数不小于k的团）"></a>拉斯维加斯算法求解团问题（是否存在顶点数不小于k的团）</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">Clique</span><span class="params">(<span class="type">const</span> Matrix&lt;<span class="type">bool</span>&gt; &amp;G, <span class="type">int</span> k, vector&lt;<span class="type">bool</span>&gt; &amp;X)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="type">int</span> n = G.<span class="built_in">rows</span>(), m = <span class="number">0</span>;</span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; ++i)</span><br><span class="line"> <span class="keyword">if</span>(<span class="built_in">rand</span>() % <span class="number">2</span> == <span class="number">1</span>)</span><br><span class="line"> X[i] = <span class="number">1</span>, ++m;</span><br><span class="line"> <span class="keyword">else</span></span><br><span class="line"> X[i] = <span class="number">0</span>;</span><br><span class="line"> <span class="keyword">if</span>(m &lt; k) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; ++i)</span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> j = i + <span class="number">1</span>; j &lt; n; ++j)</span><br><span class="line"> <span class="keyword">if</span>(X[i] == <span class="number">1</span> <span class="keyword">and</span> X[j] == <span class="number">1</span> <span class="keyword">and</span> <span class="built_in">G</span>(i, j) != <span class="number">1</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"> <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>到这里，这门课这本书的所有内容（其实就是简单讲解了下题库）都已经完结了！恭喜恭喜，如果你是从头到尾认真一路复习下来的，那么毫无疑问，你八成已经忘得差不多了QWQ（因为题主两天半写到这发现真要随机抽一道给我确实不一定会写）。但是不用担心，基本上认真看到这的对于各问题的基本思路都已经成型，大家大可按照自己喜欢的、方便的语言去完成算法。两章回溯由于题主也是第一次接触，并且老师上课节奏较快（咱也不是认真听课的人），所以采用的是强记的方式。这两天题主会根据样卷出一份考前押题卷，一个是加强自己的手写能力，二个题库的题过了一遍，发现有些题太简单了，而有些题太难了，可以很大程度的缩小背记范围。那么，这个文档到此就告一段落了，之后应该是上传到GitHub上供未来的学弟学妹参考了（毕竟考前两天才完成）。</p><p>加油加油！                                                                                                                                                            ——By Alexie-Z-Yevich 2022.5.8</p><hr><p>算是版本2.0吧，因为之前对于回溯和分枝限界不是很了解，所以连带着概率也没怎么给大家写，今天把之前埋的坑都填上了，还是好难啊，押题卷昨天就出完了，大家感兴趣还是可以看一下滴。（其实今天又过了一遍题，如果真在题库里抽的话，那么其实没啥好押题的，真是谁也说不清呢）                                                                                                                                             ——By Alexie-Z-Yevich 2022.5.9</p>]]></content>
      
      
      <categories>
          
          <category> 我的大学 </category>
          
          <category> 大二下学期 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据库系统</title>
      <link href="/2022/05/15/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/"/>
      <url>/2022/05/15/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<h2 id="考试题型："><a href="#考试题型：" class="headerlink" title="考试题型："></a>考试题型：</h2><h6 id="一、判断题（10分-x2F-10）"><a href="#一、判断题（10分-x2F-10）" class="headerlink" title="一、判断题（10分&#x2F;10）"></a>一、判断题（10分&#x2F;10）</h6><h6 id="二、填空题（20分-x2F-10）"><a href="#二、填空题（20分-x2F-10）" class="headerlink" title="二、填空题（20分&#x2F;10）"></a>二、填空题（20分&#x2F;10）</h6><h6 id="三、选择题（20分-x2F-10）"><a href="#三、选择题（20分-x2F-10）" class="headerlink" title="三、选择题（20分&#x2F;10）"></a>三、选择题（20分&#x2F;10）</h6><h6 id="四、大题一（30分-x2F-2）–-gt-关系代数-x2F-SQl语言"><a href="#四、大题一（30分-x2F-2）–-gt-关系代数-x2F-SQl语言" class="headerlink" title="四、大题一（30分&#x2F;2）–&gt;关系代数&#x2F;SQl语言"></a>四、大题一（30分&#x2F;2）–&gt;关系代数&#x2F;SQl语言</h6><h6 id="五、大题二（20分）-–-gt-关系数据库设计"><a href="#五、大题二（20分）-–-gt-关系数据库设计" class="headerlink" title="五、大题二（20分） –&gt;关系数据库设计"></a>五、大题二（20分） –&gt;关系数据库设计</h6><hr><h2 id="第一章-绪论"><a href="#第一章-绪论" class="headerlink" title="第一章 绪论"></a>第一章 绪论</h2><h6 id="1、数据库的4个基本概念"><a href="#1、数据库的4个基本概念" class="headerlink" title="1、数据库的4个基本概念"></a>1、数据库的4个基本概念</h6><p><strong>（1）数据</strong></p><p>数据是数据库中存储的基本对象，是用来描述事物的符号记录。</p><p><strong>（2）数据库</strong></p><p>存放数据的仓库。是长期储存在计算机内、有组织的、可共享的大量数据的集合。数据中的数据按一定的数据模型组织、描述和存储，具有较小的冗余度、较高的数据独立性和易扩展性，并可为用户共享。</p><p><strong>（3）数据库管理系统</strong></p><p>是位于用户和操作系统之间的一层数据管理软件。数据管理系统和操作系统一样是计算机的基础软件，也是一个大型复杂的软件系统。</p><p><strong>（4）数据库系统</strong></p><p>是数据库、数据库管理系统、应用程序和数据库管理员组成的存储、管理、处理和维护数据的系统。</p><hr><h6 id="2、数据库系统的特点"><a href="#2、数据库系统的特点" class="headerlink" title="2、数据库系统的特点"></a>2、数据库系统的特点</h6><p><strong>（1）数据结构化</strong></p><p>数据库系统实现整体数据的结构化，这是数据库的主要特征之一，也是数据库系统与文件系统的本质区别。</p><p><strong>（2）数据的共享性高、冗余度低且易扩充</strong></p><p>数据共享可以大大减少数据冗余，节约存储空间。数据共享还能够避免数据之间的不相容性与不一致性。（弹性大、易于扩充）</p><p><strong>（3）数据独立性高</strong></p><p>数据独立性包括数据的物理独立性和逻辑独立性。物理独立性是指用户的应用程序与数据库中的物理存储是相互独立的；逻辑独立性是指用户的应用程序与数据库的逻辑结构是相互独立的。</p><p><strong>（4）数据由数据库管理系统统一管理和控制</strong></p><p>1、数据的安全性保护；2、数据的完整性检查；3、并发控制；4、数据库恢复</p><p><strong>综上所述：</strong>数据库是长期储存在计算机内有组织、大量、共享的数据集合。它可以供各种用户共享，具有最小的冗余度和较高的数据独立性。数据库管理系统在数据库建立、运用和维护时对数据库进行统一控制，以保证数据的完整性和安全性，并在多用户使用数据库时进行并发控制，在发生故障后对数据库进行恢复。</p><hr><h6 id="3、概念模型"><a href="#3、概念模型" class="headerlink" title="3、概念模型"></a>3、概念模型</h6><p><strong>（1）实体：</strong>客观存在并可相互区别的事物</p><p><strong>（2）属性：</strong>实体所具有的某一特性</p><p><strong>（3）码：</strong>唯一标识实体的属性集</p><p><strong>（4）实体型：</strong>用实体名及其属性名集合来抽象和刻画同类实体（具有相同属性的实体必然具有共同的特征和性质）</p><p><strong>（5）实体集：</strong>同一类型的实体的集合</p><p><strong>（6）联系：</strong>实体[型]内部的联系和实体[型]之间的联系（通常指不同实体集之间的联系，实体之间的联系有一对一、一对多、多对多等多种类型）</p><hr><h6 id="4、数据模型"><a href="#4、数据模型" class="headerlink" title="4、数据模型"></a>4、数据模型</h6><p><strong>（1）数据结构：</strong>描述数据库的组成对象以及对象之间的联系</p><p><strong>（2）数据操作：</strong>对数据库中各种对象[型]的实例[值]允许执行的操作的集合，包括操作及有关的操作规则。（查询、更新两大类操作）</p><p><strong>（3）数据的完整性约束条件：</strong>一组完整性规则。任何关系必须满足实体完整性和参照完整性</p><hr><h6 id="5、关系模型"><a href="#5、关系模型" class="headerlink" title="5、关系模型"></a>5、关系模型</h6><p>关系模型是最重要的一种数据模型。关系数据库系统采用关系模型作为数据的组织方式。</p><p><strong>（1）关系模型的数据结构：</strong>建立在严格的数学模型的基础上。关系模型要求关系必须是规范化的，关系的每一个分量必须是一个不可分的数据项。</p><ul><li>码：也称为码键。表中的某个属性组，它可以唯一确定一个元组；</li><li>域：域是一组具有相同数据类型的值的集合；</li><li>分量：元组中的一个属性值。</li></ul><p><strong>（2）关系模型的数据操纵与完整性约束：</strong>操作对象和操作结果都是关系。</p><p><strong>（3）关系模型的优缺点：</strong></p><p>优点：</p><ul><li>关系模型与格式化模型不同，它是建立在严格的数学概念的基础上的。</li><li>关系模型的概念单一。所以数据结构简单、清晰，用户易懂易用。</li><li>关系模型的存取路径对用户透明，从而具有更高的数据独立性、更好的安全保密性，简化了程序员和数据库开发建立的工作。</li></ul><p>缺点：</p><ul><li>存取路径对用户隐蔽，导致查询效率不如格式化数据模型。</li></ul><hr><h6 id="6、数据库系统的三级模式结构"><a href="#6、数据库系统的三级模式结构" class="headerlink" title="6、数据库系统的三级模式结构"></a>6、数据库系统的三级模式结构</h6><p><strong>（1）模式：</strong>模式也称逻辑模式，是数据库中全体数据的逻辑结构和特征的描述，是所有用户的公共数据视图。</p><p><strong>（2）外模式：</strong>外模式也称子模式或用户模式，它是数据库用户能够看见和使用的局部数据的逻辑结构和特征的描述，是数据库用户的数据视图，是与某一应用有关的数据的逻辑表示。（外模式通常是模式的子集，一个数据库可以有多个外模式）</p><p><strong>（3）内模式：</strong>内模式也称存储模式，一个数据库只有一个内模式。它是数据物理结构和存储方式的描述，是数据在数据库内部的组织方式。</p><hr><h2 id="第二章-关系数据库"><a href="#第二章-关系数据库" class="headerlink" title="第二章 关系数据库"></a>第二章 关系数据库</h2><h6 id="1、一些碎片知识"><a href="#1、一些碎片知识" class="headerlink" title="1、一些碎片知识"></a>1、一些碎片知识</h6><p>（1）<strong>域</strong></p><p>域是一组拥有相同数据类型的值的集合。</p><p>（2）<strong>关系类型</strong></p><p>关系有三种类型：基本关系（通常又被称为基本表或者基表）、查询表和视图表。</p><p>（3）关系的每一个分量必须是一个<strong>不可分的数据项</strong>。</p><p>（4）关系的模式称为<strong>关系模式</strong>。</p><p>（5）关系数据库的型也被称为关系数据库模式，是对关系数据库的描述。</p><p>（6）关系操作的特点是集合操作方式，即<strong>操作的对象和结果都是集合</strong>。</p><hr><h6 id="2、传统的集合运算"><a href="#2、传统的集合运算" class="headerlink" title="2、传统的集合运算"></a>2、传统的集合运算</h6><p>传统的集合运算是二目运算，包括并、差、交、笛卡尔积4种运算。</p><p>（1）并：R∪S&#x3D;{t|t∈R∪t∈S}</p><p>（2）差：R-S&#x3D;{t|t∈R∩t∉S}</p><p>（3）交：R∩S&#x3D;{t|t∈R∩t∈S}</p><p>（4）笛卡尔积：R×S&#x3D;{(tr,ts)|tr∈R∧ts∈S}</p><hr><h6 id="3、专门的关系运算"><a href="#3、专门的关系运算" class="headerlink" title="3、专门的关系运算"></a>3、专门的关系运算</h6><p>（1）<strong>选择</strong>【限制】<br>$$<br>\sigma_F(R) &#x3D; {t|t∈R∩F(t)&#x3D;’真’}<br>$$<br>从R（表）中找出所有满足F（条件）的t（元素）。F为运算表达式，有＞、≥、＜、≤、&#x3D;、&lt;&gt;（不等于）、┐（非）、∩、∪运算符。</p><p>（2）<strong>投影</strong><br>$$<br>\Pi_A(R)&#x3D;{t[A]|t∈R}<br>$$<br>选出R（表）中的A（属性列）中的t（元素）组成新视图。</p><p>（3）<strong>连接</strong>（θ连接）</p><p>表达式太难写了这里就不写了。。。</p><p>通过AθB条件判断生成的笛卡尔积，θ为“&#x3D;”时的运算称之为<strong>等值运算</strong>。</p><p><strong>自然连接</strong>（没有AθB的表达式）是一种特殊的等值运算【取消重复列】。</p><p><strong>外连接</strong>：笛卡尔积（不存在位置给null）【保留所有关系】</p><p>左外连接：保留左边关系；右外连接：保留右边关系。</p><p>（4）<strong>除运算</strong><br>$$<br>R\div S&#x3D;{t_r[x]|t_r∈R∩\Pi_Y(S)⊆Y_x}<br>$$<br>R、S中相关元素形成的集合，可以在R中用不相关的元素得到就满足除法运算。</p><hr><h6 id="4、常用SQL运算"><a href="#4、常用SQL运算" class="headerlink" title="4、常用SQL运算"></a>4、常用SQL运算</h6><ul><li>count 对元组计数</li><li>total 求总和</li><li>max 求最大值</li><li>min 求最小值</li><li>avg求平均值</li></ul><hr><h2 id="第三章-关系数据库标准语言SQl"><a href="#第三章-关系数据库标准语言SQl" class="headerlink" title="第三章 关系数据库标准语言SQl"></a>第三章 关系数据库标准语言SQl</h2><h6 id="1、SQL的特点"><a href="#1、SQL的特点" class="headerlink" title="1、SQL的特点"></a>1、SQL的特点</h6><p>（1）综合统一；</p><p>（2）高度非过程化；</p><p>（3）面向集合的操作；</p><p>（4）以同一语法结构提供多种使用方式；</p><p>（5）语言简洁，易学易用。</p><hr><h6 id="2、SQL功能"><a href="#2、SQL功能" class="headerlink" title="2、SQL功能"></a>2、SQL功能</h6><p>（1）数据查询【select】</p><p>（2）数据定义【create、drop、alter】</p><p>（3）数据操纵【insert、update、delete】</p><p>（4）数据控制【grant、revoke】</p><hr><h2 id="第四章-数据库安全性控制"><a href="#第四章-数据库安全性控制" class="headerlink" title="第四章 数据库安全性控制"></a>第四章 数据库安全性控制</h2><p>包括用户身份鉴别、多层存取控制、审计、视图和数据加密等安全技术。</p><h6 id="1、常用的用户身份鉴别"><a href="#1、常用的用户身份鉴别" class="headerlink" title="1、常用的用户身份鉴别"></a>1、常用的用户身份鉴别</h6><p>（1）静态口令鉴别</p><p>由用户自己设定，鉴别时只要按要求输入正确的口令，系统将允许用户使用数据库管理系统。</p><p>（2）动态口令鉴别</p><p>目前较为安全的鉴别方式。口令是动态变化的，每次鉴别时均需使用动态产生的新口令登录数据库管理系统。</p><p>（3）生物特征鉴别</p><p>生物特征指的是生物体唯一具有的，可测量、识别、验证的稳定生物特征。</p><p>（4）智能卡鉴别</p><p>智能卡是一种不可复制硬件，内置集成电路的芯片，具有硬件加密功能。</p><hr><h6 id="2、存取控制"><a href="#2、存取控制" class="headerlink" title="2、存取控制"></a>2、存取控制</h6><p>存取控制机制主要包括定义用户权限和合法权限检查两部分，两机制一起组成了数据库管理系统的存取控制子系统。</p><p>（1）<strong>自主存取控制（灵活）</strong></p><p>用户对于不同的数据库对象有不同的存取权限，不同的用户对同一对象也有不同的权限，而且用户还可将其拥有的权限转授给其他用户。</p><p>（2）<strong>强制存取控制（严格）</strong></p><p>每一个数据库对象被标以一定的密级，每一个用户也被授予某一个级别的许可证。对于任意一个对象，只有具有合法许可证的用户才可以存取。</p><hr><h6 id="3、用户权限"><a href="#3、用户权限" class="headerlink" title="3、用户权限"></a>3、用户权限</h6><p>由<strong>数据库对象</strong>、<strong>操作类型</strong>组成。在数据库系统中，定义存取权限称为授权。存取控制的对象不仅有<strong>数据</strong>本身（基本表中的数据、属性列上的数据），还有<strong>数据库模式</strong>（包括模式、基本表、视图和索引的创建）。</p><hr><h6 id="4、授权语句"><a href="#4、授权语句" class="headerlink" title="4、授权语句"></a>4、授权语句</h6><p>（1）grant授予</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">grant</span> <span class="operator">&lt;</span>权限<span class="operator">&gt;</span>[,<span class="operator">&lt;</span>权限<span class="operator">&gt;</span>]…</span><br><span class="line"><span class="keyword">on</span> <span class="operator">&lt;</span>对象类型<span class="operator">&gt;</span><span class="operator">&lt;</span>对象名<span class="operator">&gt;</span>[,<span class="operator">&lt;</span>对象类型<span class="operator">&gt;</span><span class="operator">&lt;</span>对象名<span class="operator">&gt;</span>]……</span><br><span class="line"><span class="keyword">to</span> <span class="operator">&lt;</span>用户<span class="operator">&gt;</span>[,<span class="operator">&lt;</span>用户<span class="operator">&gt;</span>]…</span><br><span class="line">[<span class="keyword">with</span> <span class="keyword">grant</span> option];</span><br></pre></td></tr></table></figure><p>例：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">grant</span> <span class="keyword">insert</span> <span class="keyword">on</span> <span class="keyword">table</span> sc <span class="keyword">to</span> u5 <span class="keyword">with</span> <span class="keyword">grant</span> option;</span><br><span class="line"><span class="operator">/</span><span class="operator">/</span> 将sc表的<span class="keyword">insert</span>权限给u5用户，并且允许该用户将权限授予其他用户。</span><br></pre></td></tr></table></figure><p>（2）revoke收回</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">revoke</span> <span class="operator">&lt;</span>权限<span class="operator">&gt;</span>[,<span class="operator">&lt;</span>权限<span class="operator">&gt;</span>]…</span><br><span class="line"><span class="keyword">on</span> <span class="operator">&lt;</span>对象类型<span class="operator">&gt;</span><span class="operator">&lt;</span>对象名<span class="operator">&gt;</span>[,<span class="operator">&lt;</span>对象类型<span class="operator">&gt;</span><span class="operator">&lt;</span>对象名<span class="operator">&gt;</span>]……</span><br><span class="line"><span class="keyword">from</span> <span class="operator">&lt;</span>用户<span class="operator">&gt;</span>[,<span class="operator">&lt;</span>用户<span class="operator">&gt;</span>]…</span><br><span class="line">[cascade<span class="operator">|</span>restrict];</span><br></pre></td></tr></table></figure><p>例：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">revoke</span> <span class="keyword">insert</span> <span class="keyword">on</span> <span class="keyword">table</span> sc <span class="keyword">from</span> u5 cascade;</span><br><span class="line"><span class="operator">/</span><span class="operator">/</span> 收回u5用户在sc表的<span class="keyword">insert</span>权限（同时cascade不会收回u5授权用户的权限）</span><br><span class="line"><span class="operator">/</span><span class="operator">/</span> 所以restrict会级联收回下级用户权限</span><br></pre></td></tr></table></figure><hr><h6 id="5、数据库角色"><a href="#5、数据库角色" class="headerlink" title="5、数据库角色"></a>5、数据库角色</h6><p>数据库角色是被命名的一组与数据库操作相关的权限，角色是权限的集合。</p><p>（1）角色的创建</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> role <span class="operator">&lt;</span>角色名<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure><p>（2）给角色授权</p><p>利用grant语句将权限授予某一个或几个角色。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">grant</span> <span class="operator">&lt;</span>权限<span class="operator">&gt;</span>[,<span class="operator">&lt;</span>权限<span class="operator">&gt;</span>]…</span><br><span class="line"><span class="keyword">on</span> <span class="operator">&lt;</span>对象类型<span class="operator">&gt;</span>对象名</span><br><span class="line"><span class="keyword">to</span> <span class="operator">&lt;</span>角色<span class="operator">&gt;</span>[,<span class="operator">&lt;</span>角色<span class="operator">&gt;</span>]…</span><br></pre></td></tr></table></figure><p>（3）将一个角色授予其他的角色或用户</p><p>拥有with admin option的角色或用户可以将权限授予其他人。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">grant</span> <span class="operator">&lt;</span>角色<span class="number">1</span><span class="operator">&gt;</span>[,<span class="operator">&lt;</span>角色<span class="number">2</span><span class="operator">&gt;</span>]…</span><br><span class="line"><span class="keyword">to</span> <span class="operator">&lt;</span>角色<span class="number">3</span><span class="operator">&gt;</span>[,<span class="operator">&lt;</span>用户<span class="number">1</span><span class="operator">&gt;</span>]…</span><br><span class="line">[<span class="keyword">with</span> admin option]</span><br></pre></td></tr></table></figure><p>（4）角色权限的收回</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">revoke</span> <span class="operator">&lt;</span>权限<span class="operator">&gt;</span>[,<span class="operator">&lt;</span>权限<span class="operator">&gt;</span>]…</span><br><span class="line"><span class="keyword">on</span> <span class="operator">&lt;</span>对象类型<span class="operator">&gt;</span><span class="operator">&lt;</span>对象名<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">from</span> <span class="operator">&lt;</span>角色<span class="operator">&gt;</span>[,<span class="operator">&lt;</span>角色<span class="operator">&gt;</span>]…</span><br></pre></td></tr></table></figure><h2 id="第五章-数据库完整性"><a href="#第五章-数据库完整性" class="headerlink" title="第五章 数据库完整性"></a>第五章 数据库完整性</h2><p>数据库的完整性是指数据的<strong>正确性</strong>和<strong>相容性</strong>。</p><p>关系数据库管理系统使得完整性控制成为其核心支持的功能，从而能够为所有的用户和应用提供一致的数据库完整性。</p><h6 id="1、实体完整性"><a href="#1、实体完整性" class="headerlink" title="1、实体完整性"></a>1、实体完整性</h6><p>primary key主键定义关系的主码，具有不为空和唯一的特性。用户插入数据时会对实体完整性故则自动检查：</p><p>（1）检查主码值是否唯一，如果不唯一则拒绝插入或修改；</p><p>（2）检查主码各个属性是否为空，只要一个为空就拒绝插入和修改。</p><hr><h6 id="2、参照完整性"><a href="#2、参照完整性" class="headerlink" title="2、参照完整性"></a>2、参照完整性</h6><p>foreign key外键定义关系的外码，用references指明外码参照的是哪些表的主码。</p><p>语法结构；</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">foreign</span> key (Sno) <span class="keyword">references</span> Student(Sno);</span><br><span class="line"><span class="operator">/</span><span class="operator">/</span> 当前表的Sno元素和Student表中的Sno关联</span><br></pre></td></tr></table></figure><hr><h6 id="3、用户定义的完整性"><a href="#3、用户定义的完整性" class="headerlink" title="3、用户定义的完整性"></a>3、用户定义的完整性</h6><p>针对某一具体应用的数据必须满足的语义要求。<br>简单来说就是用户对一些属性字段进行语义限制的操作，常见的有not null&#x2F;unique等。</p><hr><h2 id="第六章-关系数据库理论"><a href="#第六章-关系数据库理论" class="headerlink" title="第六章 关系数据库理论"></a>第六章 关系数据库理论</h2><h6 id="1、术语定义"><a href="#1、术语定义" class="headerlink" title="1、术语定义"></a>1、术语定义</h6><p><strong>（1）函数依赖</strong></p><p>设R(U)是属性集U上的关系模式，X、Y是U的子集。若对于R(U)的任何一个可能的关系r，如果r中不存在两个元组在X上的属性值相等，二在Y上的属性值不等，则称<strong>X函数确定Y</strong>或<strong>Y函数依赖于X</strong>，记作X—-&gt;Y。</p><p><strong>（2）完全函数依赖</strong></p><p>在R(U)中，如果X—-&gt;Y，并且对于X的任何一个真子集X&#96;–&#x2F;–&gt;Y，则称Y对X完全函数依赖。记作X–F–&gt;Y。</p><p><strong>（3）部分函数依赖</strong></p><p>若X—-&gt;Y，但Y不完全函数依赖于X，则称Y对X部分函数依赖。记作X–P–&gt;Y。</p><p><strong>（4）候选码</strong></p><p>设K为R&lt;U,F&gt;中的属性或属性组合，若K–F–&gt;U，则K为R的候选码。如果U函数依赖于K，即K—-&gt;U，则K称为<strong>超码</strong>。包含在任何一个候选码中的属性称为<strong>主属性</strong>。</p><p><strong>（5）全码</strong></p><p>整个属性组是码，称为全码。</p><hr><h6 id="2、范式"><a href="#2、范式" class="headerlink" title="2、范式"></a>2、范式</h6><p>关系数据库中的关系是要满足一定要求的，满足不同程度要求的为不同的范式。</p><p><strong>（1）1NF</strong></p><p>若关系模式的每一个分量都是不可再分的数据项，则关系模式R属于第一范式。</p><p><strong>（2）2NF</strong></p><p>若关系模式R∈1NF，并且每一个非主属性都完全函数依赖与R的码，则R∈2NF。</p><p><strong>（3）3NF</strong></p><p>关系模式R中若不存在这样的码X，属性组Y及非主属性Z（Z不属于Y）使得X—-&gt;Y，Y—-&gt;Z成立，Y–&#x2F;–&gt;X，则称R&lt;U,F&gt;∈3NF。</p><p><strong>（4）BCNF</strong></p><p>设关系模式R∈1NF，如果对于每个函数依赖X—-&gt;Y，若Y不属于X，则X必有候选码，那么R∈BCNF。</p><hr><h6 id="3、数据依赖的公理系统"><a href="#3、数据依赖的公理系统" class="headerlink" title="3、数据依赖的公理系统"></a>3、数据依赖的公理系统</h6><p>数据依赖的公理系统是模式分解算法的理论基础。</p><p><strong>Armstrong公理系统</strong>：设U为属性集总体，F是U上的一组函数依赖，于是有关系模式R&lt;U,F&gt;，对R&lt;U,F&gt;来说有以下的推理规则：</p><p>（1）自反律：若Y包含于X包含于U，则X—-&gt;Y为F所蕴含。</p><p>（2）增广律：若X—-&gt;Y为F所蕴含，且Z包含于U，则XZ—-&gt;YZ为F所蕴含。</p><p>（3）传递律：若X—-&gt;Y及Y—-&gt;Z为F所蕴含，则X—-&gt;Z为F所蕴含。</p><p>Armstrong公理系统是<strong>有效的</strong>、<strong>完备的</strong>。</p><hr><h2 id="第七章-数据库设计"><a href="#第七章-数据库设计" class="headerlink" title="第七章 数据库设计"></a>第七章 数据库设计</h2><h6 id="1、一般定义"><a href="#1、一般定义" class="headerlink" title="1、一般定义"></a>1、一般定义</h6><p>数据库设计是指对于一个给定的应用环境，构造（设计）优化的数据库逻辑模式和物理结构，并据此建立数据库及其应用系统，使之能够有效的存储和管理数据，满足各种用户的应用需求，包括信息管理要求和数据操作要求。</p><hr><h6 id="2、数据库设计的基本步骤"><a href="#2、数据库设计的基本步骤" class="headerlink" title="2、数据库设计的基本步骤"></a>2、数据库设计的基本步骤</h6><p><strong>（1）需求分析</strong></p><p>准确了解与分析用户需求。</p><p><strong>（2）概念结构设计</strong></p><p>对用户需求进行综合、归纳与抽象，形成一个独立于具体数据库管理系统的概念模型。</p><p><strong>（3）逻辑结构设计</strong></p><p>将概念结构转换为某个数据库管理系统所支持的数据模型.</p><p><strong>（4）物理结构设计</strong></p><p>为逻辑结构模型选取一个最适合应用环境的物理结构。</p><p><strong>（5）数据库实施</strong></p><p>根据逻辑设计和物理设计的结果建立数据库，编写与调试应用程序，组织数据入库，并进行试运行。</p><p><strong>（6）数据库运行和维护</strong></p><p>不断对其进行评估、调整和修改。</p><hr><h6 id="3、需求分析【不考，写错了】"><a href="#3、需求分析【不考，写错了】" class="headerlink" title="3、需求分析【不考，写错了】"></a>3、需求分析【不考，写错了】</h6><p>（1）任务</p><p>调查的重点是“数据”和“处理”，通过调查、收集与分析，获得用户对数据库的信息要求、处理要求、安全性与完整性要求。</p><p>（2）调查步骤</p><p>【1】调查组织机构情况；</p><p>【2】调查各部门的业务活动情况；</p><p>【3】在协助业务活动的基础上，协助用户明确对新系统的各种要求；</p><p>【4】确定新系统的边界。</p><p>（3）方法</p><p>【1】跟班作业</p><p>【2】开调查会</p><p>【3】请专人介绍</p><p>【4】询问</p><p>【5】设计调查表请用户填写</p><p>【6】查阅记录</p><hr><h6 id="4、概念结构设计"><a href="#4、概念结构设计" class="headerlink" title="4、概念结构设计"></a>4、概念结构设计</h6><p>（1）主要特点</p><p>【1】能真实、充分地反映现实世界，包括事物和事物之间的联系，能满足用户对数据的处理要求，是现实世界的一个真是模型.</p><p>【2】易于理解，可以用它和不熟悉计算机的用户交换意见。</p><p>【3】易于更改，当应用环境和应用要求改变时容易对概念模型修改和扩充。</p><p>【4】易于向关系、网状、层次等各种数据模型转换。</p><p>（2）E-R模型与E-R图</p><p>E-R模型是用E-R土来描述现实世界的概念模型，包括实体、属性、实体之间的联系等。</p><p>E-R图提供了表示实体型、属性和联系的方法：</p><p>【1】实体型用矩形表示；</p><p>【2】属性用椭圆形表示；</p><p>【3】联系用菱形表示。</p><hr><h6 id="5、逻辑结构设计"><a href="#5、逻辑结构设计" class="headerlink" title="5、逻辑结构设计"></a>5、逻辑结构设计</h6><p>逻辑结构设计的任务就是把概念结构设计阶段设计好的基本E-R图转换为与选用数据库管理系统产品所支持的数据模型相符合的逻辑结构。</p><p>一个实体型转换为一个关系模式。</p><p>【1】一个1：1联系可以转换为一个独立的关系模式，也可以与任意一端对应的关系模式合并。</p><p>【2】一个1：n联系可以转换为一个独立的关系模式，也可以与n端对应的关系模式合并。</p><p>【3】一个n：m联系转换为一个关系模式。</p><p>【4】三个或三个以上实体间一个多元联系可以转换为一个关系模式。</p><p>【5】具有相同码的关系模式可以合并。</p><hr><h6 id="6、物理结构设计"><a href="#6、物理结构设计" class="headerlink" title="6、物理结构设计"></a>6、物理结构设计</h6><p>（1）确定数据库的物理结构；</p><p>（2）对物理结构进行评估。</p><hr><h2 id="第十章-数据库恢复技术"><a href="#第十章-数据库恢复技术" class="headerlink" title="第十章  数据库恢复技术"></a>第十章  数据库恢复技术</h2><h6 id="1、事物"><a href="#1、事物" class="headerlink" title="1、事物"></a>1、事物</h6><p>所谓事务是用户定义的一个数据库操作序列，这些操作要么全做，要么全不做，是一个不可分割的工作单位。</p><p>定义事务的语句一般有三条：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">begin</span> transaction;  <span class="operator">/</span><span class="operator">/</span> 代表事务的开始</span><br><span class="line"><span class="keyword">commit</span>;  <span class="operator">/</span><span class="operator">/</span> 提交事务的所有操作</span><br><span class="line"><span class="keyword">rollback</span>;  <span class="operator">/</span><span class="operator">/</span> 回滚，系统将事务中对数据库的所有已完成的操作全部撤销，回滚到事务开始时的状态</span><br></pre></td></tr></table></figure><hr><h6 id="2、事务的特性"><a href="#2、事务的特性" class="headerlink" title="2、事务的特性"></a>2、事务的特性</h6><p>（1）原子性</p><p>事务是数据库的逻辑工作单位，要么都做，要么都不做；</p><p>（2）一致性</p><p>事务的执行结构必须是使数据性一致状态变到另一个一致性状态。</p><p>（3）隔离性</p><p>一个事务的执行不能被其他事务干扰。</p><p>（4）持续性</p><p>一个事务一旦提交，他对数据库中数据的改变应该是永久的。</p><hr><h6 id="3、登录日志文件"><a href="#3、登录日志文件" class="headerlink" title="3、登录日志文件"></a>3、登录日志文件</h6><p>为保证数据库是可恢复的，登录日志文件时必须遵守两条原则：</p><p>（1）登录的次序严格按并发事务执行的时间次序。</p><p>（2）必须先写日志文件，后写数据库。</p><p>【关于（2）】如果先写了数据库修改，而在运行记录中没有登记这个修改，则以后就无法恢复这个修改了。如果先写日志，但没有修改数据库，按日志文件恢复时只不过多执行一次UNDO操作，并不会影响数据库的正确性。</p><hr><h2 id="第十一章-并发控制"><a href="#第十一章-并发控制" class="headerlink" title="第十一章 并发控制"></a>第十一章 并发控制</h2><p>事务可以一个一个地串行执行，即每个时刻只有一个事务运行。</p><p>在单处理机系统中，事务的并发执行实际上是这些并行事务的并行操作轮流交叉运行。</p><p>事务是并发控制的基本单位。为了保证事务的<strong>隔离性</strong>和<strong>一致性</strong>，数据库管理系统需要对并发操作进行正确调度。</p><h6 id="1、并发操作的数据不一致性"><a href="#1、并发操作的数据不一致性" class="headerlink" title="1、并发操作的数据不一致性"></a>1、并发操作的数据不一致性</h6><p>（1）丢失修改</p><p>两个事务T1和T2读入同一数据并修改，T2提交的结果破坏了T1提交的结果，导致T1的修改被丢失。<br>（2）不可重复读</p><p>事务T1读取数据后，事务T2执行更新操作，使T1无法再现前一次读取结果。</p><p>（3）读“脏”数据</p><p>事务T1修改某一数据并将其写回磁盘，事务T2读取同一数据后，T1由于某种原因被撤销，这时T1修改过的数据恢复原值，T2读到的数据就与数据库中的数据不一致，则T2读到的数据就为“脏”数据，即不正确的数据。</p><hr><h6 id="2、并发控制"><a href="#2、并发控制" class="headerlink" title="2、并发控制"></a>2、并发控制</h6><p>并发控制机制就是要用正确的方式调度并发操作，使一个用户事务的执行不受其他事物的干扰。</p><p>并发控制的主要技术有封锁、时间戳、乐观控制法和多版本并发控制等。</p><hr><h6 id="3、封锁"><a href="#3、封锁" class="headerlink" title="3、封锁"></a>3、封锁</h6><p>封锁是实现并发控制的一个非常重要的技术。基本的封锁类型有两种：</p><p><strong>（1）排它锁</strong></p><p>又称写锁。若事务T对数据对象A加上X锁，则只允许T读取和修改A，其他任何事务都不能再对A加任何类型的锁，直到T释放A上的锁为止。</p><p><strong>（2）共享锁</strong></p><p>又称读锁。若事务T对数据对象A加上S锁，则事务T可以读A但不能修改A，其他事务只能再对A加S锁，而不能加X锁，直到T释放A上的S锁为止。</p><hr><h6 id="4、封锁协议"><a href="#4、封锁协议" class="headerlink" title="4、封锁协议"></a>4、封锁协议</h6><p><strong>（1）一级封锁协议</strong></p><p>一级封锁协议是指，事务T在修改数据R之前必须先对其加X锁，直到事务结束才释放。</p><p>可防止丢失修改，并保证事务T是可恢复的。</p><p><strong>（2）二级封锁协议</strong></p><p>二级封锁协议是指，在一级封锁协议的基础上增加事务T在读取数据R之前必须先对其加S锁，读完后即可释放S锁。</p><p>进一步防止读“脏”数据。</p><p><strong>（3）三级封锁协议</strong></p><p>三级封锁协议是指，在一级封锁协议的基础上增加事务T在读取数据R之前必须先对其加S锁，直到事务结束才释放。</p><p>进一步防止不可重复读。</p><p>【*】三级协议的区别主要在于什么操作需要申请封锁，以及何时释放锁（即持锁时间）。</p><hr><h6 id="5、活锁和死锁"><a href="#5、活锁和死锁" class="headerlink" title="5、活锁和死锁"></a>5、活锁和死锁</h6><p>（1）活锁</p><p>活锁的情形：事务有可能永远等待。（事务未被批准而一直处于等待状态）</p><p>避免活锁的简单方法是采用先来先服务的策略。</p><p>（2）死锁</p><p>死锁的情形：多个事务之间形成互相等待的局面。</p><hr><h6 id="6、死锁的预防"><a href="#6、死锁的预防" class="headerlink" title="6、死锁的预防"></a>6、死锁的预防</h6><p><strong>（1）一次封锁法</strong></p><p>要求每个事务必须一次将所有要使用的数据全部加锁，否则就不能继续执行。</p><p>缺点：</p><p>【1】扩大了封锁的范围，降低了系统的并发度；</p><p>【2】不要求封锁的数据在执行过程中可能变成封锁对象，很难事先精确的确定每个事务所要封锁的数据对象。</p><p><strong>（2）顺序封锁法</strong></p><p>预先对数据对象规定一个封锁顺序，所有事物按这个顺序进行封锁。</p><p>缺点：</p><p>【1】封锁的数据对象极多，并且随数据的插入、删除等操作不断地变化，要维护这样的资源的封锁的顺序非常困难，成本很高。</p><p>【2】事务的封锁请求可以随事务的执行而动态的决定，很难事先确定每一个事物要封锁哪些对象，也就很难按照规定的顺序去施加封锁。</p><hr><h6 id="7、死锁的诊断和解除"><a href="#7、死锁的诊断和解除" class="headerlink" title="7、死锁的诊断和解除"></a>7、死锁的诊断和解除</h6><p>（1）诊断</p><p>【1】超时法：超过了规定时限，就认为发生了死锁。</p><p>【2】等待图法：事务的等待循序形成的有向图如果存在回路，则说明发生了死锁。</p><p>（2）解除</p><p>选择一个处理死锁代价最小的事务，将其撤销，释放此事务持有的所有锁，使其他事务得以继续运行下去。</p><hr><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这个年纪总是喜欢做一些无意义的事去强行拔高自己的存在，这个文档也就简化了一下书本，收录了一点个人理解和作业。虽然有“疑似”考卷的押题范围，但完全没有想法去为了那个做一份针对的文档。还是以学习新知识为重心吧，不要舍本逐末了。</p><p>不知道写些什么，就胡言乱语这么多吧。                                                                                                         ——By Alexie·Z·Yevich 2022.5.15</p>]]></content>
      
      
      <categories>
          
          <category> 我的大学 </category>
          
          <category> 大二下学期 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SQL </tag>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JavaWeb</title>
      <link href="/2022/05/09/JavaWeb/"/>
      <url>/2022/05/09/JavaWeb/</url>
      
        <content type="html"><![CDATA[<blockquote><p>写在前面：这篇文档旨在对于<a href="https://github.com/Lyfive/HnusterComputer/blob/main/JavaWeb/JavaWeb%E5%A4%8D%E4%B9%A0%E6%96%87%E6%A1%A3.md">LyFive的文档</a>进行一个补充（也就是仅自用的意思），我的更注重于详细的通俗易懂文字描述以及课后习题的解答，而他的主要是给大家画了流程图，方便大家了解体系结构。建议先看他那版后再来参阅我的OWO。</p><p>​                                                                                                                                                                       ——By Alexie-Z-Yevich 2022.5.9</p></blockquote><h4 id="第一章-Web应用开发简介"><a href="#第一章-Web应用开发简介" class="headerlink" title="第一章 Web应用开发简介"></a>第一章 Web应用开发简介</h4><h6 id="1、什么是C-x2F-S结构？什么是B-x2F-S结构？他们各有什么优缺点？"><a href="#1、什么是C-x2F-S结构？什么是B-x2F-S结构？他们各有什么优缺点？" class="headerlink" title="1、什么是C&#x2F;S结构？什么是B&#x2F;S结构？他们各有什么优缺点？"></a>1、什么是C&#x2F;S结构？什么是B&#x2F;S结构？他们各有什么优缺点？</h6><p>C&#x2F;S即客户端&#x2F;服务器结构，服务器常采用高性能的PC或工作站，并采用大型数据库；B&#x2F;S即浏览器&#x2F;服务器结构，客户端不需要开发任何用户界面，而统一采用浏览器，通过Web浏览器向Web服务器发送请求。</p><p>优缺点：</p><p>（1）<strong>C&#x2F;S结构开发成本高于B&#x2F;S结构</strong>，在C&#x2F;S结构中开发者需要对所有机型机型进行适配，而在B&#x2F;S结构中只需要兼容浏览器服务即可；</p><p>（2）C&#x2F;S结构的客户端负责与用于交互、收集用户信息、完成通过网络向服务器请求对数据库信息进行处理工作；B&#x2F;S结构的客户端把事务处理逻辑部分交给服务器处理，客户端只需要进行显示。对于<strong>复杂的功能</strong>来说，<strong>C&#x2F;S结构劣于B&#x2F;S结构</strong>，因为客户端程序庞大；但对于<strong>服务器负载较重</strong>，出现“崩溃”现象时，<strong>C&#x2F;S结构优于B&#x2F;S结构</strong>，因为数据能够得以保全。</p><p>（3）<strong>C&#x2F;S结构适用于专人使用</strong>的系统，<strong>安全性比较高</strong>；<strong>B&#x2F;S结构适用于多人使用</strong>，<strong>相对安全性低</strong>一些。</p><hr><h6 id="2、常见的C-x2F-S和B-x2F-S结构的例子"><a href="#2、常见的C-x2F-S和B-x2F-S结构的例子" class="headerlink" title="2、常见的C&#x2F;S和B&#x2F;S结构的例子"></a>2、常见的C&#x2F;S和B&#x2F;S结构的例子</h6><p>（1）下载的游戏—–网页游戏；</p><p>（2）QQ—–QQ邮箱；</p><p>（3）企业微信—–教务网。</p><p>（简单理解：一切网站访问的都属于B&#x2F;S结构，一切APP、客户端访问的都属于C&#x2F;S结构）</p><hr><h6 id="3、Web客户端技术有哪些？Web服务器端技术有哪些？"><a href="#3、Web客户端技术有哪些？Web服务器端技术有哪些？" class="headerlink" title="3、Web客户端技术有哪些？Web服务器端技术有哪些？"></a>3、Web客户端技术有哪些？Web服务器端技术有哪些？</h6><p>客户端技术：</p><p>（1）HTML；（2）CSS；（3）Flash；（4）客户端脚本技术（JavaScript、TypeScript等）</p><p>服务器端技术：</p><p>（1）CGI；（2）ASP；（3）PHP；（4）ASP.NET；（5）JSP</p><hr><h4 id="第二章-网页前端开发基础"><a href="#第二章-网页前端开发基础" class="headerlink" title="第二章 网页前端开发基础"></a>第二章 网页前端开发基础</h4><h6 id="1、HTML由哪几部分组成？"><a href="#1、HTML由哪几部分组成？" class="headerlink" title="1、HTML由哪几部分组成？"></a>1、HTML由哪几部分组成？</h6><p>HTML文档主要由4个主要标记组成。</p><ul><li><p>&lt;html&gt;标记：是html文件的开头，html页面的所有标记都要放在<html></html>标记<br>中，此标记没有实质性的功能。但是HTML文件不可缺少的部分。</p></li><li><p>&lt;head&gt;标记：是HTML文件的头标记，作用是放置HTML文件的信息。如：标题、css样式代码等。</p></li><li><p>&lt;title&gt;标记：网页标题，放置在head内。</p></li><li><p>&lt;body&gt;标记：是HTML页面的主体标记。页面的所有内容都定义在body标记内。</p></li></ul><hr><h6 id="2、HTML有哪些常用标记？都有什么作用？"><a href="#2、HTML有哪些常用标记？都有什么作用？" class="headerlink" title="2、HTML有哪些常用标记？都有什么作用？"></a>2、HTML有哪些常用标记？都有什么作用？</h6><ul><li>这个在LyFive的文档中有详细的描述，这里就不过多赘述。</li></ul><hr><h6 id="3、-lt-input-gt-标记有几种输入类型？"><a href="#3、-lt-input-gt-标记有几种输入类型？" class="headerlink" title="3、&lt;input&gt;标记有几种输入类型？"></a>3、&lt;input&gt;标记有几种输入类型？</h6><ul><li>text文本框</li><li>password密码域</li><li>file文件域</li><li>radio单选按钮</li><li>checkbox复选按钮</li><li>submit提交按钮</li><li>reset重置按钮</li><li>button普通按钮</li><li>hidden隐藏域</li><li>image图像域</li></ul><hr><h6 id="4、什么是CSS？CSS有哪些效果？"><a href="#4、什么是CSS？CSS有哪些效果？" class="headerlink" title="4、什么是CSS？CSS有哪些效果？"></a>4、什么是CSS？CSS有哪些效果？</h6><p>CSS（层叠样式表）是W3C协会为弥补HTML在显示属性设定上的不足而制定的一套扩展样式标准。通过引入CSS可以对HTML文件进行美化，不必要引入过多资源，加快页面访问速度。</p><hr><h6 id="5、如何为一个HTML页面添加CSS效果？"><a href="#5、如何为一个HTML页面添加CSS效果？" class="headerlink" title="5、如何为一个HTML页面添加CSS效果？"></a>5、如何为一个HTML页面添加CSS效果？</h6><ul><li>内样式：直接写在HTML标签内，通过style&#x3D;“”引入CSS样式。</li><li>内嵌式：在页面中使用&lt;style&gt;标签，将CSS代码包含在其中。</li><li>链接式：将CSS代码写在*.css文件里，在HTML中使用&lt;link href&#x3D;’*.css’&gt;链接外部文件。（href：CSS文档的绝对或相对路径；rel：定义外部文档与调用文档的关系）</li><li>导入式：@import 是 CSS 2.1 特有的。</li></ul><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--导入式引入外部样式--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">style</span>&gt;</span><span class="language-css"></span></span><br><span class="line"><span class="language-css">  <span class="keyword">@import</span> url(<span class="string">&quot;css/style.css&quot;</span>);</span></span><br><span class="line"><span class="language-css"></span><span class="tag">&lt;/<span class="name">style</span>&gt;</span></span><br></pre></td></tr></table></figure><p><strong>链接式与导入式的区别：</strong>首先 link 和 import 语法结构不同，前者 <link> 是 html 标签，只能放入 html 源代码中使用，后者 import 可看作 css 样式，作用是引入 css 样式功能。import 在 html 使用时需要 &lt;style type&#x3D;”text&#x2F;css”&gt; 标签，同时可以直接“@import url(CSS文件路径地址);” 放入 css 文件或 css 代码里引入其他 css 文件。</p><hr><h4 id="第三章-JavaScript脚本语言"><a href="#第三章-JavaScript脚本语言" class="headerlink" title="第三章 JavaScript脚本语言"></a>第三章 JavaScript脚本语言</h4><h6 id="1、什么是JavaScript？JavaScript和Java是什么关系？"><a href="#1、什么是JavaScript？JavaScript和Java是什么关系？" class="headerlink" title="1、什么是JavaScript？JavaScript和Java是什么关系？"></a>1、什么是JavaScript？JavaScript和Java是什么关系？</h6><p>JavaScript是一种基于对象和事件驱动并具有安全和性能的解释性脚本语言，在Web应用中得到了非常广泛的应用。他不需要进行编译，而是直接嵌入在http页面中。js常用来进行数据验证、控制浏览器以及生成时钟、日历和时间戳文档等。</p><p>JavaScript与Java除了语法有一些相似之外，两者毫不相关。</p><p>JS具有<strong>解释性</strong>、<strong>基于对象</strong>、<strong>事件驱动</strong>、<strong>安全性</strong>、<strong>跨平台</strong>的特点。</p><hr><h6 id="2、JavaScript脚本如何调用？JavaScript有哪些常用的属性和方法？"><a href="#2、JavaScript脚本如何调用？JavaScript有哪些常用的属性和方法？" class="headerlink" title="2、JavaScript脚本如何调用？JavaScript有哪些常用的属性和方法？"></a>2、JavaScript脚本如何调用？JavaScript有哪些常用的属性和方法？</h6><ul><li>直接嵌入：在HTML代码中直接使用&lt;script&gt;标签引入JS代码。</li><li>链接：在&lt;script&gt;标签中使用src属性引入外部的*.js文件。</li></ul><p>常用属性和方法直接参考<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript">JS的官方文档</a>。选择写几个即可。</p><hr><h6 id="3、什么是Ajax？如何用Ajax实时更新前台页面数据？"><a href="#3、什么是Ajax？如何用Ajax实时更新前台页面数据？" class="headerlink" title="3、什么是Ajax？如何用Ajax实时更新前台页面数据？"></a>3、什么是Ajax？如何用Ajax实时更新前台页面数据？</h6><p>Ajax的意思是异步的JavaScript和xml，它是js、xml、css、dom等多种已有技术的组合，可以实现客户端的异步请求操作，进而不需要刷新页面的情况下与服务器进行通信，减少用户的等待时间，减轻服务器和带宽的负担，提供更好的服务响应。</p><p>Ajax接收前端发来的信息，通过XMLHttpRequest对象向后端发送请求，同时接收response对象，将它部署到前端页面。</p><hr><h4 id="第五章-走进JSP"><a href="#第五章-走进JSP" class="headerlink" title="第五章 走进JSP"></a>第五章 走进JSP</h4><h6 id="1、什么是JSP？"><a href="#1、什么是JSP？" class="headerlink" title="1、什么是JSP？"></a>1、什么是JSP？</h6><p>JSP是在HTML代码中嵌入Java代码片段和JSP标签，构成了JSP网页。主要由指令标签、HTML语句、注释、嵌入Java代码、JSP动作标签等5个元素组成。</p><hr><h6 id="2、JSP有哪些指令标签？"><a href="#2、JSP有哪些指令标签？" class="headerlink" title="2、JSP有哪些指令标签？"></a>2、JSP有哪些指令标签？</h6><ul><li><p>page指令：定义整个JSP页面的相关属性，这些属性会在解析成Servlet时转换为对应的Java程序代<br>码。</p><ul><li><p>格式： &lt;%@ page attr1 &#x3D; “value1” attr2 &#x3D; “value2” %&gt;</p></li><li><p>属性： import 导包，pageEncoding 文件编码，contentType 设置页面文件类型<br>（如”text&#x2F;html”)，include 导入其他文件(和CPP的include基本一致)</p></li></ul></li><li><p>嵌入Java代码</p><ul><li>格式 &lt;% JavaCode %&gt;</li></ul></li><li><p>声明</p><ul><li><p>格式 &lt;%! JavaCode %&gt;</p></li><li><p>声明全局变量： &lt;%! long startTime &#x3D; System.nanoTime(); %&gt;</p></li><li><p>声明全局方法： &lt;%! int Max(int a,int b){return a &gt; b ? a : b ;} %&gt;</p></li></ul></li><li><p>JSP表达式</p><ul><li>格式 &lt;%&#x3D; 表达式 %&gt;</li><li>例如： &lt;%&#x3D; 2*Math.PI %&gt;会把2Pi的结果直接输出在页面上，类型为字符串</li></ul></li><li><p>注释</p><ul><li>HTML注释： <!-- 注释内容 --></li><li>JSP注释： &lt;%– 注释内容 –%&gt;</li><li>动态注释： 把JSP代码嵌入到HTL注释内，如 <!-- <%= new Date() %> --></li><li>JSP内部注释和Java注释一致。 &#x2F;&#x2F; 和 &#x2F;* *&#x2F;</li></ul></li></ul><hr><h6 id="3、如何在JSP中运行Java程序？"><a href="#3、如何在JSP中运行Java程序？" class="headerlink" title="3、如何在JSP中运行Java程序？"></a>3、如何在JSP中运行Java程序？</h6><p>见上体的标签。</p><hr><h6 id="4、什么是request对象？什么是response对象？什么是session对象？什么是application对象？这些对象有哪些共同点和不同点？"><a href="#4、什么是request对象？什么是response对象？什么是session对象？什么是application对象？这些对象有哪些共同点和不同点？" class="headerlink" title="4、什么是request对象？什么是response对象？什么是session对象？什么是application对象？这些对象有哪些共同点和不同点？"></a>4、什么是request对象？什么是response对象？什么是session对象？什么是application对象？这些对象有哪些共同点和不同点？</h6><ul><li>request对象：是javax.servlet.http.HTTPServletRequest类型的对象。代表了客户端的请求信息，主要用于接收HTTP传送到服务器端的数据（包括头信息Header、系统信息、请求方式Methods以及请求参数Params等）。作用域为一次请求。</li><li>response对象：代表的是对客户端的响应，主要是将JSP容器处理过的对象传回客户端。作用域为只在JSP页面内有效。</li><li>session对象：由服务器自动创建的与用户请求相关的对象。一个用户对应一个session对象，用于保存用户的信息，追踪用户的操作状态。（内部使用Map类来保存数据）</li><li>application对象：可将信息保存在服务器中直到服务器关闭（类似于缓存区？），相比于session对象，application对象的生命周期更长，类似于系统的“全局变量”。</li></ul><p>共同点：</p><p>都是asp中的作用域。（作用域详细的说就是 “信息共享的范围”，也就是一个信息能够在多大的范围内有效）</p><p>不同点：</p><p>作用域大小各不相同，作用对象也不同。request主要作用于请求；response作用于JSP页面；session和application作用于用户，但是session与用户是一对一关系，而application与用户是一对多关系。</p><p>request、response以协议为基础，为此他们面向的是参数Parameter、头信息Header；sesession、application以Attribute属性为基础，为此属性的增删改查基本都一致。</p><p><strong>扩展：</strong>cookie是小段的文本信息，通过cookie可以标识用户身份、记录用户名及密码、追踪重复用户。cookie是由服务端生成的。</p><p>cookie和session的区别：</p><p>1、cookie存储在客户端，SESSION存储在服务器；</p><p>2、cookie机制保持连接，通信时压力在客户端；session机制保持连接，通信时压力在服务器；</p><p>3、session机制更安全，因为cookie存放在客户端，容易被窃取。但是session机制依赖于sessionID,而sessionID保存在cookie中，一旦客户端禁用了cookie，session也将失效；</p><p>4、cookie是以文本的形式存储在客户端，存储量有限(&lt;&#x3D;4KB)；session可以无限量地往里面添加内容；</p><p>5、cookie支持跨域名访问，session不支持跨域名访问；</p><p>6、cookie可以设置为长期有效，而session会随会话窗口关闭而失效。</p><hr><h4 id="第六章-Servlet技术"><a href="#第六章-Servlet技术" class="headerlink" title="第六章 Servlet技术"></a>第六章 Servlet技术</h4><h6 id="1、web-xml文件是做什么用的？"><a href="#1、web-xml文件是做什么用的？" class="headerlink" title="1、web.xml文件是做什么用的？"></a>1、web.xml文件是做什么用的？</h6><p>web.xml用来配置Servlet，使Servlet对象能够正常运行。（告知web容器哪一个请求调用哪一个Servlet对象处理，对Servlet起到一个注册的作用）</p><hr><h6 id="2、Servlet都有哪些接口？这些接口都有什么作用？"><a href="#2、Servlet都有哪些接口？这些接口都有什么作用？" class="headerlink" title="2、Servlet都有哪些接口？这些接口都有什么作用？"></a>2、Servlet都有哪些接口？这些接口都有什么作用？</h6><ul><li>Servlet接口：Servlet运行需要Servlet容器的支持，servlet容器通过调用Servlet对象提供了标准的API接口，对请求进行处理。简单来说就是Servet的生命周期，包含init初始化、service处理请求、getServlet config获取配置信息、getServletInfo返回配置信息、destory销毁对象五个过程。</li><li>ServletConfig接口：封装Servlet的配置信息，每个Servlet都有且只有一个ServletConfig对象。</li><li>HttpServletRequest接口：继承于javax.servlet.ServletRequest接口，用于接收前端传来的的基本信息（路径、参数、类型、方法等）。</li><li>HttpservletResponse接口：继承于javax.servlet.ServletResponse接口，用于向前端发送后端的处理信息（cookie、状态码等）。</li></ul><hr><h6 id="3、如何指定项目默认页面？"><a href="#3、如何指定项目默认页面？" class="headerlink" title="3、如何指定项目默认页面？"></a>3、如何指定项目默认页面？</h6><p>在web.xml中对servlet进行配置，通过配置&lt;servlet-mapping&gt;指定项目默认页面。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;servlet&gt;</span><br><span class="line">&lt;servlet-name&gt;Servlet&lt;/servlet-name&gt;  <span class="comment">// 设置Servlet名字</span></span><br><span class="line">   &lt;servlet-class&gt;com.*.Servlet&lt;/servlet-class&gt;  <span class="comment">// 导入class类文件</span></span><br><span class="line">&lt;/servlet&gt;</span><br><span class="line">&lt;servlet-mapping&gt;</span><br><span class="line">        &lt;servlet-name&gt;Servlet&lt;/servlet-name&gt;  <span class="comment">// 找到映射对象</span></span><br><span class="line">        &lt;url-parttern&gt;/&lt;/url-parttern&gt;  <span class="comment">// 设置映射地址</span></span><br><span class="line">&lt;/servlet-mapping&gt;</span><br></pre></td></tr></table></figure><hr><h6 id="4、如何使用过滤器？过滤器中有哪些方法？它们运行的顺序是什么？"><a href="#4、如何使用过滤器？过滤器中有哪些方法？它们运行的顺序是什么？" class="headerlink" title="4、如何使用过滤器？过滤器中有哪些方法？它们运行的顺序是什么？"></a>4、如何使用过滤器？过滤器中有哪些方法？它们运行的顺序是什么？</h6><ul><li>在web.xml中配置&lt;filter&gt;标签以及&lt;filter-mapping&gt;标签配置过滤器。</li><li>过滤器中的方法：init初始化、doFilter执行过滤操作、destory销毁（主要方法）。</li><li>运行顺序：初始化-&gt;执行-&gt;销毁，但是注意：过滤器之间同样有优先顺序，在web.xml上面的配置先于下面的配置执行，因此需要注意过滤器把其他过滤器给过滤掉了。</li></ul><hr><h4 id="第七章-数据库技术"><a href="#第七章-数据库技术" class="headerlink" title="第七章 数据库技术"></a>第七章 数据库技术</h4><h6 id="1、简述JDBC连接数据库的基本步骤。"><a href="#1、简述JDBC连接数据库的基本步骤。" class="headerlink" title="1、简述JDBC连接数据库的基本步骤。"></a>1、简述JDBC连接数据库的基本步骤。</h6><ul><li>导入JDBC驱动；</li><li>输入数据库信息连接数据库；</li><li>预载SQL语句；</li><li>更新数据库。（这个是老师上课讲的，没有照着书本来）</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Class.forName(<span class="string">&quot;com.mysql.jdbc.Driver&quot;</span>);  <span class="comment">// 导入驱动（需要try/catch语句包裹）</span></span><br><span class="line"><span class="type">Connection</span> <span class="variable">connection</span> <span class="operator">=</span> DriverManager.getConnection(<span class="string">&quot;jdbc:mysql://127.0.0.1:3306/MysqlDatabase&quot;</span>, <span class="string">&quot;username&quot;</span>, <span class="string">&quot;password&quot;</span>);</span><br><span class="line"><span class="type">PreparedStatement</span> <span class="variable">preparedStatement</span> <span class="operator">=</span> connection.preparedStatement(<span class="string">&quot;select * from MysqlTable&quot;</span>);  <span class="comment">// 动态加载将预载和更新融为一步。</span></span><br></pre></td></tr></table></figure><hr><h6 id="2、执行动态SQL语句的接口是什么？-amp-3、JDBC提供的两种实现数据查询的方法是什么？"><a href="#2、执行动态SQL语句的接口是什么？-amp-3、JDBC提供的两种实现数据查询的方法是什么？" class="headerlink" title="2、执行动态SQL语句的接口是什么？&amp; 3、JDBC提供的两种实现数据查询的方法是什么？"></a>2、执行动态SQL语句的接口是什么？&amp; 3、JDBC提供的两种实现数据查询的方法是什么？</h6><ul><li>Statement接口执行静态SQL语句；</li><li>PreparedStatement接口执行动态SQL语句。</li></ul><hr><h6 id="4、Statement类中的两个方法：executeQuery-和executeUpdate-，两者的区别是什么？"><a href="#4、Statement类中的两个方法：executeQuery-和executeUpdate-，两者的区别是什么？" class="headerlink" title="4、Statement类中的两个方法：executeQuery()和executeUpdate()，两者的区别是什么？"></a>4、Statement类中的两个方法：executeQuery()和executeUpdate()，两者的区别是什么？</h6><ul><li>executeUpdate()：返回int类型数值，代表影响数据库记录的条数；（对于增删改操作）</li><li>executeQuery()：返回ResultSet类型的结果集，包含了返回的所有信息。（对应查操作）</li></ul><hr><h4 id="第九章-Spring-MVC框架"><a href="#第九章-Spring-MVC框架" class="headerlink" title="第九章 Spring MVC框架"></a>第九章 Spring MVC框架</h4><h6 id="1、MVC模式由哪几部分组成？"><a href="#1、MVC模式由哪几部分组成？" class="headerlink" title="1、MVC模式由哪几部分组成？"></a>1、MVC模式由哪几部分组成？</h6><p>MVC（Model-View-Controller，模型-视图-控制器）是一个存在服务器表达层的模型。</p><hr><h6 id="2、WEB-INF目录下的资源有什么特点？需要如何访问？"><a href="#2、WEB-INF目录下的资源有什么特点？需要如何访问？" class="headerlink" title="2、WEB-INF目录下的资源有什么特点？需要如何访问？"></a>2、WEB-INF目录下的资源有什么特点？需要如何访问？</h6><p>WEB-INF目录下存放安全性较高的资源文件，不能直接通过浏览器直接访问的，需要通过服务器来访问。在外部通过配置控制层映射访问文件。</p><hr><h6 id="3、Spring-MVC的拦截器有哪些方法？这些方法各有什么特点？"><a href="#3、Spring-MVC的拦截器有哪些方法？这些方法各有什么特点？" class="headerlink" title="3、Spring MVC的拦截器有哪些方法？这些方法各有什么特点？"></a>3、Spring MVC的拦截器有哪些方法？这些方法各有什么特点？</h6><ul><li><p>HanderInterceptor接口：</p><ul><li>preHandle：对请求进行判断，决定程序是否继续执行；</li><li>postHandle：同意处理返回的视图；</li><li>agterCompletion：进行统一的异常或者日志处理操作。</li></ul></li><li><p>WebRequestInterceptor接口：</p><ul><li><p>preHandle：方法的前期准备；</p></li><li><p>postHandle：改变ModelMap中的属性来改变Controller最终返回的Model模型；</p></li><li><p>agterCompletion：将WebRequest参数中不需要的准备资源释放掉。</p></li></ul></li></ul><hr><h4 id="第十一章-Spring框架"><a href="#第十一章-Spring框架" class="headerlink" title="第十一章 Spring框架"></a>第十一章 Spring框架</h4><h6 id="1、什么是IoC注入？如何使用Spring框架进行注入？"><a href="#1、什么是IoC注入？如何使用Spring框架进行注入？" class="headerlink" title="1、什么是IoC注入？如何使用Spring框架进行注入？"></a>1、什么是IoC注入？如何使用Spring框架进行注入？</h6><p>IoC（控制反转）和DI密不可分，IoC是在设计的角度看Spring，DI是在Sping的角度看代码，角度不同但是含义一样：依赖注入–将原本实例化的功能从开发者给到了Spring。</p><p>注入方法：</p><ul><li>接口注入：实现容器所规定的接口，使程序代码和容器的API绑定在一起；</li><li>Setter注入：基于JavaBean的Setter方法为属性赋值；</li><li>构造器注入：基于构造方法为属性赋值，在实例化对象的同时完成了属性的初始化。</li></ul><hr><h6 id="2、什么是AOP？"><a href="#2、什么是AOP？" class="headerlink" title="2、什么是AOP？"></a>2、什么是AOP？</h6><p>AOP是一种思想，即面向切面编程。基于Java的代理机制，使方法与类分离。</p><hr><h6 id="3、Spring框架有哪些项目开发优势？"><a href="#3、Spring框架有哪些项目开发优势？" class="headerlink" title="3、Spring框架有哪些项目开发优势？"></a>3、Spring框架有哪些项目开发优势？</h6><p>1.低侵入式设计，重复代码量少；</p><p>2.独立于各种应用服务器，基于Spring框架的应用，可以真正实现一个代码，多平台复用；</p><p>3.Spring的DI机制降低了业务对象替换的复杂性，提高了组件之间的解耦；</p><p>4.Spring的AOP支持允许将一些通用任务如安全、事务、日志等进行集中式管理，从而提供了更好的复用；</p><p>5.Spring的ORM和DAO提供了与第三方持久层框架的良好整合，并简化了底层的数据库访问；</p><p>6.Spring并不强制应用完全依赖于Spring，开发者可自由选用Spring框架的部分或全部。</p><hr><h4 id="第十二章-SSM框架整合应用"><a href="#第十二章-SSM框架整合应用" class="headerlink" title="第十二章 SSM框架整合应用"></a>第十二章 SSM框架整合应用</h4><h6 id="什么是SSM？"><a href="#什么是SSM？" class="headerlink" title="什么是SSM？"></a>什么是SSM？</h6><p>SSM（Spring+SpringMVC+MyBatis）框架集由Spring、MyBatis两个开源框架整合而成（SpringMVC是Spring中的部分内容），常作为数据源较简单的web项目的框架。</p><p><strong>Spring</strong><br>Spring就像是整个项目中装配bean的大工厂，在配置文件中可以指定使用特定的参数去调用实体类的构造方法来实例化对象。也可以称之为项目中的粘合剂。</p><p>Spring的核心思想是IoC（控制反转），即不再需要程序员去显式地 new 一个对象，而是让Spring框架帮你来完成这一切。</p><p><strong>SpringMVC</strong><br>SpringMVC在项目中拦截用户请求，它的核心Servlet即DispatcherServlet承担中介或是前台这样的职责，将用户请求通过HandlerMapping去匹配Controller，Controller就是具体对应请求所执行的操作。SpringMVC相当于SSH框架中struts。</p><p><strong>Mybatis</strong><br>mybatis是对jdbc的封装，它让数据库底层操作变的透明。mybatis的操作都是围绕一个sqlSessionFactory实例展开的。mybatis通过配置文件关联到各实体类的Mapper文件，Mapper文件中配置了每个类对数据库所需进行的sql语句映射。在每次与数据库交互时，通过sqlSessionFactory拿到一个sqlSession，再执行sql命令。</p>]]></content>
      
      
      <categories>
          
          <category> 我的大学 </category>
          
          <category> 大二下学期 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> JavaWeb </tag>
            
            <tag> 前后端技术 </tag>
            
            <tag> Vue </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
